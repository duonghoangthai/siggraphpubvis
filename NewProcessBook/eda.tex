We expect our raw data to require a substantial cleanup process. So far we have collected all the SIGGRAPH papers's pdf files from 2002 to 2015, totaling 17GB of data. These pdf files will be converted to text format, from which we will extract from each paper its title, authors and their affiliations, references and keywords. The extraction process is done using a combination of homemade Python scripts and opensource tools such as \href{http://aye.comp.nus.edu.sg/parsCit/}{ParsCit}.

Meaningful keyword extraction is the most difficult step of the extraction process. Most papers provide a set of "keywords" after the abstract but in our experience, these keywords are not meaningful enough: in any given year, most keywords are used by only one paper. We are looking into using an auto-summarizing tools for this step. Because of the uncertainty of keyword extraction, all features that require keywords will be optional.

We have done cursory testing of our tools and they seemed to be able to extract the required information with high accuracy, thanks to the uniformity in format of the papers. There is still some chance that noise will show up in the extracted data, in which case some post-process cleaning has to be done. We will finally need to remove all non-SIGGRAPH papers from the list of references to make our data more self-contained and easier to work with.

Since our data is highly relational, we plan to store it in an SQL database and query the data with Javascript. At the moment \href{https://github.com/kripken/sql.js/}{sql.js} and \href{https://github.com/mapbox/node-sqlite3}{node-sqlite3} seem to be promising candidates. Tentatively, there will be different tables, one for each of the following: papers, authors, institutions, keywords. Each entry in a table will have necessary fields, for example a paper will contain links to its authors and keywords, an author entry will have links back to his or her papers, and (optionally) links to the institution where he/she worked when a paper was published.

An alternative design is to flatten all the SQL tables into JSON files and load those instead. The SQL approach allows us to not having to load everything into memory at once, perhaps at the cost of more processing time each time users change their query/filter of the data. It is not yet clear to us how big the data will be, and which one of the two approaches will work better.

Our data acquisition and processing pipeline is as follows:
\begin{itemize}
    \item We start by downloading all SIGGRAPH publications (in PDF format) since 2002 from the ACM Digital Library. 
    \item Download BibTeX files (in XML format) for all SIGGRAPH and TOG papers from the Digital Bibliographic Library Browser
    \item Use a PDF processing tool to perform OCR and convert all the PDF files to TXT.
    \item Based on the TXT files, use ParsCit to extract the title and abstract from each paper.
    \item Use a homegrown tool (written in Python) to extract the list of references from each paper.
    \item Use another homegrown tool (in Python) to query Google Scholar to get the number of citations for all papers. This step is needed because we want to account for citations from non-SIGGRAPH papers as well.
    \item To extract the keywords, we use a Web service called Alchemy API (from IBM). The keywords returned by this tool will be combined with the keywords extracted directly from each paper's Keywords section.
    \item Finally we use a Python script to combine all the extracted information into a data structure in memory, from which we write several JSON files ready to be used by our Vis scripts.
\end{itemize}

At the moment, we have finished extracting all the essential information (title, author, year, references, citation count, DOI link) from our paper database, and produced working JSON files that have been used in our prototype. Below is an excerpt from our main JSON file:

\begin{lstlisting}
"2002": [
{
    "authors": [
    "Jeffrey Smith", 
    "Jessica K. Hodgins", 
    "Irving Oppenheim", 
    "Andrew P. Witkin"
    ], 
    "cited_by": [
    1349, 
    1384, 
    1543, 
    1752, 
    1704, 
    1846
    ], 
    "id": 69, 
    "link": "http://doi.acm.org/10.1145/566654.566580", 
    "references": [], 
    "title": "Creating models of truss structures with optimization", 
    "year": "2002"
}, 
{
    "authors": [
    "Timothy J. Purcell", 
    "Ian Buck", 
    "William R. Mark", 
    "Pat Hanrahan"
    ], 
    "cited_by": [
    163, 
    124, 
    134, 
    93, 
    120, 
    190
    ], 
    "id": 63, 
    "link": "http://doi.acm.org/10.1145/566654.566640", 
    "references": [], 
    "title": "Ray tracing on programmable graphics hardware", 
    "year": "2002"
}, 
\end{lstlisting}

This database will be updated once the keyword extraction step finishes, in at most two days, at which point there will be no data gathering tasks left. Compared to what was written in the proposal, it turned out that extracting the affiliation information for the authors from the paper texts is too difficult, hence we have decided to drop the Institution view from the project.