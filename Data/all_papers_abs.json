[
    {
        "abstract": "Geometric transformations are most commonly represented as square matrices in computer graphics. Following simple geometric arguments we derive a natural and geometrically meaningful definition of scalar multiples and a commutative addition of transformations based on the matrix representation, given that the matrices have no negative real eigenvalues. Together, these operations allow the linear combination of transformations. This provides the ability to create weighted combination of transformations, interpolate between transformations, and to construct or use arbitrary transformations in a structure similar to a basis of a vector space. These basic techniques are useful for synthesis and analysis of motions or animations. Animations through a set of key transformations are generated using standard techniques such as subdivision curves. For analysis and progressive compression a PCA can be applied to sequences of transformations. We describe an implementation of the techniques that enables an easy-to-use and transparent way of dealing with geometric transformations in graphics software. We compare and relate our approach to other techniques such as matrix decomposition and quaternion interpolation. ", 
        "id": 0, 
        "title": "Linear combination of transformations."
    }, 
    {
        "abstract": "This paper presents an example-based method for calculating skeleton-driven body deformations. Our example data consists of range scans of a human body in a variety of poses. Using markers captured during range scanning, we construct a kinematic skeleton and identify the pose of each scan. We then construct a mutually consistent parameterization of all the scans using a posable subdivision surface template. The detail deformations are represented as displacements from this surface, and holes are filled smoothly within the displacement maps. Finally, we combine the range scans using k-nearest neighbor interpolation in pose space. We demonstrate results for a human upper body with controllable pose, kinematics, and underlying surface shape. ", 
        "id": 1, 
        "title": "Articulated body deformation from range scan data."
    }, 
    {
        "abstract": "We present a novel technique, both flexible and efficient, for interactive remeshing of irregular geometry. First, the original (arbitrary genus) mesh is substituted by a series of 2D maps in parameter space. Using these maps, our algorithm is then able to take advantage of established signal processing and halftoning tools that offer real-time interaction and intricate control. The user can easily combine these maps to create a control map  a map which controls the sampling density over the surface patch. This map is then sampled at interactive rates allowing the user to easily design a tailored re-sampling. Once this sampling is complete, a Delaunay triangulation and fast optimization are performed to perfect the final mesh. As a result, our remeshing technique is extremely versatile and general, being able to produce arbitrarily complex meshes with a variety of properties including: uniformity, regularity, semi-regularity, curvature sensitive resampling, and feature preservation. We provide a high level of control over the sampling distribution allowing the user to interactively custom design the mesh based on their requirements thereby increasing their productivity in creating a wide variety of meshes.", 
        "id": 2, 
        "title": "Interactive geometry remeshing."
    }, 
    {
        "abstract": "", 
        "id": 3, 
        "title": "Topology-reducing surface simplification using a discrete solid representation."
    }, 
    {
        "abstract": "There are many applications that demand large quantities of natural looking motion. It is difficult to synthesize motion that looks natural, particularly when it is people who must move. In this paper, we present a framework that generates human motions by cutting and pasting motion capture data. Selecting a collection of clips that yields an acceptable motion is a combinatorial problem that we manage as a randomized search of a hierarchy of graphs. This approach can generate motion sequences that satisfy a variety of constraints automatically. The motions are smooth and human-looking. They are generated in real time so that we can author complex motions interactively. The algorithm generates multiple motions that satisfy a given set of constraints, allowing a variety of choices for the animator. It can easily synthesize multiple motions that interact with each other using constraints. This framework allows the extensive re-use of motion capture data for new purposes. ", 
        "id": 4, 
        "title": "Interactive motion generation from examples."
    }, 
    {
        "abstract": "", 
        "id": 5, 
        "title": "Steerable illumination textures."
    }, 
    {
        "abstract": "We introduce Object-Based Image Editing (OBIE) for real-time animation and manipulation of static digital photographs. Individual image objects (such as an arm or nose, Figure 1) are selected, scaled, stretched, bent, warped or even deleted (with automatic hole filling) - at the object, rather than the pixel level - using simple gesture motions with a mouse. OBIE gives the user direct, local control over object shape, size, and placement while dramatically reducing the time required to perform image editing tasks. Object selection is performed by manually collecting (subobject) regions detected by a watershed algorithm. Objects are tessellated into a triangular mesh, allowing shape modification to be performed in real time using OpenGL's texture mapping hardware. Through the use of anchor points, the user is able to interactively perform editing operations on a whole object, or just part(s) of an object - including moving, scaling, rotating, stretching, bending, and deleting. Indirect manipulation of object shape is also provided through the use of sliders and Bezier curves. Holes created by movement are filled in real-time based on surrounding texture. When objects stretch or scale, we provide a method for preserving texture granularity or scale. We also present a texture brush, which allows the user to \"paint\" texture into different parts of an image, using existing image texture(s). OBIE allows the user to perform interactive, high-level editing of image objects in a few seconds to a few ten's of seconds ", 
        "id": 6, 
        "title": "Object-based image editing."
    }, 
    {
        "abstract": "", 
        "id": 7, 
        "title": "Ordered and quantum treemaps: Making effective use of 2D space to display hierarchies."
    }, 
    {
        "abstract": "Texturing using a set of two dimensional image maps is an established and widespread practice. However, it has many limitations. Parameterizing a model in texture space can be very difficult, particularly with representations such as implicit surfaces, subdivision surfaces, and very dense or detailed polygonal meshes. This paper proposes the use of a new kind of texture based on an octree, which needs no parameterization other than the surface itself, and yet has similar storage requirements to 2D maps. In addition, it offers adaptive detail, regular sampling over the surface, and continuity across surface boundaries. The paper addresses texture creation, painting, storage, processing, and rendering with octree textures. ", 
        "id": 8, 
        "title": "Octree textures."
    }, 
    {
        "abstract": "Cutting and pasting to combine different elements into a common structure are widely used operations that have been successfully adapted to many media types. Surface design could also benefit from the availability of a general, robust, and efficient cut-andpaste tool, especially during the initial stages of design when a large space of alternatives needs to be explored. Techniques to support cut-and-paste operations for surfaces have been proposed in the past, but have been of limited usefulness due to constraints on the type of shapes supported and the lack of real-time interaction. In this paper, we describe a set of algorithms based on multiresolution subdivision surfaces that perform at interactive rates and enable intuitive cut-and-paste operations. ", 
        "id": 9, 
        "title": "Cut-and-paste editing of multiresolution surfaces."
    }, 
    {
        "abstract": "The ability to learn is a potentially compelling and important quality for interactive synthetic characters. To that end, we describe a practical approach to real-time learning for synthetic characters. Our implementation is grounded in the techniques of reinforcement learning and informed by insights from animal training. It simplies the learning task for characters by (a) enabling them to take advantage of predictable regularities in their world, (b) allowing them to make maximal use of any supervisory signals, and (c) making them easy to train by humans. We built an autonomous animated dog that can be trained with a technique used to train real dogs called \"clicker training\". Capabilities demonstrated include being trained to recognize and use acoustic patterns as cues for actions, as well as to synthesize new actions from novel paths through its motion space. A key contribution of this paper is to demonstrate that by addressing the three problems of state, action, and state-action space discovery at the same time, the solution for each becomes easier. Finally, we articulate heuristics and design principles that make learning practical for synthetic characters. ", 
        "id": 10, 
        "title": "Integrated learning for interactive synthetic characters."
    }, 
    {
        "abstract": "In this paper, we present a technique we call \"cartoon capture and retargeting\" which we use to track the motion from traditionally animated cartoons and retarget it onto 3-D models, 2-D drawings, and photographs. By using animation as the source, we can produce new animations that are expressive, exaggerated or non-realistic. Cartoon capture transforms a digitized cartoon into a cartoon motion representation. Using a combination of affine transformation and key-shape interpolation, cartoon capture tracks non-rigid shape changes in cartoon layers. Cartoon retargeting translates this information into different output media. The result is an animation with a new look but with the movement of the original cartoon. ", 
        "id": 11, 
        "title": "Turning to the masters: motion capturing cartoons."
    }, 
    {
        "abstract": "We present an algorithm to efficiently and robustly process collisions, contact and friction in cloth simulation. It works with any technique for simulating the internal dynamics of the cloth, and allows true modeling of cloth thickness. We also show how our simulation data can be post-processed with a collision-aware subdivision scheme to produce smooth and interference free data for rendering. ", 
        "id": 12, 
        "title": "Robust treatment of collisions, contact and friction for cloth animation."
    }, 
    {
        "abstract": " We present a simple method of interactive texture editing that utilizes self-similarity to replicate intended operations globally over an image. Inspired by the recent successes of hierarchical approaches to texture synthesis, this method also uses multi-scale neighborhoods to assess the similarity of pixels within a texture. However, neighborhood matching is not employed to generate new instances of a texture. We instead locate similar neighborhoods for the purpose of replicating editing operations on the original texture itself, thereby creating a fundamentally new texture. This general approach is applied to texture painting, cloning and warping. These global operations are performed interactively, most often directed with just a single mouse movement. ", 
        "id": 13, 
        "title": "Self-similarity based texture editing."
    }, 
    {
        "abstract": "This paper presents a framework for the skeleton-driven animation of elastically deformable characters. A character is embedded in a coarse volumetric control lattice, which provides the structure needed to apply the finite element method. To incorporate skeletal controls, we introduce line constraints along the bones of simple skeletons. The bones are made to coincide with edges of the control lattice, which enables us to apply the constraints efficiently using algebraic methods. To accelerate computation, we associate regions of the volumetric mesh with particular bones and perform locally linearized simulations, which are blended at each time step. We define a hierarchical basis on the control lattice, so for detailed interactions the simulation can adapt the level of detail. We demonstrate the ability to animate complex models using simple skeletons and coarse volumetric meshes in a manner that simulates secondary motions at interactive rates. ", 
        "id": 14, 
        "title": "Interactive skeleton-driven dynamic deformations."
    }, 
    {
        "abstract": "", 
        "id": 15, 
        "title": "Meshed atlases for real-time procedural solid texturing."
    }, 
    {
        "abstract": " A light field parameterized on the surface offers a natural and intuitive description of the view-dependent appearance of scenes with complex reflectance properties. To enable the use of surface light fields in real-time rendering we develop a compact representation suitable for an accelerated graphics pipeline. We propose to approximate the light field data by partitioning it over elementary surface primitives and factorizing each part into a small set of lower-dimensional functions. We show that our representation can be further compressed using standard image compression techniques leading to extremely compact data sets that are up to four orders of magnitude smaller than the input data. Finally, we develop an image-based rendering method, light field mapping, that can visualize surface light fields directly from this compact representation at interactive frame rates on a personal computer. We also implement a new method of approximating the light field data that produces positive only factors allowing for faster rendering using simpler graphics hardware than earlier methods. We demonstrate the results for a variety of non-trivial synthetic scenes and physical objects scanned through 3D photography. ", 
        "id": 16, 
        "title": "Light field mapping: efficient representation and hardware rendering of surface light fields."
    }, 
    {
        "abstract": "Human hair modeling is a difficult task. This paper presents a constructive hair modeling system with which users can sculpt a wide variety of hairstyles. Our Multiresolution Hair Modeling (MHM) system is based on the observed tendency of adjacent hair strands to form clusters at multiple scales due to static attraction. In our system, initial hair designs are quickly created with a small set of hair clusters. Refinements at finer levels are achieved by subdividing these initial hair clusters. Users can edit an evolving model at any level of detail, down to a single hair strand. High level editing tools support curling, scaling, and copy/paste, enabling users to rapidly create widely varying hairstyles. Editing ease and model realism are enhanced by efficient hair rendering, shading, antialiasing, and shadowing algorithms. ", 
        "id": 17, 
        "title": "Interactive multiresolution hair modeling and editing."
    }, 
    {
        "abstract": "We present techniques for realistic modeling and rendering of feathers and birds. Our approach is motivated by the observation that a feather is a branching structure that can be described by an Lsystem. The parametric L-system we derived allows the user to easily create feathers of different types and shapes by changing a few parameters. The randomness in feather geometry is also incorporated into this L-system. To render a feather realistically, we have derived an efficient form of the bidirectional texture function (BTF), which describes the small but visible geometry details on the feather blade. A rendering algorithm combining the L-system and the BTF displays feathers photorealistically while capitalizing on graphics hardware for efficiency. Based on this framework of feather modeling and rendering, we developed a system that can automatically generate appropriate feathers to cover different parts of a bird's body from a few \"key feathers\" supplied by the user, and produce realistic renderings of the bird. ", 
        "id": 18, 
        "title": "Modeling and rendering of realistic feathers."
    }, 
    {
        "abstract": "We present a semi-implicit cloth simulation technique that is very stable yet also responsive. The stability of the technique allows the use of a large fixed time step when simulating all types of fabrics and character motions. The animations generated using this technique are strikingly realistic. Wrinkles form and disappear in a quite natural way, which is the feature that most distinguishes textile fabrics from other sheet materials. Significant improvements in both the stability and realism were made possible by overcoming the post-buckling instability as well as the numerical instability. The instability caused by buckling arises from a structural instability and therefore cannot be avoided by simply employing a semi-implicit method. Addition of a damping force may help to avoid instabilities; however, it can significantly degrade the realism of the cloth motion. The method presented here uses a particlebased physical model to handle the instability in the post-buckling response without introducing any fictitious damping. ", 
        "id": 19, 
        "title": "Stable but responsive cloth."
    }, 
    {
        "abstract": "This paper describes a new framework for video matting, the process of pulling a high-quality alpha matte and foreground from a video sequence. The framework builds upon techniques in natural image matting, optical flow computation, and background estimation. User interaction is comprised of garbage matte specification if background estimation is needed, and hand-drawn keyframe segmentations into \"foreground,\" \"background,\" and \"unknown\". The segmentations, called trimaps, are interpolated across the video volume using forward and backward optical flow. Competing flow estimates are combined based on information about where flow is likely to be accurate. A Bayesian matting technique uses the flowed trimaps to yield high-quality mattes of moving foreground elements with complex boundaries filmed by a moving camera. A novel technique for smoke matte extraction is also demonstrated. ", 
        "id": 20, 
        "title": "Video matting of complex scenes."
    }, 
    {
        "abstract": "We present a procedural approach to authoring layered, solid models. Using a simple scripting language, we define the internal structure of a volume from one or more input meshes. Sculpting and simulation operators are applied within the context of the language to shape and modify the model. Our framework treats simulation as a modeling operator rather than simply as a tool for animation, thereby suggesting a new paradigm for modeling as well as a new level of abstraction for interacting with simulation environments. Capturing real-world effects with standard modeling techniques is extremely challenging. Our key contribution is a concise procedural approach for seamlessly building and modifying complex solid geometry. We present an implementation of our language using a flexible tetrahedral representation. We show a variety of complex objects modeled in our system using tools that interface with finite element method and particle system simulations. Additional ", 
        "id": 21, 
        "title": "A procedural approach to authoring solid models."
    }, 
    {
        "abstract": "We describe a process for compositing a live performance of an actor into a virtual set wherein the actor is consistently illuminated by the virtual environment. The Light Stage used in this work is a two-meter sphere of inward-pointing RGB light emitting diodes focused on the actor, where each light can be set to an arbitrary color and intensity to replicate a real-world or virtual lighting environment. We implement a digital two-camera infrared matting system to composite the actor into the background plate of the environment without affecting the visible-spectrum illumination on the actor. The color reponse of the system is calibrated to produce correct color renditions of the actor as illuminated by the environment. We demonstrate moving-camera composites of actors into real-world environments and virtual sets such that the actor is properly illuminated by the environment into which they are composited. ", 
        "id": 22, 
        "title": "A lighting reproduction approach to live-action compositing."
    }, 
    {
        "abstract": "This paper presents a solution for texture mapping unparameterized models. The quality of a texture on a model is often limited by the model's parameterization into a 2D texture space. For models with complex topologies or complex distributions of structural detail, finding this parameterization can be very difficult and usually must be performed manually through a slow iterative process between the modeler and texture painter. This is especially true of models which carry no natural parameterizations, such as subdivision surfaces or models acquired from 3D scanners. Instead, we remove the 2D parameterization and store the texture in 3D space as a sparse, adaptive octree. Because no parameterization is necessary, textures can be painted on any surface that can be rendered. No mappings between disparate topologies are used, so texture artifacts such as seams and stretching do not exist. Because this method is adaptive, detail is created in the map only where required by the texture painter, conserving memory usage. ", 
        "id": 23, 
        "title": "Painting and rendering textures on unparameterized models."
    }, 
    {
        "abstract": "Good information design depends on clarifying the meaningful structure in an image. We describe a computational approach to stylizing and abstracting photographs that explicitly responds to this design goal. Our system transforms images into a line-drawing style using bold edges and large regions of constant color. To do this, it represents images as a hierarchical structure of parts and boundaries computed using state-of-the-art computer vision. Our system identifies the meaningful elements of this structure using a model of human perception and a record of a user's eye movements in looking at the photo; the system renders a new image using transformations that preserve and highlight these visual elements. Our method thus represents a new alternative for non-photorealistic rendering both in its visual style, in its approach to visual form, and in its techniques for interaction. ", 
        "id": 24, 
        "title": "Stylization and abstraction of photographs."
    }, 
    {
        "abstract": "The Scalable, Advanced Graphics Environment (SAGE) is a new high-end, multi-chip rendering architecture. Each single SAGE board can render in excess of 80 million fully lit, textured, antialiased triangles per second. SAGE brings high quality antialiasing filters to video rate hardware for the first time. To achieve this, the concept of a frame buffer is replaced by a fully double-buffered sample buffer of between 1 and 16 non-uniformly placed samples per final output pixel. The video output raster of samples is subject to convolution by a 55 programmable reconstruction and bandpass filter that replaces the traditional RAMDAC. The reconstruction filter processes up to 400 samples per output pixel, and supports any radially symmetric filter, including those with negative lobes (full Mitchell-Netravali filter). Each SAGE board comprises four parallel rendering sub-units, and supports up to two video output channels. Multiple SAGE systems can be tiled together to support even higher fill rates, resolutions, and performance. ", 
        "id": 25, 
        "title": "The SAGE graphics architecture."
    }, 
    {
        "abstract": "Analytic visibility algorithms, for example methods which compute a subdivided mesh to represent shadows, are notoriously unrobust and hard to use in practice. We present a new method based on a generalized definition of extremal stabbing lines, which are the extremities of shadow boundaries. We treat scenes containing multiple edges or vertices in degenerate configurations, (e.g., collinear or coplanar). We introduce a robust  method to determine whether each generalized extremal stabbing line is blocked, or is touched by these scene elements, and thus added to the line's generators. We develop robust blocker predicates for polygons which are smaller than . For larger  values, small shadow features merge and eventually disappear. We can thus robustly connect generalized extremal stabbing lines in degenerate scenes to form shadow boundaries. We show that our approach is consistent, and that shadow boundary connectivity is preserved when features merge. We have implemented our algorithm, and show that we can robustly compute analytic shadow boundaries to the precision of our chosen  threshold for non-trivial models, containing numerous degeneracies. ", 
        "id": 26, 
        "title": "Robust epsilon visibility."
    }, 
    {
        "abstract": "We present a new technique for the display of high-dynamic-range images, which reduces the contrast while preserving detail. It is based on a two-scale decomposition of the image into a base layer, encoding large-scale variations, and a detail layer. Only the base layer has its contrast reduced, thereby preserving detail. The base layer is obtained using an edge-preserving filter called the bilateral filter. This is a non-linear filter, where the weight of each pixel is computed using a Gaussian in the spatial domain multiplied by an influence function in the intensity domain that decreases the weight of pixels with large intensity differences. We express bilateral filtering in the framework of robust statistics and show how it relates to anisotropic diffusion. We then accelerate bilateral filtering by using a piecewise-linear approximation in the intensity domain and appropriate subsampling. This results in a speed-up of two orders of magnitude. The method is fast and requires no parameter setting. ", 
        "id": 27, 
        "title": "Fast bilateral filtering for the display of high-dynamic-range images."
    }, 
    {
        "abstract": "", 
        "id": 28, 
        "title": "The 3D visibility complex."
    }, 
    {
        "abstract": "We present a new method for the animation and rendering of photorealistic water effects. Our method is designed to produce visually plausible three dimensional effects, for example the pouring of water into a glass (see figure 1) and the breaking of an ocean wave, in a manner which can be used in a computer animation environment. In order to better obtain photorealism in the behavior of the simulated water surface, we introduce a new \"thickened\" front tracking technique to accurately represent the water surface and a new velocity extrapolation method to move the surface in a smooth, water-like manner. The velocity extrapolation method allows us to provide a degree of control to the surface motion, e.g. to generate a windblown look or to force the water to settle quickly. To ensure that the photorealism of the simulation carries over to the final images, we have integrated our method with an advanced physically based rendering system. ", 
        "id": 29, 
        "title": "Animation and rendering of complex water surfaces."
    }, 
    {
        "abstract": "We describe how to create with machine learning techniques a generative, videorealistic, speech animation module. A human subject is first recorded using a videocamera as he/she utters a predetermined speech corpus. After processing the corpus automatically, a visual speech module is learned from the data that is capable of synthesizing the human subject's mouth uttering entirely novel utterances that were not recorded in the original video. The synthesized utterance is re-composited onto a background sequence which contains natural head and eye movement. The final output is videorealistic in the sense that it looks like a video camera recording of the subject. At run time, the input to the system can be either real audio sequences or synthetic audio produced by a text-to-speech system, as long as they have been phonetically aligned. The two key contributions of this paper are 1) a variant of the multidimensional morphable model (MMM) to synthesize new, previously unseen mouth configurations from a small set of mouth image prototypes; and 2) a trajectory synthesis technique based on regularization, which is automatically trained from the recorded video corpus, and which is capable of synthesizing trajectories in MMM space corresponding to any desired utterance. ", 
        "id": 30, 
        "title": "Trainable videorealistic speech animation."
    }, 
    {
        "abstract": "We present a new method for rendering high dynamic range images on conventional displays. Our method is conceptually simple, computationally efficient, robust, and easy to use. We manipulate the gradient field of the luminance image by attenuating the magnitudes of large gradients. A new, low dynamic range image is then obtained by solving a Poisson equation on the modified gradient field. Our results demonstrate that the method is capable of drastic dynamic range compression, while preserving fine details and avoiding common artifacts, such as halos, gradient reversals, or loss of local contrast. The method is also able to significantly enhance ordinary images by bringing out detail in dark regions. ", 
        "id": 31, 
        "title": "Gradient domain high dynamic range compression."
    }, 
    {
        "abstract": " Figure 1: Steps in the progressive decompression of various models.  Efficient algorithms for compressing geometric data have been widely developed in the recent years, but they are mainly de-  ", 
        "id": 32, 
        "title": "Progressive lossless compression of arbitrary simplicial complexes."
    }, 
    {
        "abstract": "", 
        "id": 33, 
        "title": "On the algebraic and geometric foundations of computer graphics."
    }, 
    {
        "abstract": "Finite element solvers are a basic component of simulation applications; they are common in computer graphics, engineering, and medical simulations. Although adaptive solvers can be of great value in reducing the often high computational cost of simulations they are not employed broadly. Indeed, building adaptive solvers can be a daunting task especially for 3D finite elements. In this paper we are introducing a new approach to produce conforming, hierarchical, adaptive refinement methods (CHARMS). The basic principle of our approach is to refine basis functions, not elements. This removes a number of implementation headaches associated with other approaches and is a general technique independent of domain dimension (here 2D and 3D), element type (e.g., triangle, quad, tetrahedron, hexahedron), and basis function order (piecewise linear, higher order B-splines, Loop subdivision, etc.). The (un-)refinement algorithms are simple and require little in terms of data structure support. We demonstrate the versatility of our new approach through 2D and 3D examples, including medical applications and thin-shell animations. ", 
        "id": 34, 
        "title": "CHARMS: a simple framework for adaptive simulation."
    }, 
    {
        "abstract": "Surface geometry is often modeled with irregular triangle meshes. The process of remeshing refers to approximating such geometry using a mesh with (semi)-regular connectivity, which has advantages for many graphics applications. However, current techniques for remeshing arbitrary surfaces create only semi-regular meshes. The original mesh is typically decomposed into a set of disk-like charts, onto which the geometry is parametrized and sampled. In this paper, we propose to remesh an arbitrary surface onto a completely regular structure we call a geometry image. It captures geometry as a simple 2D array of quantized points. Surface signals like normals and colors are stored in similar 2D arrays using the same implicit surface parametrization -- texture coordinates are absent. To create a geometry image, we cut an arbitrary mesh along a network of edge paths, and parametrize the resulting single chart onto a square. Geometry images can be encoded using traditional image compression algorithms, such as wavelet-based coders. ", 
        "id": 35, 
        "title": "Geometry images."
    }, 
    {
        "abstract": "", 
        "id": 36, 
        "title": "Acknowledgments."
    }, 
    {
        "abstract": "We describe Chromium, a system for manipulating streams of graphics API commands on clusters of workstations. Chromium's stream filters can be arranged to create sort-first and sort-last parallel graphics architectures that, in many cases, support the same applications while using only commodity graphics accelerators. In addition, these stream filters can be extended programmatically, allowing the user to customize the stream transformations performed by nodes in a cluster. Because our stream processing mechanism is completely general, any cluster-parallel rendering algorithm can be either implemented on top of or embedded in Chromium. In this paper, we give examples of real-world applications that use Chromium to achieve good scalability on clusters of workstations, and describe other potential uses of this stream processing technology. By completely abstracting the underlying graphics architecture, network topology, and API command processing semantics, we allow a variety of applications to run in different environments. ", 
        "id": 37, 
        "title": "Chromium: a stream-processing framework for interactive rendering on clusters."
    }, 
    {
        "abstract": "In this paper we describe how to simulate geometrically complex, interactive, physically-based, volumetric, dynamic deformation models with negligible main CPU costs. This is achieved using a Dynamic Response Texture, or DyRT, that can be mapped onto any conventional animation as an optional rendering stage using commodity graphics hardware. The DyRT simulation process employs precomputed modal vibration models excited by rigid body motions. We present several examples, with an emphasis on bone-based character animation for interactive applications. ", 
        "id": 38, 
        "title": "DyRT: dynamic response textures for real time deformation simulation with graphics hardware."
    }, 
    {
        "abstract": "This paper introduces an efficient two-pass rendering technique for translucent materials. We decouple the computation of irradiance at the surface from the evaluation of scattering inside the material. This is done by splitting the evaluation into two passes, where the first pass consists of computing the irradiance at selected points on the surface. The second pass uses a rapid hierarchical integration technique to evaluate a diffusion approximation based on the irradiance samples. This approach is substantially faster than previous methods for rendering translucent materials, and it has the advantage that it integrates seamlessly with both scanline rendering and global illumination methods. We show several images and animations from our implementation that demonstrate that the approach is both fast and robust, making it suitable for rendering translucent materials in production. ", 
        "id": 39, 
        "title": "A rapid hierarchical rendering technique for translucent materials."
    }, 
    {
        "abstract": "This paper describes a new method for contouring a signed grid whose edges are tagged by Hermite data (i.e; exact intersection points and normals). This method avoids the need to explicitly identify and process \"features\" as required in previous Hermite contouring methods. Using a new, numerically stable representation for quadratic error functions, we develop an octree-based method for simplifying contours produced by this method. We next extend our contouring method to these simplied octrees. This new method imposes no constraints on the octree (such as being a restricted octree) and requires no \"crack patching\". We conclude with a simple test for preserving the topology of the contour during simplification. ", 
        "id": 40, 
        "title": "Dual contouring of hermite data."
    }, 
    {
        "abstract": "We present a system that lets a designer directly annotate a 3D model with strokes, imparting a personal aesthetic to the non-photorealistic rendering of the object. The artist chooses a \"brush\" style, then draws strokes over the model from one or more viewpoints. When the system renders the scene from any new viewpoint, it adapts the number and placement of the strokes appropriately to maintain the original look. ", 
        "id": 41, 
        "title": "WYSIWYG NPR: drawing strokes directly on 3D models."
    }, 
    {
        "abstract": "This paper introduces a new kind of mosaic, called Jigsaw Image Mosaic (JIM), where image tiles of arbitrary shape are used to compose the final picture. The generation of a Jigsaw Image Mosaic is a solution to the following problem: given an arbitrarily-shaped container image and a set of arbitrarily-shaped image tiles, fill the container as compactly as possible with tiles of similar color to the container taken from the input set while optionally deforming them slightly to achieve a more visuallypleasing effect. We approach the problem by defining a mosaic as the tile configuration that minimizes a mosaicing energy function. We introduce a general energy-based framework for mosaicing problems that extends some of the existing algorithms such as Photomosaics and Simulated Decorative Mosaics. We also present a fast algorithm to solve the mosaicing problem at an acceptable computational cost. We demonstrate the use of our method by applying it to a wide range of container images and tiles. ", 
        "id": 42, 
        "title": "Jigsaw image mosaics."
    }, 
    {
        "abstract": "In this paper we present a novel method for creating realistic, controllable motion. Given a corpus of motion capture data, we automatically construct a directed graph called a motion graph that encapsulates connections among the database. The motion graph consists both of pieces of original motion and automatically generated transitions. Motion can be generated simply by building walks on the graph. We present a general framework for extracting particular graph walks that meet a user's specifications. We then show how this framework can be applied to the specific problem of generating different styles of locomotion along arbitrary paths. ", 
        "id": 43, 
        "title": "Motion graphs."
    }, 
    {
        "abstract": "Rendering performance of consumer graphics hardware benefits from pre-processing geometric data into a form targeted to the underlying API and hardware. The various elements of geometric data are then coupled with a shading program at runtime to draw the asset. In this paper we describe a system in which pre-processing is done in a compilation process in which the geometric data are processed with knowledge of their shading programs. The data are converted into structures targeted directly to the hardware, and a code stream is assembled that describes the manipulations required to render these data structures. Our compiler is structured like a traditional code compiler, with a front end that reads the geometric data and attributes (hereafter referred to as an art asset) output from a 3D modeling package and shaders in a platform independent form and performs platform-independent optimizations, and a back end that performs platform-specific optimizations and generates platform-targeted data structures and code streams. Our compiler back-end has been targeted to four platforms, three of which are radically different from one another. On all platforms the rendering performance of our compiled assets, used in real situations, is well above that of hand-coded assets. ", 
        "id": 44, 
        "title": "Shader-driven compilation of rendering assets."
    }, 
    {
        "abstract": "In this paper we describe a system for animating flames. Stochastic models of flickering and buoyant diffusion provide realistic local appearance while physics-based wind fields and Kolmogorov noise add controllable motion and scale. Procedural mechanisms are developed for animating all aspects of flame behavior including moving sources, combustion spread, flickering, separation and merging, and interaction with stationary objects. At all stages in the process the emphasis is on total artistic and behavioral control while maintaining interactive animation rates. The final system is suitable for a high volume production pipeline. ", 
        "id": 45, 
        "title": "Structural modeling of flames for a production environment."
    }, 
    {
        "abstract": "Several techniques have been developed to approximate Bidirectional Reflectance Distribution Functions (BRDF) with acceptable quality and performance for realtime applications. The recently published Homomorphic Factorization by McCool et al. is a general approximation approach that can be used with various setups and for different quality requirements. In this paper we propose a new technique based on the Homomorphic Factorization. Instead of approximating the BRDF, our technique factorizes the full lighting computation of an isotropic BRDF in a global illumination scenario. With this method materials in complex lighting situations can be simulated with only two textures by using commonly available computation capabilities of current graphics hardware. The new technique can also be considered as a generalized approach to several environment map prefiltering techniques. Existing prefiltering techniques are usually limited to specific BRDFs or require advanced hardware capabilities like 3D texturing. With the factorization only common 2D textures are required. ", 
        "id": 46, 
        "title": "Homomorphic factorization of BRDF-based lighting computation."
    }, 
    {
        "abstract": "For an animated human face model to appear natural it should produce eye movements consistent with human ocular behavior. During face-to-face conversational interactions, eyes exhibit conversational turn-taking and agent thought processes through gaze direction, saccades, and scan patterns. We have implemented an eye movement model based on empirical models of saccades and statistical models of eye-tracking data. Face animations using stationary eyes, eyes with random saccades only, and eyes with statistically derived saccades are compared, to evaluate whether they appear natural and effective while communicating. ", 
        "id": 47, 
        "title": "Eyes alive."
    }, 
    {
        "abstract": "Real-time control of three-dimensional avatars is an important problem in the context of computer games and virtual environments. Avatar animation and control is difficult, however, because a large repertoire of avatar behaviors must be made available, and the user must be able to select from this set of behaviors, possibly with a low-dimensional input device. One appealing approach to obtaining a rich set of avatar behaviors is to collect an extended, unlabeled sequence of motion data appropriate to the application. In this paper, we show that such a motion database can be preprocessed for flexibility in behavior and efficient search and exploited for real-time avatar control. Flexibility is created by identifying plausible transitions between motion segments, and efficient search through the resulting graph structure is obtained through clustering. Three interface techniques are demonstrated for controlling avatar motion using this data structure: the user selects from a set of available choices, sketches a path through an environment, or acts out a desired motion in front of a video camera. We demonstrate the flexibility of the approach through four different applications and compare the avatar motion to directly recorded human motion. ", 
        "id": 48, 
        "title": "Interactive control of avatars animated with human motion data."
    }, 
    {
        "abstract": "A Texture Atlas is an efficient color representation for 3D Paint Systems. The model to be textured is decomposed into charts homeomorphic to discs, each chart is parameterized, and the unfolded charts are packed in texture space. Existing texture atlas methods for triangulated surfaces suffer from several limitations, requiring them to generate a large number of small charts with simple borders. The discontinuities between the charts cause artifacts, and make it difficult to paint large areas with regular patterns. In this paper, our main contribution is a new quasi-conformal parameterization method, based on a least-squares approximation of the Cauchy-Riemann equations. The so-defined objective function minimizes angle deformations, and we prove the following properties: the minimum is unique, independent of a similarity in texture space, independent of the resolution of the mesh and cannot generate triangle flips. The function is numerically well behaved and can therefore be very efficiently minimized. Our approach is robust, and can parameterize large charts with complex borders. We also introduce segmentation methods to decompose the model into charts with natural shapes, and a new packing algorithm to gather them in texture space. We demonstrate our approach applied to paint both scanned and modeled data sets. ", 
        "id": 49, 
        "title": "Least squares conformal maps for automatic texture atlas generation."
    }, 
    {
        "abstract": "", 
        "id": 50, 
        "title": "Pareto-optimal formulations for cost versus colorimetric accuracy trade-offs in printer color management."
    }, 
    {
        "abstract": "In this paper we present a general method for rapid prototyping of realistic character motion. We solve for the natural motion from a simple animation provided by the animator. Our framework can be used to produce relatively complex realistic motion with little user effort. We describe a novel constraint detection method that automatically determines different constraints on the character by analyzing the input motion. We show that realistic motion can be achieved by enforcing a small set of linear and angular momentum constraints. This simplified approach helps us avoid the complexities of computing muscle forces. Simpler dynamic constraints also allow us to generate animations of models with greater complexity, performing more intricate motions. Finally, we show that by learning a small set of key parameters that describe a character pose we can help a non-skilled animator rapidly create realistic character motion. ", 
        "id": 51, 
        "title": "Synthesis of complex dynamic character motion from simple animations."
    }, 
    {
        "abstract": "In this paper, we describe a novel technique, called motion texture, for synthesizing complex human-figure motion (e.g., dancing) that is statistically similar to the original motion captured data. We define motion texture as a set of motion textons and their distribution, which characterize the stochastic and dynamic nature of the captured motion. Specifically, a motion texton is modeled by a linear dynamic system (LDS) while the texton distribution is represented by a transition matrix indicating how likely each texton is switched to another. We have designed a maximum likelihood algorithm to learn the motion textons and their relationship from the captured dance motion. The learnt motion texture can then be used to generate new animations automatically and/or edit animation sequences interactively. Most interestingly, motion texture can be manipulated at different levels, either by changing the fine details of a specific motion at the texton level or by designing a new choreography at the distribution level. Our approach is demonstrated by many synthesized sequences of visually compelling dance motion. ", 
        "id": 52, 
        "title": "Motion texture: a two-level statistical model for character motion synthesis."
    }, 
    {
        "abstract": "We have built a system for acquiring and displaying high quality graphical models of objects that are impossible to scan with traditional scanners. Our system can acquire highly specular and fuzzy materials, such as fur and feathers. The hardware set-up consists of a turntable, two plasma displays, an array of cameras, and a rotating array of directional lights. We use multi-background matting techniques to acquire alpha mattes of the object from multiple viewpoints. The alpha mattes are used to construct an opacity hull. The opacity hull is a new shape representation, defined as the visual hull of the object with view-dependent opacity. It enables visualization of complex object silhouettes and seamless blending of objects into new environments. Our system also supports relighting of objects with arbitrary appearance using surface reflectance fields, a purely image-based appearance representation. Our system is the first to acquire and render surface reflectance fields under varying illumination from arbitrary viewpoints. We have built three generations of digitizers with increasing sophistication. In this paper, we present our results from digitizing hundreds of models. ", 
        "id": 53, 
        "title": "Image-based 3D photography using opacity hulls."
    }, 
    {
        "abstract": "A common measure of the quality or effectiveness of a virtual environment (VE) is the amount of presence it evokes in users. Presence is often defined as the sense of being there in a VE. There has been much debate about the best way to measure presence, and presence researchers need, and have sought, a measure that is reliable, valid, sensitive, and objective. We hypothesized that to the degree that a VE seems real, it would evoke physiological responses similar to those evoked by the corresponding real environment, and that greater presence would evoke a greater response. To examine this, we conducted three experiments, the results of which support the use of physiological reaction as a reliable, valid, sensitive, and objective presence measure. The experiments compared participants' physiological reactions to a non-threatening virtual room and their reactions to a stressful virtual height situation. We found that change in heart rate satisfied our requirements for a measure of presence, change in skin conductance did to a lesser extent, and that change in skin temperature did not. Moreover, the results showed that inclusion of a passive haptic element in the VE significantly increased presence and that for presence evoked: 30FPS > 20FPS > 15FPS.  In order to study a VE's effectiveness in evoking presence, researchers need a well-designed and verified measure of the phenomena. This paper reports our evaluation of three physiological measures  heart rate, skin conductance, and skin temperature  as alternate operational measures of presence in stressful VEs. Since the concept and idea of measuring presence are heavily debated, finding a measure that could find wide acceptance would be ideal. In that hope, we investigated the reliability, validity, sensitivity, and objectivity of each physiological measure.  ", 
        "id": 54, 
        "title": "Physiological measures of presence in stressful virtual environments."
    }, 
    {
        "abstract": "", 
        "id": 55, 
        "title": "A framework for geometric warps and deformations."
    }, 
    {
        "abstract": "We present a level set framework for implementing editing operators for surfaces. Level set models are deformable implicit surfaces where the deformation of the surface is controlled by a speed function in the level set partial differential equation. In this paper we define a collection of speed functions that produce a set of surface editing operators. The speed functions describe the velocity at each point on the evolving surface in the direction of the surface normal. All of the information needed to deform a surface is encapsulated in the speed function, providing a simple, unified computational framework. The user combines pre-defined building blocks to create the desired speed function. The surface editing operators are quickly computed and may be applied both regionally and globally. The level set framework offers several advantages. 1) By construction, self-intersection cannot occur, which guarantees the generation of physically-realizable, simple, closed surfaces. 2) Level set models easily change topological genus, and 3) are free of the edge connectivity and mesh quality problems associated with mesh models. We present five examples of surface editing operators: blending, smoothing, sharpening, openings/closings and embossing. We demonstrate their effectiveness on several scanned objects and scan-converted models. ", 
        "id": 56, 
        "title": "Level set surface editing operators."
    }, 
    {
        "abstract": "We present a physically based method for modeling and animating fire. Our method is suitable for both smooth (laminar) and turbulent flames, and it can be used to animate the burning of either solid or gas fuels. We use the incompressible Navier-Stokes equations to independently model both vaporized fuel and hot gaseous products. We develop a physically based model for the expansion that takes place when a vaporized fuel reacts to form hot gaseous products, and a related model for the similar expansion that takes place when a solid fuel is vaporized into a gaseous state. The hot gaseous products, smoke and soot rise under the influence of buoyancy and are rendered using a blackbody radiation model. We also model and render the blue core that results from radicals in the chemical reaction zone where fuel is converted into products. Our method allows the fire and smoke to interact with objects, and flammable objects can catch on fire. ", 
        "id": 57, 
        "title": "Physically based modeling and animation of fire."
    }, 
    {
        "abstract": "In this paper, we describe a method for realistically animating ductile fracture in common solid materials such as plastics and metals. The effects that characterize ductile fracture occur due to interaction between plastic yielding and the fracture process. By modeling this interaction, our ductile fracture method can generate realistic motion for a much wider range of materials than could be realized with a purely brittle model. This method directly extends our prior work on brittle fracture [O'Brien and Hodgins, SIGGRAPH 99]. We show that adapting that method to ductile as well as brittle materials requires only a simple to implement modification that is computationally inexpensive. This paper describes this modification and presents results demonstrating some of the effects that may be realized with it. ", 
        "id": 58, 
        "title": "Graphical modeling and animation of ductile fracture."
    }, 
    {
        "abstract": "", 
        "id": 59, 
        "title": "Shape distributions."
    }, 
    {
        "abstract": "Placing shadows is difficult task since shadows depend on the relative positions of lights and objects in an unintuitive manner. To simplify the task of the modeler, we present a user interface for designing shadows in 3d environments. In our interface, shadows are treated as first-class modeling primitives just like objects and lights. To transform a shadow, the user can simply move, rescale or rotate the shadow as if it was a 2d object on the scene's surfaces. When the user transforms a shadow, the system moves lights or objects in the scene as required and updates the shadows in realtime during mouse movement. To facilitate interaction, the user can also specify constraints that the shadows must obey, such as never casting a shadow on the face of a character. These constraints are then verified in real-time, limiting mouse movement when necessary. We also integrate in our interface fake shadows typically used in computer animation. This allows the user to draw shadowed and non-shadowed regions directly on surfaces in the scene. ", 
        "id": 60, 
        "title": "A user interface for interactive cinematic shadow design."
    }, 
    {
        "abstract": " is shaded; then the surface normal (which is itself a derivative operator) has a visibly discontinuous derivative (Figure 1a).  Two deficiencies in the original Noise algorithm are corrected: second order interpolation discontinuity and unoptimal gradient computation. With these defects corrected, Noise both looks better and runs faster. The latter change also makes it easier to define a uniform mathematical reference standard.  ", 
        "id": 61, 
        "title": "Improving noise."
    }, 
    {
        "abstract": "We discuss a method for creating animations that allows the animator to sketch an animation by setting a small number of keyframes on a fraction of the possible degrees of freedom. Motion capture data is then used to enhance the animation. Detail is added to degrees of freedom that were keyframed, a process we call texturing. Degrees of freedom that were not keyframed are synthesized. The method takes advantage of the fact that joint motions of an articulated figure are often correlated, so that given an incomplete data set, the missing degrees of freedom can be predicted from those that are present. ", 
        "id": 62, 
        "title": "Motion capture assisted animation: texturing and synthesis."
    }, 
    {
        "abstract": "Recently a breakthrough has occurred in graphics hardware: fixed function pipelines have been replaced with programmable vertex and fragment processors. In the near future, the graphics pipeline is likely to evolve into a general programmable stream processor capable of more than simply feed-forward triangle rendering. In this paper, we evaluate these trends in programmability of the graphics pipeline and explain how ray tracing can be mapped to graphics hardware. Using our simulator, we analyze the performance of a ray casting implementation on next generation programmable graphics hardware. In addition, we compare the performance difference between non-branching programmable hardware using a multipass implementation and an architecture that supports branching. We also show how this approach is applicable to other ray tracing algorithms such as Whitted ray tracing, path tracing, and hybrid rendering algorithms. Finally, we demonstrate that ray tracing on graphics hardware could prove to be faster than CPU based implementations as well as competitive with traditional hardware accelerated feed-forward triangle rendering. ", 
        "id": 63, 
        "title": "Ray tracing on programmable graphics hardware."
    }, 
    {
        "abstract": "We present a new method for real-time rendering of objects with complex isotropic BRDFs under distant natural illumination, as specified by an environment map. Our approach is based on spherical frequency space analysis and includes three main contributions. Firstly, we are able to theoretically analyze required sampling rates and resolutions, which have traditionally been determined in an ad-hoc manner. We also introduce a new compact representation, which we call a spherical harmonic reflection map (SHRM), for efficient representation and rendering. Finally, we show how to rapidly prefilter the environment map to compute the SHRM--our frequency domain prefiltering algorithm is generally orders of magnitude faster than previous angular (spatial) domain approaches. ", 
        "id": 64, 
        "title": "Frequency space environment map rendering."
    }, 
    {
        "abstract": "A classic photographic task is the mapping of the potentially high dynamic range of real world luminances to the low dynamic range of the photographic print. This tone reproduction problem is also faced by computer graphics practitioners who map digital images to a low dynamic range print or screen. The work presented in this paper leverages the time-tested techniques of photographic practice to develop a new tone reproduction operator. In particular, we use and extend the techniques developed by Ansel Adams to deal with digital images. The resulting algorithm is simple and produces good results for a wide variety of images. ", 
        "id": 65, 
        "title": "Photographic tone reproduction for digital images."
    }, 
    {
        "abstract": "The digitization of the 3D shape of real objects is a rapidly expanding field, with applications in entertainment, design, and archaeology. We propose a new 3D model acquisition system that permits the user to rotate an object by hand and see a continuously-updated model as the object is scanned. This tight feedback loop allows the user to find and fill holes in the model in real time, and determine when the object has been completely covered. Our system is based on a 60 Hz. structured-light rangefinder, a real-time variant of ICP (iterative closest points) for alignment, and point-based merging and rendering algorithms. We demonstrate the ability of our prototype to scan objects faster and with greater ease than conventional model acquisition pipelines. ", 
        "id": 66, 
        "title": "Real-time 3D model acquisition."
    }, 
    {
        "abstract": "", 
        "id": 67, 
        "title": "Smoothing an overlay grid to minimize linear distortion in texture mapping."
    }, 
    {
        "abstract": " We present a new, real-time method for rendering diffuse and  glossy objects in low-frequency lighting environments that cap-  tures soft shadows, interreflections, and caustics. As a preprocess, a novel global transport simulator creates functions over the  object's surface representing transfer of arbitrary, low-frequency  incident lighting into transferred radiance which includes global effects like shadows and interreflections from the object onto  itself. At run-time, these transfer functions are applied to actual  incident lighting. Dynamic, local lighting is handled by sampling it close to the object every frame; the object can also be rigidly  rotated with respect to the lighting and vice versa. Lighting and transfer functions are represented using low-order spherical harmonics. This avoids aliasing and evaluates efficiently on graphics hardware by reducing the shading integral to a dot product of 9 to 25 element vectors for diffuse receivers. Glossy objects are handled using matrices rather than vectors. We further introduce functions for radiance transfer from a dynamic lighting environment through a preprocessed object to neighboring points in space. These allow soft shadows and caustics from rigidly moving objects to be cast onto arbitrary, dynamic receivers. We demonstrate real-time global lighting effects with this approach.  Figure 1: Precomputed, unshadowed irradiance from [34] (left) vs. our precomputed transfer (right). The right model can be rendered at 129Hz with self-shadowing and self-interreflection in any lighting environment. frequency lighting environments, using a low-order spherical harmonic (SH) basis to represent such environments efficiently without aliasing. The main idea is to represent how an object scatters this light onto itself or its neighboring space. To describe our technique, assume initially we have a convex, diffuse object lit by an infinitely distant environment map. The object's shaded \"response\" to its environment can be viewed as a  ", 
        "id": 68, 
        "title": "Precomputed radiance transfer for real-time rendering in dynamic, low-frequency lighting environments."
    }, 
    {
        "abstract": "We present a method for designing truss structures, a common and complex category of buildings, using non-linear optimization. Truss structures are ubiquitous in the industrialized world, appearing as bridges, towers, roof supports and building exoskeletons, yet are complex enough that modeling them by hand is time consuming and tedious. We represent trusses as a set of rigid bars connected by pin joints, which may change location during optimization. By including the location of the joints as well as the strength of individual beams in our design variables, we can simultaneously optimize the geometry and the mass of structures. We present the details of our technique together with examples illustrating its use, including comparisons with real structures. ", 
        "id": 69, 
        "title": "Creating models of truss structures with optimization."
    }, 
    {
        "abstract": " Cyril Soler Marie-Paule Cani Alexis Angelidis iMAGIS / GRAVIR-IMAG / INRIA  We present a multi-scale algorithm for mapping a texture defined by an input image onto an arbitrary surface. It avoids the generation and storage of a new, specific texture. The idea is to progressively cover the surface by texture patches of various sizes and shapes, selected from a single input image. The process starts with large patches. A mapping that minimizes the texture fitting error with already textured neighbouring patches is selected. When this error is above a threshold, the patch is split into smaller ones, and the algorithm recursively looks for good fits at a smaller scale. The process ends when the surface is entirely covered. Our results show that the method correctly handles a wide set of texture patterns, which can be used at different mapping scales. Hierarchical texture mapping only outputs texture coordinates in the original texture for each triangle of the initial mesh. Rendering is therefore easy and memory cost minimal. Moreover the initial geometry is preserved. ", 
        "id": 70, 
        "title": "Hierarchical pattern mapping."
    }, 
    {
        "abstract": "Shadow maps are probably the most widely used means for the generation of shadows, despite their well known aliasing problems. In this paper we introduce perspective shadow maps, which are generated in normalized device coordinate space, i.e., after perspective transformation. This results in important reduction of shadow map aliasing with almost no overhead. We correctly treat light source transformations and show how to include all objects which cast shadows in the transformed space. Perspective shadow maps can directly replace standard shadow maps for interactive hardware accelerated rendering as well as in high-quality, offline renderers. ", 
        "id": 71, 
        "title": "Perspective shadow maps."
    }, 
    {
        "abstract": "In this paper, we present a system for interactive computation of global illumination in dynamic scenes. Our system uses a novel scheme for caching the results of a high quality pixel-based renderer such as a bidirectional path tracer. The Shading Cache is an objectspace hierarchical subdivision mesh with lazily computed shading values at its vertices. A high frame rate display is generated from the Shading Cache using hardware-based interpolation and texture mapping. An image space sampling scheme refines the Shading Cache in regions that have the most interpolation error or those that are most likely to be affected by object or camera motion. Our system handles dynamic scenes and moving light sources efficiently, providing useful feedback within a few seconds and high quality images within a few tens of seconds, without the need for any pre-computation. Our approach allows us to significantly outperform other interactive systems based on caching ray-tracing samples, especially in dynamic scenes. Based on our results, we believe that the Shading Cache will be an invaluable tool in lighting design and modelling while rendering. ", 
        "id": 72, 
        "title": "Interactive global illumination in dynamic scenes."
    }, 
    {
        "abstract": "The bidirectional texture function (BTF) is a 6D function that can describe textures arising from both spatially-variant surface reflectance and surface mesostructures. In this paper, we present an algorithm for synthesizing the BTF on an arbitrary surface from a sample BTF. A main challenge in surface BTF synthesis is the requirement of a consistent mesostructure on the surface, and to achieve that we must handle the large amount of data in a BTF sample. Our algorithm performs BTF synthesis based on surface textons, which extract essential information from the sample BTF to facilitate the synthesis. We also describe a general search strategy, called the -coherent search, for fast BTF synthesis using surface textons. A BTF synthesized using our algorithm not only looks similar to the BTF sample in all viewing/lighthing conditions but also exhibits a consistent mesostructure when viewing and lighting directions change. Moreover, the synthesized BTF fits the target surface naturally and seamlessly. We demonstrate the effectiveness of our algorithm with sample BTFs from various sources, including those measured from real-world textures. ", 
        "id": 73, 
        "title": "Synthesis of bidirectional texture functions on arbitrary surfaces."
    }, 
    {
        "abstract": "", 
        "id": 74, 
        "title": "Modelling with implicit surfaces that interpolate."
    }, 
    {
        "abstract": "We introduce a general technique for \"colorizing\" greyscale images by transferring color between a source, color image and a destination, greyscale image. Although the general problem of adding chromatic values to a greyscale image has no exact, objective solution, the current approach attempts to provide a method to help minimize the amount of human labor required for this task. Rather than choosing RGB colors from a palette to color individual components, we transfer the entire color \"mood\" of the source to the target image by matching luminance and texture information between the images. We choose to transfer only chromatic information and retain the original luminance values of the target image. Further, the procedure is enhanced by allowing the user to match areas of the two images with rectangular swatches. We show that this simple technique can be successfully applied to a variety of images and video, provided that texture and luminance are sufficiently distinct. The images generated demonstrate the potential and utility of our technique in a diverse set of application domains. ", 
        "id": 75, 
        "title": "Transferring color to greyscale images."
    }, 
    {
        "abstract": "A new method for the visualization of two-dimensional fluid flow is presented. The method is based on the advection and decay of dye. These processes are simulated by defining each frame of a flow animation as a blend between a warped version of the previous image and a number of background images. For the latter a sequence of filtered white noise images is used: filtered in time and space to remove high frequency components. Because all steps are done using images, the method is named Image Based Flow Visualization (IBFV). With IBFV a wide variety of visualization techniques can be emulated. Flow can be visualized as moving textures with line integral convolution and spot noise. Arrow plots, streamlines, particles, and topological images can be generated by adding extra dye to the image. Unsteady flows, defined on arbitrary meshes, can be handled. IBFV achieves a high performance by using standard features of graphics hardware. Typically fifty frames per second are generated using standard graphics cards on PCs. Finally, IBFV is easy to understand, analyse, and implement. ", 
        "id": 76, 
        "title": "Image based flow visualization."
    }, 
    {
        "abstract": "", 
        "id": 77, 
        "title": "Permission grids: practical, error-bounded simplification."
    }, 
    {
        "abstract": "We present a feature-based technique for morphing 3D objects represented by light fields. Our technique enables morphing of imagebased objects whose geometry and surface properties are too difficult to model with traditional vision and graphics techniques. Light field morphing is not based on 3D reconstruction; instead it relies on ray correspondence, i.e., the correspondence between rays of the source and target light fields. We address two main issues in light field morphing: feature specification and visibility changes. For feature specification, we develop an intuitive and easy-to-use user interface (UI). The key to this UI is feature polygons, which are intuitively specified as 3D polygons and are used as a control mechanism for ray correspondence in the abstract 4D ray space. For handling visibility changes due to object shape changes, we introduce ray-space warping. Ray-space warping can fill arbitrarily large holes caused by object shape changes; these holes are usually too large to be properly handled by traditional image warping. Our method can deal with non-Lambertian surfaces, including specular surfaces (with dense light fields). We demonstrate that light field morphing is an effective and easy-to-use technqiue that can generate convincing 3D morphing effects. ", 
        "id": 78, 
        "title": "Feature-based light field morphing."
    }, 
    {
        "abstract": "We present a system for interactive shape and appearance editing of 3D point-sampled geometry. By generalizing conventional 2D pixel editors, our system supports a great variety of different interaction techniques to alter shape and appearance of 3D point models, including cleaning, texturing, sculpting, carving, filtering, and resampling. One key ingredient of our framework is a novel concept for interactive point cloud parameterization allowing for distortion minimal and aliasing-free texture mapping. A second one is a dynamic, adaptive resampling method which builds upon a continuous reconstruction of the model surface and its attributes. These techniques allow us to transfer the full functionality of 2D image editing operations to the irregular 3D point setting. Our system reads, processes, and writes point-sampled models without intermediate tesselation. It is intended to complement existing low cost 3D scanners and point rendering pipelines for efficient 3D content creation. ", 
        "id": 79, 
        "title": "Pointshop 3D: an interactive system for point-based surface editing."
    }, 
    {
        "abstract": "In this paper we present an algorithm to perform interactive boolean operations on free-form solids bounded by surfels. We introduce a fast inside-outside test to check whether surfels lie within the bounds of another surfel-bounded solid. This enables us to add, subtract and intersect complex solids at interactive rates. Our algorithm is fast both in displaying and constructing the new geometry resulting from the boolean operation. We present a resampling operator to solve problems resulting from sharp edges in the resulting solid. The operator resamples the surfels intersecting with the surface of the other solid. This enables us to represent the sharp edges with great detail. We believe our algorithm to be an ideal tool for interactive editing of free-form solids. ", 
        "id": 80, 
        "title": "Interactive boolean operations on surfel-bounded solids."
    }, 
    {
        "abstract": "Importance w/ 300 samples Importance w/ 3000 samples Structured importance w/ 300 samples Structured importance w/ 4.7 rays/pixel Figure 1: Close-up rendering of a glossy buddha in the grace cathedral environment. The two images on the left have been rendered using stratified importance sampling with 300 and 3000 samples, while the two images on the right show the result of structured importance sampling using 300 samples, and after further rendering optimizations an average of 4.7 rays per pixel to evaluate the 300 possible samples. Abstract We introduce structured importance sampling, a new technique for efficiently rendering scenes illuminated by distant natural illumination given in an environment map. Our method handles occlusion, high-frequency lighting, and is significantly faster than alternative methods based on Monte Carlo sampling. We achieve this speedup as a result of several ideas. First, we present a new metric for stratifying and sampling an environment map taking into account both the illumination intensity as well as the expected variance due to occlusion within the scene. We then present a novel hierarchical stratification algorithm that uses our metric to automatically stratify the environment map into regular strata. This approach enables a number of rendering optimizations, such as pre-integrating the illumination within each stratum to eliminate noise at the cost of adding bias, and sorting the strata to reduce the number of sample rays. We have rendered several scenes illuminated by natural lighting, and our results indicate that structured importance sampling is better than the best previous Monte Carlo techniques, requiring one to two orders of magnitude fewer samples for the same image quality.", 
        "id": 81, 
        "title": "Structured importance sampling of environment maps."
    }, 
    {
        "abstract": "We present design principles for creating effective assembly instructions and a system that is based on these principles. The principles are drawn from cognitive psychology research which investigated people's conceptual models of assembly and effective methods to visually communicate assembly information. Our system is inspired by earlier work in robotics on assembly planning and in visualization on automated presentation design. Although other systems have considered presentation and planning independently, we believe it is necessary to address the two problems simultaneously in order to create effective assembly instructions. We describe the algorithmic techniques used to produce assembly instructions given object geometry, orientation, and optional grouping and ordering constraints on the object's parts. Our results demonstrate that it is possible to produce aesthetically pleasing and easy to follow instructions for many everyday objects. ", 
        "id": 82, 
        "title": "Designing effective step-by-step assembly instructions."
    }, 
    {
        "abstract": "In causal processes decisions do not depend on future data. Many well-known problems, such as occlusion culling, order-independent transparency and edge antialiasing cannot be properly solved using the traditional causal rendering architectures, because future data may change the interpretation of current events. We propose adding a delay stream between the vertex and pixel processing units. While a triangle resides in the delay stream, subsequent triangles generate occlusion information. As a result, the triangle may be culled by primitives that were submitted after it. We show two- to fourfold efficiency improvements in pixel processing and video memory bandwidth usage in common benchmark scenes. We also demonstrate how the memory requirements of order-independent transparency can be substantially reduced by using delay streams. Finally, we describe how discontinuity edges can be detected in hardware. Previously used heuristics for collapsing samples in adaptive supersampling are thus replaced by connectivity information. ", 
        "id": 83, 
        "title": "Delay streams for graphics hardware."
    }, 
    {
        "abstract": " The mobile phone is one of the most widespread devices with rendering capabilities. Those capabilities have been very limited because the resources on such devices are extremely scarce; small amounts of memory, little bandwidth, little chip area dedicated for special purposes, and limited power consumption. The small display resolutions present a further challenge; the angle subtended by a pixel is relatively large, and therefore reasonably high quality rendering is needed to generate high fidelity images. To increase the mobile rendering capabilities, we propose a new hardware architecture for rasterizing textured triangles. Our architecture focuses on saving memory bandwidth, since an external memory access typically is one of the most energy-consuming operations, and because mobile phones need to use as little power as possible. Therefore, our system includes three new key innovations: I) an inexpensive multisampling scheme that gives relatively high quality at the same cost of previous inexpensive schemes, II) a texture minification system, including texture compression, which gives quality relatively close to trilinear mipmapping at the cost of 1.33 32-bit memory accesses on average, III) a scanline-based culling scheme that avoids a significant amount of z-buffer reads, and that only requires one context. Software simulations show that these three innovations together significantly reduce the memory bandwidth, and thus also the power consumption.  ", 
        "id": 84, 
        "title": "Graphics for the masses: a hardware rasterization architecture for mobile phones."
    }, 
    {
        "abstract": "We develop a novel method for fitting high-resolution template meshes to detailed human body range scans with sparse 3D markers. We formulate an optimization problem in which the degrees of freedom are an affine transformation at each template vertex. The objective function is a weighted combination of three measures: proximity of transformed vertices to the range data, similarity between neighboring transformations, and proximity of sparse markers at corresponding locations on the template and target surface. We solve for the transformations with a non-linear optimizer, run at two resolutions to speed convergence. We demonstrate reconstruction and consistent parameterization of 250 human body models. With this parameterized set, we explore a variety of applications for human body modeling, including: morphing, texture transfer, statistical analysis of shape, model fitting from sparse markers, feature analysis to modify multiple correlated parameters (such as the weight and height of an individual), and transfer of surface detail and animation controls from a template to fitted models. ", 
        "id": 85, 
        "title": "The space of human body shapes: reconstruction and parameterization from range scans."
    }, 
    {
        "abstract": "In this paper, we propose a novel polygonal remeshing technique that exploits a key aspect of surfaces: the intrinsic anisotropy of natural or man-made geometry. In particular, we use curvature directions to drive the remeshing process, mimicking the lines that artists themselves would use when creating 3D models from scratch. After extracting and smoothing the curvature tensor field of an input genus-0 surface patch, lines of minimum and maximum curvatures are used to determine appropriate edges for the remeshed version in anisotropic regions, while spherical regions are simply pointsampled since there is no natural direction of symmetry locally. As a result our technique generates polygon meshes mainly composed of quads in anisotropic regions, and of triangles in spherical regions. Our approach provides the flexibility to produce meshes ranging from isotropic to anisotropic, from coarse to dense, and from uniform to curvature adapted. ", 
        "id": 86, 
        "title": "Anisotropic polygonal remeshing."
    }, 
    {
        "abstract": "This paper describes a framework that allows a user to synthesize human motion while retaining control of its qualitative properties. The user paints a timeline with annotations -- like walk, run or jump -- from a vocabulary which is freely chosen by the user. The system then assembles frames from a motion database so that the final motion performs the specified actions at specified times. The motion can also be forced to pass through particular configurations at particular times, and to go to a particular position and orientation. Annotations can be painted positively (for example, must run), negatively (for example, may not run backwards) or as a don't-care. The system uses a novel search method, based around dynamic programming at several scales, to obtain a solution efficiently so that authoring is interactive. Our results demonstrate that the method can generate smooth, natural-looking motion. The annotation vocabulary can be chosen to fit the application, and allows specification of composite motions (run and jump simultaneously, for example). The process requires a collection of motion data that has been annotated with the chosen vocabulary. This paper also describes an effective tool, based around repeated use of support vector machines, that allows a user to annotate a large collection of motions quickly and easily so that they may be used with the synthesis algorithm. ", 
        "id": 87, 
        "title": "Motion synthesis from annotations."
    }, 
    {
        "abstract": "Most previous soft shadow algorithms have either suffered from aliasing, been too slow, or could only use a limited set of shadow casters and/or receivers. Therefore, we present a strengthened soft shadow volume algorithm that deals with these problems. Our critical improvements include robust penumbra wedge construction, geometry-based visibility computation, and also simplified computation through a four-dimensional texture lookup. This enables us to implement the algorithm using programmable graphics hardware, and it results in images that most often are indistinguishable from images created as the average of 1024 hard shadow images. Furthermore, our algorithm can use both arbitrary shadow casters and receivers. Also, one version of our algorithm completely avoids sampling artifacts which is rare for soft shadow algorithms. As a bonus, the four-dimensional texture lookup allows for small textured light sources, and, even video textures can be used as light sources. Our algorithm has been implemented in pure software, and also using the GeForce FX emulator with pixel shaders. Our software implementation renders soft shadows at 0.55 frames per second for the images in this paper. With actual hardware, we expect that our algorithm will render soft shadows in real time. An important performance measure is bandwidth usage. For the same image quality, an algorithm using the accumulated hard shadow images uses almost two orders of magnitude more bandwidth than our algorithm. ", 
        "id": 88, 
        "title": "A geometry-based soft shadow volume algorithm using graphics hardware."
    }, 
    {
        "abstract": "", 
        "id": 89, 
        "title": "SwingWrapper: Retiling triangle meshes for better edgebreaker compression."
    }, 
    {
        "abstract": "", 
        "id": 90, 
        "title": "Anisotropic diffusion of surfaces and functions on surfaces."
    }, 
    {
        "abstract": "This paper presents a new interactive rendering and display technique for complex scenes with expensive shading, such as global illumination. Our approach combines sparsely sampled shading (points) and analytically computed discontinuities (edges) to interactively generate high-quality images. The edge-and-point image is a new compact representation that combines edges and points such that fast, table-driven interpolation of pixel shading from nearby point samples is possible, while respecting discontinuities. The edge-and-point renderer is extensible, permitting the use of arbitrary shaders to collect shading samples. Shading discontinuities, such as silhouettes and shadow edges, are found at interactive rates. Our software implementation supports interactive navigation and object manipulation in scenes that include expensive lighting effects (such as global illumination) and geometrically complex objects. For interactive rendering we show that high-quality images of these scenes can be rendered at 814 frames per second on a desktop PC: a speedup of 2060 over a ray tracer computing a single sample per pixel. ", 
        "id": 91, 
        "title": "Combining edges and points for interactive high-quality rendering."
    }, 
    {
        "abstract": "Deficient cloth-to-cloth collision response is the most serious shortcoming of most cloth simulation systems. Past approaches to clothcloth collision have used history to decide whether nearby cloth regions have interpenetrated. The biggest pitfall of history-based methods is that an error anywhere along the way can give rise to persistent tangles. This is a particularly serious issue for production character animation, because characters' bodies routinely selfintersect, for instance in the bend of an elbow or knee, or where the arm or hand rests against the body. Cloth that becomes pinched in these regions is often forced into jagged self-intersections that defeat history-based methods, leaving a tangled mess when the body parts separate. This paper describes a history-free cloth collision response algorithm based on global intersection analysis of cloth meshes at each simulation step. The algorithm resolves tangles that arise during pinching as soon as the surrounding geometry permits, and also resolves tangled initial conditions. The ability to untangle cloth after pinching is not sufficient, because standard clothsolid collision algorithms handle pinches so poorly that they often give rise to visible flutters and other simulation artifacts during the pinch. As a companion to the global intersection analysis method, we present a cloth-solid collision algorithm called collision flypapering, that eliminates these artifacts. The two algorithms presented have been used together extensively and successfully in a production animation environment. ", 
        "id": 92, 
        "title": "Untangling cloth."
    }, 
    {
        "abstract": "Many computer graphics applications require high-intensity numerical simulation. We show that such computations can be performed efficiently on the GPU, which we regard as a full function streaming processor with high floating-point performance. We implemented two basic, broadly useful, computational kernels: a sparse matrix conjugate gradient solver and a regular-grid multigrid solver. Realtime applications ranging from mesh smoothing and parameterization to fluid solvers and solid mechanics can greatly benefit from these, evidence our example applications of geometric flow and fluid simulation running on NVIDIA's GeForce FX. ", 
        "id": 93, 
        "title": "Sparse matrix solvers on the GPU: conjugate gradients and multigrid."
    }, 
    {
        "abstract": "In free-viewpoint video, the viewer can interactively choose his viewpoint in 3-D space to observe the action of a dynamic realworld scene from arbitrary perspectives. The human body and its motion plays a central role in most visual media and its structure can be exploited for robust motion estimation and efficient visualization. This paper describes a system that uses multi-view synchronized video footage of an actor's performance to estimate motion parameters and to interactively re-render the actor's appearance from any viewpoint. The actor's silhouettes are extracted from synchronized video frames via background segmentation and then used to determine a sequence of poses for a 3D human body model. By employing multi-view texturing during rendering, time-dependent changes in the body surface are reproduced in high detail. The motion capture subsystem runs offline, is non-intrusive, yields robust motion parameter estimates, and can cope with a broad range of motion. The rendering subsystem runs at real-time frame rates using ubiquous graphics hardware, yielding a highly naturalistic impression of the actor. The actor can be placed in virtual environments to create composite dynamic scenes. Free-viewpoint video allows the creation of camera fly-throughs or viewing the action interactively from arbitrary perspectives. ", 
        "id": 94, 
        "title": "Free-viewpoint video of human actors."
    }, 
    {
        "abstract": "", 
        "id": 95, 
        "title": "Planning biped locomotion using motion capture data and probabilistic roadmaps."
    }, 
    {
        "abstract": "In this paper, we describe a method for extracting shadows from one natural scene and inserting them into another. We develop physically-based shadow matting and compositing equations and use these to pull a shadow matte from a source scene in which the shadow is cast onto an arbitrary planar background. We then acquire the photometric and geometric properties of the target scene by sweeping oriented linear shadows (cast by a straight object) across it. From these shadow scans, we can construct a shadow displacement map without requiring camera or light source calibration. This map can then be used to deform the original shadow matte. We demonstrate our approach for both indoor scenes with controlled lighting and for outdoor scenes using natural lighting. ", 
        "id": 96, 
        "title": "Shadow matting and compositing."
    }, 
    {
        "abstract": "We present a simple stochastic system for non-periodically tiling the plane with a small set of Wang Tiles. The tiles may be filled with texture, patterns, or geometry that when assembled create a continuous representation. The primary advantage of using Wang Tiles is that once the tiles are filled, large expanses of non-periodic texture (or patterns or geometry) can be created as needed very efficiently at runtime. Wang Tiles are squares in which each edge is assigned a color. A valid tiling requires all shared edges between tiles to have matching colors. We present a new stochastic algorithm to nonperiodically tile the plane with a small set of Wang Tiles at runtime. Furthermore, we present new methods to fill the tiles with 2D texture, 2D Poisson distributions, or 3D geometry to efficiently create at runtime as much non-periodic texture (or distributions, or geometry) as needed. We leverage previous texture synthesis work and adapt it to fill Wang Tiles. We demonstrate how to fill individual tiles with Poisson distributions that maintain their statistical properties when combined. These are used to generate a large arrangement of plants or other objects on a terrain. We show how such environments can be rendered efficiently by pre-lighting the individual Wang Tiles containing the geometry. We also extend the definition of Wang Tiles to include a coding of the tile corners to allow discrete objects to overlap more than one edge. The larger set of tiles provides increased degrees of freedom. ", 
        "id": 97, 
        "title": "Wang Tiles for image and texture generation."
    }, 
    {
        "abstract": " In this paper we present sequential point trees, a data structure that allows adaptive rendering of point clouds completely on the graphics processor. Sequential point trees are based on a hierarchical point representation, but the hierarchical rendering traversal is replaced by sequential processing on the graphics processor, while the CPU is available for other tasks. Smooth transition to triangle rendering for optimized performance is integrated. We describe optimizations for backface culling and texture adaptive point selection. Finally, we discuss implementation issues and show results.  ", 
        "id": 98, 
        "title": "Sequential point trees."
    }, 
    {
        "abstract": "In this paper, we describe a non-photorealistic rendering system that conveys shape using lines. We go beyond contours and creases by developing a new type of line to draw: the suggestive contour. Suggestive contours are lines drawn on clearly visible parts of the surface, where a true contour would first appear with a minimal change in viewpoint. We provide two methods for calculating suggestive contours, including an algorithm that finds the zero crossings of the radial curvature. We show that suggestive contours can be drawn consistently with true contours, because they anticipate and extend them. We present a variety of results, arguing that these images convey shape more effectively than contour alone. ", 
        "id": 99, 
        "title": "Suggestive contours for conveying shape."
    }, 
    {
        "abstract": "We introduce billboard clouds  a new approach for extreme simplification in the context of real-time rendering. 3D models are simplified onto a set of planes with texture and transparency maps. We present an optimization approach to build a billboard cloud given a geometric error threshold. After computing an appropriate density function in plane space, a greedy approach is used to select suitable representative planes. A good surface approximation is ensured by favoring planes that are \"nearly tangent\" to the model. This method does not require connectivity information, but instead avoids cracks by projecting primitives onto multiple planes when needed. For extreme simplification, our approach combines the strengths of mesh decimation and image-based impostors. We demonstrate our technique on a large class of models, including smooth manifolds and composite objects. ", 
        "id": 100, 
        "title": "Billboard clouds for extreme model simplification."
    }, 
    {
        "abstract": "In computer graphics, most research focuses on creating images. However, there has been much recent work on the automatic generation of sound linked to objects in motion and the relative positions of receivers and sound sources. This paper proposes a new method for creating one type of sound called aerodynamic sound. Examples of aerodynamic sound include sound generated by swinging swords or by wind blowing. A major source of aerodynamic sound is vortices generated in fluids such as air. First, we propose a method for creating sound textures for aerodynamic sound by making use of computational fluid dynamics. Next, we propose a method using the sound textures for real-time rendering of aerodynamic sound according to the motion of objects or wind velocity. ", 
        "id": 101, 
        "title": "Real-time rendering of aerodynamic sound using sound textures based on computational fluid dynamics."
    }, 
    {
        "abstract": "We introduce an acting-based animation system for creating and editing character animation at interactive speeds. Our system requires minimal training, typically under an hour, and is well suited for rapidly prototyping and creating expressive motion. A real-time motion-capture framework records the user's motions for simultaneous analysis and playback on a large screen. The animator's realworld, expressive motions are mapped into the character's virtual world. Visual feedback maintains a tight coupling between the animator and character. Complex motion is created by layering multiple passes of acting. We also introduce a novel motion-editing technique, which derives implicit relationships between the animator and character. The animator mimics some aspect of the character motion, and the system infers the association between features of the animator's motion and those of the character. The animator modifies the mimic by acting again, and the system maps the changes onto the character. We demonstrate our system with several examples and present the results from informal user studies with expert and novice animators. ", 
        "id": 102, 
        "title": "Layered acting for character animation."
    }, 
    {
        "abstract": "We present a new method for completing missing parts caused by the removal of foreground or background elements from an image. Our goal is to synthesize a complete, visually plausible and coherent image. The visible parts of the image serve as a training set to infer the unknown parts. Our method iteratively approximates the unknown regions and composites adaptive image fragments into the image. Values of an inverse matte are used to compute a confidence map and a level set that direct an incremental traversal within the unknown area from high to low confidence. In each step, guided by a fast smooth approximation, an image fragment is selected from the most similar and frequent examples. As the selected fragments are composited, their likelihood increases along with the mean confidence of the image, until reaching a complete image. We demonstrate our method by completion of photographs and paintings. ", 
        "id": 103, 
        "title": "Fragment-based image completion."
    }, 
    {
        "abstract": "", 
        "id": 104, 
        "title": "Perceptually-driven decision theory for interactive realistic rendering."
    }, 
    {
        "abstract": "Optimization is a promising way to generate new animations from a minimal amount of input data. Physically based optimization techniques, however, are difficult to scale to complex animated characters, in part because evaluating and differentiating physical quantities becomes prohibitively slow. Traditional approaches often require optimizing or constraining parameters involving joint torques; obtaining first derivatives for these parameters is generally an O(D2) process, where D is the number of degrees of freedom of the character. In this paper, we describe a set of objective functions and constraints that lead to linear time analytical first derivatives. The surprising finding is that this set includes constraints on physical validity, such as ground contact constraints. Considering only constraints and objective functions that lead to linear time first derivatives results in fast per-iteration computation times and an optimization problem that appears to scale well to more complex characters. We show that qualities such as squash-and-stretch that are expected from physically based optimization result from our approach. Our animation system is particularly useful for synthesizing highly dynamic motions, and we show examples of swinging and leaping motions for characters having from 7 to 22 degrees of freedom. ", 
        "id": 105, 
        "title": "Efficient synthesis of physically valid human motion."
    }, 
    {
        "abstract": "This paper describes a method for animating suspended particle explosions. Rather than modeling the numerically troublesome, and largely invisible blast wave, the method uses a relatively stable incompressible fluid model to account for the motion of air and hot gases. The fluid's divergence field is adjusted directly to account for detonations and the generation and expansion of gaseous combustion products. Particles immersed in the fluid track the motion of particulate fuel and soot as they are advected by the fluid. Combustion is modeled using a simple but effective process governed by the particle and fluid systems. The method has enough flexibility to also approximate sprays of burning liquids. This paper includes several demonstrative examples showing air bursts, explosions near obstacles, confined explosions, and burning sprays. Because the method is based on components that allow large time integration steps, it only requires a few seconds of computation per frame for the examples shown. ", 
        "id": 106, 
        "title": "Animating suspended particle explosions."
    }, 
    {
        "abstract": "", 
        "id": 107, 
        "title": "Progressive point set surfaces."
    }, 
    {
        "abstract": " We present an anisotropic mesh denoising algorithm that is effective, simple and fast. This is accomplished by filtering vertices of the mesh in the normal direction using local neighborhoods. Motivated by the impressive results of bilateral filtering for image denoising, we adopt it to denoise 3D meshes; addressing the specific issues required in the transition from two-dimensions to manifolds in three dimensions. We show that the proposed method successfully removes noise from meshes while preserving features. Furthermore, the presented algorithm excels in its simplicity both in concept and implementation. ", 
        "id": 108, 
        "title": "Bilateral mesh denoising."
    }, 
    {
        "abstract": "", 
        "id": 109, 
        "title": "Learning style translation for the lines of a drawing."
    }, 
    {
        "abstract": "", 
        "id": 110, 
        "title": "A search engine for 3D models."
    }, 
    {
        "abstract": "This paper presents a technique for estimating the spatially-varying reflectance properties of a surface based on its appearance during a single pass of a linear light source. By using a linear light rather than a point light source as the illuminant, we are able to reliably observe and estimate the diffuse color, specular color, and specular roughness of each point of the surface. The reflectometry apparatus we use is simple and inexpensive to build, requiring a single direction of motion for the light source and a fixed camera viewpoint. Our model fitting technique first renders a reflectance table of how diffuse and specular reflectance lobes would appear under moving linear light source illumination. Then, for each pixel we compare its series of intensity values to the tabulated reflectance lobes to determine which reflectance model parameters most closely produce the observed reflectance values. Using two passes of the linear light source at different angles, we can also estimate per-pixel surface normals as well as the reflectance parameters. Additionally our system records a per-pixel height map for the object and estimates its per-pixel translucency. We produce real-time renderings of the captured objects using a custom hardware shading algorithm. We apply the technique to a test object exhibiting a variety of materials as well as to an illuminated manuscript with gold lettering. To demonstrate the technique's accuracy, we compare renderings of the captured models to real photographs of the original objects. ", 
        "id": 111, 
        "title": "Linear light source reflectometry."
    }, 
    {
        "abstract": "", 
        "id": 112, 
        "title": "Snap-together motion: assembling run-time animations."
    }, 
    {
        "abstract": "Realistic image synthesis requires both complex and realistic models of real-world light sources and efficient rendering algorithms to deal with them. In this paper, we describe a processing pipeline for dealing with complex light sources from acquisition to global illumination rendering. We carefully design optical filters to guarantee high precision measurements of real-world light sources. We discuss two practically feasible setups that allow us to measure light sources with different characteristics. Finally, we introduce an efficient importance sampling algorithm for our representation that can be used, for example, in conjunction with Photon Maps. ", 
        "id": 113, 
        "title": "Accurate light source acquisition and rendering."
    }, 
    {
        "abstract": "Parameterization of 3D mesh data is important for many graphics applications, in particular for texture mapping, remeshing and morphing. Closed manifold genus-0 meshes are topologically equivalent to a sphere, hence this is the natural parameter domain for them. Parameterizing a triangle mesh onto the sphere means assigning a 3D position on the unit sphere to each of the mesh vertices, such that the spherical triangles induced by the mesh connectivity are not too distorted and do not overlap. Satisfying the non-overlapping requirement is the most difficult and critical component of this process. We describe a generalization of the method of barycentric coordinates for planar parameterization which solves the spherical parameterization problem, prove its correctness by establishing a connection to spectral graph theory and show how to compute these parameterizations. ", 
        "id": 114, 
        "title": "Fundamentals of spherical parameterization for 3D meshes."
    }, 
    {
        "abstract": "We present a new algorithm for interactive generation of hard-edged, umbral shadows in complex environments with a moving light source. Our algorithm uses a hybrid approach that combines the image quality of object-precision methods with the efficiencies of image-precision techniques. We present an algorithm for computing a compact potentially visible set (PVS) using levels-of-detail (LODs) and visibility culling. We use the PVSs computed from both the eye and the light in a novel cross-culling algorithm that identifies a reduced set of potential shadow-casters and shadowreceivers. Finally, we use a combination of shadow-polygons and shadow maps to generate shadows. We also present techniques for LOD-selection to minimize possible artifacts arising from the use of LODs. Our algorithm can generate sharp shadow edges and reduces the aliasing in pure shadow map approaches. We have implemented the algorithm on a three-PC system with NVIDIA GeForce 4 cards. We achieve 7-25 frames per second in three complex environments composed of millions of triangles.  ", 
        "id": 115, 
        "title": "Interactive shadow generation in complex environments."
    }, 
    {
        "abstract": "We present blue-c, a new immersive projection and 3D video acquisition environment for virtual design and collaboration. It combines simultaneous acquisition of multiple live video streams with advanced 3D projection technology in a CAVETM-like environment, creating the impression of total immersion. The blue-c portal currently consists of three rectangular projection screens that are built from glass panels containing liquid crystal layers. These screens can be switched from a whitish opaque state (for projection) to a transparent state (for acquisition), which allows the video cameras to \"look through\" the walls. Our projection technology is based on active stereo using two LCD projectors per screen. The projectors are synchronously shuttered along with the screens, the stereo glasses, active illumination devices, and the acquisition hardware. From multiple video streams, we compute a 3D video representation of the user in real time. The resulting video inlays are integrated into a networked virtual environment. Our design is highly scalable, enabling blue-c to connect to portals with less sophisticated hardware. ", 
        "id": 116, 
        "title": "blue-c: a spatially immersive display and 3D video portal for telepresence."
    }, 
    {
        "abstract": "We consider the simulation of nonconvex rigid bodies focusing on interactions such as collision, contact, friction (kinetic, static, rolling and spinning) and stacking. We advocate representing the geometry with both a triangulated surface and a signed distance function defined on a grid, and this dual representation is shown to have many advantages. We propose a novel approach to time integration merging it with the collision and contact processing algorithms in a fashion that obviates the need for ad hoc threshold velocities. We show that this approach matches the theoretical solution for blocks sliding and stopping on inclined planes with friction. We also present a new shock propagation algorithm that allows for efficient use of the propagation (as opposed to the simultaneous) method for treating contact. These new techniques are demonstrated on a variety of problems ranging from simple test cases to stacking problems with as many as 1000 nonconvex rigid bodies with friction as shown in Figure 1. ", 
        "id": 117, 
        "title": "Nonconvex rigid bodies with stacking."
    }, 
    {
        "abstract": "We describe a new technique for measuring the bidirectional texture function (BTF) of a surface that requires no mechanical movement, can measure surfaces in situ under arbitrary lighting conditions, and can be made small, portable and inexpensive. The enabling innovation is the use of a tapered kaleidoscope, which allows a camera to view the same surface sample simultaneously from many directions. Similarly, the surface can be simultaneously illuminated from many directions, using only a single structured light source. We describe the techniques of construction and measurement, and we show experimental results. ", 
        "id": 118, 
        "title": "Measuring bidirectional texture reflectance with a kaleidoscope."
    }, 
    {
        "abstract": "By combining a metallic ink and standard inks, one may create printed images having a dynamic appearance: an image viewed under specular reflection may be considerably different from the same image viewed under non-specular reflection. Patterns which are either dark or hidden become highlighted under specular reflection, yielding interesting visual effects. To create such images, one needs to be able to reproduce at non-specular reflection angles the same colors, by standard inks alone or in combination with a metallic ink. Accurate color prediction models need to be established which model the underlying physical phenomena in a consistent manner. To meet this challenge, we propose two models, one for predicting the reflection spectra of standard inks on coated paper and one for predicting the reflection spectra of a combination of standard inks and a metallic ink. They are enhancements of the classical Clapper-Yule model which models optical dot gain of halftone prints by taking into account lateral scattering within the paper bulk and multiple internal reflections. The models we propose also take into account physical dot gain and ink spreading for standard inks as well as the low reflectance of metallic inks at nonspecular reflection angles and the poor adherence of standard inks printed on top of a metallic ink (trapping effect). These models open the way towards color separation of images to be reproduced by combining a metallic ink and standard inks. Several designs printed on an offset press demonstrate their applicability and their benefits for high-end design and security applications. ", 
        "id": 119, 
        "title": "Reproducing color images with embedded metallic patterns."
    }, 
    {
        "abstract": " Graphics hardware is undergoing a change from fixed-function pipelines to more programmable organizations that resemble general purpose stream processors. In this paper, we show that certain general algorithms, not normally associated with computer graphics, can be mapped to such designs. Specifically, we cast nonlinear optimization as a data streaming process that is well matched to modern graphics processors. Our framework is particularly well suited for solving image-based modeling problems since it can be used to represent a large and diverse class of these problems using a common formulation. We successfully apply this approach to two distinct image-based modeling problems: light field mapping approximation and fitting the Lafortune model to spatial bidirectional reflectance distribution functions. Comparing the performance of the graphics hardware implementation to a CPU implementation, we show more than 5-fold improvement.  ", 
        "id": 120, 
        "title": "Nonlinear optimization framework for image-based modeling on programmable graphics hardware."
    }, 
    {
        "abstract": "", 
        "id": 121, 
        "title": "Clothing manipulation."
    }, 
    {
        "abstract": "Polygonal models acquired with emerging 3D scanning technology or from large scale CAD applications easily reach sizes of several gigabytes and do not fit in the address space of common 32-bit desktop PCs. In this paper we propose an out-of-core mesh compression technique that converts such gigantic meshes into a streamable, highly compressed representation. During decompression only a small portion of the mesh needs to be kept in memory at any time. As full connectivity information is available along the decompression boundaries, this provides seamless mesh access for incremental in-core processing on gigantic meshes. Decompression speeds are CPU-limited and exceed one million vertices and two million triangles per second on a 1.8 GHz Athlon processor. A novel external memory data structure provides our compression engine with transparent access to arbitrary large meshes. This out-of-core mesh was designed to accommodate the access pattern of our region-growing based compressor, which - in return - performs mesh queries as seldom and as local as possible by remembering previous queries as long as needed and by adapting its traversal slightly. The achieved compression rates are state-of-the-art. ", 
        "id": 122, 
        "title": "Out-of-core compression for gigantic polygon meshes."
    }, 
    {
        "abstract": "Grid-based page designs are ubiquitous in commercially printed publications,such as newspapers and magazines.Yet,to date,no one has invented a good way to easily and automatically adapt suchdesigns toarbitrarily-sized electronicdisplays.The difficulty ofgeneralizing grid-based designs explains the generally inferior nature ofon-screen layouts when compared to their printed coun-terparts,and is arguably one ofthe greatestremaining impediments to creating on-line reading experiences thatrival those ofink on paper.In this work,we presenta new ap-proachtoadaptive grid-based document layout, which attempts to bridge this gap.In our approach,anadaptive lay-outstyle is encoded as a set of grid-based templates that know how toadapttoa range ofpage sizes and other viewing conditions. These templates include various types of layout elements (such as text,figures,etc.)and define, throughconstraint-based rela-tionships,justhow these elements are to be laid out together as a function of both the properties ofthe content itself,such as a figure's size and aspectratio,and the properties of the viewing conditions under which the content is being displayed. We describe an XML-based representation for our templates and content,which maintains a clean separation between the two.We also describe the various parts of our research prototype system:a layoutengine for formatting the page;a paginator for determining a globally optimalallocation of contentamongstthe pages,as wellas an optimalpairing oftem-plates withcontent;and a graphicaluser interface for interactively creating adaptive templates.We also provide numerous examples demonstratingthe capabilities ofthis prototype,includingthis pa-per,itself,whichhas beenlaid outwithour system. ", 
        "id": 123, 
        "title": "Adaptive grid-based document layout."
    }, 
    {
        "abstract": "We present an approach for precomputing data-driven models of interactive physically based deformable scenes. The method permits real-time hardware synthesis of nonlinear deformation dynamics, including self-contact and global illumination effects, and supports real-time user interaction. We use data-driven tabulation of the system's deterministic state space dynamics, and model reduction to build efficient low-rank parameterizations of the deformed shapes. To support runtime interaction, we also tabulate impulse response functions for a palette of external excitations. Although our approach simulates particular systems under very particular interaction conditions, it has several advantages. First, parameterizing all possible scene deformations enables us to precompute novel reduced coparameterizations of global scene illumination for lowfrequency lighting conditions. Second, because the deformation dynamics are precomputed and parameterized as a whole, collisions are resolved within the scene during precomputation so that runtime self-collision handling is implicit. Optionally, the data-driven models can be synthesized on programmable graphics hardware, leaving only the low-dimensional state space dynamics and appearance data models to be computed by the main CPU. ", 
        "id": 124, 
        "title": "Precomputing interactive dynamic deformable scenes."
    }, 
    {
        "abstract": "", 
        "id": 125, 
        "title": "Multiresolution green's function methods for interactive simulation of large-scale elastostatic objects."
    }, 
    {
        "abstract": "With the increasing use of geometry scanners to create 3D models, there is a rising need for fast and robust mesh smoothing to remove inevitable noise in the measurements. While most previous work has favored diffusion-based iterative techniques for feature-preserving smoothing, we propose a radically different approach, based on robust statistics and local first-order predictors of the surface. The robustness of our local estimates allows us to derive a non-iterative feature-preserving filtering technique applicable to arbitrary \"triangle soups\". We demonstrate its simplicity of implementation and its efficiency, which make it an excellent solution for smoothing large, noisy, and non-manifold meshes. ", 
        "id": 126, 
        "title": "Non-iterative, feature-preserving mesh smoothing."
    }, 
    {
        "abstract": "Facial reconstruction for postmortem identification of humans from their skeletal remains is a challenging and fascinating part of forensic art. The former look of a face can be approximated by predicting and modeling the layers of tissue on the skull. This work is as of today carried out solely by physical sculpting with clay, where experienced artists invest up to hundreds of hours to craft a reconstructed face model. Remarkably, one of the most popular tissue reconstruction methods bears many resemblances with surface fitting techniques used in computer graphics, thus suggesting the possibility of a transfer of the manual approach to the computer. In this paper, we present a facial reconstruction approach that fits an anatomy-based virtual head model, incorporating skin and muscles, to a scanned skull using statistical data on skull / tissue relationships. The approach has many advantages over the traditional process: a reconstruction can be completed in about an hour from acquired skull data; also, variations such as a slender or a more obese build of the modeled individual are easily created. Last not least, by matching not only skin geometry but also virtual muscle layers, an animatable head model is generated that can be used to form facial expressions beyond the neutral face typically used in physical reconstructions. ", 
        "id": 127, 
        "title": "Reanimating the dead: reconstruction of expressive faces from skull data."
    }, 
    {
        "abstract": "We describe a way to render stylized silhouettes of animated 3D models with temporal coherence. Coherence is one of the central challenges for non-photorealistic rendering. It is especially difficult for silhouettes, because they may not have obvious correspondences between frames. We demonstrate various coherence effects for stylized silhouettes with a robust working system. Our method runs in real-time for models of moderate complexity, making it suitable for both interactive applications and offline animation. ", 
        "id": 128, 
        "title": "Coherent stylized silhouettes."
    }, 
    {
        "abstract": "Typical video footage captured using an off-the-shelf camcorder suffers from limited dynamic range. This paper describes our approach to generate high dynamic range (HDR) video from an image sequence of a dynamic scene captured while rapidly varying the exposure of each frame. Our approach consists of three parts: automatic exposure control during capture, HDR stitching across neighboring frames, and tonemapping for viewing. HDR stitching requires accurately registering neighboring frames and choosing appropriate pixels for computing the radiance map. We show examples for a variety of dynamic scenes. We also show how we can compensate for scene and camera movement when creating an HDR still from a series of bracketed still photographs. ", 
        "id": 129, 
        "title": "High dynamic range video."
    }, 
    {
        "abstract": "Cutting up a complex object into simpler sub-objects is a fundamental problem in various disciplines. In image processing, images are segmented while in computational geometry, solid polyhedra are decomposed. In recent years, in computer graphics, polygonal meshes are decomposed into sub-meshes. In this paper we propose a novel hierarchical mesh decomposition algorithm. Our algorithm computes a decomposition into the meaningful components of a given mesh, which generally refers to segmentation at regions of deep concavities. The algorithm also avoids over-segmentation and jaggy boundaries between the components. Finally, we demonstrate the utility of the algorithm in control-skeleton extraction. ", 
        "id": 130, 
        "title": "Hierarchical mesh decomposition using fuzzy clustering and cuts."
    }, 
    {
        "abstract": " Good parameterizations are of central importance in many digital geometry processing tasks. Typically the behavior of such processing algorithms is related to the smoothness of the parameterization and how much distortion it contains. Since a parameterization maps a bounded region of the plane to the surface, a parameterization for a surface which is not homeomorphic to a disc must be made up of multiple pieces. We present a novel parameterization algorithm for arbitrary topology surface meshes which computes a globally smooth parameterization with low distortion. We optimize the patch layout subject to criteria such as shape quality and metric distortion, which are used to steer a mesh simplification approach for base complex construction. Global smoothness is achieved through simultaneous relaxation over all patches, with suitable transition functions between patches incorporated into the relaxation procedure. We demonstrate the quality of our parameterizations through numerical evaluation of distortion measures and the excellent rate distortion performance of semi-regular remeshes produced with these parameterizations. The numerical algorithms required to compute the parameterizations are robust and run on the order of minutes even for large meshes. ", 
        "id": 131, 
        "title": "Globally smooth parameterizations with low distortion."
    }, 
    {
        "abstract": "Real-time animation of human-like characters is an active research area in computer graphics. The conventional approaches have, however, hardly dealt with the rhythmic patterns of motions, which are essential in handling rhythmic motions such as dancing and locomotive motions. In this paper, we present a novel scheme for synthesizing a new motion from unlabelled example motions while preserving their rhythmic pattern. Our scheme first captures the motion beats from the example motions to extract the basic movements and their transitions. Based on those data, our scheme then constructs a movement transition graph that represents the example motions. Given an input sound signal, our scheme finally synthesizes a novel motion in an on-line manner while traversing the motion transition graph, which is synchronized with the input sound signal and also satisfies kinematic constraints given explicitly and implicitly. Through experiments, we have demonstrated that our scheme can effectively produce a variety of rhythmic motions. ", 
        "id": 132, 
        "title": "Rhythmic-motion synthesis based on motion-beat analysis."
    }, 
    {
        "abstract": " Figure 1: Constrained texture mapping. Dots indicate constrained vertices and their positions. ", 
        "id": 133, 
        "title": "Matchmaker: constructing constrained texture maps."
    }, 
    {
        "abstract": "In this work, the emphasis is on the development of strategies to realize techniques of numerical computing on the graphics chip. In particular, the focus is on the acceleration of techniques for solving sets of algebraic equations as they occur in numerical simulation. We introduce a framework for the implementation of linear algebra operators on programmable graphics processors (GPUs), thus providing the building blocks for the design of more complex numerical algorithms. In particular, we propose a stream model for arithmetic operations on vectors and matrices that exploits the intrinsic parallelism and efficient communication on modern GPUs. Besides performance gains due to improved numerical computations, graphics algorithms benefit from this model in that the transfer of computation results to the graphics processor for display is avoided. We demonstrate the effectiveness of our approach by implementing direct solvers for sparse matrices, and by applying these solvers to multi-dimensional finite difference equations, i.e. the 2D wave equation and the incompressible Navier-Stokes equations. ", 
        "id": 134, 
        "title": "Linear algebra operators for GPU implementation of numerical algorithms."
    }, 
    {
        "abstract": "", 
        "id": 135, 
        "title": "Continuous contact simulation for smooth surfaces."
    }, 
    {
        "abstract": "In this paper we introduce a new algorithm for image and video texture synthesis. In our approach, patch regions from a sample image or video are transformed and copied to the output and then stitched together along optimal seams to generate a new (and typically larger) output. In contrast to other techniques, the size of the patch is not chosen a-priori, but instead a graph cut technique is used to determine the optimal patch region for any given offset between the input and output texture. Unlike dynamic programming, our graph cut technique for seam optimization is applicable in any dimension. We specifically explore it in 2D and 3D to perform video texture synthesis in addition to regular image synthesis. We present approximative offset search techniques that work well in conjunction with the presented patch size optimization. We show results for synthesizing regular, random, and natural images and videos. We also demonstrate how this method can be used to interactively merge different images to generate new scenes. ", 
        "id": 136, 
        "title": "Graphcut textures: image and video synthesis using graph cuts."
    }, 
    {
        "abstract": "We present a progressive encoding technique specifically designed for complex isosurfaces. It achieves better rate distortion performance than all standard mesh coders, and even improves on all previous single rate isosurface coders. Our novel algorithm handles isosurfaces with or without sharp features, and deals gracefully with high topologic and geometric complexity. The inside/outside function of the volume data is progressively transmitted through the use of an adaptive octree, while a local frame based encoding is used for the fine level placement of surface samples. Local patterns in topology and local smoothness in geometry are exploited by context-based arithmetic encoding, allowing us to achieve an average of 6.10 bits per vertex (b/v) at very low distortion. Of this rate only 0.65 b/v are dedicated to connectivity data: this improves by 24% over the best previous single rate isosurface encoder. ", 
        "id": 137, 
        "title": "Progressive encoding of complex isosurfaces."
    }, 
    {
        "abstract": "", 
        "id": 138, 
        "title": "Image-based reconstruction of spatial appearance and geometric detail."
    }, 
    {
        "abstract": "Shape optimization and surface fairing for polygon meshes have been active research areas for the last few years. Existing approaches either require the border of the surface to be fixed, or are only applicable to closed surfaces. In this paper, we propose a new approach, that computes natural boundaries. This makes it possible not only to smooth an existing geometry, but also to extrapolate its shape beyond the existing border. Our approach is based on a global parameterization of the surface and on a minimization of the squared curvatures, discretized on the edges of the surface. The soconstructed surface is an approximation of a minimal energy surface (MES). Using a global parameterization makes it possible to completely decouple the outer fairness (surface smoothness) from the inner fairness (mesh quality). In addition, the parameter space provides the user with a new means of controlling the shape of the surface. When used as a geometry filter, our approach computes a smoothed mesh that is discrete conformal to the original one. This allows smoothing textured meshes without introducing distortions. ", 
        "id": 139, 
        "title": "Dual domain extrapolation."
    }, 
    {
        "abstract": "From-region visibility culling is considered harder than from-point visibility culling, since it is inherently four-dimensional. We present a conservative occlusion culling method based on factorizing the 4D visibility problem into horizontal and vertical components. The visibility of the two components is solved asymmetrically: the horizontal component is based on a parameterization of the ray space, and the visibility of the vertical component is solved by incrementally merging umbrae. The technique is designed so that the horizontal and vertical operations can be efficiently realized together by modern graphics hardware. Similar to image-based from-point methods, we use an occlusion map to encode visibility; however, the image-space occlusion map is in the ray space rather than in the primal space. Our results show that the culling time and the size of the computed potentially visible set depend on the size of the viewcell. For moderate viewcells, conservative occlusion culling of large urban scenes takes less than a second, and the size of the potentially visible set is only about two times larger than the size of the exact visible set. ", 
        "id": 140, 
        "title": "Ray space factorization for from-region visibility."
    }, 
    {
        "abstract": "A free-form deformation that warps a surface or solid may be specified in terms of one or several point-displacement constraints that must be interpolated by the deformation. The Twister approach introduced here, adds the capability to impose an orientation change, adding three rotational constraints, at each displaced point. Furthermore, it solves for a space warp that simultaneously interpolates two sets of such displacement and orientation constraints. With a 6 DoF magnetic tracker in each hand, the user may grab two points on or near the surface of an object and simultaneously drag them to new locations while rotating the trackers to tilt, bend, or twist the shape near the displaced points. Using a new formalism based on a weighted average of screw displacements, Twister computes in realtime a smooth deformation, whose effect decays with distance from the grabbed points, simultaneously interpolating the 12 constraints. It is continuously applied to the shape, providing realtime graphic feedback. The two-hand interface and the resulting deformation are intuitive and hence offer an effective direct manipulation tool for creating or modifying 3D shapes. ", 
        "id": 141, 
        "title": "Twister: a space-warp operator for the two-handed editing of 3D shapes."
    }, 
    {
        "abstract": "Motivation Conducting design evaluation and assembly verification tasks in immersive virtual environments (VEs) enables designers to evaluate and validate alternative designs more quickly and be cheaply than if mock-ups are built, and more thoroughly than can done from drawings. Design review has become one of the major productive applications of VEs [Brooks 1999]. The ideal VE system would have the participant fully convinced he was actually performing a task [Sutherland 1965]. Parts and tools would have mass, feel real, and handle properly with appropriate visual and haptic feedback. The user would interact with virtual objects as if he were actually doing the task, and virtual objects would respond to the users actions. Both assembly and servicing are hands-on tasks and the principal drawback of virtual models  that there is nothing there to feel, to give manual affordances, and to constrain motions  is a serious one for these applications. Using a six degree-of-freedom wand to simulate a wrench, for example, is far from natural or realistic, perhaps too far to be useful. Imagine trying to simulate a task as basic as unscrewing an oil filter from a car engine in a VE! Interacting with purely virtual objects limits the types of feedback the system can provide. We feel a hybrid environment system, one that incorporates representations of dynamic real objects into the VE, would assist in providing natural interactivity. Dynamic real objects are defined as objects that can deform, change topology, and change appearance. Examples include a socket wrench, clothing, and the human hand. For a many types of VEs, incorporating dynamic real objects would provide improved affordance matching and tactile feedback. Incorporating real objects is defined as being able to see, and have virtual objects react to, the virtual representations of real objects. We believe spatial cognitive tasks would benefit from incorporating real objects. These tasks require problem solving while manipulating objects and maintaining mental model of spatial relationships among them. With the capability of having real objects interact with virtual models, designers can see if there is enough space to reach a certain location all while handling real parts, real tools, and the variability among participants. Approach We use a hybrid environment system that uses image-based object reconstruction algorithms to generate real-time virtual representations, avatars, of real objects. The participant sees avatars of himself and real objects visually incorporated into the Permission to make digital/hard copy of part of all of this work for personal or classroom use is granted without fee provided that the copies are not made or distributed for profit or commercial advantage, the copyright notice, the title of the publication, and its date appear, and notice is given that copying is by permission of ACM, Inc. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.  2003 ACM 0730-0301/03/0700-0701 $5.00 VE. Further, the participant handles and feels the real objects while interacting with virtual objects. The system models each real object as the visual hull derived from multiple camera views, and then texture-maps the objects image from a HMD mounted camera onto the visual hull. The resulting real-object avatars are visually combined with virtual objects and correct obscuration. We then developed algorithms to use the virtual representations in physically-based mechanics simulations. This includes new collision-detection and collision-response algorithms that exploit graphics hardware for computing results in real time. Combined with lighting and shadow rendering algorithms, they provide a more natural interface with the VE, allowing the real-object avatars to affect simulations such as particle systems, cloth simulations, and rigid-body dynamics. For example, Figure 1 shows a participant parting a virtual curtain to look out a virtual window. The interaction between the real hand and virtual cloth involves first detecting the collision between hand and cloth, and then the cloth simulations appropriately responding to the collision. In an exploratory study, four payload design experts from NASA Langley Research Center (NASA LaRC) used the hybrid environment system to evaluate an abstracted version of a payload assembly task. The participants experiences with the system showed anecdotally the effectiveness of handling real objects when interacting with virtual objects. We expect hybrid VEs to expand the types of tasks and applications that would benefit from immersive VEs by providing a higher-fidelity natural interaction. Figure 1 - The participant parts the virtual curtains to look out a window in the VE.", 
        "id": 142, 
        "title": "Incorporating dynamic real objects into immersive virtual environments."
    }, 
    {
        "abstract": "The latest real-time graphics architectures include programmable floating-point vertex and fragment processors, with support for data-dependent control flow in the vertex processor. We present a programming language and a supporting system that are designed for programming these stream processors. The language follows the philosophy of C, in that it is a hardware-oriented, generalpurpose language, rather than an application-specific shading language. The language includes a variety of facilities designed to support the key architectural features of programmable graphics processors, and is designed to support multiple generations of graphics architectures with different levels of functionality. The system supports both of the major 3D graphics APIs: OpenGL and Direct3D. This paper identifies many of the choices that we faced as we designed the system, and explains why we made the decisions that we did. ", 
        "id": 143, 
        "title": "Cg: a system for programming graphics hardware in a C-like language."
    }, 
    {
        "abstract": "Light scattering from hair is normally simulated in computer graphics using Kajiya and Kay's classic phenomenological model. We have made new measurements of scattering from individual hair fibers that exhibit visually significant effects not predicted by Kajiya and Kay's model. Our measurements go beyond previous hair measurements by examining out-of-plane scattering, and together with this previous work they show a multiple specular highlight and variation in scattering with rotation about the fiber axis. We explain the sources of these effects using a model of a hair fiber as a transparent elliptical cylinder with an absorbing interior and a surface covered with tilted scales. Based on an analytical scattering function for a circular cylinder, we propose a practical shading model for hair that qualitatively matches the scattering behavior shown in the measurements. In a comparison between a photograph and rendered images, we demonstrate the new model's ability to match the appearance of real hair. ", 
        "id": 144, 
        "title": "Light scattering from human hair fibers."
    }, 
    {
        "abstract": "We present an image-based technique to relight real objects illuminated by a 4D incident light field, representing the illumination of an environment. By exploiting the richness in angular and spatial variation of the light field, objects can be relit with a high degree of realism. We record photographs of an object, illuminated from various positions and directions, using a projector mounted on a gantry as a moving light source. The resulting basis images are used to create a subset of the full reflectance field of the object. Using this reflectance field, we can create an image of the object, relit with any incident light field and observed from a fixed camera position. To maintain acceptable recording times and reduce the amount of data, we propose an efficient data acquisition method. Since the object can be relit with a 4D incident light field, illumination effects encoded in the light field, such as shafts of shadow or spot light effects, can be realized. ", 
        "id": 145, 
        "title": "Relighting with 4D incident light fields."
    }, 
    {
        "abstract": "We present a generative model for isotropic bidirectional reflectance distribution functions (BRDFs) based on acquired reflectance data. Instead of using analytical reflectance models, we represent each BRDF as a dense set of measurements. This allows us to interpolate and extrapolate in the space of acquired BRDFs to create new BRDFs. We treat each acquired BRDF as a single high-dimensional vector taken from a space of all possible BRDFs. We apply both linear (subspace) and non-linear (manifold) dimensionality reduction tools in an effort to discover a lowerdimensional representation that characterizes our measurements. We let users define perceptually meaningful parametrization directions to navigate in the reduced-dimension BRDF space. On the low-dimensional manifold, movement along these directions produces novel but valid BRDFs. ", 
        "id": 146, 
        "title": "A data-driven reflectance model."
    }, 
    {
        "abstract": "Good character animation requires convincing skin deformations including subtleties and details like muscle bulges. Such effects are typically created in commercial animation packages which provide very general and powerful tools. While these systems are convenient and flexible for artists, the generality often leads to characters that are slow to compute or that require a substantial amount of memory and thus cannot be used in interactive systems. Instead, interactive systems restrict artists to a specific character deformation model which is fast and memory efficient but is notoriously difficult to author and can suffer from many deformation artifacts. This paper presents an automated framework that allows character artists to use the full complement of tools in high-end systems to create characters for interactive systems. Our method starts with an arbitrarily rigged character in an animation system. A set of examples is exported, consisting of skeleton configurations paired with the deformed geometry as static meshes. Using these examples, we fit the parameters of a deformation model that best approximates the original data yet remains fast to compute and compact in memory. ", 
        "id": 147, 
        "title": "Building efficient, accurate character skins from examples."
    }, 
    {
        "abstract": "Structural comparison of large trees is a difficult task that is only partially supported by current visualization techniques, which are mainly designed for browsing. We present TreeJuxtaposer, a system designed to support the comparison task for large trees of several hundred thousand nodes. We introduce the idea of \"guaranteed visibility\", where highlighted areas are treated as landmarks that must remain visually apparent at all times. We propose a new methodology for detailed structural comparison between two trees and provide a new nearly-linear algorithm for computing the best corresponding node from one tree to another. In addition, we present a new rectilinear Focus+Context technique for navigation that is well suited to the dynamic linking of side-by-side views while guaranteeing landmark visibility and constant frame rates. These three contributions result in a system delivering a fluid exploration experience that scales both in the size of the dataset and the number of pixels in the display. We have based the design decisions for our system on the needs of a target audience of biologists who must understand the structural details of many phylogenetic, or evolutionary, trees. Our tool is also useful in many other application domains where tree comparison is needed, ranging from network management to call graph optimization to genealogy. ", 
        "id": 148, 
        "title": "TreeJuxtaposer: scalable tree comparison using Focus+Context with guaranteed visibility."
    }, 
    {
        "abstract": "We present a method, based on pre-computed light transport, for real-time rendering of objects under all-frequency, time-varying illumination represented as a high-resolution environment map. Current techniques are limited to small area lights, with sharp shadows, or large low-frequency lights, with very soft shadows. Our main contribution is to approximate the environment map in a wavelet basis, keeping only the largest terms (this is known as a non-linear approximation). We obtain further compression by encoding the light transport matrix sparsely but accurately in the same basis. Rendering is performed by multiplying a sparse light vector by a sparse transport matrix, which is very fast. For accurate rendering, using non-linear wavelets is an order of magnitude faster than using linear spherical harmonics, the current best technique. ", 
        "id": 149, 
        "title": "All-frequency shadows using non-linear wavelet lighting approximation."
    }, 
    {
        "abstract": "NumSplits fNues o GL Set Viewpoint Clip Planes & Translation s of GL ss n e n Original Application OpenGL Multiple Playback plits Pa nal Ope . lits Pass . ied Ope Multipass Composite mS rigi Sp odif . (a) System block diagram Set Viewpoint Clip Planes & Translation Num M Figure 1: Overview of our visualization system. (a) The system is divided into two stages; geometric analysis and rendering. Geometric analysis occurs once and determines where to section the environment into stories. Rendering occurs every frame and produces an interactive exploded view. Each box represents a computational operation and arrows represent data. (b) An exploded view of the dm7 environment from Quake III generated non-invasively by our system.", 
        "id": 150, 
        "title": "Non-invasive interactive visualization of dynamic architectural environments."
    }, 
    {
        "abstract": "We present a new shape representation, the multi-level partition of unity implicit surface, that allows us to construct surface models from very large sets of points. There are three key ingredients to our approach: 1) piecewise quadratic functions that capture the local shape of the surface, 2) weighting functions (the partitions of unity) that blend together these local shape functions, and 3) an octree subdivision method that adapts to variations in the complexity of the local shape. Our approach gives us considerable flexibility in the choice of local shape functions, and in particular we can accurately represent sharp features such as edges and corners by selecting appropriate shape functions. An error-controlled subdivision leads to an adaptive approximation whose time and memory consumption depends on the required accuracy. Due to the separation of local approximation and local blending, the representation is not global and can be created and evaluated rapidly. Because our surfaces are described using implicit functions, operations such as shape blending, offsets, deformations and CSG are simple to perform. ", 
        "id": 151, 
        "title": "Multi-level partition of unity implicits."
    }, 
    {
        "abstract": "For many systems that produce physically based animations, plausibility rather than accuracy is acceptable. We consider the problem of evaluating the visual quality of animations in which physical parameters have been distorted or degraded, either unavoidably due to real-time frame-rate requirements, or intentionally for aesthetic reasons. To date, no generic means of evaluating or predicting the fidelity, either physical or visual, of the dynamic events occurring in an animation exists. As a first step towards providing such a metric, we present a set of psychophysical experiments that established some thresholds for human sensitivity to dynamic anomalies, including angular, momentum and spatio-temporal distortions applied to simple animations depicting the elastic collision of two rigid objects. In addition to finding significant acceptance thresholds for these distortions under varying conditions, we identified some interesting biases that indicate non-symmetric responses to these distortions (e.g., expansion of the angle between postcollision trajectories was preferred to contraction and increases in velocity were preferred to decreases). Based on these results, we derived a set of probability functions that can be used to evaluate the visual fidelity of a physically based simulation. To illustrate how our results could be used, two simple case studies of simulation levels of detail and constrained dynamics are presented. ", 
        "id": 152, 
        "title": "Evaluating the visual fidelity of physically based animations."
    }, 
    {
        "abstract": " We introduce a novel \"sensation preserving\" simplification algorithm for faster collision queries between two polyhedral objects in haptic rendering. Given a polyhedral model, we construct a multiresolution hierarchy using \"filtered edge collapse\", subject to constraints imposed by collision detection. The resulting hierarchy is then used to compute fast contact response for haptic display. The computation model is inspired by human tactual perception of contact information. We have successfully applied and demonstrated the algorithm on a time-critical collision query framework for haptically displaying complex object-object interaction. Compared to existing exact contact query algorithms, we observe noticeable performance improvement in update rates with little degradation in the haptic perception of contacts.  ", 
        "id": 153, 
        "title": "Sensation preserving simplification for haptic rendering."
    }, 
    {
        "abstract": "We present a versatile and complete free-form shape modeling framework for point-sampled geometry. By combining unstructured point clouds with the implicit surface definition of the moving least squares approximation, we obtain a hybrid geometry representation that allows us to exploit the advantages of implicit and parametric surface models. Based on this representation we introduce a shape modeling system that enables the designer to perform large constrained deformations as well as boolean operations on arbitrarily shaped objects. Due to minimum consistency requirements, point-sampled surfaces can easily be re-structured on the fly to support extreme geometric deformations during interactive editing. In addition, we show that strict topology control is possible and sharp features can be generated and preserved on point-sampled objects. We demonstrate the effectiveness of our system on a large set of input models, including noisy range scans, irregular point clouds, and sparsely as well as densely sampled models. ", 
        "id": 154, 
        "title": "Shape modeling with point-sampled geometry."
    }, 
    {
        "abstract": "Using generic interpolation machinery based on solving Poisson equations, a variety of novel tools are introduced for seamless editing of image regions. The first set of tools permits the seamless importation of both opaque and transparent source image regions into a destination region. The second set is based on similar mathematical ideas and allows the user to modify the appearance of the image seamlessly, within a selected region. These changes can be arranged to affect the texture, the illumination, and the color of objects lying in the region, or to make tileable a rectangular selection. ", 
        "id": 155, 
        "title": "Poisson image editing."
    }, 
    {
        "abstract": "", 
        "id": 156, 
        "title": "Motion sketching for control of rigid-body simulations."
    }, 
    {
        "abstract": "The traditional approach for parametrizing a surface involves cutting it into charts and mapping these piecewise onto a planar domain. We introduce a robust technique for directly parametrizing a genus-zero surface onto a spherical domain. A key ingredient for making such a parametrization practical is the minimization of a stretch-based measure, to reduce scaledistortion and thereby prevent undersampling. Our second contribution is a scheme for sampling the spherical domain using uniformly subdivided polyhedral domains, namely the tetrahedron, octahedron, and cube. We show that these particular semiregular samplings can be conveniently represented as completely regular 2D grids, i.e. geometry images. Moreover, these images have simple boundary extension rules that aid many processing operations. Applications include geometry remeshing, level-ofdetail, morphing, compression, and smooth surface subdivision. ", 
        "id": 157, 
        "title": "Spherical parametrization and remeshing."
    }, 
    {
        "abstract": "Projectors are currently undergoing a transformation as they evolve from static output devices to portable, environment-aware, communicating systems. An enhanced projector can determine and respond to the geometry of the display surface, and can be used in an ad-hoc cluster to create a self-configuring display. Information display is such a prevailing part of everyday life that new and more flexible ways to present data are likely to have significant impact. This paper examines geometrical issues for enhanced projectors, relating to customized projection for different shapes of display surface, object augmentation, and co-operation between multiple units. We introduce a new technique for adaptive projection on nonplanar surfaces using conformal texture mapping. We describe object augmentation with a hand-held projector, including interaction techniques. We describe the concept of a display created by an ad-hoc cluster of heterogeneous enhanced projectors, with a new global alignment scheme, and new parametric image transfer methods for quadric surfaces, to make a seamless projection. The work is illustrated by several prototypes and applications. ", 
        "id": 158, 
        "title": "iLamps: geometrically aware and self-configuring projectors."
    }, 
    {
        "abstract": "In this paper, we present an efficient method for simulating highly detailed large scale participating media such as the nuclear explosions shown in figure 1. We capture this phenomena by simulating the motion of particles in a fluid dynamics generated velocity field. A novel aspect of this paper is the creation of highly detailed threedimensional turbulent velocity fields at interactive rates using a low to moderate amount of memory. The key idea is the combination of two-dimensional high resolution physically based flow fields with a moderate sized three-dimensional Kolmogorov velocity field tiled periodically in space. ", 
        "id": 159, 
        "title": "Smoke simulation for large scale phenomena."
    }, 
    {
        "abstract": "Motion capture data and techniques for blending, editing, and sequencing that data can produce rich, realistic character animation; however, the output of these motion processing techniques sometimes appears unnatural. For example, the motion may violate physical laws or reflect unreasonable forces from the character or the environment. While problems such as these can be fixed, doing so is not yet feasible in real time environments. We are interested in developing ways to estimate perceived error in animated human motion so that the output quality of motion processing techniques can be better controlled to meet user goals. This paper presents results of a study of user sensitivity to errors in animated human motion. Errors were systematically added to human jumping motion, and the ability of subjects to detect these errors was measured. We found that users were able to detect motion with errors, and noted some interesting trends: errors in horizontal velocity were easier to detect than errors in vertical velocity, and added accelerations were easier to detect than added decelerations. On the basis of our results, we propose a perceptually based metric for measuring errors in ballistic human motion. ", 
        "id": 160, 
        "title": "Perceptual metrics for character animation: sensitivity to errors in ballistic motion."
    }, 
    {
        "abstract": "We describe a method for the acquisition of deformable human geometry from silhouettes. Our technique uses a commercial tracking system to determine the motion of the skeleton, then estimates geometry for each bone using constraints provided by the silhouettes from one or more cameras. These silhouettes do not give a complete characterization of the geometry for a particular point in time, but when the subject moves, many observations of the same local geometries allow the construction of a complete model. Our reconstruction algorithm provides a simple mechanism for solving the problems of view aggregation, occlusion handling, hole filling, noise removal, and deformation modeling. The resulting model is parameterized to synthesize geometry for new poses of the skeleton. We demonstrate this capability by rendering the geometry for motion sequences that were not included in the original datasets. ", 
        "id": 161, 
        "title": "Continuous capture of skin deformation."
    }, 
    {
        "abstract": "This paper presents a generalization of non-uniform B-spline surfaces called T-splines. T-spline control grids permit Tjunctions, so lines of control points need not traverse the entire control grid. T-splines support many valuable operations within a consistent framework, such as local refinement, and the merging of several B-spline surfaces that have different knot vectors into a single gap-free model. The paper focuses on T-splines of degree three, which are C2 (in the absence of multiple knots). T-NURCCs (Non-Uniform Rational Catmull-Clark Surfaces with T-junctions) are a superset of both T-splines and Catmull-Clark surfaces. Thus, a modeling program for T-NURCCs can handle any NURBS or Catmull-Clark model as special cases. T-NURCCs enable true local refinement of a Catmull-Clark-type control grid: individual control points can be inserted only where they are needed to provide additional control, or to create a smoother tessellation, and such insertions do not alter the limit surface. T-NURCCs use stationary refinement rules and are C2 except at extraordinary points and features. ", 
        "id": 162, 
        "title": "T-splines and T-NURCCs."
    }, 
    {
        "abstract": "The most popular techniques for interactive rendering of hard shadows are shadow maps and shadow volumes. Shadow maps work well in regions that are completely in light or in shadow but result in objectionable artifacts near shadow boundaries. In contrast, shadow volumes generate precise shadow boundaries but require high fill rates. In this paper, we propose the method of silhouette maps, in which a shadow depth map is augmented by storing the location of points on the geometric silhouette. This allows the shader to construct a piecewise linear approximation to the true shadow silhouette, improving the visual quality over the piecewise constant approximation of conventional shadow maps. We demonstrate an implementation of our approach running on programmable graphics hardware in real-time. ", 
        "id": 163, 
        "title": "Shadow silhouette maps."
    }, 
    {
        "abstract": "", 
        "id": 164, 
        "title": "Constraint-based approach for automatic hinting of digital typefaces."
    }, 
    {
        "abstract": "We compress storage and accelerate performance of precomputed radiance transfer (PRT), which captures the way an object shadows, scatters, and reflects light. PRT records over many surface points a transfer matrix. At run-time, this matrix transforms a vector of spherical harmonic coefficients representing distant, low-frequency source lighting into exiting radiance. Per-point transfer matrices form a high-dimensional surface signal that we compress using clustered principal component analysis (CPCA), which partitions many samples into fewer clusters each approximating the signal as an affine subspace. CPCA thus reduces the high-dimensional transfer signal to a low-dimensional set of perpoint weights on a per-cluster set of representative matrices. Rather than computing a weighted sum of representatives and applying this result to the lighting, we apply the representatives to the lighting per-cluster (on the CPU) and weight these results perpoint (on the GPU). Since the output of the matrix is lowerdimensional than the matrix itself, this reduces computation. We also increase the accuracy of encoded radiance functions with a new least-squares optimal projection of spherical harmonics onto the hemisphere. We describe an implementation on graphics hardware that performs real-time rendering of glossy objects with dynamic self-shadowing and interreflection without fixing the view or light as in previous work. Our approach also allows significantly increased lighting frequency when rendering diffuse objects and includes subsurface scattering. ", 
        "id": 165, 
        "title": "Clustered principal components for precomputed radiance transfer."
    }, 
    {
        "abstract": "Radiance transfer represents how generic source lighting is shadowed and scattered by an object to produce view-dependent appearance. We generalize by rendering transfer at two scales. A macro-scale is coarsely sampled over an object's surface, providing global effects like shadows cast from an arm onto a body. A meso-scale is finely sampled over a small patch to provide local texture. Low-order (25D) spherical harmonics represent lowfrequency lighting dependence for both scales. To render, a coefficient vector representing distant source lighting is first transformed at the macro-scale by a matrix at each vertex of a coarse mesh. The resulting vectors represent a spatially-varying hemisphere of lighting incident to the meso-scale. A 4D function, called a radiance transfer texture (RTT), then specifies the surface's meso-scale response to each lighting basis component, as a function of a spatial index and a view direction. Finally, a 25D dot product of the macro-scale result vector with the vector looked up from the RTT performs the correct shading integral. We use an id map to place RTT samples from a small patch over the entire object; only two scalars are specified at high spatial resolution. Results show that bi-scale decomposition makes preprocessing practical and efficiently renders self-shadowing and interreflection effects from dynamic, low-frequency light sources at both scales. ", 
        "id": 166, 
        "title": "Bi-scale radiance transfer."
    }, 
    {
        "abstract": "", 
        "id": 167, 
        "title": "An efficient instantiation algorithm for simulating radiant energy transfer in plant models."
    }, 
    {
        "abstract": "", 
        "id": 168, 
        "title": "Errata: ACM SIGGRAPH 2002 Papers."
    }, 
    {
        "abstract": "In this paper we introduce a method to simulate fluid flows on smooth surfaces of arbitrary topology: an effect never seen before. We achieve this by combining a two-dimensional stable fluid solver with an atlas of parametrizations of a Catmull-Clark surface. The contributions of this paper are: (i) an extension of the Stable Fluids solver to arbitrary curvilinear coordinates, (ii) an elegant method to handle cross-patch boundary conditions and (iii) a set of new external forces custom tailored for surface flows. Our techniques can also be generalized to handle other types of processes on surfaces modeled by partial differential equations, such as reactiondiffusion. Some of our simulations allow a user to interactively place densities and apply forces to the surface, then watch their effects in real-time. We have also computed higher resolution animations of surface flows off-line. ", 
        "id": 169, 
        "title": "Flows on surfaces of arbitrary topology."
    }, 
    {
        "abstract": "", 
        "id": 170, 
        "title": "Geometric surface processing via normal maps."
    }, 
    {
        "abstract": "While 2D and 3D vector fields are ubiquitous in computational sciences, their use in graphics is often limited to regular grids, where computations are easily handled through finite-difference methods. In this paper, we propose a set of simple and accurate tools for the analysis of 3D discrete vector fields on arbitrary tetrahedral grids. We introduce a variational, multiscale decomposition of vector fields into three intuitive components: a divergence-free part, a curl-free part, and a harmonic part. We show how our discrete approach matches its well-known smooth analog, called the HelmotzHodge decomposition, and that the resulting computational tools have very intuitive geometric interpretation. We demonstrate the versatility of these tools in a series of applications, ranging from data visualization to fluid and deformable object simulation. ", 
        "id": 171, 
        "title": "Discrete multiscale vector field decomposition."
    }, 
    {
        "abstract": "We describe a method for controlling smoke simulations through user-specified keyframes. To achieve the desired behavior, a continuous quasi-Newton optimization solves for appropriate \"wind\" forces to be applied to the underlying velocity field throughout the simulation. The cornerstone of our approach is a method to efficiently compute exact derivatives through the steps of a fluid simulation. We formulate an objective function corresponding to how well a simulation matches the user's keyframes, and use the derivatives to solve for force parameters that minimize this function. For animations with several keyframes, we present a novel multipleshooting approach. By splitting large problems into smaller overlapping subproblems, we greatly speed up the optimization process while avoiding certain local minima. ", 
        "id": 172, 
        "title": "Keyframe control of smoke simulations."
    }, 
    {
        "abstract": "We review the Boom Chameleon, a novel input/output device consisting of a flat-panel display mounted on a tracked mechanical armature. The display acts as a physical window into 3D virtual environments, through which a one-to-one mapping between real and virtual space is preserved. The Boom Chameleon is further augmented with a touch-screen and a microphone/speaker combination. We created a 3D annotation application that exploits this unique configuration in order to simultaneously capture viewpoint, voice and gesture information. Results of an informal user study show that the Boom Chameleon annotation facilities have the potential to be an effective, and intuitive system for reviewing 3D designs. ", 
        "id": 173, 
        "title": "Boom chameleon: simultaneous capture of 3D viewpoint, voice and gesture annotations on a spatially-aware display."
    }, 
    {
        "abstract": "This paper proposes an E-cosmetic function for digital images based on physics and physiologically-based image processing. A practical skin color and texture analysis/synthesis technique is introduced for this E-cosmetic function. Shading on the face is removed by a simple color vector analysis in the optical density domain as an inverse lighting technique. The image without shading is analyzed by a previously introduced technique that extracts hemoglobin and melanin components by independent component analysis. Experimental results using UV-B irradiation and the application of methyl nicotinate on the arms support the physiological validity of the analysis and the effectiveness of the proposed shading removal. We synthesized the way facial images changed due to tanning or alcohol consumption, and compared the synthesized images with images of actual changes in skin color. The comparison shows an excellent match between the synthesized and actual images of changes due to tanning and alcohol consumption. We also proposed a technique to synthesize the change of texture in pigment due to aging or the application of cosmetics. The pyramid-based texture analysis/synthesis technique was used for the spatial processing of texture. Using the proposed technique, we could realistically change the skin color and texture of a 50 year-old woman to that of a 20 year-old woman. ", 
        "id": 174, 
        "title": "Image-based skin color and texture analysis/synthesis by extracting hemoglobin and melanin information in the skin."
    }, 
    {
        "abstract": "Significant visual effects arise from surface mesostructure, such as fine-scale shadowing, occlusion and silhouettes. To efficiently render its detailed appearance, we introduce a technique called viewdependent displacement mapping (VDM) that models surface displacements along the viewing direction. Unlike traditional displacement mapping, VDM allows for efficient rendering of selfshadows, occlusions and silhouettes without increasing the complexity of the underlying surface mesh. VDM is based on per-pixel processing, and with hardware acceleration it can render mesostructure with rich visual appearance in real time. ", 
        "id": 175, 
        "title": "View-dependent displacement mapping."
    }, 
    {
        "abstract": "We present an incremental algorithm to compute image-based simplifications of a large environment. We use an optimization-based approach to generate samples based on scene visibility, and from each viewpoint create textured depth meshes (TDMs) using sampled range panoramas of the environment. The optimization function minimizes artifacts such as skins and cracks in the reconstruction. We also present an encoding scheme for multiple TDMs that exploits spatial coherence among different viewpoints. The resulting simplifications, incremental textured depth meshes (ITDMs), reduce preprocessing, storage, rendering costs and visible artifacts. Our algorithm has been applied to large, complex synthetic environments comprising millions of primitives. It is able to render them at 20 - 40 frames a second on a PC with little loss in visual fidelity. ", 
        "id": 176, 
        "title": "Simplifying complex environments using incremental textured depth meshes."
    }, 
    {
        "abstract": "This paper presents a new method for the automatic modeling of architecture. Building designs are derived using split grammars, a new type of parametric set grammar based on the concept of shape. The paper also introduces an attribute matching system and a separate control grammar, which offer the flexibility required to model buildings using a large variety of different styles and design ideas. Through the adaptive nature of the design grammar used, the created building designs can either be generic or adhere closely to a specified goal, depending on the amount of data available. ", 
        "id": 177, 
        "title": "Instant architecture."
    }, 
    {
        "abstract": "In this paper we describe a physics-based method for synthesis of bird flight animations. Our method computes a realistic set of wingbeats that enables a bird to follow the specified trajectory. We model the bird as an articulated skeleton with elastically deformable feathers. The bird motion is created by applying joint torques and aerodynamic forces over time in a forward dynamics simulation. We solve for each wingbeat motion separately by optimizing for wingbeat parameters that create the most natural motion. The final animation is constructed by concatenating a series of optimal wingbeats. This detailed bird flight model enables us to produce flight motions of different birds performing a variety of maneuvers including taking off, cruising, rapidly descending, turning, and landing. ", 
        "id": 178, 
        "title": "Realistic modeling of bird flight animations."
    }, 
    {
        "abstract": "", 
        "id": 179, 
        "title": "List of reviewers."
    }, 
    {
        "abstract": "The Actuated Workbench is a device that uses magnetic forces to move objects on a table in two dimensions. It is intended for use with existing tabletop tangible interfaces, providing an additional feedback loop for computer output, and helping to resolve inconsistencies that otherwise arise from the computer's inability to move objects on the table. Introduction Tabletop tangible interfaces, or \"workbench interfaces,\" track objects on a flat surface and respond to users' physical input with graphical output. Systems such as [Wellner], [Fitzmaurice], [Underkoffler and Ishii], and [Patten et al.] offer many advantages over purely graphical interfaces, including the ability for users to organize data spatially, the potential for two-handed interaction, and ease of collaboration between collocated users. Current workbench systems share a common weakness. While input occurs through the physical manipulation of tangible objects, output is displayed only through sound or graphical projection on and around the objects. In addition, though the objects are intended to be physical instantiations of data information itself, this metaphor can break down when links between the digital data and the physical objects are broken. Such broken links can arise when a change occurs in the computer model that is not reflected in a physical change of its associated object. With the computer system unable to move objects on the table, physical interaction between human and computer remains one-sided. The Actuated Workbench addresses this issue by providing a hardware and software infrastructure for a computer to smoothly move objects in two dimensions on a table surface. Permission to make digital/hard copy of part of all of this work for personal or classroom use is granted without fee provided that the copies are not made or distributed for profit or commercial advantage, the copyright notice, the title of the publication, and its date appear, and notice is given that copying is by permission of ACM, Inc. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.  2003 ACM 0730-0301/03/0700-0699 $5.00  System Description and Motion Techniques The actuation platform consists of a 16.5cm (6.5\") fixed array of 64 electromagnets arranged in an 8 x 8 grid under a layer of 0.63cm (\") acrylic. Custom electronics drive each electromagnet in the array bi-directionally, making it possible to set the polarity and strength of each magnet's field through pulsewidth-modulation. Objects are tracked with a vision-based system that tracks infrared LED's in the pucks. The system's array-based design makes moving multiple objects simultaneously a simple matter of setting up separate magnetic fields in different areas of the array. Rotation of the objects can be controlled if objects are built with multiple permanent magnets. It is also possible to tile these arrays together to create a larger actuation area. With the Actuated Workbench, we are faced with a problem similar to that of anti-aliasing in computer graphics: we wish to render an analog signal (in this case, a force of a particular direction and magnitude) using a discrete array of cells (variableduty electromagnets). To do so, we employ a similar solution: the strength of each electromagnet is determined by the \"overlap\" of its magnetic flux lines with the location of the point force. Applications Basic GUI Functions. The actuated workbench can be used to provide physical versions of existing GUI functions. These include: search and retrieve, sort, history and undo, highlighting (getting attention), and guiding users in interactions. Remote Collaboration. The Actuated Workbench mechanism can be used to provide real-time physical synchronization of two tabletop interfaces for remote collaboration. Simulation Display (Eduacation). Actuation could help teach students about physics, demonstrating the attraction and repulsion of charged particles represented by moving pucks on the table. Entertainment. Though motorized chess sets have existed for many years, they operate using a single electromagnet mounted on an x-y plotter mechanism, which limits them to moving one object at a time. The Actuated Workbench could provide a significant improvement to these devices, making them more flexible for games that involve the simultaneous movement of multiple pieces. References FITZMAURICE, G.W., ISHII, H., AND BUXTON, W. Bricks: Laying the Foundations for Graspable User Interfaces. In Proceedings of CHI '95, ACM Press, pp. 442-449. PATTEN, J., ISHII, H., HINES, J., PANGARO, G. Sensetable: A Wireless Object Tracking Platform for Tangible User Interfaces. In Proceedings of CHI '01, ACM Press, pp. 253-260. UNDERKOFFLER, J. AND ISHII, H. Urp: A Luminous-Tangible Workbench for Urban Planning and Design. In Proceedings of CHI '99, ACM Press, pp. 386-393. WELLNER, P. Interacting with Paper on the DigitalDesk, Communications of the ACM, 1993. For full paper, published in Proc. of UIST 2002, please see: http://tangible.media.mit.edu/papers/Actuated_Workbench_UIST02/Actua ted_Workbench_UIST02.htm  699  \f ", 
        "id": 180, 
        "title": "The actuated workbench: computer-controlled actuation in tabletop tangible interfaces."
    }, 
    {
        "abstract": "We present an approach for decorating surfaces with progressivelyvariant textures. Unlike a homogeneous texture, a progressivelyvariant texture can model local texture variations, including the scale, orientation, color, and shape variations of texture elements. We describe techniques for modeling progressively-variant textures in 2D as well as for synthesizing them over surfaces. For 2D texture modeling, our feature-based warping technique allows the user to control the shape variations of texture elements, making it possible to capture complex texture variations such as those seen in animal coat patterns. In addition, our feature-based blending technique can create a smooth transition between two given homogeneous textures, with progressive changes of both shapes and colors of texture elements. For synthesizing textures over surfaces, the biggest challenge is that the synthesized texture elements tend to break apart as they progressively vary. To address this issue, we propose an algorithm based on texton masks, which mark most prominent texture elements in the 2D texture sample. By leveraging the power of texton masks, our algorithm can maintain the integrity of the synthesized texture elements on the target surface. ", 
        "id": 181, 
        "title": "Synthesis of progressively-variant textures on arbitrary surfaces."
    }, 
    {
        "abstract": "In this paper, we describe the use of threshold modulation to remove the visual artifacts contained in the variable-coefficient error-diffusion algorithm. To obtain a suitable parameter set for the threshold modulation, a cost function used for the search of optimal parameters is designed. An optimal diffusion parameter set, as well as the corresponding threshold modulation strength values, is thus obtained. Experiments over this new set of parameters show that, compared with the original variable-coefficient error-diffusion algorithm, threshold modulation can remove visual anomalies more effectively. The result of the new algorithm is an artifact-free halftoning in the full range of intensities. Fourier analysis of the experimental results further support this conclusion.", 
        "id": 182, 
        "title": "Improving mid-tone quality of variable-coefficient error diffusion using threshold modulation."
    }, 
    {
        "abstract": "We describe an interactive, computer-assisted framework for combining parts of a set of photographs into a single composite picture, a process we call \"digital photomontage.\" Our framework makes use of two techniques primarily: graph-cut optimization, to choose good seams within the constituent images so that they can be combined as seamlessly as possible; and gradient-domain fusion, a process based on Poisson equations, to further reduce any remaining visible artifacts in the composite. Also central to the framework is a suite of interactive tools that allow the user to specify a variety of high-level image objectives, either globally across the image, or locally through a painting-style interface. Image objectives are applied independently at each pixel location and generally involve a function of the pixel values (such as \"maximum contrast\") drawn from that same location in the set of source images. Typically, a user applies a series of image objectives iteratively in order to create a finished composite. The power of this framework lies in its generality; we show how it can be used for a wide variety of applications, including \"selective composites\" (for instance, group photos in which everyone looks their best), relighting, extended depth of field, panoramic stitching, clean-plate production, stroboscopic visualization of movement, and time-lapse mosaics. ", 
        "id": 183, 
        "title": "Interactive digital photomontage."
    }, 
    {
        "abstract": "We describe a new approach to rotoscoping -- the process of tracking contours in a video sequence -- that combines computer vision with user interaction. In order to track contours in video, the user specifies curves in two or more frames; these curves are used as keyframes by a computer-vision-based tracking algorithm. The user may interactively refine the curves and then restart the tracking algorithm. Combining computer vision with user interaction allows our system to track any sequence with significantly less effort than interpolation-based systems -- and with better reliability than \"pure\" computer vision systems. Our tracking algorithm is cast as a spacetime optimization problem that solves for time-varying curve shapes based on an input video sequence and user-specified constraints. We demonstrate our system with several rotoscoped examples. Additionally, we show how these rotoscoped contours can be used to help create cartoon animation by attaching user-drawn strokes to the tracked contours. ", 
        "id": 184, 
        "title": "Keyframe-based tracking for rotoscoping and animation."
    }, 
    {
        "abstract": "Typical stereo displays provide incorrect focus cues because the light comes from a single surface. We describe a prototype stereo display comprising two independent fixed-viewpoint volumetric displays. Like autostereoscopic volumetric displays, fixedviewpoint volumetric displays generate near-correct focus cues without tracking eye position, because light comes from sources at the correct focal distances. (In our prototype, from three image planes at different physical distances.) Unlike autostereoscopic volumetric displays, however, fixed-viewpoint volumetric displays retain the qualities of modern projective graphics: view-dependent lighting effects such as occlusion, specularity, and reflection are correctly depicted; modern graphics processor and 2-D display technology can be utilized; and realistic fields of view and depths of field can be implemented. While not a practical solution for general-purpose viewing, our prototype display is a proof of concept and a platform for ongoing vision research. The design, implementation, and verification of this stereo display are described, including a novel technique of filtering along visual lines using 1-D texture mapping. ", 
        "id": 185, 
        "title": "A stereo display prototype with multiple focal distances."
    }, 
    {
        "abstract": "The MLS surface [Levin 2003], used for modeling and rendering with point clouds, was originally defined algorithmically as the output of a particular meshless construction. We give a new explicit definition in terms of the critical points of an energy function on lines determined by a vector field. This definition reveals connections to research in computer vision and computational topology. Variants of the MLS surface can be created by varying the vector field and the energy function. As an example, we define a similar surface determined by a cloud of surfels (points equipped with normals), rather than points. We also observe that some procedures described in the literature to take points in space onto the MLS surface fail to do so, and we describe a simple iterative procedure which does. ", 
        "id": 186, 
        "title": "Defining point-set surfaces."
    }, 
    {
        "abstract": "This paper presents a novel algorithm for synthesizing and editing video of natural phenomena that exhibit continuous flow patterns. The algorithm analyzes the motion of textured particles in the input video along user-specified flow lines, and synthesizes seamless video of arbitrary length by enforcing temporal continuity along a second set of user-specified flow lines. The algorithm is simple to implement and use. We used this technique to edit video of waterfalls, rivers, flames, and smoke. ", 
        "id": 187, 
        "title": "Flow-based video synthesis and editing."
    }, 
    {
        "abstract": "We present a freeform modeling framework for unstructured triangle meshes which is based on constraint shape optimization. The goal is to simplify the user interaction even for quite complex freeform or multiresolution modifications. The user first sets various boundary constraints to define a custom tailored (abstract) basis function which is adjusted to a given design task. The actual modification is then controlled by moving one single 9-dof manipulator object. The technique can handle arbitrary support regions and piecewise boundary conditions with smoothness ranging continuously from C0 to C2. To more naturally adapt the modification to the shape of the support region, the deformed surface can be tuned to bend with anisotropic stiffness. We are able to achieve real-time response in an interactive design session even for complex meshes by precomputing a set of scalar-valued basis functions that correspond to the degrees of freedom of the manipulator by which the user controls the modification. ", 
        "id": 188, 
        "title": "An intuitive framework for real-time freeform modeling."
    }, 
    {
        "abstract": "", 
        "id": 189, 
        "title": "Adaptive medial-axis approximation for sphere-tree construction."
    }, 
    {
        "abstract": "In this paper, we present Brook for GPUs, a system for general-purpose computation on programmable graphics hardware. Brook extends C to include simple data-parallel constructs, enabling the use of the GPU as a streaming coprocessor. We present a compiler and runtime system that abstracts and virtualizes many aspects of graphics hardware. In addition, we present an analysis of the effectiveness of the GPU as a compute engine compared to the CPU, to determine when the GPU can outperform the CPU for a particular algorithm. We evaluate our system with five applications, the SAXPY and SGEMV BLAS operators, image segmentation, FFT, and ray tracing. For these applications, we demonstrate that our Brook implementations perform comparably to hand-written GPU code and up to seven times faster than their CPU counterparts. ", 
        "id": 190, 
        "title": "Brook for GPUs: stream computing on graphics hardware."
    }, 
    {
        "abstract": "A passive wand tracked in 3D using computer vision techniques is explored as a new input mechanism for interacting with large displays. We demonstrate a variety of interaction techniques and visual widgets that exploit the affordances of the wand, resulting in an effective interface for large scale display interaction. The lack of any buttons or other electronics on the wand presents a challenge that we address by developing a set of gestures and postures to track state and enable command input. ", 
        "id": 191, 
        "title": "VisionWand: interaction techniques for large displays using a passive wand tracked in 3D."
    }, 
    {
        "abstract": "We present the Rigid Fluid method, a technique for animating the interplay between rigid bodies and viscous incompressible fluid with free surfaces. We use distributed Lagrange multipliers to ensure two-way coupling that generates realistic motion for both the solid objects and the fluid as they interact with one another. We call our method the rigid fluid method because the simulator treats the rigid objects as if they were made of fluid. The rigidity of such an object is maintained by identifying the region of the velocity field that is inside the object and constraining those velocities to be rigid body motion. The rigid fluid method is straightforward to implement, incurs very little computational overhead, and can be added as a bridge between current fluid simulators and rigid body solvers. Many solid objects of different densities (e.g., wood or lead) can be combined in the same animation. ", 
        "id": 192, 
        "title": "Rigid fluid: animating the interplay between rigid bodies and fluid."
    }, 
    {
        "abstract": "Surface painting is a technique that allows a user to paint a texture directly onto a surface, usually with a texture atlas: a 1:1 mapping between the surface and its texture image. Many good automatic texture atlas generation methods exist that evenly distribute texture samples across a surface based on its area and/or curvature, and some are even sensitive to the frequency spectrum of the input texture. However, during the surface painting process, the texture can change non-uniformly and unpredictably and even the best atlases are static and can thus fail to reproduce sections of finely painted detail such as surface illustration. We present a new texture atlas algorithm that distributes initial texture samples evenly according to surface area and texture frequency, and, more importantly, maintains this distribution as the texture signal changes during the surface painting process. The running time is further accelerated with a novel GPU implementation of the surface painting process. The redistribution of samples is transparent to the user, resulting in a surface painting system of seemingly unlimited resolution. The atlas construction is local, making it fast enough to run interactively on models containing over 100K faces. ", 
        "id": 193, 
        "title": "Painting detail."
    }, 
    {
        "abstract": "We propose a texture function for realistic modeling and efficient rendering of materials that exhibit surface mesostructures, translucency and volumetric texture variations. The appearance of such complex materials for dynamic lighting and viewing directions is expensive to calculate and requires an impractical amount of storage to precompute. To handle this problem, our method models an object as a shell layer, formed by texture synthesis of a volumetric material sample, and a homogeneous inner core. To facilitate computation of surface radiance from the shell layer, we introduce the shell texture function (STF) which describes voxel irradiance fields based on precomputed fine-level light interactions such as shadowing by surface mesostructures and scattering of photons inside the object. Together with a diffusion approximation of homogeneous inner core radiance, the STF leads to fast and detailed raytraced renderings of complex materials. ", 
        "id": 194, 
        "title": "Shell texture functions."
    }, 
    {
        "abstract": "We describe an efficient technique for out-of-core construction and accurate view-dependent visualization of very large surface models. The method uses a regular conformal hierarchy of tetrahedra to spatially partition the model. Each tetrahedral cell contains a precomputed simplified version of the original model, represented using cache coherent indexed strips for fast rendering. The representation is constructed during a fine-to-coarse simplification of the surface contained in diamonds (sets of tetrahedral cells sharing their longest edge). The construction preprocess operates out-of-core and parallelizes nicely. Appropriate boundary constraints are introduced in the simplification to ensure that all conforming selective subdivisions of the tetrahedron hierarchy lead to correctly matching surface patches. For each frame at runtime, the hierarchy is traversed coarse-to-fine to select diamonds of the appropriate resolution given the view parameters. The resulting system can intera-tively render high quality views of out-of-core models of hundreds of millions of triangles at over 40Hz (or 70M triangles/s) on current commodity graphics platforms.", 
        "id": 195, 
        "title": "Adaptive tetrapuzzles: efficient out-of-core construction and visualization of gigantic multiresolution polygonal models."
    }, 
    {
        "abstract": "A method for concise, faithful approximation of complex 3D datasets is key to reducing the computational cost of graphics applications. Despite numerous applications ranging from geometry compression to reverse engineering, efficiently capturing the geometry of a surface remains a tedious task. In this paper, we present both theoretical and practical contributions that result in a novel and versatile framework for geometric approximation of surfaces. We depart from the usual strategy by casting shape approximation as a variational geometric partitioning problem. Using the concept of geometric proxies, we drive the distortion error down through repeated clustering of faces into best-fitting regions. Our approach is entirely discrete and error-driven, and does not require parameterization or local estimations of differential quantities. We also introduce a new metric based on normal deviation, and demonstrate its superior behavior at capturing anisotropy. ", 
        "id": 196, 
        "title": "Variational shape approximation."
    }, 
    {
        "abstract": "We enhance photographs shot in dark environments by combining a picture taken with the available light and one taken with the flash. We preserve the ambiance of the original lighting and insert the sharpness from the flash image. We use the bilateral filter to decompose the images into detail and large scale. We reconstruct the image using the large scale of the available lighting and the detail of the flash. We detect and correct flash shadows. This combines the advantages of available illumination and flash photography. ", 
        "id": 197, 
        "title": "Flash photography enhancement via intrinsic relighting."
    }, 
    {
        "abstract": "We combine existing techniques for shape-from-shading and texture synthesis to create a new tool for texturing objects in photographs. Our approach clusters pixels with similar recovered normals into patches on which texture is synthesized. Distorting the texture based on the recovered normals creates the illusion that the texture adheres to the undulations of the photographed surface. Inconsistencies in the recovered surface are disguised by the graphcut blending of the individually textured patches. Further applications include the generation of detail on manually-shaded painting, extracting and synthesizing a displacement map from a texture swatch, and the embossed transfer of normals from one image to another, which would be difficult to create with current image processing packages. ", 
        "id": 198, 
        "title": "Textureshop: texture synthesis as a photograph editing tool."
    }, 
    {
        "abstract": "In this paper we present a new method for efficiently controlling animated smoke. Given a sequence of target smoke states, our method generates a smoke simulation in which the smoke is driven towards each of these targets in turn, while exhibiting natural-looking interesting smoke-like behavior. This control is made possible by two new terms that we add to the standard flow equations: (i) a driving force term that causes the fluid to carry the smoke towards a particular target, and (ii) a smoke gathering term that prevents the smoke from diffusing too much. These terms are explicitly defined by the instantaneous state of the system at each simulation timestep. Thus, no expensive optimization is required, allowing complex smoke animations to be generated with very little additional cost compared to ordinary flow simulations. ", 
        "id": 199, 
        "title": "Target-driven smoke animation."
    }, 
    {
        "abstract": "", 
        "id": 200, 
        "title": "GADGET: a toolkit for optimization-based approaches to interface and display generation."
    }, 
    {
        "abstract": "", 
        "id": 201, 
        "title": "Variational normal meshes."
    }, 
    {
        "abstract": "In this paper, we investigate a data-driven synthesis approach to constructing 3D geometric surface models. We provide methods with which a user can search a large database of 3D meshes to find parts of interest, cut the desired parts out of the meshes with intelligent scissoring, and composite them together in different ways to form new objects. The main benefit of this approach is that it is both easy to learn and able to produce highly detailed geometric models  the conceptual design for new models comes from the user, while the geometric details come from examples in the database. The focus of the paper is on the main research issues motivated by the proposed approach: (1) interactive segmentation of 3D surfaces, (2) shape-based search to find 3D models with parts matching a query, and (3) composition of parts to form new models. We provide new research contributions on all three topics and incorporate them into a prototype modeling system. Experience with our prototype system indicates that it allows untrained users to create interesting and detailed 3D models. ", 
        "id": 202, 
        "title": "Modeling by example."
    }, 
    {
        "abstract": "Translucent objects are characterized by diffuse light scattering beneath the object's surface. Light enters and leaves an object at possibly distinct surface locations. This paper presents the first method to acquire this transport behavior for arbitrary inhomogeneous objects. Individual surface points are illuminated in our DISCO measurement facility and the object's impulse response is recorded with a high-dynamic range video camera. The acquired data is resampled into a hierarchical model of the object's light scattering properties. Missing values are consistently interpolated resulting in measurement-based, complete and accurate representations of real translucent objects which can be rendered with various algorithms. ", 
        "id": 203, 
        "title": "DISCO: acquisition of translucent objects."
    }, 
    {
        "abstract": "This paper describes a technique for animating the behavior of viscoelastic fluids, such as mucus, liquid soap, pudding, toothpaste, or clay, that exhibit a combination of both fluid and solid characteristics. The technique builds upon prior Eulerian methods for animating incompressible fluids with free surfaces by including additional elastic terms in the basic Navier-Stokes equations. The elastic terms are computed by integrating and advecting strain-rate throughout the fluid. Transition from elastic resistance to viscous flow is controlled by von Mises's yield condition, and subsequent behavior is then governed by a quasi-linear plasticity model. ", 
        "id": 204, 
        "title": "A method for animating viscoelastic fluids."
    }, 
    {
        "abstract": "", 
        "id": 205, 
        "title": "A novel cubic-order algorithm for approximating principal direction vectors."
    }, 
    {
        "abstract": "", 
        "id": 206, 
        "title": "Human facial illustrations: Creation and psychophysical evaluation."
    }, 
    {
        "abstract": "", 
        "id": 207, 
        "title": "A final reconstruction approach for a unified global illumination algorithm."
    }, 
    {
        "abstract": "This paper presents an inverse kinematics system based on a learned model of human poses. Given a set of constraints, our system can produce the most likely pose satisfying those constraints, in realtime. Training the model on different input data leads to different styles of IK. The model is represented as a probability distribution over the space of all possible poses. This means that our IK system can generate any pose, but prefers poses that are most similar to the space of poses in the training data. We represent the probability with a novel model called a Scaled Gaussian Process Latent Variable Model. The parameters of the model are all learned automatically; no manual tuning is required for the learning component of the system. We additionally describe a novel procedure for interpolating between styles. Our style-based IK can replace conventional IK, wherever it is used in computer animation and computer vision. We demonstrate our system in the context of a number of applications: interactive character posing, trajectory keyframing, real-time motion capture with missing markers, and posing from a 2D image. ", 
        "id": 208, 
        "title": "Style-based inverse kinematics."
    }, 
    {
        "abstract": "We present an algorithm for rendering faceted colored gemstones in real time, using graphics hardware. Beyond the technical challenge of handling the complex behavior of light in such objects, a real time high quality rendering of gemstones has direct applications in the field of jewelry prototyping, which has now become a standard practice for replacing tedious (and less interactive) wax carving methods. Our solution is based on a number of controlled approximations of the physical phenomena involved when light enters a stone, which permit an implementation based on the most recent  yet commonly available  hardware features such as fragment programs, cube-mapping. ", 
        "id": 209, 
        "title": "Graphics gems revisited: fast and physically-based rendering of gemstones."
    }, 
    {
        "abstract": " We present the CAT (Control Action Table), a 6 degrees of freedom freestanding input device designed for interaction with Virtual Environments displayed on huge screens. Both isotonic and isometric sensing modes allow the user to easily and efficiently perform 3D interaction techniques. A 2D tablet fixed on the tabletop allows them to perform accurate 2D interaction techniques.  ", 
        "id": 210, 
        "title": "The CAT for efficient 2D and 3D interaction as an alternative to mouse adaptations."
    }, 
    {
        "abstract": "", 
        "id": 211, 
        "title": "Real-time rendering of translucent meshes."
    }, 
    {
        "abstract": "In this paper we examine to what extent the lengths of the links in an animated articulated-figure can be changed without the viewer being aware of the change. This is investigated in terms of a framework that emphasizes the role of attention in visual perception. We conducted a set of five experiments to establish bounds for the sensitivity to changes in length as a function of several parameters and the amount of attention available. We found that while length changes of 3% can be perceived when the relevant links are given full attention, changes of over 20% can go unnoticed when attention is not focused in this way. These results provide general guidelines for algorithms that produce or process character motion data and also bring to light some of the potential gains that stand to be achieved with attention-based algorithms. ", 
        "id": 212, 
        "title": "Obscuring length changes during animated motion."
    }, 
    {
        "abstract": "", 
        "id": 213, 
        "title": "Perceptually based brush strokes for nonphotorealistic visualization."
    }, 
    {
        "abstract": "We propose a new powerful way of synthesizing moir images that enables the creation of dynamically moving messages incorporating text, symbols, and color elements. Moir images appear when superposing a base layer made of replicated base bands and a revealing layer made of a line grating comprising thin transparent lines. Each replicated base band contains the same image, e.g. text or color motifs. Since the base bands and the revealing line grating have similar periods, the revealed moir image is the image located within each base band, enlarged along one dimension. By considering the formation of the moir image as a line sampling process, we derive the linear transformation between the base layer and the moir image. We obtain the geometric layout of the resulting moir image, i.e. its orientation, size and displacement direction when moving the revealing layer on top of the base layer. Interesting moir images can be synthesized by applying geometric transformations to both the base and the revealing layers. We propose a mathematical model describing the geometric transformation that a moir image undergoes, when its base layer and its revealing layer are subject to different freely chosen non-linear geometric transformations. By knowing in advance the layout of a moir image as a function of the layouts of the base layer and of the revealing layer, we are able to create moir components running up and down at different speeds and orientations upon translation of the revealing layer. We also derive layer transformations which yield periodic moir images despite the fact that both the base and the revealing layers are curved. By offering a new means of artistic expression, band moir images can be used to create new designs and to synthesize visually appealing applications. ", 
        "id": 214, 
        "title": "Band moir\u00e9 images."
    }, 
    {
        "abstract": "Variational interpolation in curved geometries has many applications, so there has always been demand for geometrically meaningful and efficiently computable splines in manifolds. We extend the definition of the familiar cubic spline curves and splines in tension, and we show how to compute these on parametric surfaces, level sets, triangle meshes, and point samples of surfaces. This list is more comprehensive than it looks, because it includes variational motion design for animation, and allows the treatment of obstacles via barrier surfaces. All these instances of the general concept are handled by the same geometric optimization algorithm, which minimizes an energy of curves on surfaces of arbitrary dimension and codimension. ", 
        "id": 215, 
        "title": "Energy-minimizing splines in manifolds."
    }, 
    {
        "abstract": "", 
        "id": 216, 
        "title": "On the support of recursive subdivision."
    }, 
    {
        "abstract": "We describe the use of traditional stereological methods to synthesize 3D solid textures from 2D images of existing materials. We first illustrate our approach for aggregate materials of spherical particles, and then extend the technique to apply to particles of arbitrary shapes. We demonstrate the effectiveness of the approach with side-by-side comparisons of a real material and a synthetic model with its appearance parameters derived from its physical counterpart. Unlike ad hoc methods for texture synthesis, stereology provides a disciplined, systematic basis for predicting material structure with well-defined assumptions. ", 
        "id": 217, 
        "title": "Stereological techniques for solid textures."
    }, 
    {
        "abstract": "We introduce the Bounded Deformation Tree, or BD-Tree, which can perform collision detection with reduced deformable models at costs comparable to collision detection with rigid objects. Reduced deformable models represent complex deformations as linear superpositions of arbitrary displacement fields, and are used in a variety of applications of interactive computer graphics. The BD-Tree is a bounding sphere hierarchy for output-sensitive collision detection with such models. Its bounding spheres can be updated after deformation in any order, and at a cost independent of the geometric complexity of the model; in fact the cost can be as low as one multiplication and addition per tested sphere, and at most linear in the number of reduced deformation coordinates. We show that the BDTree is also extremely simple to implement, and performs well in practice for a variety of real-time and complex off-line deformable simulation examples. ", 
        "id": 218, 
        "title": "BD-tree: output-sensitive collision detection for reduced deformable models."
    }, 
    {
        "abstract": "We present a robust method for repairing arbitrary polygon models. The method is guaranteed to produce a closed surface that partitions the space into disjoint internal and external volumes. Given any model represented as a polygon soup, we construct an inside/outside volume using an octree grid, and reconstruct the surface by contouring. Our novel algorithm can efficiently process large models containing millions of polygons and is capable of reproducing sharp features in the original geometry. ", 
        "id": 219, 
        "title": "Robust repair of polygonal models."
    }, 
    {
        "abstract": "", 
        "id": 220, 
        "title": "Islamic star patterns in absolute geometry."
    }, 
    {
        "abstract": "With recent improvements in methods for the acquisition and rendering of 3D models, the need for retrieval of models has gained prominence in the graphics and vision communities. A variety of methods have been proposed that enable the efficient querying of model repositories for a desired 3D shape. Many of these methods use a 3D model as a query and attempt to retrieve models from the database that have a similar shape. In this paper we consider the implications of anisotropy on the shape matching paradigm. In particular, we propose a novel method for matching 3D models that factors the shape matching equation as the disjoint outer product of anisotropy and geometric comparisons. We provide a general method for computing the factored similarity metric and show how this approach can be applied to improve the matching performance of many existing shape matching methods. ", 
        "id": 221, 
        "title": "Shape matching and anisotropy."
    }, 
    {
        "abstract": "Valuable 3D graphical models, such as high-resolution digital scans of cultural heritage objects, may require protection to prevent piracy or misuse, while still allowing for interactive display and manipulation by a widespread audience. We have investigated techniques for protecting 3D graphics content, and we have developed a remote rendering system suitable for sharing archives of 3D models while protecting the 3D geometry from unauthorized extraction. The system consists of a 3D viewer client that includes lowresolution versions of the 3D models, and a rendering server that renders and returns images of high-resolution models according to client requests. The server implements a number of defenses to guard against 3D reconstruction attacks, such as monitoring and limiting request streams, and slightly perturbing and distorting the rendered images. We consider several possible types of reconstruction attacks on such a rendering server, and we examine how these attacks can be defended against without excessively compromising the interactive experience for non-malicious users. ", 
        "id": 222, 
        "title": "Protected interactive 3D graphics via remote rendering."
    }, 
    {
        "abstract": "Large motion data sets often contain many variants of the same kind of motion, but without appropriate tools it is difficult to fully exploit this fact. This paper provides automated methods for identifying logically similar motions in a data set and using them to build a continuous and intuitively parameterized space of motions. To find logically similar motions that are numerically dissimilar, our search method employs a novel distance metric to find \"close\" motions and then uses them as intermediaries to find more distant motions. Search queries are answered at interactive speeds through a precomputation that compactly represents all possibly similar motion segments. Once a set of related motions has been extracted, we automatically register them and apply blending techniques to create a continuous space of motions. Given a function that defines relevant motion parameters, we present a method for extracting motions from this space that accurately possess new parameters requested by the user. Our algorithm extends previous work by explicitly constraining blend weights to reasonable values and having a run-time cost that is nearly independent of the number of example motions. We present experimental results on a test data set of 37, 000 frames, or about ten minutes of motion sampled at 60 Hz. ", 
        "id": 223, 
        "title": "Automated extraction and parameterization of motions in large data sets."
    }, 
    {
        "abstract": "Many geometry processing applications, such as morphing, shape blending, transfer of texture or material properties, and fitting template meshes to scan data, require a bijective mapping between two or more models. This mapping, or crossparameterization, typically needs to preserve the shape and features of the parameterized models, mapping legs to legs, ears to ears, and so on. Most of the applications also require the models to be represented by compatible meshes, i.e. meshes with identical connectivity, based on the cross-parameterization. In this paper we introduce novel methods for shape preserving cross-parameterization and compatible remeshing. Our crossparameterization method computes a low-distortion bijective mapping between models that satisfies user prescribed constraints. Using this mapping, the remeshing algorithm preserves the user-defined feature vertex correspondence and the shape correlation between the models. The remeshing algorithm generates output meshes with significantly fewer elements compared to previous techniques, while accurately approximating the input geometry. As demonstrated by the examples, the compatible meshes we construct are ideally suitable for morphing and other geometry processing applications. ", 
        "id": 224, 
        "title": "Cross-parameterization and compatible remeshing of 3D models."
    }, 
    {
        "abstract": "We present mathematical sketching, a novel, pen-based, modeless gestural interaction paradigm for mathematics problem solving. Mathematical sketching derives from the familiar pencil-and-paper process of drawing supporting diagrams to facilitate the formulation of mathematical expressions; however, with a mathematical sketch, users can also leverage their physical intuition by watching their hand-drawn diagrams animate in response to continuous or discrete parameter changes in their written formulas. Diagram animation is driven by implicit associations that are inferred, either automatically or with gestural guidance, from mathematical expressions, diagram labels, and drawing elements. The modeless nature of mathematical sketching enables users to switch freely between modifying diagrams or expressions and viewing animations. Mathematical sketching can also support computational tools for graphing, manipulating and solving equations; initial feedback from a small user group of our mathematical sketching prototype application, MathPad2, suggests that it has the potential to be a powerful tool for mathematical problem solving and visualization. ", 
        "id": 225, 
        "title": "MathPad2: a system for the creation and exploration of mathematical sketches."
    }, 
    {
        "abstract": "High-quality Monte Carlo image synthesis requires the ability to importance sample realistic BRDF models. However, analytic sampling algorithms exist only for the Phong model and its derivatives such as Lafortune and Blinn-Phong. This paper demonstrates an importance sampling technique for a wide range of BRDFs, including complex analytic models such as Cook-Torrance and measured materials, which are being increasingly used for realistic image synthesis. Our approach is based on a compact factored representation of the BRDF that is optimized for sampling. We show that our algorithm consistently offers better efficiency than alternatives that involve fitting and sampling a Lafortune or Blinn-Phong lobe, and is more compact than sampling strategies based on tabulating the full BRDF. We are able to efficiently create images involving multiple measured and analytic BRDFs, under both complex direct lighting and global illumination. ", 
        "id": 226, 
        "title": "Efficient BRDF importance sampling using a factored representation."
    }, 
    {
        "abstract": "Colorization is a computer-assisted process of adding color to a monochrome image or movie. The process typically involves segmenting images into regions and tracking these regions across image sequences. Neither of these tasks can be performed reliably in practice; consequently, colorization requires considerable user intervention and remains a tedious, time-consuming, and expensive task. In this paper we present a simple colorization method that requires neither precise image segmentation, nor accurate region tracking. Our method is based on a simple premise: neighboring pixels in space-time that have similar intensities should have similar colors. We formalize this premise using a quadratic cost function and obtain an optimization problem that can be solved efficiently using standard techniques. In our approach an artist only needs to annotate the image with a few color scribbles, and the indicated colors are automatically propagated in both space and time to produce a fully colorized image or sequence. We demonstrate that high quality colorizations of stills and movie clips may be obtained from a relatively modest amount of user input. ", 
        "id": 227, 
        "title": "Colorization using optimization."
    }, 
    {
        "abstract": "Confocal microscopy is a family of imaging techniques that employ focused patterned illumination and synchronized imaging to create cross-sectional views of 3D biological specimens. In this paper, we adapt confocal imaging to large-scale scenes by replacing the optical apertures used in microscopy with arrays of real or virtual video projectors and cameras. Our prototype implementation uses a video projector, a camera, and an array of mirrors. Using this implementation, we explore confocal imaging of partially occluded environments, such as foliage, and weakly scattering environments, such as murky water. We demonstrate the ability to selectively image any plane in a partially occluded environment, and to see further through murky water than is otherwise possible. By thresholding the confocal images, we extract mattes that can be used to selectively illuminate any plane in the scene. ", 
        "id": 228, 
        "title": "Synthetic aperture confocal imaging."
    }, 
    {
        "abstract": "Although existing GUIs have a sense of space, they provide no sense of place. Numerous studies report that users misplace files and have trouble wayfinding in virtual worlds despite the fact that people have remarkable visual and spatial abilities. This issue is considered in the human-computer interface field and has been addressed with alternate display/navigation schemes. Our paper presents a fundamentally graphics based approach to this `lost in hyperspace' problem. Specifically, we propose that spatial display of files is not sufficient to engage our visual skills; scenery (distinctive visual appearance) is needed as well. While scenery (in the form of custom icon assignments) is already possible in current operating systems, few if any users take the time to manually assign icons to all their files. As such, our proposal is to generate visually distinctive icons (\"VisualIDs\") automatically, while allowing the user to replace the icon if desired. The paper discusses psychological and conceptual issues relating to icons, visual memory, and the necessary relation of scenery to data. A particular icon generation algorithm is described; subjects using these icons in simulated file search and recall tasks show significantly improved performance with little effort. Although the incorporation of scenery in a graphical user interface will introduce many new (and interesting) design problems that cannot be addressed in this paper, we show that automatically created scenery is both beneficial and feasible. ", 
        "id": 229, 
        "title": "VisualIDs: automatic distinctive icons for desktop interfaces."
    }, 
    {
        "abstract": "In this paper, we present Lazy Snapping, an interactive image cutout tool. Lazy Snapping separates coarse and fine scale processing, making object specification and detailed adjustment easy. Moreover, Lazy Snapping provides instant visual feedback, snapping the cutout contour to the true object boundary efficiently despite the presence of ambiguous or low contrast edges. Instant feedback is made possible by a novel image segmentation algorithm which combines graph cut with pre-computed over-segmentation. A set of intuitive user interface (UI) tools is designed and implemented to provide flexible control and editing for the users. Usability studies indicate that Lazy Snapping provides a better user experience and produces better segmentation results than the state-of-the-art interactive image cutout tool, Magnetic Lasso in Adobe Photoshop. ", 
        "id": 230, 
        "title": "Lazy snapping."
    }, 
    {
        "abstract": "A near-regular texture deviates geometrically and photometrically from a regular congruent tiling. Although near-regular textures are ubiquitous in the man-made and natural world, they present computational challenges for state of the art texture analysis and synthesis algorithms. Using regular tiling as our anchor point, and with user-assisted lattice extraction, we can explicitly model the deformation of a near-regular texture with respect to geometry, lighting and color. We treat a deformation field both as a function that acts on a texture and as a texture that is acted upon, and develop a multimodal framework where each deformation field is subject to analysis, synthesis and manipulation. Using this formalization, we are able to construct simple parametric models to faithfully synthesize the appearance of a near-regular texture and purposefully control its regularity. ", 
        "id": 231, 
        "title": "Near-regular texture analysis and manipulation."
    }, 
    {
        "abstract": "We present a method for simulating water and smoke on an unrestricted octree data structure exploiting mesh refinement techniques to capture the small scale visual detail. We propose a new technique for discretizing the Poisson equation on this octree grid. The resulting linear system is symmetric positive definite enabling the use of fast solution methods such as preconditioned conjugate gradients, whereas the standard approximation to the Poisson equation on an octree grid results in a non-symmetric linear system which is more computationally challenging to invert. The semi-Lagrangian characteristic tracing technique is used to advect the velocity, smoke density, and even the level set making implementation on an octree straightforward. In the case of smoke, we have multiple refinement criteria including object boundaries, optical depth, and vorticity concentration. In the case of water, we refine near the interface as determined by the zero isocontour of the level set function. ", 
        "id": 232, 
        "title": "Simulating water and smoke with an octree data structure."
    }, 
    {
        "abstract": "Rendering throughput has reached a level that enables a novel approach to level-of-detail (LOD) control in terrain rendering. We introduce the geometry clipmap, which caches the terrain in a set of nested regular grids centered about the viewer. The grids are stored as vertex buffers in fast video memory, and are incrementally refilled as the viewpoint moves. This simple framework provides visual continuity, uniform frame rate, complexity throttling, and graceful degradation. Moreover it allows two new exciting real-time functionalities: decompression and synthesis. Our main dataset is a 40GB height map of the United States. A compressed image pyramid reduces the size by a remarkable factor of 100, so that it fits entirely in memory. This compressed data also contributes normal maps for shading. As the viewer approaches the surface, we synthesize grid levels finer than the stored terrain using fractal noise displacement. Decompression, synthesis, and normal-map computations are incremental, thereby allowing interactive flight at 60 frames/sec. ", 
        "id": 233, 
        "title": "Geometry clipmaps: terrain rendering using nested regular grids."
    }, 
    {
        "abstract": "Due to rapid technological progress in high dynamic range (HDR) video capture and display, the efficient storage and transmission of such data is crucial for the completeness of any HDR imaging pipeline. We propose a new approach for inter-frame encoding of HDR video, which is embedded in the well-established MPEG4 video compression standard. The key component of our technique is luminance quantization that is optimized for the contrast threshold perception in the human visual system. The quantization scheme requires only 1011 bits to encode 12 orders of magnitude of visible luminance range and does not lead to perceivable contouring artifacts. Besides video encoding, the proposed quantization provides perceptually-optimized luminance sampling for fast implementation of any global tone mapping operator using a lookup table. To improve the quality of synthetic video sequences, we introduce a coding scheme for discrete cosine transform (DCT) blocks with high contrast. We demonstrate the capabilities of HDR video in a player, which enables decoding, tone mapping, and applying post-processing effects in real-time. The tone mapping algorithm as well as its parameters can be changed interactively while the video is playing. We can simulate post-processing effects such as glare, night vision, and motion blur, which appear very realistic due to the usage of HDR data. ", 
        "id": 234, 
        "title": "Perception-motivated high dynamic range video encoding."
    }, 
    {
        "abstract": "Reconstructing and rendering trees is a challenging problem due to the geometric complexity involved, and the inherent difficulties of capture. In this paper we propose a volumetric approach to capture and render trees with relatively sparse foliage. Photographs of such trees typically have single pixels containing the blended projection of numerous leaves/branches and background. We show how we estimate opacity values on a recursive grid, based on alphamattes extracted from a small number of calibrated photographs of a tree. This data structure is then used to render billboards attached to the centers of the grid cells. Each billboard is assigned a set of view-dependent textures corresponding to each input view. These textures are generated by approximating coverage masks based on opacity and depth from the camera. Rendering is performed using a view-dependent texturing algorithm. The resulting volumetric tree structure has low polygon count, permitting interactive rendering of realistic 3D trees. We illustrate the implementation of our system on several different real trees, and show that we can insert the resulting model in virtual scenes. ", 
        "id": 235, 
        "title": "Volumetric reconstruction and interactive rendering of trees from photographs."
    }, 
    {
        "abstract": "Three-dimensional TV is expected to be the next revolution in the history of television. We implemented a 3D TV prototype system with real-time acquisition, transmission, and 3D display of dynamic scenes. We developed a distributed, scalable architecture to manage the high computation and bandwidth demands. Our system consists of an array of cameras, clusters of network-connected PCs, and a multi-projector 3D display. Multiple video streams are individually encoded and sent over a broadband network to the display. The 3D display shows high-resolution (1024  768) stereoscopic color images for multiple viewpoints without special glasses. We implemented systems with rear-projection and front-projection lenticular screens. In this paper, we provide a detailed overview of our 3D TV system, including an examination of design choices and tradeoffs. We present the calibration and image alignment procedures that are necessary to achieve good image quality. We present qualitative results and some early user feedback. We believe this is the first real-time end-to-end 3D TV system with enough views and resolution to provide a truly immersive 3D experience.", 
        "id": 236, 
        "title": "3D TV: a scalable system for real-time acquisition, transmission, and autostereoscopic display of dynamic scenes."
    }, 
    {
        "abstract": "An algebra consists of a set of objects and a set of operators that act on those objects. We treat shader programs as first-class objects and define two operators: connection and combination. Connection is functional composition: the outputs of one shader are fed into the inputs of another. Combination concatenates the input channels, output channels, and computations of two shaders. Similar operators can be used to manipulate streams and apply computational kernels expressed as shaders to streams. Connecting a shader program to a stream applies that program to all elements of the stream; combining streams concatenates the record definitions of those streams. In conjunction with an optimizing compiler, these operators can manipulate shader programs in many useful ways, including specialization, without modifying the original source code. We demonstrate these operators in Sh, a metaprogramming shading language embedded in C++. ", 
        "id": 237, 
        "title": "Shader algebra."
    }, 
    {
        "abstract": "We describe a novel method for controlling physics-based fluid simulations through gradient-based nonlinear optimization. Using a technique known as the adjoint method, derivatives can be computed efficiently, even for large 3D simulations with millions of control parameters. In addition, we introduce the first method for the full control of free-surface liquids. We show how to compute adjoint derivatives through each step of the simulation, including the fast marching algorithm, and describe a new set of control parameters specifically designed for liquids. ", 
        "id": 238, 
        "title": "Fluid control using the adjoint method."
    }, 
    {
        "abstract": "We propose a new method for producing unfolded papercraft patterns of rounded toy animal figures from triangulated meshes by means of strip-based approximation. Although in principle a triangulated model can be unfolded simply by retaining as much as possible of its connectivity while checking for intersecting triangles in the unfolded plane, creating a pattern with tens of thousands of triangles is unrealistic. Our approach is to approximate the mesh model by a set of continuous triangle strips with no internal vertices. Initially, we subdivide our mesh into parts corresponding to the features of the model. We segment each part into zonal regions, grouping triangles which are similar topological distances from the part boundary. We generate triangle strips by simplifying the mesh while retaining the borders of the zonal regions and additional cut-lines. The pattern is then created simply by unfolding the set of strips. The distinguishing feature of our method is that we approximate a mesh model by a set of continuous strips, not by other ruled surfaces such as parts of cones or cylinders. Thus, the approximated unfolded pattern can be generated using only mesh operations and a simple unfolding algorithm. Furthermore, a set of strips can be crafted just by bending the paper (without breaking edges) and can represent smooth features of the original mesh models.", 
        "id": 239, 
        "title": "Making papercraft toys from meshes using strip-based approximate unfolding."
    }, 
    {
        "abstract": "We propose a virtual node algorithm that allows material to separate along arbitrary (possibly branched) piecewise linear paths through a mesh. The material within an element is fragmented by creating several replicas of the element and assigning a portion of real material to each replica. This results in elements that contain both real material and empty regions. The missing material is contained in another copy (or copies) of this element. Our new virtual node algorithm automatically determines the number of replicas and the assignment of material to each. Moreover, it provides the degrees of freedom required to simulate the partially or fully fragmented material in a fashion consistent with the embedded geometry. This approach enables efficient simulation of complex geometry with a simple mesh, i.e. the geometry need not align itself with element boundaries. It also alleviates many shortcomings of traditional Lagrangian simulation techniques for meshes with changing topology. For example, slivers do not require small CFL time step restrictions since they are embedded in well shaped larger elements. To enable robust simulation of embedded geometry, we propose new algorithms for handling rigid body and self collisions. In addition, we present several mechanisms for influencing and controlling fracture with grain boundaries, prescoring, etc. We illustrate our method for both volumetric and thin-shell simulations. ", 
        "id": 240, 
        "title": "A virtual node algorithm for changing mesh topology during simulation."
    }, 
    {
        "abstract": "Many applications have used a head-mounted display (HMD), such as in virtual and mixed realities and telepresence. However, the field of view (FOV) of commercial HMD systems is too narrow for feeling immersion. In this paper, we propose a super-wide field of view head-mounted display consisting of an ellipsoidal mirror and a hyperboloidal curved mirror. The horizontal FOV of the proposed HMD is 180 degrees and includes the peripheral vision of humans. It increases the reality and immersion for users. ", 
        "id": 241, 
        "title": "Super wide viewer using catadioptrical optics."
    }, 
    {
        "abstract": "", 
        "id": 242, 
        "title": "Lighting sensitive display."
    }, 
    {
        "abstract": "This paper focuses on efficient rendering based on pre-computed light transport, with realistic materials and shadows under allfrequency direct lighting such as environment maps. The basic difficulty is representation and computation in the 6D space of light direction, view direction, and surface position. While image-based and synthetic methods for real-time rendering have been proposed, they do not scale to high sampling rates with variation of both lighting and viewpoint. Current approaches are therefore limited to lower dimensionality (only lighting or viewpoint variation, not both) or lower sampling rates (low frequency lighting and materials). We propose a new mathematical and computational analysis of pre-computed light transport. We use factored forms, separately pre-computing and representing visibility and material properties. Rendering then requires computing triple product integrals at each vertex, involving the lighting, visibility and BRDF. Our main contribution is a general analysis of these triple product integrals, which are likely to have broad applicability in computer graphics and numerical analysis. We first determine the computational complexity in a number of bases like point samples, spherical harmonics and wavelets. We then give efficient linear and sublinear-time algorithms for Haar wavelets, incorporating non-linear wavelet approximation of lighting and BRDFs. Practically, we demonstrate rendering of images under new lighting and viewing conditions in a few seconds, significantly faster than previous techniques. ", 
        "id": 243, 
        "title": "Triple product wavelet integrals for all-frequency relighting."
    }, 
    {
        "abstract": "Morse theory reveals the topological structure of a shape based on the critical points of a real function over the shape. A poor choice of this real function can lead to a complex configuration of an unnecessarily high number of critical points. This paper solves a relaxed form of Laplace's equation to find a \"fair\" Morse function with a user-controlled number and configuration of critical points. When the number is minimal, the resulting Morse complex cuts the shape into a disk. Specifying additional critical points at surface features yields a base domain that better represents the geometry and shares the same topology as the original mesh, and can also cluster a mesh into approximately developable patches. We make Morse theory on meshes more robust with teflon saddles and flat edge collapses, and devise a new \"intermediate value propagation\" multigrid solver for finding fair Morse functions that runs in provably linear time. ", 
        "id": 244, 
        "title": "Fair morse functions for extracting the topological structure of a surface mesh."
    }, 
    {
        "abstract": "The combination of the cornea of an eye and a camera viewing the eye form a catadioptric (mirror + lens) imaging system with a very wide field of view. We present a detailed analysis of the characteristics of this corneal imaging system. Anatomical studies have shown that the shape of a normal cornea (without major defects) can be approximated with an ellipsoid of fixed eccentricity and size. Using this shape model, we can determine the geometric parameters of the corneal imaging system from the image. Then, an environment map of the scene with a large field of view can be computed from the image. The environment map represents the illumination of the scene with respect to the eye. This use of an eye as a natural light probe is advantageous in many relighting scenarios. For instance, it enables us to insert virtual objects into an image such that they appear consistent with the illumination of the scene. The eye is a particularly useful probe when relighting faces. It allows us to reconstruct the geometry of a face by simply waving a light source in front of the face. Finally, in the case of an already captured image, eyes could be the only direct means for obtaining illumination information. We show how illumination computed from eyes can be used to replace a face in an image with another one. We believe that the eye not only serves as a useful tool for relighting but also makes relighting possible in situations where current approaches are hard to use. ", 
        "id": 245, 
        "title": "Eyes for relighting."
    }, 
    {
        "abstract": "We propose a simple and effective method for detecting view- and scale-independent ridge-valley lines defined via first- and secondorder curvature derivatives on shapes approximated by dense triangle meshes. A high-quality estimation of high-order surface derivatives is achieved by combining multi-level implicit surface fitting and finite difference approximations. We demonstrate that the ridges and valleys are geometrically and perceptually salient surface features and, therefore, can be potentially used for shape recognition, coding, and quality evaluation purposes. ", 
        "id": 246, 
        "title": "Ridge-valley lines on meshes via implicit surface fitting."
    }, 
    {
        "abstract": "This paper presents a novel method for efficiently generating a good sampling pattern given an importance density over a 2D domain. A Penrose tiling is hierarchically subdivided creating a sufficiently large number of sample points. These points are numbered using the Fibonacci number system, and these numbers are used to threshold the samples against the local value of the importance density. Pre-computed correction vectors, obtained using relaxation, are used to improve the spectral characteristics of the sampling pattern. The technique is deterministic and very fast; the sampling time grows linearly with the required number of samples. We illustrate our technique with importance-based environment mapping, but the technique is versatile enough to be used in a large variety of computer graphics applications, such as light transport calculations, digital halftoning, geometry processing, and various rendering techniques. ", 
        "id": 247, 
        "title": "Fast hierarchical importance sampling with blue noise properties."
    }, 
    {
        "abstract": "This paper presents an interactive system for designing and browsing volumetric illustrations. Volumetric illustrations are 3D models with internal textures that the user can browse by cutting the models at desired locations. To assign internal textures to a surface mesh, the designer cuts the mesh and provides simple guiding information to specify the correspondence between the cross-section and a reference 2D image. The guiding information is stored with the geometry and used during the synthesis of cross-sectional textures. The key idea is to synthesize a plausible cross-sectional image using a 2D texturesynthesis technique, instead of sampling from a complete 3D RGB volumetric representation directly. This simplifies the design interface and reduces the amount of data, making it possible for non-experts to rapidly design and use volumetric illustrations. We believe that our system can enrich human communications in various domains, such as medicine, biology, and geology. ", 
        "id": 248, 
        "title": "Volumetric illustration: designing 3D models with internal textures."
    }, 
    {
        "abstract": "Hair is a major feature of digital characters. Unfortunately, it has a complex geometry which challenges standard modeling tools. Some dedicated techniques exist, but creating a realistic hairstyle still takes hours. Complementary to user-driven methods, we here propose an image-based approach to capture the geometry of hair. The novelty of this work is that we draw information from the scattering properties of the hair that are normally considered a hindrance. To do so, we analyze image sequences from a fixed camera with a moving light source. We first introduce a novel method to compute the image orientation of the hairs from their anisotropic behavior. This method is proven to subsume and extend existing work while improving accuracy. This image orientation is then raised into a 3D orientation by analyzing the light reflected by the hair fibers. This part relies on minimal assumptions that have been proven correct in previous work. Finally, we show how to use several such image sequences to reconstruct the complete hair geometry of a real person. Results are shown to illustrate the fidelity of the captured geometry to the original hair. This technique paves the way for a new approach to digital hair generation. ", 
        "id": 249, 
        "title": "Capture of hair geometry from multiple images."
    }, 
    {
        "abstract": "Volume textures aligned with a surface can be used to add topologically complex geometric detail to objects in an efficient way, while retaining an underlying simple surface structure. Adding a volume texture to a surface requires more than a conventional two-dimensional parameterization: a part of the space surrounding the surface has to be parameterized. Another problem with using volume textures for adding geometric detail is the difficulty in rendering implicitly represented surfaces, especially when they are changed interactively. In this paper we present algorithms for constructing and rendering volume-textured surfaces. We demonstrate a number of interactive operations that these algorithms enable. ", 
        "id": 250, 
        "title": "Interactive modeling of topologically complex geometric detail."
    }, 
    {
        "abstract": "", 
        "id": 251, 
        "title": "Combining 4- and 3-direction subdivision."
    }, 
    {
        "abstract": "Digital photography has made it possible to quickly and easily take a pair of images of low-light environments: one with flash to capture detail and one without flash to capture ambient illumination. We present a variety of applications that analyze and combine the strengths of such flash/no-flash image pairs. Our applications include denoising and detail transfer (to merge the ambient qualities of the no-flash image with the high-frequency flash detail), white-balancing (to change the color tone of the ambient image), continuous flash (to interactively adjust flash intensity), and red-eye removal (to repair artifacts in the flash image). We demonstrate how these applications can synthesize new images that are of higher quality than either of the originals. ", 
        "id": 252, 
        "title": "Digital photography with flash and no-flash image pairs."
    }, 
    {
        "abstract": "", 
        "id": 253, 
        "title": "A signal-processing framework for reflection."
    }, 
    {
        "abstract": "This paper describes how to instrument the physical world so that objects become self-describing, communicating their identity, geometry, and other information such as history or user annotation. The enabling technology is a wireless tag which acts as a radio frequency identity and geometry (RFIG) transponder. We show how addition of a photo-sensor to a wireless tag significantly extends its functionality to allow geometric operations - such as finding the 3D position of a tag, or detecting change in the shape of a tagged object. Tag data is presented to the user by direct projection using a handheld locale-aware mobile projector. We introduce a novel technique that we call interactive projection to allow a user to interact with projected information e.g. to navigate or update the projected information. The ideas are demonstrated using objects with active radio frequency (RF) tags. But the work was motivated by the advent of unpowered passive-RFID, a technology that promises to have significant impact in real-world applications. We discuss how our current prototypes could evolve to passive-RFID in the future. ", 
        "id": 254, 
        "title": "RFIG lamps: interacting with a self-describing world via photosensing wireless tags and projectors."
    }, 
    {
        "abstract": "We present a non-photorealistic rendering approach to capture and convey shape features of real-world scenes. We use a camera with multiple flashes that are strategically positioned to cast shadows along depth discontinuities in the scene. The projective-geometric relationship of the camera-flash setup is then exploited to detect depth discontinuities and distinguish them from intensity edges due to material discontinuities. We introduce depiction methods that utilize the detected edge features to generate stylized static and animated images. We can highlight the detected features, suppress unnecessary details or combine features from multiple images. The resulting images more clearly convey the 3D structure of the imaged scenes. We take a very different approach to capturing geometric features of a scene than traditional approaches that require reconstructing a 3D model. This results in a method that is both surprisingly simple and computationally efficient. The entire hardware/software setup can conceivably be packaged into a self-contained device no larger than existing digital cameras. ", 
        "id": 255, 
        "title": "Non-photorealistic camera: depth edge detection and stylized rendering using multi-flash imaging."
    }, 
    {
        "abstract": "The problem of efficient, interactive foreground/background segmentation in still images is of great practical importance in image editing. Classical image segmentation tools use either texture (colour) information, e.g. Magic Wand, or edge (contrast) information, e.g. Intelligent Scissors. Recently, an approach based on optimization by graph-cut has been developed which successfully combines both types of information. In this paper we extend the graph-cut approach in three respects. First, we have developed a more powerful, iterative version of the optimisation. Secondly, the power of the iterative algorithm is used to simplify substantially the user interaction needed for a given quality of result. Thirdly, a robust algorithm for \"border matting\" has been developed to estimate simultaneously the alpha-matte around an object boundary and the colours of foreground pixels. We show that for moderately difficult examples the proposed method outperforms competitive tools. ", 
        "id": 256, 
        "title": "\"GrabCut\": interactive foreground extraction using iterated graph cuts."
    }, 
    {
        "abstract": "Optimization is an appealing way to compute the motion of an animated character because it allows the user to specify the desired motion in a sparse, intuitive way. The difficulty of solving this problem for complex characters such as humans is due in part to the high dimensionality of the search space. The dimensionality is an artifact of the problem representation because most dynamic human behaviors are intrinsically low dimensional with, for example, legs and arms operating in a coordinated way. We describe a method that exploits this observation to create an optimization problem that is easier to solve. Our method utilizes an existing motion capture database to find a low-dimensional space that captures the properties of the desired behavior. We show that when the optimization problem is solved within this low-dimensional subspace, a sparse sketch can be used as an initial guess and full physics constraints can be enabled. We demonstrate the power of our approach with examples of forward, vertical, and turning jumps; with running and walking; and with several acrobatic flips. ", 
        "id": 257, 
        "title": "Synthesizing physically realistic human motion in low-dimensional, behavior-specific spaces."
    }, 
    {
        "abstract": "This paper describes a method for bringing two videos (recorded at different times) into spatiotemporal alignment, then comparing and combining corresponding pixels for applications such as background subtraction, compositing, and increasing dynamic range. We align a pair of videos by searching for frames that best match according to a robust image registration process. This process uses locally weighted regression to interpolate and extrapolate highlikelihood image correspondences, allowing new correspondences to be discovered and refined. Image regions that cannot be matched are detected and ignored, providing robustness to changes in scene content and lighting, which allows a variety of new applications. ", 
        "id": 258, 
        "title": "Video matching."
    }, 
    {
        "abstract": "This extended abstract reprises our UIST '03 paper on \"Perceptually-Supported Image Editing of Text and Graphics.\" We introduce a novel image editing program, called ScanScribe, that emphasizes easy selection and manipulation of material found in informal, casual documents such as sketches, handwritten notes, whiteboard images, screen snapshots, and scanned documents. 1 Summary A longstanding goal in graphics has been to develp \"smart\" image editors that reflect awareness, at some perceptual or semantic level, of the content of the image material being manipulated. These would enable easy selection of complex objects or sets of related objects, recognition and conversion of hand writing and drawing into structured entities, and \"follow-my-example\" acceleration of multi-step and repeated operations. This work focuses on the first of these, convenient selection, in a targeted imagery domain, document images. Photographic image editors such as Adobe Photoshop gain power to the extent that they employ \"smart scissors\" and other techniques for establishing selection regions. But professional-level image editors are overly complicated for many purposes and are not designed to facilitate editing of document image material in particular. Their notion of image layers provides an organizing principle for the critical function of grouping collections of pixels together. But conventional image layers can be difficult to learn and use, and demand significant attention of the user. We have implemented a prototype document image editor, called ScanScribe, whose goal is WYPIWYG image editing: \"What You Perceive Is What You Get.\" The tool is designed to maintain representations of the image objects and visual structures the user is likely to perceive as sensible chunks or objects to select, and make these readily available via the interface. In general this can entail image analysis and recognition which can become arbitrarily complex. ScanScribe's architecture provides a framework in which recognition algorithms can be brought in incrementally, and are not required to work perfectly to provide useful results. ScanScribe offers four significant advances. First, it presents a new, intuitive model for maintaining image objects and groups, Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 1515 Broadway, New York, NY 10036 USA, fax +1 (212) 869-0481, or permissions@acm.org.  2004 ACM 0730-0301/04/0800-0728 $5.00  along with underlying logic for updating these in the course of an editing session. Independent objects are formally equivalent to image layers, and groups, to collections of layers. These are advantageously implemented beneath the level of the users' conscious awareness, and without consuming screen space for complicated layer control apparatus. Second, ScanScribe takes advantage of newly developed image processing algorithms to separate foreground markings from a white or light background, and thus can automatically render the background transparent so that image material can be rearranged without occlusion by background pixels. Third, ScanScribe introduces new interface techniques for selecting image objects with a pointing device without resorting to a palette of tool modes. Lasso, rectangle drag, and point-and-click selection are overloaded so that they are all immediately available. The success of this design depends on the foreground/background separation previously mentioned. Additionally, selection among alternative groupings of atomic level primitive objects is integrated seamlessly with the point-and-click selection protocol. Fourth, ScanScribe presents a platform for exploiting image analysis and recognition methods to make perceptually significant structure readily available to the user. In contrast to the conventional hierarchical tree model for grouping, ScanScribe employs a lattice model whereby any atomic image element may participate in multiple groups. This design respects the richness and compositional structure of human perception of visual scenes. Perceptual structuring occurs in two stages. First, the original undifferentiated bitmap is segmented into primitive image objects by an automatic mechanism. Second, sensible groupings of these primitives are formed through algorithms mimicing the Gestalt laws of perceptual organization. These are expressed as groups in the lattice and are accessible through the selection protocols outlined above. Although our current perceptual structuring algorithms are crude, they delineate the powerful role that computer vision algorithms will have in creating smart image editors, as they mature. As a package, the ScanScribe document image editor combines new user interface techniques, a novel arrangement of extant methods, and newly developed image processing algorithms, amounting to a uniquely distinct user experience and a framework for enhancing this experience as document image analysis techniques improve over time. In its research prototype form, ScanScribe has proven useful in the work of members of our laboratory, and has been released for user testing and evaluation. The program runs in Java and may be downloaded at \"http://www.parc.com/scanscribe.\" Saund, E., Fleet, D., Larner, D., and Mahoney, J. 2003. Perceptually-Supported Image Editing of Text and Graphics. In Proceedings ACM UIST 2003, 183-192.  728  \f ", 
        "id": 259, 
        "title": "Perceptually-supported image editing of text and graphics."
    }, 
    {
        "abstract": "We consider the problem of creating a map between two arbitrary triangle meshes. Whereas previous approaches compose parametrizations over a simpler intermediate domain, we directly create and optimize a continuous map between the meshes. Map distortion is measured with a new symmetric metric, and is minimized during interleaved coarse-to-fine refinement of both meshes. By explicitly favoring low inter-surface distortion, we obtain maps that naturally align corresponding shape elements. Typically, the user need only specify a handful of feature correspondences for initial registration, and even these constraints can be removed during optimization. Our method robustly satisfies hard constraints if desired. Inter-surface mapping is shown using geometric and attribute morphs. Our general framework can also be applied to parametrize surfaces onto simplicial domains, such as coarse meshes (for semi-regular remeshing), and octahedron and toroidal domains (for geometry image remeshing). In these settings, we obtain better parametrizations than with previous specialized techniques, thanks to our fine-grain optimization. ", 
        "id": 260, 
        "title": "Inter-surface mapping."
    }, 
    {
        "abstract": "A typical NURBS surface model has a large percentage of superfluous control points that significantly interfere with the design process. This paper presents an algorithm for eliminating such superfluous control points, producing a T-spline. The algorithm can remove substantially more control points than competing methods such as B-spline wavelet decomposition. The paper also presents a new T-spline local refinement algorithm and answers two fundamental open questions on T-spline theory. ", 
        "id": 261, 
        "title": "T-spline simplification and local refinement."
    }, 
    {
        "abstract": "The dynamic range of many real-world environments exceeds the capabilities of current display technology by several orders of magnitude. In this paper we discuss the design of two different display systems that are capable of displaying images with a dynamic range much more similar to that encountered in the real world. The first display system is based on a combination of an LCD panel and a DLP projector, and can be built from off-the-shelf components. While this design is feasible in a lab setting, the second display system, which relies on a custom-built LED panel instead of the projector, is more suitable for usual office workspaces and commercial applications. We describe the design of both systems as well as the software issues that arise. We also discuss the advantages and disadvantages of the two designs and potential applications for both systems. ", 
        "id": 262, 
        "title": "High dynamic range display systems."
    }, 
    {
        "abstract": "Sampling complex, real-world geometry with range scanning devices almost always yields imperfect surface samplings. These \"holes\" in the surface are commonly filled with a smooth patch that conforms with the boundary. We introduce a context-based method: the characteristics of the given surface are analyzed, and the hole is iteratively filled by copying patches from valid regions of the given surface. In particular, the method needs to determine best matching patches, and then, fit imported patches by aligning them with the surrounding surface. The completion process works top down, where details refine intermediate coarser approximations. To align an imported patch with the existing surface, we apply a rigid transformation followed by an iterative closest point procedure with nonrigid transformations. The surface is essentially treated as a point set, and local implicit approximations aid in measuring the similarity between two point set patches. We demonstrate the method at several point-sampled surfaces, where the holes either result from imperfect sampling during range scanning or manual removal. ", 
        "id": 263, 
        "title": "Context-based surface completion."
    }, 
    {
        "abstract": "This paper describes a method for building interpolating or approximating implicit surfaces from polygonal data. The user can choose to generate a surface that exactly interpolates the polygons, or a surface that approximates the input by smoothing away features smaller than some user-specified size. The implicit functions are represented using a moving least-squares formulation with constraints integrated over the polygons. The paper also presents an improved method for enforcing normal constraints and an iterative procedure for ensuring that the implicit surface tightly encloses the input vertices. ", 
        "id": 264, 
        "title": "Interpolating and approximating implicit surfaces from polygon soup."
    }, 
    {
        "abstract": "", 
        "id": 265, 
        "title": "Pop-up light field: An interactive image-based modeling and rendering system."
    }, 
    {
        "abstract": "In this paper we introduce a new perceptual metric for efficient, high quality, global illumination rendering. The metric is based on a rendering-by-components framework in which the direct, and indirect diffuse, glossy, and specular light transport paths are separately computed and then composited to produce an image. The metric predicts the perceptual importances of the computationally expensive indirect illumination components with respect to image quality. To develop the metric we conducted a series of psychophysical experiments in which we measured and modeled the perceptual importances of the components. An important property of this new metric is that it predicts component importances from inexpensive estimates of the reflectance properties of a scene, and therefore adds negligible overhead to the rendering process. This perceptual metric should enable the development of an important new class of efficient global-illumination rendering systems that can intelligently allocate limited computational resources, to provide high quality images at interactive rates. ", 
        "id": 266, 
        "title": "Perceptual illumination components: a new approach to efficient, high quality global illumination rendering."
    }, 
    {
        "abstract": "We describe a method for using a database of recorded speech and captured motion to create an animated conversational character. People's utterances are composed of short, clearly-delimited phrases; in each phrase, gesture and speech go together meaningfully and synchronize at a common point of maximum emphasis. We develop tools for collecting and managing performance data that exploit this structure. The tools help create scripts for performers, help annotate and segment performance data, and structure specific messages for characters to use within application contexts. Our animations then reproduce this structure. They recombine motion samples with new speech samples to recreate coherent phrases, and blend segments of speech and motion together phraseby-phrase into extended utterances. By framing problems for utterance generation and synthesis so that they can draw closely on a talented performance, our techniques support the rapid construction of animated characters with rich and appropriate expression. ", 
        "id": 267, 
        "title": "Speaking with hands: creating animated conversational characters from recordings of human performance."
    }, 
    {
        "abstract": "Deformation transfer applies the deformation exhibited by a source triangle mesh onto a different target triangle mesh. Our approach is general and does not require the source and target to share the same number of vertices or triangles, or to have identical connectivity. The user builds a correspondence map between the triangles of the source and those of the target by specifying a small set of vertex markers. Deformation transfer computes the set of transformations induced by the deformation of the source mesh, maps the transformations through the correspondence from the source to the target, and solves an optimization problem to consistently apply the transformations to the target shape. The resulting system of linear equations can be factored once, after which transferring a new deformation to the target mesh requires only a backsubstitution step. Global properties such as foot placement can be achieved by constraining vertex positions. We demonstrate our method by retargeting full body key poses, applying scanned facial deformations onto a digital character, and remapping rigid and non-rigid animation sequences from one mesh onto another. ", 
        "id": 268, 
        "title": "Deformation transfer for triangle meshes."
    }, 
    {
        "abstract": " In this paper, we formulate the problem of natural image matting as one of solving Poisson equations with the matte gradient field. Our approach, which we call Poisson matting, has the following advantages. First, the matte is directly reconstructed from a continuous matte gradient field by solving Poisson equations using boundary information from a user-supplied trimap. Second, by interactively manipulating the matte gradient field using a number of filtering tools, the user can further improve Poisson matting results locally until he or she is satisfied. The modified local result is seamlessly integrated into the final result. Experiments on many complex natural images demonstrate that Poisson matting can generate good matting results that are not possible using existing matting techniques. ", 
        "id": 269, 
        "title": "Poisson matting."
    }, 
    {
        "abstract": "Lighting models used in the production of computer generated feature animation have to be flexible, easy to control, and efficient to compute. Global illumination techniques do not lend themselves easily to flexibility, ease of use, or speed, and have remained out of reach thus far for the vast majority of images generated in this context. This paper describes the implementation and integration of indirect illumination within a feature animation production renderer. For efficiency reasons, we choose to partially solve the rendering equation. We explain how this compromise allows us to speed-up final gathering calculations and reduce noise. We describe an efficient ray tracing strategy and its integration with a micro-polygon based scan line renderer supporting displacement mapping and programmable shaders. We combine a modified irradiance gradient caching technique with an approximate lighting model that enhances caching coherence and provides good scalability to render complex scenes into highresolution images suitable for film. We describe the tools that are made available to the artists to control indirect lighting in final renders. We show that our approach provides an efficient solution, easy to art direct, that allows animators to enhance considerably the quality of images generated for a large category of production work. ", 
        "id": 270, 
        "title": "An approximate global illumination system for computer generated films."
    }, 
    {
        "abstract": "Standard texture mapping of real-world meshes suffers from the presence of seams that need to be introduced in order to avoid excessive distortions and to make the topology of the mesh compatible to the one of the texture domain. In contrast, cube maps provide a mechanism that could be used for seamless texture mapping with low distortion, but only if the object roughly resembles a cube. We extend this concept to arbitrary meshes by using as texture domain the surface of a polycube whose shape is similar to that of the given mesh. Our approach leads to a seamless texture mapping method that is simple enough to be implemented in currently available graphics hardware. ", 
        "id": 271, 
        "title": "PolyCube-Maps."
    }, 
    {
        "abstract": "Athletes and coaches in most professional sports make use of hightech equipment to analyze and, subsequently, improve the athlete's performance. High-speed video cameras are employed, for instance, to record the swing of a golf club or a tennis racket, the movement of the feet while running, and the body motion in apparatus gymnastics. High-tech and high-speed equipment, however, usually implies high-cost as well. In this paper, we present a passive optical approach to capture high-speed motion using multiexposure images obtained with low-cost commodity still cameras and a stroboscope. The recorded motion remains completely undisturbed by the motion capture process. We apply our approach to capture the motion of hand and ball for a variety of baseball pitches and present algorithms to automatically track the position, velocity, rotation axis, and spin of the ball along its trajectory. To demonstrate the validity of our setup and algorithms, we analyze the consistency of our measurements with a physically based model that predicts the trajectory of a spinning baseball. Our approach can be applied to capture a wide variety of other high-speed objects and activities such as golfing, bowling, or tennis for visualization as well as analysis purposes. ", 
        "id": 272, 
        "title": "Pitching a baseball: tracking high-speed motion with multi-exposure images."
    }, 
    {
        "abstract": "In this paper we present a novel system for sketching the motion of a character. The process begins by sketching a character to be animated. An animated motion is then created for the character by drawing a continuous sequence of lines, arcs, and loops. These are parsed and mapped to a parameterized set of output motions that further reflect the location and timing of the input sketch. The current system supports a repertoire of 18 different types of motions in 2D and a subset of these in 3D. The system is unique in its use of a cursive motion specification, its ability to allow for fast experimentation, and its ease of use for non-experts. ", 
        "id": 273, 
        "title": "Motion doodles: an interface for sketching character motion."
    }, 
    {
        "abstract": "We propose a real-time 3D audio rendering pipeline for complex virtual scenes containing hundreds of moving sound sources. The approach, based on auditory culling and spatial level-of-detail, can handle more than ten times the number of sources commonly available on consumer 3D audio hardware, with minimal decrease in audio quality. The method performs well for both indoor and outdoor environments. It leverages the limited capabilities of audio hardware for many applications, including interactive architectural acoustics simulations and automatic 3D voice management for video games. Our approach dynamically eliminates inaudible sources and groups the remaining audible sources into a budget number of clusters. Each cluster is represented by one impostor sound source, positioned using perceptual criteria. Spatial audio processing is then performed only on the impostor sound sources rather than on every original source thus greatly reducing the computational cost. A pilot validation study shows that degradation in audio quality, as well as localization impairment, are limited and do not seem to vary significantly with the cluster budget. We conclude that our real-time perceptual audio rendering pipeline can generate spatialized audio for complex auditory environments without introducing disturbing changes in the resulting perceived soundfield. ", 
        "id": 274, 
        "title": "Perceptual audio rendering of complex virtual environments."
    }, 
    {
        "abstract": "This paper introduces a tensor framework for image-based rendering. In particular, we develop an algorithm called TensorTextures that learns a parsimonious model of the bidirectional texture function (BTF) from observational data. Given an ensemble of images of a textured surface, our nonlinear, generative model explicitly represents the multifactor interaction implicit in the detailed appearance of the surface under varying photometric angles, including local (per-texel) reflectance, complex mesostructural self-occlusion, interreflection and self-shadowing, and other BTF-relevant phenomena. Mathematically, TensorTextures is based on multilinear algebra, the algebra of higher-order tensors, hence its name. It is computed through a decomposition known as the N-mode SVD, an extension to tensors of the conventional matrix singular value decomposition (SVD). We demonstrate the application of Tensor-Textures to the image-based rendering of natural and synthetic textured surfaces under continuously varying viewpoint and illumination conditions.", 
        "id": 275, 
        "title": "TensorTextures: multilinear image-based rendering."
    }, 
    {
        "abstract": "We describe a system for transforming an input video into a highly abstracted, spatio-temporally coherent cartoon animation with a range of styles. To achieve this, we treat video as a space-time volume of image data. We have developed an anisotropic kernel mean shift technique to segment the video data into contiguous volumes. These provide a simple cartoon style in themselves, but more importantly provide the capability to semi-automatically rotoscope semantically meaningful regions. In our system, the user simply outlines objects on keyframes. A mean shift guided interpolation algorithm is then employed to create three dimensional semantic regions by interpolation between the keyframes, while maintaining smooth trajectories along the time dimension. These regions provide the basis for creating smooth two dimensional edge sheets and stroke sheets embedded within the spatio-temporal video volume. The regions, edge sheets, and stroke sheets are rendered by slicing them at particular times. A variety of styles of rendering are shown. The temporal coherence provided by the smoothed semantic regions and sheets results in a temporally consistent non-photorealistic appearance. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 1515 Broadway, New York, NY 10036 USA, fax +1 (212) 869-0481, or permissions@acm.org.  2004 ACM 0730-0301/04/0800-0574 $5.00  ", 
        "id": 276, 
        "title": "Video tooning."
    }, 
    {
        "abstract": "Level of detail (LOD) is widely used to control visual feedback in interactive applications. LOD control is typically based on perception at threshold  the conditions in which a stimulus first becomes perceivable. Yet most LOD manipulations are quite perceivable and occur well above threshold. Moreover, research shows that supra-threshold perception differs drastically from perception at threshold. In that case, should supra-threshold LOD control also differ from LOD control at threshold? In two experiments, we examine supra-threshold LOD control in the visual periphery and find that indeed, it should differ drastically from LOD control at threshold. Specifically, we find that LOD must support a task-dependent level of reliable perceptibility. Above that level, perceptibility of LOD control manipulations should be minimized, and detail contrast is a better predictor of perceptibility than detail size. Below that level, perceptibility must be maximized, and LOD should be improved as eccentricity rises or contrast drops. This directly contradicts prevailing threshold-based LOD control schemes, and strongly suggests a reexamination of LOD control for foveal display. ", 
        "id": 277, 
        "title": "Supra-threshold control of peripheral LOD."
    }, 
    {
        "abstract": "", 
        "id": 278, 
        "title": "Removing excess topology from isosurfaces."
    }, 
    {
        "abstract": "One significant problem in patch-based texture synthesis is the presence of broken features at the boundary of adjacent patches. The reason is that optimization schemes for patch merging may fail when neighborhood search cannot find satisfactory candidates in the sample texture because of an inaccurate similarity measure. In this paper, we consider both curvilinear features and their deformation. We develop a novel algorithm to perform feature matching and alignment by measuring structural similarity. Our technique extracts a feature map from the sample texture, and produces both a new feature map and texture map. Texture synthesis guided by feature maps can significantly reduce the number of feature discontinuities and related artifacts, and gives rise to satisfactory results. ", 
        "id": 279, 
        "title": "Feature matching and deformation for texture synthesis."
    }, 
    {
        "abstract": "Even such simple tasks as placing a box on a shelf are difficult to animate, because the animator must carefully position the character to satisfy geometric and balance constraints while creating motion to perform the task with a natural-looking style. In this paper, we explore an approach for animating characters manipulating objects that combines the power of path planning with the domain knowledge inherent in data-driven, constraint-based inverse kinematics. A path planner is used to find a motion for the object such that the corresponding poses of the character satisfy geometric, kinematic, and posture constraints. The inverse kinematics computation of the character's pose resolves redundancy by biasing the solution toward natural-looking poses extracted from a database of captured motions. Having this database greatly helps to increase the quality of the output motion. The computed path is converted to a motion trajectory using a model of the velocity profile. We demonstrate the effectiveness of the algorithm by generating animations across a wide range of scenarios that cover variations in the geometric, kinematic, and dynamic models of the character, the manipulated object, and obstacles in the scene. ", 
        "id": 280, 
        "title": "Synthesizing animations of human manipulation tasks."
    }, 
    {
        "abstract": "We present a smooth surface construction based on the manifold approach of Grimm and Hughes. We demonstrate how this approach can relatively easily produce a number of desirable properties which are hard to achieve simultaneously with polynomial patches, subdivision or variational surfaces. Our surfaces are Ccontinuous with explicit nonsingular C parameterizations, highorder flexible at control vertices, depend linearly on control points, have fixed-size local support for basis functions, and have good visual quality. ", 
        "id": 281, 
        "title": "A simple manifold-based construction of surfaces of arbitrary smoothness."
    }, 
    {
        "abstract": "In this paper, we introduce a novel approach to mesh editing with the Poisson equation as the theoretical foundation. The most distinctive feature of this approach is that it modifies the original mesh geometry implicitly through gradient field manipulation. Our approach can produce desirable and pleasing results for both global and local editing operations, such as deformation, object merging, and smoothing. With the help from a few novel interactive tools, these operations can be performed conveniently with a small amount of user interaction. Our technique has three key components, a basic mesh solver based on the Poisson equation, a gradient field manipulation scheme using local transforms, and a generalized boundary condition representation based on local frames. Experimental results indicate that our framework can outperform previous related mesh editing techniques. ", 
        "id": 282, 
        "title": "Mesh editing with poisson-based gradient field manipulation."
    }, 
    {
        "abstract": "", 
        "id": 283, 
        "title": "Jump map-based interactive texture synthesis."
    }, 
    {
        "abstract": "We present an end-to-end system that goes from video sequences to high resolution, editable, dynamically controllable face models. The capture system employs synchronized video cameras and structured light projectors to record videos of a moving face from multiple viewpoints. A novel spacetime stereo algorithm is introduced to compute depth maps accurately and overcome over-fitting deficiencies in prior work. A new template fitting and tracking procedure fills in missing data and yields point correspondence across the entire sequence without using markers. We demonstrate a datadriven, interactive method for inverse kinematics that draws on the large set of fitted templates and allows for posing new expressions by dragging surface points directly. Finally, we describe new tools that model the dynamics in the input sequence to enable new animations, created via key-framing or texture-synthesis techniques. ", 
        "id": 284, 
        "title": "Spacetime faces: high resolution capture for modeling and animation."
    }, 
    {
        "abstract": "The ability to interactively control viewpoint while watching a video is an exciting application of image-based rendering. The goal of our work is to render dynamic scenes with interactive viewpoint control using a relatively small number of video cameras. In this paper, we show how high-quality video-based rendering of dynamic scenes can be accomplished using multiple synchronized video streams combined with novel image-based modeling and rendering algorithms. Once these video streams have been processed, we can synthesize any intermediate view between cameras at any time, with the potential for space-time manipulation. In our approach, we first use a novel color segmentation-based stereo algorithm to generate high-quality photoconsistent correspondences across all camera views. Mattes for areas near depth discontinuities are then automatically extracted to reduce artifacts during view synthesis. Finally, a novel temporal two-layer compressed representation that handles matting is developed for rendering at interactive rates. ", 
        "id": 285, 
        "title": "High-quality video view interpolation using a layered representation."
    }, 
    {
        "abstract": "This paper describes a mostly automatic method for taking the output of a single panning video camera and creating a panoramic video texture (PVT): a video that has been stitched into a single, wide field of view and that appears to play continuously and indefinitely. The key problem in creating a PVT is that although only a portion of the scene has been imaged at any given time, the output must simultaneously portray motion throughout the scene. Like previous work in video textures, our method employs min-cut optimization to select fragments of video that can be stitched together both spatially and temporally. However, it differs from earlier work in that the optimization must take place over a much larger set of data. Thus, to create PVTs, we introduce a dynamic programming step, followed by a novel hierarchical min-cut optimization algorithm. We also use gradient-domain compositing to further smooth boundaries between video fragments. We demonstrate our results with an interactive viewer in which users can interactively pan and zoom on high-resolution PVTs. ", 
        "id": 286, 
        "title": "Panoramic video textures."
    }, 
    {
        "abstract": "Flash images are known to suffer from several problems: saturation of nearby objects, poor illumination of distant objects, reflections of objects strongly lit by the flash and strong highlights due to the reflection of flash itself by glossy surfaces. We propose to use a flash and no-flash (ambient) image pair to produce better flash images. We present a novel gradient projection scheme based on a gradient coherence model that allows removal of reflections and highlights from flash images. We also present a brightness-ratio based algorithm that allows us to compensate for the falloff in the flash image brightness due to depth. In several practical scenarios, the quality of flash/no-flash images may be limited in terms of dynamic range. In such cases, we advocate using several images taken under different flash intensities and exposures. We analyze the flash intensity-exposure space and propose a method for adaptively sampling this space so as to minimize the number of captured images for any given scene. We present several experimental results that demonstrate the ability of our algorithms to produce improved flash images. ", 
        "id": 287, 
        "title": "Removing photography artifacts using gradient projection and flash-exposure sampling."
    }, 
    {
        "abstract": "In this paper, a novel Delaunay-based variational approach to isotropic tetrahedral meshing is presented. To achieve both robustness and efficiency, we minimize a simple mesh-dependent energy through global updates of both vertex positions and connectivity. As this energy is known to be the L1 distance between an isotropic quadratic function and its linear interpolation on the mesh, our minimization procedure generates well-shaped tetrahedra. Mesh design is controlled through a gradation smoothness parameter and selection of the desired number of vertices. We provide the foundations of our approach by explaining both the underlying variational principle and its geometric interpretation. We demonstrate the quality of the resulting meshes through a series of examples. ", 
        "id": 288, 
        "title": "Variational tetrahedral meshing."
    }, 
    {
        "abstract": "", 
        "id": 289, 
        "title": "Error-resilient transmission of 3D models."
    }, 
    {
        "abstract": "We introduce the SCAPE method (Shape Completion and Animation for PEople) -- a data-driven method for building a human shape model that spans variation in both subject shape and pose. The method is based on a representation that incorporates both articulated and non-rigid deformations. We learn a pose deformation model that derives the non-rigid surface deformation as a function of the pose of the articulated skeleton. We also learn a separate model of variation based on body shape. Our two models can be combined to produce 3D surface models with realistic muscle deformation for different people in different poses, when neither appear in the training set. We show how the model can be used for shape completion -- generating a complete surface mesh given a limited set of markers specifying the target shape. We present applications of shape completion to partial view completion and motion capture animation. In particular, our method is capable of constructing a high-quality animated surface model of a moving person, with realistic muscle deformation, using just a single static scan and a marker motion capture sequence of the person. ", 
        "id": 290, 
        "title": "SCAPE: shape completion and animation of people."
    }, 
    {
        "abstract": "We introduce CrossY, a simple drawing application developed as a benchmark to demonstrate the feasibility of goal-crossing as the basis for a graphical user interface. While crossing was previously identified as a potential substitute for the classic point-and-click interaction, this work is the first to report on the practical aspects of implementing an interface solely based on goal-crossing. Summary The recent introduction of portable, pen-based computers has demonstrated that, while very powerful, the standard WIMPinterface (Windows, Icons, Menus, and Pointers) is not very well adapted to direct, pen-based interaction. Many interactions that were originally developed for the mouse are difficult to perform with a pen on a tablet computer. For example, while it is easy to double-click on a target with a mouse (since the pointer is stable), doing the same proves to be quite difficult in pen-based interfaces. Other difficulties that arise in pen-based interfaces include occlusions created by the user's hand due to the direct setting and reduced access to the keyboard which is crucial for expert performance. A promising alternative for pen computing is goalcrossing, an interaction style in which actions are triggered by crossing goals displayed on the screen. While empirical studies have shown that goal-crossing can be as fast as point-and-click interactions, the use of goal-crossing as a building block for interaction design has so far been very limited in scope. To explore this design space, we developed CrossY (Fig. 1), a simple sketching application in which all interface elements rely solely on goal-crossing. For example, users select the drawing tool by crossing the pen icon on top of the tool palette (Fig. 1, top right) from right to left. They then set the pen parameters by crossing the color and width sliders on the brush palette (Fig. 1, top left) at the desired values. As users become more proficient, they may select both parameters in a single stroke. Promoting the fluid composition of commands is a key aspect of our work as shown in the design of our find and replace dialog box (Fig. 1, bottom). To find strokes with certain parameters, (e.g., a red line of medium thickness), users cross the corresponding radio buttons on the top panel, before crossing the find button. The first item that matches the parameters is selected on the canvas. In the same stroke, users can now proceed to cross the replace button, as well as the radio buttons representing the replacement parameters. For multiple find and replace operations, Copyright  2005 by the Association for Computing Machinery, Inc. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org.  2005 ACM 0730-0301/05/0700-0930 $5.00  Figure 1 The CrossY interface with the find and replace dialog box (top). Issuing a find and replace command (bottom left), and repeating the command (bottom right). it is not necessary to reselect parameters. A simple circular path through the find and replace buttons will trigger replacement. Since the find and replace buttons are directional, actions can be undone by reversing the crossing direction. CrossY also offers a crossing-based version of a scrollbar and dialog boxes such as a file-open dialog box. Designing and implementing CrossY provided us with unique insights into the challenges of designing a practical crossingbased interface. We found that crossing is not only as expressive as the current point-and-click interface, but that the goal-crossing paradigm offers more flexibility and enables the fluid composition of commands. We also found that for crossing-based interaction, the overall spatial layout of the interface is a key factor in designing fluid interactions. While CrossY was implemented on a Tablet PC, our findings are not restricted to this platform and can be easily extended to other configurations such as wall size displays and PDAs. Reference APITZ, GEORG, and FRANCOIS GUIMBRETIERE. \"CrossY: A Crossing-Based Drawing Application\". In Proceedings of the 17th annual ACM symposium on User interface software and technology 2004, p. 3 - 12.  930  \f ", 
        "id": 291, 
        "title": "CrossY: a crossing-based drawing application."
    }, 
    {
        "abstract": "In this paper we present an approximate method for accelerated computation of the final gathering step in a global illumination algorithm. Our method operates by decomposing the radiance field close to surfaces into separate far- and near-field components that can be approximated individually. By computing surface shading using these approximations, instead of directly querying the global illumination solution, we have been able to obtain rendering time speed ups on the order of 10 compared to previous acceleration methods. Our approximation schemes rely mainly on the assumptions that radiance due to distant objects will exhibit low spatial and angular variation, and that the visibility between a surface and nearby surfaces can be reasonably predicted by simple locationand orientation-based heuristics. Motivated by these assumptions, our far-field scheme uses scattered-data interpolation with spherical harmonics to represent spatial and angular variation, and our near-field scheme employs an aggressively simple visibility heuristic. For our test scenes, the errors introduced when our assumptions fail do not result in visually objectionable artifacts or easily noticeable deviation from a ground-truth solution. We also discuss how our near-field approximation can be used with standard local illumination algorithms to produce significantly improved images at only negligible additional cost. ", 
        "id": 292, 
        "title": "Fast and detailed approximate global illumination by irradiance decomposition."
    }, 
    {
        "abstract": "Illustrating motion in still imagery for the purpose of summary, abstraction and motion description is important for a diverse spectrum of fields, ranging from arts to sciences. In this paper, we introduce a method that produces an action synopsis for presenting motion in still images. The method carefully selects key poses based on an analysis of a skeletal animation sequence, to facilitate expressing complex motions in a single image or a small number of concise views. Our approach is to embed the high-dimensional motion curve in a low-dimensional Euclidean space, where the main characteristics of the skeletal action are kept. The lower complexity of the embedded motion curve allows a simple iterative method which analyzes the curve and locates significant points, associated with the key poses of the original motion. We present methods for illustrating the selected poses in an image as a means to convey the action. We applied our methods to a variety of motions of human actions given either as 3D animation sequences or as video clips, and generated images that depict their synopsis. ", 
        "id": 293, 
        "title": "Action synopsis: pose selection and illustration."
    }, 
    {
        "abstract": "", 
        "id": 294, 
        "title": "Simulating the dynamics of auroral phenomena."
    }, 
    {
        "abstract": "In this paper, we present an approach for fast subspace integration of reduced-coordinate nonlinear deformable models that is suitable for interactive applications in computer graphics and haptics. Our approach exploits dimensional model reduction to build reducedcoordinate deformable models for objects with complex geometry. We exploit the fact that model reduction on large deformation models with linear materials (as commonly used in graphics) result in internal force models that are simply cubic polynomials in reduced coordinates. Coefficients of these polynomials can be precomputed, for efficient runtime evaluation. This allows simulation of nonlinear dynamics using fast implicit Newmark subspace integrators, with subspace integration costs independent of geometric complexity. We present two useful approaches for generating low-dimensional subspace bases: modal derivatives and an interactive sketching technique. Mass-scaled principal component analysis (mass-PCA) is suggested for dimensionality reduction. Finally, several examples are given from computer animation to illustrate high performance, including force-feedback haptic rendering of a complicated object undergoing large deformations. ", 
        "id": 295, 
        "title": "Real-Time subspace integration for St. Venant-Kirchhoff deformable models."
    }, 
    {
        "abstract": "", 
        "id": 296, 
        "title": "On the optimality of spectral compression of mesh data."
    }, 
    {
        "abstract": "We enhance underexposed, low dynamic range videos by adaptively and independently varying the exposure at each photoreceptor in a post-process. This virtual exposure is a dynamic function of both the spatial neighborhood and temporal history at each pixel. Temporal integration enables us to expand the image's dynamic range while simultaneously reducing noise. Our non-linear exposure variation and denoising filters smoothly transition from temporal to spatial for moving scene elements. Our virtual exposure framework also supports temporally coherent per frame tone mapping. Our system outputs restored video sequences with significantly reduced noise, increased exposure time of dark pixels, intact motion, and improved details. ", 
        "id": 297, 
        "title": "Video enhancement using per-pixel virtual exposures."
    }, 
    {
        "abstract": "", 
        "id": 298, 
        "title": "Automatic restoration of polygon models."
    }, 
    {
        "abstract": "This paper presents a new technique for fast, view-dependent, realtime visualization of large multiresolution geometric models with color or texture information. This method uses geomorphing to smoothly interpolate between geometric patches composing a hierarchical level-of-detail structure, and to maintain seamless continuity between neighboring patches of the model. It combines the advantages of view-dependent rendering with numerous additional features: the high performance rendering associated with static preoptimized geometry, the capability to display at both low and high resolution with minimal artefacts, and a low CPU usage since all the geomorphing is done on the GPU. Furthermore, the hierarchical subdivision of the model into a tree structure can be accomplished according to any spatial or topological criteria. This property is particularly useful in dealing with models with high resolution textures derived from digital photographs. Results are presented for both highly tesselated models (372 million triangles), and for models which also contain large quantities of texture (200 million triangles + 20 GB of compressed texture). The method also incorporates asynchronous out-of-core model management. Performances obtained on commodity hardware are in the range of 50 million geomorphed triangles/second for a benchmark model such as Stanford's St. Matthew dataset. ", 
        "id": 299, 
        "title": "GoLD: interactive display of huge colored and textured models."
    }, 
    {
        "abstract": "Renderings of volumetric data have become an important data analysis tool for applications ranging from medicine to scientific simulation. We propose a volumetric drawing system that directly extracts sparse linear features, such as silhouettes and suggestive contours, using a temporally coherent seed-and-traverse framework. In contrast to previous methods based on isosurfaces or nonrefractive transparency, producing these drawings requires examining an asymptotically smaller subset of the data, leading to efficiency on large data sets. In addition, the resulting imagery is often more comprehensible than standard rendering styles, since it focuses attention on important features in the data. We test our algorithms on datasets up to 5123, demonstrating interactive extraction and rendering of line drawings in a variety of drawing styles. ", 
        "id": 300, 
        "title": "Line drawings from volume data."
    }, 
    {
        "abstract": "", 
        "id": 301, 
        "title": "Expressive speech-driven facial animation."
    }, 
    {
        "abstract": "This paper introduces an approach to performance animation that employs video cameras and a small set of retro-reflective markers to create a low-cost, easy-to-use system that might someday be practical for home use. The low-dimensional control signals from the user's performance are supplemented by a database of pre-recorded human motion. At run time, the system automatically learns a series of local models from a set of motion capture examples that are a close match to the marker locations captured by the cameras. These local models are then used to reconstruct the motion of the user as a full-body animation. We demonstrate the power of this approach with real-time control of six different behaviors using two video cameras and a small set of retro-reflective markers. We compare the resulting animation to animation from commercial motion capture equipment with a full set of markers. ", 
        "id": 302, 
        "title": "Performance animation from low-dimensional control signals."
    }, 
    {
        "abstract": "", 
        "id": 303, 
        "title": "Algebraic analysis of high-pass quantization."
    }, 
    {
        "abstract": "Weathering modeling introduces blemishes such as dirt, rust, cracks and scratches to virtual scenery. In this paper we present a visual simulation technique that works well for a wide variety of weathering phenomena. Our technique, called -ton tracing, is based on a type of aging-inducing particles called -tons. Modeling a weathering effect with -ton tracing involves tracing a large number of -tons through the scene in a way similar to photon tracing and then generating the weathering effect using the recorded -ton transport information. With this technique, we can produce weathering effects that are customized to the scene geometry and tailored to the weathering sources. Several effects that are challenging for existing techniques can be readily captured by -ton tracing. These include global transport effects, or \"stain-bleeding\". -ton tracing also enables visual simulations of complex multi-weathering effects. Lastly -ton tracing can generate weathering effects that not only involve texture changes but also large-scale geometry changes. We demonstrate our technique with a variety of examples. ", 
        "id": 304, 
        "title": "Visual simulation of weathering by gamma-ton tracing."
    }, 
    {
        "abstract": "", 
        "id": 305, 
        "title": "Mood swings: expressive speech animation."
    }, 
    {
        "abstract": "In this paper, we explore the problem of enhancing still pictures with subtly animated motions. We limit our domain to scenes containing passive elements that respond to natural forces in some fashion. We use a semi-automatic approach, in which a human user segments the scene into a series of layers to be individually animated. Then, a \"stochastic motion texture\" is automatically synthesized using a spectral method, i.e., the inverse Fourier transform of a filtered noise spectrum. The motion texture is a time-varying 2D displacement map, which is applied to each layer. The resulting warped layers are then recomposited to form the animated frames. The result is a looping video texture created from a single still image, which has the advantages of being more controllable and of generally higher image quality and resolution than a video texture created from a video source. We demonstrate the technique on a variety of photographs and paintings. ", 
        "id": 306, 
        "title": "Animating pictures with stochastic motion textures."
    }, 
    {
        "abstract": "This paper presents a physically-based method for simulating ink dispersion in absorbent paper for art creation purposes. We devise a novel fluid flow model based on the lattice Boltzmann equation suitable for simulating percolation in disordered media, like paper, in real time. Our model combines the simulations of spontaneous shape evolution and porous media flow under a unified framework. We also couple our physics simulation with simple implicit modeling and image-based methods to render high quality output. We demonstrate the effectiveness of our techniques in a digital paint system and achieve various realistic effects of ink dispersion, including complex flow patterns observed in real artwork, and other special effects. ", 
        "id": 307, 
        "title": "MoXi: real-time ink dispersion in absorbent paper."
    }, 
    {
        "abstract": "We present a new technique for importance sampling products of complex functions using wavelets. First, we generalize previous work on wavelet products to higher dimensional spaces and show how this product can be sampled on-thefly without the need of evaluating the full product. This makes it possible to sample products of high-dimensional functions even if the product of the two functions in itself is too memory consuming. Then, we present a novel hierarchical sample warping algorithm that generates high-quality point distributions, which match the wavelet representation exactly. One application of the new sampling technique is rendering of objects with measured BRDFs illuminated by complex distant lighting -- our results demonstrate how the new sampling technique is more than an order of magnitude more efficient than the best previous techniques. ", 
        "id": 308, 
        "title": "Wavelet importance sampling: efficiently evaluating products of complex functions."
    }, 
    {
        "abstract": "We present Energy Redistribution (ER) sampling as an unbiased method to solve correlated integral problems. ER sampling is a hybrid algorithm that uses Metropolis sampling-like mutation strategies in a standard Monte Carlo integration setting, rather than resorting to an intermediate probability distribution step. In the context of global illumination, we present Energy Redistribution Path Tracing (ERPT). Beginning with an inital set of light samples taken from a path tracer, ERPT uses path mutations to redistribute the energy of the samples over the image plane to reduce variance. The result is a global illumination algorithm that is conceptually simpler than Metropolis Light Transport (MLT) while retaining its most powerful feature, path mutation. We compare images generated with the new technique to standard path tracing and MLT. ", 
        "id": 309, 
        "title": "Energy redistribution path tracing."
    }, 
    {
        "abstract": "Noise functions are an essential building block for writing procedural shaders in 3D computer graphics. The original noise function introduced by Ken Perlin is still the most popular because it is simple and fast, and many spectacular images have been made with it. Nevertheless, it is prone to problems with aliasing and detail loss. In this paper we analyze these problems and show that they are particularly severe when 3D noise is used to texture a 2D surface. We use the theory of wavelets to create a new class of simple and fast noise functions that avoid these problems. ", 
        "id": 310, 
        "title": "Wavelet noise."
    }, 
    {
        "abstract": "A photon accurate model of individual cones in the human eye perceiving images on digital display devices is presented. Playback of streams of pixel video data is modeled as individual photon emission events from within the physical substructure of each display pixel. The thus generated electromagnetic wavefronts are refracted through a four surface model of the human cornea and lens, and diffracted at the pupil. The position, size, shape, and orientation of each of the five million photoreceptor cones in the retina are individually modeled by a new synthetic retina model. Photon absorption events map the collapsing wavefront to photon detection events in a particular cone, resulting in images of the photon counts in the retinal cone array. The custom rendering systems used to generate sequences of these images takes a number of optical and physical properties of the image formation into account, including wavelength dependent absorption in the tissues of the eye, and the motion blur caused by slight movement of the eye during a frame of viewing. The creation of this new model is part of a larger framework for understanding how changes to computer graphics rendering algorithms and changes in image display devices are related to artifacts visible to human viewers. ", 
        "id": 311, 
        "title": "A photon accurate model of the human eye."
    }, 
    {
        "abstract": "", 
        "id": 312, 
        "title": "Fast multi-level adaptation for interactive autonomous characters."
    }, 
    {
        "abstract": "", 
        "id": 313, 
        "title": "Texture transfer during shape transformation."
    }, 
    {
        "abstract": "", 
        "id": 314, 
        "title": "Geopostors: a real-time geometry/impostor crowd rendering system."
    }, 
    {
        "abstract": "This paper introduces a shading model for light diffusion in multilayered translucent materials. Previous work on diffusion in translucent materials has assumed smooth semi-infinite homogeneous materials and solved for the scattering of light using a dipole diffusion approximation. This approximation breaks down in the case of thin translucent slabs and multi-layered materials. We present a new efficient technique based on multiple dipoles to account for diffusion in thin slabs. We enhance this multipole theory to account for mismatching indices of refraction at the top and bottom of of translucent slabs, and to model the effects of rough surfaces. To model multiple layers, we extend this single slab theory by convolving the diffusion profiles of the individual slabs. We account for multiple scattering between slabs by using a variant of Kubelka-Munk theory in frequency space. Our results demonstrate diffusion of light in thin slabs and multi-layered materials such as paint, paper, and human skin. ", 
        "id": 315, 
        "title": "Light diffusion in multi-layered translucent materials."
    }, 
    {
        "abstract": "We present a new, unified approach to debugging graphics software. We propose a representation of all graphics state over the course of program execution as a relational database, and produce a query-based framework for extracting, manipulating, and visualizing data from all stages of the graphics pipeline. Using an SQLbased query language, the programmer can establish functional relationships among all the data, linking OpenGL state to primitives to vertices to fragments to pixels. Based on the Chromium library, our approach requires no modification to or recompilation of the program to be debugged, and forms a superset of many existing techniques for debugging graphics software. ", 
        "id": 316, 
        "title": "A relational debugging engine for the graphics pipeline."
    }, 
    {
        "abstract": "We present a signal-processing framework for light transport. We study the frequency content of radiance and how it is altered by phenomena such as shading, occlusion, and transport. This extends previous work that considered either spatial or angular dimensions, and it offers a comprehensive treatment of both space and angle. We show that occlusion, a multiplication in the primal, amounts in the Fourier domain to a convolution by the spectrum of the blocker. Propagation corresponds to a shear in the space-angle frequency domain, while reflection on curved objects performs a different shear along the angular frequency axis. As shown by previous work, reflection is a convolution in the primal and therefore a multiplication in the Fourier domain. Our work shows how the spatial components of lighting are affected by this angular convolution. Our framework predicts the characteristics of interactions such as caustics and the disappearance of the shadows of small features. Predictions on the frequency content can then be used to control sampling rates for rendering. Other potential applications include precomputed radiance transfer and inverse rendering. ", 
        "id": 317, 
        "title": "A frequency analysis of light transport."
    }, 
    {
        "abstract": "This paper presents a method for animating gases on unstructured tetrahedral meshes to efficiently model the interaction of fluids with irregularly shaped obstacles. Because our discretization scheme parallels that of the standard staggered grid mesh, we are able to combine tetrahedral cells with regular hexahedral cells in a single mesh. This hybrid mesh offers both accuracy near obstacles and efficiency in open regions. ", 
        "id": 318, 
        "title": "Animating gases with hybrid meshes."
    }, 
    {
        "abstract": "We introduce a robust moving least-squares technique for reconstructing a piecewise smooth surface from a potentially noisy point cloud. We use techniques from robust statistics to guide the creation of the neighborhoods used by the moving least squares (MLS) computation. This leads to a conceptually simple approach that provides a unified framework for not only dealing with noise, but also for enabling the modeling of surfaces with sharp features. Our technique is based on a new robust statistics method for outlier detection: the forward-search paradigm. Using this powerful technique, we locally classify regions of a point-set to multiple outlier-free smooth regions. This classification allows us to project points on a locally smooth region rather than a surface that is smooth everywhere, thus defining a piecewise smooth surface and increasing the numerical stability of the projection operator. Furthermore, by treating the points across the discontinuities as outliers, we are able to define sharp features. One of the nice features of our approach is that it automatically disregards outliers during the surface-fitting phase. ", 
        "id": 319, 
        "title": "Robust moving least-squares fitting with sharp features."
    }, 
    {
        "abstract": "", 
        "id": 320, 
        "title": "Quadric-based simplification in any dimension."
    }, 
    {
        "abstract": "We present an efficient approach for end-to-end out-of-core construction and interactive inspection of very large arbitrary surface models. The method tightly integrates visibility culling and outof-core data management with a level-of-detail framework. At preprocessing time, we generate a coarse volume hierarchy by binary space partitioning the input triangle soup. Leaf nodes partition the original data into chunks of a fixed maximum number of triangles, while inner nodes are discretized into a fixed number of cubical voxels. Each voxel contains a compact direction dependent approximation of the appearance of the associated volumetric subpart of the model when viewed from a distance. The approximation is constructed by a visibility aware algorithm that fits parametric shaders to samples obtained by casting rays against the full resolution dataset. At rendering time, the volumetric structure, maintained off-core, is refined and rendered in front-to-back order, exploiting vertex programs for GPU evaluation of view-dependent voxel representations, hardware occlusion queries for culling occluded subtrees, and asynchronous I/O for detecting and avoiding data access latencies. Since the granularity of the multiresolution structure is coarse, data management, traversal and occlusion culling cost is amortized over many graphics primitives. The efficiency and generality of the approach is demonstrated with the interactive rendering of extremely complex heterogeneous surface models on current commodity graphics platforms. ", 
        "id": 321, 
        "title": "Far voxels: a multiresolution framework for interactive rendering of huge complex 3D models on commodity graphics platforms."
    }, 
    {
        "abstract": " Visually important image features often disappear when color images are converted to grayscale. The algorithm introduced here reduces such losses by attempting to preserve the salient features of the color image. The Color2Gray algorithm is a 3-step process: 1) convert RGB inputs to a perceptually uniform CIE Lab color space, 2) use chrominance and luminance differences to create grayscale target differences between nearby image pixels, and 3) solve an optimization problem designed to selectively modulate the grayscale representation as a function of the chroma variation of the source image. The Color2Gray results offer viewers salient information missing from previous grayscale image creation methods. ", 
        "id": 322, 
        "title": "Color2Gray: salience-preserving color removal."
    }, 
    {
        "abstract": "We present a novel algorithm for accurately detecting all contacts, including self-collisions, between deformable models. We precompute a chromatic decomposition of a mesh into non-adjacent primitives using graph coloring algorithms. The chromatic decomposition enables us to check for collisions between non-adjacent primitives using a linear-time culling algorithm. As a result, we achieve higher culling efficiency and significantly reduce the number of false positives. We use our algorithm to check for collisions among complex deformable models consisting of tens of thousands of triangles for cloth modeling and medical simulation. Our algorithm accurately computes all contacts at interactive rates. We observed up to an order of magnitude speedup over prior methods. ", 
        "id": 323, 
        "title": "Interactive collision detection between deformable models using chromatic decomposition."
    }, 
    {
        "abstract": "Volumetric displays provide interesting opportunities and challenges for 3D interaction and visualization, particularly when used in a highly interactive manner. We explore this area through the design and implementation of techniques for interactive direct manipulation of objects with a 3D volumetric display. Motion tracking of the user's fingers provides for direct gestural interaction with the virtual objects, through manipulations on and around the display's hemispheric enclosure. Our techniques leverage the unique features of volumetric displays, including a 360 viewing volume that enables manipulation from any viewpoint around the display, as well as natural and accurate perception of true depth information in the displayed 3D scene. We demonstrate our techniques within a prototype 3D geometric model building application.  ", 
        "id": 324, 
        "title": "Multi-finger gestural interaction with 3D volumetric displays."
    }, 
    {
        "abstract": "We present a novel method for solid/fluid coupling that can treat infinitesimally thin solids modeled by a lower dimensional triangulated surface. Since classical solid/fluid coupling algorithms rasterize the solid body onto the fluid grid, an entirely new approach is required to treat thin objects that do not contain an interior region. Robust ray casting is used to augment a number of interpolation, finite difference and rendering techniques so that fluid does not leak through the triangulated surface. Moreover, we propose a technique for properly enforcing incompressibility so that fluid does not incorrectly compress (and appear to lose mass) near the triangulated surface. This allows for the robust interaction of cloth and shells with thin sheets of water. The proposed method works for both rigid body shells and for deformable manifolds such as cloth, and we present a two way coupling technique that allows the fluid's pressure to affect the solid. Examples illustrate that our method performs well, especially in the difficult case of water and cloth where it produces visually rich interactions between the particle level set method for treating the water/air interface and our newly proposed method for treating the solid/fluid interface. We have implemented the method on both uniform and adaptive octree grids. ", 
        "id": 325, 
        "title": "Coupling water and smoke to thin deformable and rigid shells."
    }, 
    {
        "abstract": "As there is no hardware support neither for rendering trimmed NURBS  the standard surface representation in CAD  nor for T-Spline surfaces the usability of existing rendering APIs like OpenGL, where a run-time tessellation is performed on the CPU, is limited to simple scenes. Due to the irregular mesh data structures required for trimming no algorithms exists that exploit the GPU for tessellation. Therefore, recent approaches perform a pretessellation and use level-of-detail techniques. In contrast to a simple API these methods require tedious preparation of the models before rendering and hinder interactive editing. Furthermore, due to the tremendous amount of triangle data smooth zoom-ins from long shot to close-up are not possible. In this paper we show how the trimming region can be defined by a trim-texture that is dynamically adapted to the required resolution and allows for an efficient trimming of surfaces on the GPU. Combining this new method with GPU-based tessellation of cubic rational surfaces allows a new rendering algorithm for arbitrary trimmed NURBS and T-Spline surfaces with prescribed error in screen space on the GPU. The performance exceeds current CPU-based techniques by a factor of up to 1000 and makes real-time visualization of real-world trimmed NURBS and T-Spline models possible on consumer-level graphics cards. ", 
        "id": 326, 
        "title": "GPU-based trimming and tessellation of NURBS and T-Spline surfaces."
    }, 
    {
        "abstract": "", 
        "id": 327, 
        "title": "Physically-based simulation of twilight phenomena."
    }, 
    {
        "abstract": "By combining depth peeling with a linear formulation of a Boolean expression called Blist, the Blister algorithm renders an arbitrary CSG model of n primitives in at most k steps, where k is the number of depth-layers in the arrangement of the primitives. Each step starts by rendering each primitive to produce candidate surfels on the next depth-layer. Then, it renders the primitives again, one at a time, to classify the candidate surfels against the primitive and to evaluate the Boolean expression directly on the GPU. Since Blist does not expand the CSG expression into a disjunctive (sum-of-products) form, Blister has O(kn) time complexity. We explain the Blist formulation while providing algorithms for CSG-to-Blist conversion and Blist-based parallel surfel classification. We report real-time performance for nontrivial CSG models. On hardware with an 8-bit stencil buffer, we can render all possible CSG expressions with 3909 primitives.  Figure 1: Boolean combinations of a red block A with a blue cylinder B: union AB, intersection AB, and difference AB. A CSG expression describes a tree, in which leaves represent primitives and nodes represent Boolean operators (Fig. 2). For simplicity, we assume that parent-nodes with more than two children have been expanded into a binary tree.  ", 
        "id": 328, 
        "title": "Blister: GPU-based rendering of Boolean combinations of free-form triangulated shapes."
    }, 
    {
        "abstract": "We present a technique for capturing time-varying volumetric data of participating media. A laser sheet is swept repeatedly through the volume, and the scattered light is imaged using a high-speed camera. Each sweep of the laser provides a near-simultaneous volume of density values. We demonstrate rendered animations under changing viewpoint and illumination, making use of measured values for the scattering phase function and albedo. ", 
        "id": 329, 
        "title": "Acquisition of time-varying participating media."
    }, 
    {
        "abstract": "This paper presents a fully automatic method for creating a 3D model from a single photograph. The model is made up of several texture-mapped planar billboards and has the complexity of a typical children's pop-up book illustration. Our main insight is that instead of attempting to recover precise geometry, we statistically model geometric classes defined by their orientations in the scene. Our algorithm labels regions of the input image into coarse categories: \"ground\", \"sky\", and \"vertical\". These labels are then used to \"cut and fold\" the image into a pop-up model using a set of simple assumptions. Because of the inherent ambiguity of the problem and the statistical nature of the approach, the algorithm is not expected to work on every image. However, it performs surprisingly well for a wide range of scenes taken from a typical person's photo album. ", 
        "id": 330, 
        "title": "Automatic photo pop-up."
    }, 
    {
        "abstract": "At interfaces between different fluids, properties such as density, viscosity, and molecular cohesion are discontinuous. To animate small-scale details of incompressible viscous multi-phase fluids realistically, we focus on the discontinuities in the state variables that express these properties. Surface tension of both free and bubble surfaces is modeled using the jump condition in the pressure field; and discontinuities in the velocity gradient field, driven by viscosity differences, are also considered. To obtain derivatives of the pressure and velocity fields with sub-grid accuracy, they are extrapolated across interfaces using continuous variables based on physical properties. The numerical methods that we present are easy to implement and do not impact the performance of existing solvers. Small-scale fluid motions, such as capillary instability, breakup of liquid sheets, and bubbly water can all be successfully animated.", 
        "id": 331, 
        "title": "Discontinuous fluids."
    }, 
    {
        "abstract": "Style translation is the process of transforming an input motion into a new style while preserving its original content. This problem is motivated by the needs of interactive applications, which require rapid processing of captured performances. Our solution learns to translate by analyzing differences between performances of the same content in input and output styles. It relies on a novel correspondence algorithm to align motions, and a linear time-invariant model to represent stylistic differences. Once the model is estimated with system identification, our system is capable of translating streaming input with simple linear operations at each frame. ", 
        "id": 332, 
        "title": "Style translation for human motion."
    }, 
    {
        "abstract": "We present an interactive system that lets a user move and deform a two-dimensional shape without manually establishing a skeleton or freeform deformation (FFD) domain beforehand. The shape is represented by a triangle mesh and the user moves several vertices of the mesh as constrained handles. The system then computes the positions of the remaining free vertices by minimizing the distortion of each triangle. While physically based simulation or iterative refinement can also be used for this purpose, they tend to be slow. We present a two-step closed-form algorithm that achieves real-time interaction. The first step finds an appropriate rotation for each triangle and the second step adjusts its scale. The key idea is to use quadratic error metrics so that each minimization problem becomes a system of linear equations. After solving the simultaneous equations at the beginning of interaction, we can quickly find the positions of free vertices during interactive manipulation. Our approach successfully conveys a sense of rigidity of the shape, which is difficult in space-warp approaches. With a multiple-point input device, even beginners can easily move, rotate, and deform shapes at will. ", 
        "id": 333, 
        "title": "As-rigid-as-possible shape manipulation."
    }, 
    {
        "abstract": " Takeo Igarashi PRESTO/JST  We present a system for modeling flowers in three dimensions quickly and easily while preserving correct botanical structures. We use floral diagrams and inflorescences, which were developed by botanists to concisely describe structural information of flowers. Floral diagrams represent the layout of floral components on a single flower, while inflorescences are arrangements of multiple flowers. Based on these notions, we created a simple user interface that is specially tailored to flower editing, while retaining a maximum variety of generable models. We also provide sketching interfaces to define the geometries of floral components. Separation of structural editing and editing of geometry makes the authoring process more flexible and efficient. We found that even novice users could easily design various flower models using our technique. Our system is an example of application-customized sketching, illustrating the potential power of a sketching interface that is carefully designed for a specific application. ", 
        "id": 334, 
        "title": "Floral diagrams and inflorescences: interactive flower modeling using botanical structural constraints."
    }, 
    {
        "abstract": "We extend approaches for skinning characters to the general setting of skinning deformable mesh animations. We provide an automatic algorithm for generating progressive skinning approximations, that is particularly efficient for pseudo-articulated motions. Our contributions include the use of nonparametric mean shift clustering of high-dimensional mesh rotation sequences to automatically identify statistically relevant bones, and robust least squares methods to determine bone transformations, bone-vertex influence sets, and vertex weight values. We use a low-rank data reduction model defined in the undeformed mesh configuration to provide progressive convergence with a fixed number of bones. We show that the resulting skinned animations enable efficient hardware rendering, rest pose editing, and deformable collision detection. Finally, we present numerous examples where skins were automatically generated using a single set of parameter values. ", 
        "id": 335, 
        "title": "Skinning mesh animations."
    }, 
    {
        "abstract": "", 
        "id": 336, 
        "title": "The irregular Z-buffer: Hardware acceleration for irregular data structures."
    }, 
    {
        "abstract": "Constructing a function that interpolates a set of values defined at vertices of a mesh is a fundamental operation in computer graphics. Such an interpolant has many uses in applications such as shading, parameterization and deformation. For closed polygons, mean value coordinates have been proven to be an excellent method for constructing such an interpolant. In this paper, we generalize mean value coordinates from closed 2D polygons to closed triangular meshes. Given such a mesh P, we show that these coordinates are continuous everywhere and smooth on the interior of P. The coordinates are linear on the triangles of P and can reproduce linear functions on the interior of P. To illustrate their usefulness, we conclude by considering several interesting applications including constructing volumetric textures and surface deformation. ", 
        "id": 337, 
        "title": "Mean value coordinates for closed triangular meshes."
    }, 
    {
        "abstract": "", 
        "id": 338, 
        "title": "Statistical geometry representation for efficient transmission and rendering."
    }, 
    {
        "abstract": "We describe an efficient algorithm for the simulation of large sets of non-convex rigid bodies. The algorithm finds a simultaneous solution for a multi-body system that is linear in the total number of contacts detected in each iteration. We employ a novel contact model that uses mass, location, and velocity information from all contacts, at the moment of maximum compression, to constrain rigid body velocities. We also develop a new friction model in the configuration space of rigid bodies. These models are used to compute the feasible velocity and the frictional response of each body. Implementation is simple and leads to a fast rigid body simulator that computes steps on the order of seconds for simulations involving over one thousand non-convex objects in high contact configurations. ", 
        "id": 339, 
        "title": "Fast frictional dynamics for rigid bodies."
    }, 
    {
        "abstract": "Techniques for interactive deformation of unstructured polygon meshes are of fundamental importance to a host of applications. Most traditional approaches to this problem have emphasized precise control over the deformation being made. However, they are often cumbersome and unintuitive for non-expert users. In this paper, we present an interactive system for deforming unstructured polygon meshes that is very easy to use. The user interacts with the system by sketching curves in the image plane. A single stroke can define a free-form skeleton and the region of the model to be deformed. By sketching the desired deformation of this reference curve, the user can implicitly and intuitively control the deformation of an entire region of the surface. At the same time, the reference curve also provides a basis for controlling additional parameters, such as twist and scaling. We demonstrate that our system can be used to interactively edit a variety of unstructured mesh models with very little effort. Furthermore, we can also use our formulation of the deformation to achieve a natural interpolation between character poses, thus producing simple key framed animations.  Figure 1: A simple sketch-based mesh deformation. The user draws a reference curve along the leg, followed by a second target curve. This induces a deformation of the leg itself.  Overview In our system, the user initiates a deformation by drawing a reference curve on the image plane. This curve implicitly partitions the model into three components: (1) a static component, (2) a rigid component, and (3) a region of interest -- that part of the surface which will be deformed. The user then applies the deformation either by sketching a new target shape for the reference curve or by directly manipulating a deformation parameter such as twist or scaling. Figure 1 illustrates our basic interaction model. The user begins by drawing a reference curve along the leg. The region of interest is highlighted with a red-to-blue color ramp. The static component is the whole body beyond the left thigh, which is not transformed at all, and the left foot is the rigid component that is rigidly transformed. The user then draws a target curve indicating the desired deformation. From this pair of curves, the system automatically generates the deformation of the leg. Users of our system can make significant edits to complex 3D mesh models with only a handful of mouse gestures. Figure 2 shows some more complete examples produced with our system. The original raptor and hand models--indicated by arrows--are reposed in a number of ways. Each reposed model was generated in 2 minutes or less. e-mail: kho@uiuc.edu e-mail: garland@uiuc.edu Copyright  2005 by the Association for Computing Machinery, Inc. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org.  2005 ACM 0730-0301/05/0700-0934 $5.00  Figure 2: Various examples derived from the two originals indicated by arrows. Each edited model was produced in no more than 2 minutes. Further Details Complete details can be found in our full paper [Kho and Garland 2005]. Electronic copies of this paper, movies illustrating our system in action, and other materials can be found online at: http://graphics.cs.uiuc.edu/kho/smd.html. References KHO, Y., AND GARLAND, M. 2005. Sketching mesh deformations. In ACM Symposium on Interactive 3D Graphics and Games, ACM Press, 147154.  934  \f ", 
        "id": 340, 
        "title": "Sketching mesh deformations."
    }, 
    {
        "abstract": "This paper introduces a new method for real-time relighting of scenes illuminated by local light sources. We extend previous work on precomputed radiance transfer for distant lighting to local lighting by introducing the concept of unstructured light clouds. The unstructured light cloud enables a compact representation of local lights in the model and real-time rendering of complex models with full global illumination due to local light sources. We use simplification of lights, and clustered PCA to obtain a compressed representation. When storing only the indirect component of the illumination, we are able to get high quality with only 8 16 lighting coefficients per vertex. Our results demonstrate real-time rendering of scenes with moving lights, dynamic cameras, glossy materials and global illumination. ", 
        "id": 341, 
        "title": "Precomputed local radiance transfer for real-time lighting design."
    }, 
    {
        "abstract": "We present a novel technique for texture synthesis using optimization. We define a Markov Random Field (MRF)-based similarity metric for measuring the quality of synthesized texture with respect to a given input sample. This allows us to formulate the synthesis problem as minimization of an energy function, which is optimized using an Expectation Maximization (EM)-like algorithm. In contrast to most example-based techniques that do region-growing, ours is a joint optimization approach that progressively refines the entire texture. Additionally, our approach is ideally suited to allow for controllable synthesis of textures. Specifically, we demonstrate controllability by animating image textures using flow fields. We allow for general two-dimensional flow fields that may dynamically change over time. Applications of this technique include dynamic texturing of fluid animations and texture-based flow visualization. ", 
        "id": 342, 
        "title": "Texture optimization for example-based synthesis."
    }, 
    {
        "abstract": "", 
        "id": 343, 
        "title": "A procedural object distribution function."
    }, 
    {
        "abstract": "We present a new, fast algorithm for rendering physically-based soft shadows in ray tracing-based renderers. Our method replaces the hundreds of shadow rays commonly used in stochastic ray tracers with a single shadow ray and a local reconstruction of the visibility function. Compared to tracing the shadow rays, our algorithm produces exactly the same image while executing one to two orders of magnitude faster in the test scenes used. Our first contribution is a two-stage method for quickly determining the silhouette edges that overlap an area light source, as seen from the point to be shaded. Secondly, we show that these partial silhouettes of occluders, along with a single shadow ray, are sufficient for reconstructing the visibility function between the point and the light source. ", 
        "id": 344, 
        "title": "Soft shadow volumes for ray tracing."
    }, 
    {
        "abstract": "Tone mapping operators are designed to reproduce visibility and the overall impression of brightness, contrast and color of the real world onto limited dynamic range displays and printers. Although many tone mapping operators have been published in recent years, no thorough psychophysical experiments have yet been undertaken to compare such operators against the real scenes they are purporting to depict. In this paper, we present the results of a series of psychophysical experiments to validate six frequently used tone mapping operators against linearly mapped High Dynamic Range (HDR) scenes displayed on a novel HDR device. Individual operators address the tone mapping issue using a variety of approaches and the goals of these techniques are often quite different from one another. Therefore, the purpose of this investigation was not simply to determine which is the \"best\" algorithm, but more generally to propose an experimental methodology to validate such operators and to determine the participants' impressions of the images produced compared to what is visible on a high contrast ratio display. ", 
        "id": 345, 
        "title": "Evaluation of tone mapping operators using a High Dynamic Range display."
    }, 
    {
        "abstract": "", 
        "id": 346, 
        "title": "Feature-based multiresolution modeling of solids."
    }, 
    {
        "abstract": "Research over the last decade has built a solid mathematical foundation for representation and analysis of 3D meshes in graphics and geometric modeling. Much of this work however does not explicitly incorporate models of low-level human visual attention. In this paper we introduce the idea of mesh saliency as a measure of regional importance for graphics meshes. Our notion of saliency is inspired by low-level human visual system cues. We define mesh saliency in a scale-dependent manner using a center-surround operator on Gaussian-weighted mean curvatures. We observe that such a definition of mesh saliency is able to capture what most would classify as visually interesting regions on a mesh. The human-perceptioninspired importance measure computed by our mesh saliency operator results in more visually pleasing results in processing and viewing of 3D meshes, compared to using a purely geometric measure of shape, such as curvature. We discuss how mesh saliency can be incorporated in graphics applications such as mesh simplification and viewpoint selection and present examples that show visually appealing results from using mesh saliency. ", 
        "id": 347, 
        "title": "Mesh saliency."
    }, 
    {
        "abstract": "We present a texture synthesis scheme based on neighborhood matching, with contributions in two areas: parallelism and control. Our scheme defines an infinite, deterministic, aperiodic texture, from which windows can be computed in real-time on a GPU. We attain high-quality synthesis using a new analysis structure called the Gaussian stack, together with a coordinate upsampling step and a subpass correction approach. Texture variation is achieved by multiresolution jittering of exemplar coordinates. Combined with the local support of parallel synthesis, the jitter enables intuitive user controls including multiscale randomness, spatial modulation over both exemplar and output, feature dragand-drop, and periodicity constraints. We also introduce synthesis magnification, a fast method for amplifying coarse synthesis results to higher resolution. ", 
        "id": 348, 
        "title": "Parallel controllable texture synthesis."
    }, 
    {
        "abstract": "We introduce a rigid motion invariant mesh representation based on discrete forms defined on the mesh. The reconstruction of mesh geometry from this representation requires solving two sparse linear systems that arise from the discrete forms: the first system defines the relationship between local frames on the mesh, and the second encodes the position of the vertices via the local frames. The reconstructed geometry is unique up to a rigid transformation of the mesh. We define surface editing operations by placing user-defined constraints on the local frames and the vertex positions. These constraints are incorporated in the two linear reconstruction systems, and their solution produces a deformed surface geometry that preserves the local differential properties in the least-squares sense. Linear combination of shapes expressed with our representation enables linear shape interpolation that correctly handles rotations. We demonstrate the effectiveness of the new representation with various detail-preserving editing operators and shape morphing. ", 
        "id": 349, 
        "title": "Linear rotation-invariant coordinates for meshes."
    }, 
    {
        "abstract": "righ dynmi rnge @rhA imging is n re of inresing imE portneD ut most disply devies still hve limited dynmi rnge @vhAF rious tehniques hve een proposed for ompressing the dynmi rnge while retining importnt visul informtionF wultiE sle imge proessing tehniquesD whih re widely used for mny imge proessing tsksD hve  reputtion of using hlo rtifts when used for rnge ompressionF roweverD we demonstrte tht they n work when properly implementedF e use  symmetril nlysisEsynthesis lter nkD nd pply lol gin ontrol to the sundsF e lso show tht the tehnique n e dpted for the relted prolem of ompndingD in whih n rh imge is onE verted to n vh imgeD nd lter expnded k to high dynmi rngeF ", 
        "id": 350, 
        "title": "Compressing and companding high dynamic range images with subband architectures."
    }, 
    {
        "abstract": "In this paper, we present a system for cutting a moving object out from a video clip. The cutout object sequence can be pasted onto another video or a background image. To achieve this, we first apply a new 3D graph cut based segmentation approach on the spatialtemporal video volume. Our algorithm partitions watershed presegmentation regions into foreground and background while preserving temporal coherence. Then, the initial segmentation result is refined locally. Given two frames in the video sequence, we specify two respective windows of interest which are then tracked using a bi-directional feature tracking algorithm. For each frame in between these two given frames, the segmentation in each tracked window is refined using a 2D graph cut that utilizes a local color model. Moreover, we provide brush tools for the user to control the object boundary precisely wherever needed. Based on the accurate binary segmentation result, we apply coherent matting to extract the alpha mattes and foreground colors of the object. ", 
        "id": 351, 
        "title": "Video object cut and paste."
    }, 
    {
        "abstract": "This paper presents a novel physics-based representation of realistic character motion. The dynamical model incorporates several factors of locomotion derived from the biomechanical literature, including relative preferences for using some muscles more than others, elastic mechanisms at joints due to the mechanical properties of tendons, ligaments, and muscles, and variable stiffness at joints depending on the task. When used in a spacetime optimization framework, the parameters of this model define a wide range of styles of natural human movement. Due to the complexity of biological motion, these style parameters are too difficult to design by hand. To address this, we introduce Nonlinear Inverse Optimization, a novel algorithm for estimating optimization parameters from motion capture data. Our method can extract the physical parameters from a single short motion sequence. Once captured, this representation of style is extremely flexible: motions can be generated in the same style but performing different tasks, and styles may be edited to change the physical properties of the body. ", 
        "id": 352, 
        "title": "Learning physics-based motion style with nonlinear inverse optimization."
    }, 
    {
        "abstract": "We present motion magnification, a technique that acts like a microscope for visual motion. It can amplify subtle motions in a video sequence, allowing for visualization of deformations that would otherwise be invisible. To achieve motion magnification, we need to accurately measure visual motions, and group the pixels to be modified. After an initial image registration step, we measure motion by a robust analysis of feature point trajectories, and segment pixels based on similarity of position, color, and motion. A novel measure of motion similarity groups even very small motions according to correlation over time, which often relates to physical cause. An outlier mask marks observations not explained by our layered motion model, and those pixels are simply reproduced on the output from the original registered observations. The motion of any selected layer may be magnified by a userspecified amount; texture synthesis fills-in unseen \"holes\" revealed by the amplified motions. The resulting motion-magnified images can reveal or emphasize small motions in the original sequence, as we demonstrate with deformations in load-bearing structures, subtle motions or balancing corrections of people, and \"rigid\" structures bending under hand pressure. ", 
        "id": 353, 
        "title": "Motion magnification."
    }, 
    {
        "abstract": "We present a method for resolution independent rendering of paths and bounded regions, defined by quadratic and cubic spline curves, that leverages the parallelism of programmable graphics hardware to achieve high performance. A simple implicit equation for a parametric curve is found in a space that can be thought of as an analog to texture space. The image of a curve's Bezier control points are found in this space and assigned to the control points as texture coordinates. When the triangle(s) corresponding to the Bezier curve control hull are rendered, a pixel shader program evaluates the implicit equation for a pixel's interpolated texture coordinates to determine an inside/outside test for the curve. We extend our technique to handle anti-aliasing of boundaries. We also construct a vector image from mosaics of triangulated Bezier control points and show how to deform such images to create resolution independent texture on three dimensional objects. ", 
        "id": 354, 
        "title": "Resolution independent curve rendering using programmable graphics hardware."
    }, 
    {
        "abstract": "In this paper [MacIntyre et al 2004], we describe The Designer's Augmented Reality Toolkit (DART). DART is built on top of Macromedia Director, a widely used multimedia development environment. We summarize the most significant problems faced by designers working with AR in the real world, and discuss how DART addresses them. Most of DART is implemented in an interpreted scripting language, and can be modified by designers to suit their needs. Our work focuses on supporting early design activities, especially a rapid transition from storyboards to working experience, so that the experiential part of a design can be tested early and often. DART allows designers to specify complex relationships between the physical and virtual worlds, and supports 3D animatic actors (informal, sketch-based content) in addition to more polished content. Designers can capture and replay synchronized video and sensor data, allowing them to work off-site and to test specific parts of their experience more effectively. ", 
        "id": 355, 
        "title": "DART: a toolkit for rapid design exploration of augmented reality experiences."
    }, 
    {
        "abstract": "", 
        "id": 356, 
        "title": "Perceptual photometric seamlessness in projection-based tiled displays."
    }, 
    {
        "abstract": "Wood coated with transparent finish has a beautiful and distinctive appearance that is familiar to everyone. Woods with unusual grain patterns, such as tiger, burl, and birdseye figures, have a strikingly unusual directional reflectance that is prized for decorative applications. With new, high resolution measurements of spatially varying BRDFs, we show that this distinctive appearance is due to light scattering that does not conform to the usual notion of anisotropic surface reflection. The behavior can be explained by scattering from the matrix of wood fibers below the surface, resulting in a subsurface highlight that occurs on a cone with an out-of-plane axis. We propose a new shading model component to handle reflection from subsurface fibers, which is combined with the standard diffuse and specular components to make a complete shading model. Rendered results from fits of our model to the measurement data demonstrate that this new model captures the distinctive appearance of wood. ", 
        "id": 357, 
        "title": "Measuring and modeling the appearance of finished wood."
    }, 
    {
        "abstract": "We present a system for designing novel textures in the space of textures induced by an input database. We capture the structure of the induced space by a simplicial complex where vertices of the simplices represent input textures. A user can generate new textures by interpolating within individual simplices. We propose a morphable interpolation for textures, which also defines a metric used to build the simplicial complex. To guarantee sharpness in interpolated textures, we enforce histograms of high-frequency content using a novel method for histogram interpolation. We allow users to continuously navigate in the simplicial complex and design new textures using a simple and efficient user interface. We demonstrate the usefulness of our system by integrating it with a 3D texture painting application, where the user interactively designs desired textures. ", 
        "id": 358, 
        "title": "Texture design using a simplicial complex of morphable textures."
    }, 
    {
        "abstract": "Video matting is the process of pulling a high-quality alpha matte and foreground from a video sequence. Current techniques require either a known background (e.g., a blue screen) or extensive user interaction (e.g., to specify known foreground and background elements). The matting problem is generally under-constrained, since not enough information has been collected at capture time. We propose a novel, fully autonomous method for pulling a matte using multiple synchronized video streams that share a point of view but differ in their plane of focus. The solution is obtained by directly minimizing the error in filter-based image formation equations, which are over-constrained by our rich data stream. Our system solves the fully dynamic video matting problem without user assistance: both the foreground and background may be high frequency and have dynamic content, the foreground may resemble the background, and the scene is lit by natural (as opposed to polarized or collimated) illumination. ", 
        "id": 359, 
        "title": "Defocus video matting."
    }, 
    {
        "abstract": "", 
        "id": 360, 
        "title": "Low-complexity maximum intensity projection."
    }, 
    {
        "abstract": "A common motion interpolation technique for realistic human animation is to blend similar motion samples with weighting functions whose parameters are embedded in an abstract space. Existing methods, however, are insensitive to statistical properties, such as correlations between motions. In addition, they lack the capability to quantitatively evaluate the reliability of synthesized motions. This paper proposes a method that treats motion interpolations as statistical predictions of missing data in an arbitrarily definable parametric space. A practical technique of geostatistics, called universal kriging, is then introduced for statistically estimating the correlations between the dissimilarity of motions and the distance in the parametric space. Our method statistically optimizes interpolation kernels for given parameters at each frame, using a pose distance metric to efficiently analyze the correlation. Motions are accurately predicted for the spatial constraints represented in the parametric space, and they therefore have few undesirable artifacts, if any. This property alleviates the problem of spatial inconsistencies, such as foot-sliding, that are associated with many existing methods. Moreover, numerical estimates for the reliability of predictions enable motions to be adaptively sampled. Since the interpolation kernels are computed with a linear system in real-time, motions can be interactively edited using various spatial controls. ", 
        "id": 361, 
        "title": "Geostatistical motion interpolation."
    }, 
    {
        "abstract": "We present a new approach for simulating deformable objects. The underlying model is geometrically motivated. It handles pointbased objects and does not need connectivity information. The approach does not require any pre-processing, is simple to compute, and provides unconditionally stable dynamic simulations. The main idea of our deformable model is to replace energies by geometric constraints and forces by distances of current positions to goal positions. These goal positions are determined via a generalized shape matching of an undeformed rest state with the current deformed state of the point cloud. Since points are always drawn towards well-defined locations, the overshooting problem of explicit integration schemes is eliminated. The versatility of the approach in terms of object representations that can be handled, the efficiency in terms of memory and computational complexity, and the unconditional stability of the dynamic simulation make the approach particularly interesting for games. ", 
        "id": 362, 
        "title": "Meshless deformations based on shape matching."
    }, 
    {
        "abstract": "The reuse of human motion capture data to create new, realistic motions by applying morphing and blending techniques has become an important issue in computer animation. This requires the identification and extraction of logically related motions scattered within some data set. Such content-based retrieval of motion capture data, which is the topic of this paper, constitutes a difficult and timeconsuming problem due to significant spatio-temporal variations between logically related motions. In our approach, we introduce various kinds of qualitative features describing geometric relations between specified body points of a pose and show how these features induce a time segmentation of motion capture data streams. By incorporating spatio-temporal invariance into the geometric features and adaptive segments, we are able to adopt efficient indexing methods allowing for flexible and efficient content-based retrieval and browsing in huge motion capture databases. Furthermore, we obtain an efficient preprocessing method substantially accelerating the cost-intensive classical dynamic time warping techniques for the time alignment of logically similar motion data streams. We present experimental results on a test data set of more than one million frames, corresponding to 180 minutes of motion. The linearity of our indexing algorithms guarantees the scalability of our results to much larger data sets. ", 
        "id": 363, 
        "title": "Efficient content-based retrieval of motion capture data."
    }, 
    {
        "abstract": "In this paper we present a method for the intuitive editing of surface meshes by means of view-dependent sketching. In most existing shape deformation work, editing is carried out by selecting and moving a handle, usually a set of vertices. Our system lets the user easily determine the handle, either by silhouette selection and cropping, or by sketching directly onto the surface. Subsequently, an edit is carried out by sketching a new, view-dependent handle position or by indirectly influencing differential properties along the sketch. Combined, these editing and handle metaphors greatly simplify otherwise complex shape modeling tasks. ", 
        "id": 364, 
        "title": "A sketch-based interface for detail-preserving mesh editing."
    }, 
    {
        "abstract": "Range scanning, manual 3D editing, and other modeling approaches can provide information about the geometry of surfaces in the form of either 3D positions (e.g., triangle meshes or range images) or orientations (normal maps or bump maps). We present an algorithm that combines these two kinds of estimates to produce a new surface that approximates both. Our formulation is linear, allowing it to operate efficiently on complex meshes commonly used in graphics. It also treats high- and low-frequency components separately, allowing it to optimally combine outputs from data sources such as stereo triangulation and photometric stereo, which have different error-vs.-frequency characteristics. We demonstrate the ability of our technique to both recover high-frequency details and avoid low-frequency bias, producing surfaces that are more widely applicable than position or orientation data alone.  ", 
        "id": 365, 
        "title": "Efficiently combining positions and normals for precise 3D geometry."
    }, 
    {
        "abstract": "This paper contributes to the theory of photograph formation from light fields. The main result is a theorem that, in the Fourier domain, a photograph formed by a full lens aperture is a 2D slice in the 4D light field. Photographs focused at different depths correspond to slices at different trajectories in the 4D space. The paper demonstrates the utility of this theorem in two different ways. First, the theorem is used to analyze the performance of digital refocusing, where one computes photographs focused at different depths from a single light field. The analysis shows in closed form that the sharpness of refocused photographs increases linearly with directional resolution. Second, the theorem yields a Fourier-domain algorithm for digital refocusing, where we extract the appropriate 2D slice of the light field's Fourier transform, and perform an inverse 2D Fourier transform. This method is faster than previous approaches. ", 
        "id": 366, 
        "title": "Fourier slice photography."
    }, 
    {
        "abstract": "", 
        "id": 367, 
        "title": "Beta-connection: Generating a family of models from planar cross sections."
    }, 
    {
        "abstract": "We present a new meshless animation framework for elastic and plastic materials that fracture. Central to our method is a highly dynamic surface and volume sampling method that supports arbitrary crack initiation, propagation, and termination, while avoiding many of the stability problems of traditional mesh-based techniques. We explicitly model advancing crack fronts and associated fracture surfaces embedded in the simulation volume. When cutting through the material, crack fronts directly affect the coupling between simulation nodes, requiring a dynamic adaptation of the nodal shape functions. We show how local visibility tests and dynamic caching lead to an efficient implementation of these effects based on point collocation. Complex fracture patterns of interacting and branching cracks are handled using a small set of topological operations for splitting, merging, and terminating crack fronts. This allows continuous propagation of cracks with highly detailed fracture surfaces, independent of the spatial resolution of the simulation nodes, and provides effective mechanisms for controlling fracture paths. We demonstrate our method for a wide range of materials, from stiff elastic to highly plastic objects that exhibit brittle and/or ductile fracture. ", 
        "id": 368, 
        "title": "Meshless animation of fracturing solids."
    }, 
    {
        "abstract": " ", 
        "id": 369, 
        "title": "User-configurable automatic shader simplification."
    }, 
    {
        "abstract": "In computer cinematography, the process of lighting design involves placing and configuring lights to define the visual appearance of environments and to enhance story elements. This process is labor intensive and time consuming, primarily because lighting artists receive poor feedback from existing tools: interactive previews have very poor quality, while final-quality images often take hours to render. This paper presents an interactive cinematic lighting system used in the production of computer-animated feature films containing environments of very high complexity, in which surface and light appearances are described using procedural RenderMan shaders. Our system provides lighting artists with high-quality previews at interactive framerates with only small approximations compared to the final rendered images. This is accomplished by combining numerical estimation of surface response, image-space caching, deferred shading, and the computational power of modern graphics hardware. Our system has been successfully used in the production of two feature-length animated films, dramatically accelerating lighting tasks. In our experience interactivity fundamentally changes an artist's workflow, improving both productivity and artistic expressiveness. ", 
        "id": 370, 
        "title": "Lpics: a hybrid hardware-accelerated relighting engine for computer cinematography."
    }, 
    {
        "abstract": "A new progressive lossless 3D triangular mesh encoder is proposed in this work, which can encode any 3D triangular mesh with an arbitrary topological structure. Given a mesh, the quantized 3D vertices are first partitioned into an octree (OT) structure, which is then traversed from the root and gradually to the leaves. During the traversal, each 3D cell in the tree front is subdivided into eight childcells. For each cell subdivision, both local geometry and connectivity changes are encoded, where the connectivity coding is guided by the geometry coding. Furthermore, prioritized cell subdivision is performed in the tree front to provide better rate-distortion (RD) performance. Experiments show that the proposed mesh coder outperforms the kd-tree algorithm in both geometry and connectivity coding efficiency. For the geometry coding part, the range of improvement is typically around 10%20%, but may go up to 50%60% for meshes with highly regular geometry data and/or tight clustering of vertices. ", 
        "id": 371, 
        "title": "Geometry-guided progressive lossless 3D mesh coding with octree (OT) decomposition."
    }, 
    {
        "abstract": "This paper describes the construction of second generation bandelet bases and their application to 3D geometry compression. This new coding scheme is orthogonal and the corresponding basis functions are regular. In our method, surfaces are decomposed in a bandelet basis with a fast bandeletization algorithm that removes the geometric redundancy of orthogonal wavelet coefficients. The resulting transform coding scheme has an error decay that is asymptotically optimal for geometrically regular surfaces. We then use these bandelet bases to perform geometry image and normal map compression. Numerical tests show that for complex surfaces bandelets bring an improvement of 1.5dB to 2dB over state of the art compression schemes. ", 
        "id": 372, 
        "title": "Surface compression with geometric bandelets."
    }, 
    {
        "abstract": "We present a technique for mapping relief textures onto arbitrary polygonal models in real time, producing correct self-occlusions, interpenetrations, shadows and per-pixel lighting. The technique uses a pixel-driven formulation based on an efficient ray-heightfield intersection implemented on the GPU. It has very low memory requirements, supports extreme close-up views of the surfaces and can be applicable to surfaces undergoing deformation.  ", 
        "id": 373, 
        "title": "Real-time relief mapping on arbitrary polygonal surfaces."
    }, 
    {
        "abstract": "A shell map is a bijective mapping between shell space and texture space that can be used to generate small-scale features on surfaces using a variety of modeling techniques. The method is based upon the generation of an offset surface and the construction of a tetrahedral mesh that fills the space between the base surface and its offset. By identifying a corresponding tetrahedral mesh in texture space, the shell map can be implemented through a straightforward barycentriccoordinate map between corresponding tetrahedra. The generality of shell maps allows texture space to contain geometric objects, procedural volume textures, scalar fields, or other shell-mapped objects. ", 
        "id": 374, 
        "title": "Shell maps."
    }, 
    {
        "abstract": " Forward dynamics is central to physically-based simulation and control of articulated bodies. We present an adaptive algorithm for computing forward dynamics of articulated bodies: using novel motion error metrics, our algorithm can automatically simplify the dynamics of a multi-body system, based on the desired number of degrees of freedom and the location of external forces and active joint forces. We demonstrate this method in plausible animation of articulated bodies, including a large-scale simulation of 200 animated humanoids and multi-body dynamics systems with many degrees of freedom. The graceful simplification allows us to achieve up to two orders of magnitude performance improvement in several complex benchmarks. ", 
        "id": 375, 
        "title": "Adaptive dynamics of articulated bodies."
    }, 
    {
        "abstract": "In this paper, we investigate whether it is possible to develop a measure that quantifies the naturalness of human motion (as defined by a large database). Such a measure might prove useful in verifying that a motion editing operation had not destroyed the naturalness of a motion capture clip or that a synthetic motion transition was within the space of those seen in natural human motion. We explore the performance of mixture of Gaussians (MoG), hidden Markov models (HMM), and switching linear dynamic systems (SLDS) on this problem. We use each of these statistical models alone and as part of an ensemble of smaller statistical models. We also implement a Naive Bayes (NB) model for a baseline comparison. We test these techniques on motion capture data held out from a database, keyframed motions, edited motions, motions with noise added, and synthetic motion transitions. We present the results as receiver operating characteristic (ROC) curves and compare the results to the judgments made by subjects in a user study. ", 
        "id": 376, 
        "title": "A data-driven approach to quantifying natural human motion."
    }, 
    {
        "abstract": "", 
        "id": 377, 
        "title": "Learning silhouette features for control of human motion."
    }, 
    {
        "abstract": "We propose new approaches to ray tracing that greatly reduce the required number of operations while strictly preserving the geometrical correctness of the solution. A hierarchical \"beam\" structure serves as a proxy for a collection of rays. It is tested against a kd-tree representing the overall scene in order to discard from consideration the sub-set of the kd-tree (and hence the scene) that is guaranteed not to intersect with any possible ray inside the beam. This allows for all the rays inside the beam to start traversing the tree from some node deep inside thus eliminating unnecessary operations. The original beam can be further sub-divided, and we can either continue looking for new optimal entry points for the sub-beams, or we can decompose the beam into individual rays. This is a hierarchical process that can be adapted to the geometrical complexity of a particular view direction allowing for efficient geometric anti-aliasing. By amortizing the cost of partially traversing the tree for all the rays in a beam, up to an order of magnitude performance improvement can be achieved enabling interactivity for complex scenes on ordinary desktop machines. ", 
        "id": 378, 
        "title": "Multi-level ray tracing algorithm."
    }, 
    {
        "abstract": "We introduce a class of biologically-motivated algorithms for generating leaf venation patterns. These algorithms simulate the interplay between three processes: (1) development of veins towards hormone (auxin) sources embedded in the leaf blade; (2) modification of the hormone source distribution by the proximity of veins; and (3) modification of both the vein pattern and source distribution by leaf growth. These processes are formulated in terms of iterative geometric operations on sets of points that represent vein nodes and auxin sources. In addition, a vein connection graph is maintained to determine vein widths. The effective implementation of the algorithms relies on the use of space subdivision (Voronoi diagrams) and time coherence between iteration steps. Depending on the specification details and parameters used, the algorithms can simulate many types of venation patterns, both open (tree-like) and closed (with loops). Applications of the presented algorithms include texture and detailed structure generation for image synthesis purposes, and modeling of morphogenetic processes in support of biological research. ", 
        "id": 379, 
        "title": "Modeling and visualization of leaf venation patterns."
    }, 
    {
        "abstract": "Virtual reality (VR) has long been hampered by the gear needed to make the experience possible; specifically, stereo glasses and tracking devices. Autostereoscopic display devices are gaining popularity by freeing the user from stereo glasses, however few qualify as VR displays. The Electronic Visualization Laboratory (EVL) at the University of Illinois at Chicago (UIC) has designed and produced a large scale, high resolution headtracked barrier-strip autostereoscopic display system that produces a VR immersive experience without requiring the user to wear any encumbrances. The resulting system, called Varrier, is a passive parallax barrier 35-panel tiled display that produces a wide field of view, head-tracked VR experience. This paper presents background material related to parallax barrier autostereoscopy, provides system configuration and construction details, examines Varrier interleaving algorithms used to produce the stereo images, introduces calibration and testing, and discusses the camera-based tracking subsystem. ", 
        "id": 380, 
        "title": "The VarrierTM autostereoscopic virtual reality display."
    }, 
    {
        "abstract": "", 
        "id": 381, 
        "title": "On C"
    }, 
    {
        "abstract": "Vorticity confinement reintroduces the small scale detail lost when using efficient semi-Lagrangian schemes for simulating smoke and fire. However, it only amplifies the existing vorticity, and thus can be insufficient for highly turbulent effects such as explosions or rough water. We introduce a new hybrid technique that makes synergistic use of Lagrangian vortex particle methods and Eulerian grid based methods to overcome the weaknesses of both. Our approach uses vorticity confinement itself to couple these two methods together. We demonstrate that this approach can generate highly turbulent effects unachievable by standard grid based methods, and show applications to smoke, water and explosion simulations. ", 
        "id": 382, 
        "title": "A vortex particle method for smoke, water and explosions."
    }, 
    {
        "abstract": "We present a novel photographic technique called dual photography, which exploits Helmholtz reciprocity to interchange the lights and cameras in a scene. With a video projector providing structured illumination, reciprocity permits us to generate pictures from the viewpoint of the projector, even though no camera was present at that location. The technique is completely image-based, requiring no knowledge of scene geometry or surface properties, and by its nature automatically includes all transport paths, including shadows, inter-reflections and caustics. In its simplest form, the technique can be used to take photographs without a camera; we demonstrate this by capturing a photograph using a projector and a photo-resistor. If the photo-resistor is replaced by a camera, we can produce a 4D dataset that allows for relighting with 2D incident illumination. Using an array of cameras we can produce a 6D slice of the 8D reflectance field that allows for relighting with arbitrary light fields. Since an array of cameras can operate in parallel without interference, whereas an array of light sources cannot, dual photography is fundamentally a more efficient way to capture such a 6D dataset than a system based on multiple projectors and one camera. As an example, we show how dual photography can be used to capture and relight scenes. ", 
        "id": 383, 
        "title": "Dual photography."
    }, 
    {
        "abstract": "", 
        "id": 384, 
        "title": "ABF++: fast and robust angle based flattening."
    }, 
    {
        "abstract": "By organizing the control mesh of subdivision in texture memory so that irregularities occur strictly inside independently refinable fragment meshes, all major features of subdivision algorithms can be realized in the framework of highly parallel stream processing. Our implementation of Catmull-Clark subdivision as a GPU kernel in programmable graphics hardware can model features like semi-smooth creases and global boundaries; and a simplified version achieves near-realtime depth-five re-evaluation of moderatesreizfiendemsuebndtivpiastitoenrnms,essuhcehs.aTs hLeooappp, rDooacoh-Siasbeinasoilryad3aapnteddittoalolothwesr for postprocessing with additional shaders. ", 
        "id": 385, 
        "title": "A realtime GPU subdivision kernel."
    }, 
    {
        "abstract": "", 
        "id": 386, 
        "title": "Controllable smoke animation with guiding objects."
    }, 
    {
        "abstract": "We built an anatomically accurate model of facial musculature, passive tissue and underlying skeletal structure using volumetric data acquired from a living male subject. The tissues are endowed with a highly nonlinear constitutive model including controllable anisotropic muscle activations based on fiber directions. Detailed models of this sort can be difficult to animate requiring complex coordinated stimulation of the underlying musculature. We propose a solution to this problem automatically determining muscle activations that track a sparse set of surface landmarks, e.g. acquired from motion capture marker data. Since the resulting animation is obtained via a three dimensional nonlinear finite element method, we obtain visually plausible and anatomically correct deformations with spatial and temporal coherence that provides robustness against outliers in the motion capture data. Moreover, the obtained muscle activations can be used in a robust simulation framework including contact and collision of the face with external objects. ", 
        "id": 387, 
        "title": "Automatic determination of facial muscle activations from sparse motion capture marker data."
    }, 
    {
        "abstract": "Precomputed radiance transfer (PRT) captures realistic lighting effects from distant, low-frequency environmental lighting but has been limited to static models or precomputed sequences. We focus on PRT for local effects such as bumps, wrinkles, or other detailed features, but extend it to arbitrarily deformable models. Our approach applies zonal harmonics (ZH) which approximate spherical functions as sums of circularly symmetric Legendre polynomials around different axes. By spatially varying both the axes and coefficients of these basis functions, we can fit to spatially varying transfer signals. Compared to the spherical harmonic (SH) basis, the ZH basis yields a more compact approximation. More important, it can be trivially rotated whereas SH rotation is expensive and unsuited for dense per-vertex or per-pixel evaluation. This property allows, for the first time, PRT to be mapped onto deforming models which re-orient the local coordinate frame. We generate ZH transfer models by fitting to PRT signals simulated on meshes or simple parametric models for thin membranes and wrinkles. We show how shading with ZH transfer can be significantly accelerated by specializing to a given lighting environment. Finally, we demonstrate real-time rendering results with soft shadows, inter-reflections, and subsurface scatter on deforming models. ", 
        "id": 388, 
        "title": "Local, deformable precomputed radiance transfer."
    }, 
    {
        "abstract": "", 
        "id": 389, 
        "title": "Stable but nondissipative water."
    }, 
    {
        "abstract": "", 
        "id": 390, 
        "title": "Adaptation of performed ballistic motion."
    }, 
    {
        "abstract": "The ability to position a small subset of mesh vertices and produce a meaningful overall deformation of the entire mesh is a fundamental task in mesh editing and animation. However, the class of meaningful deformations varies from mesh to mesh and depends on mesh kinematics, which prescribes valid mesh configurations, and a selection mechanism for choosing among them. Drawing an analogy to the traditional use of skeleton-based inverse kinematics for posing skeletons, we define mesh-based inverse kinematics as the problem of finding meaningful mesh deformations that meet specified vertex constraints. Our solution relies on example meshes to indicate the class of meaningful deformations. Each example is represented with a feature vector of deformation gradients that capture the affine transformations which individual triangles undergo relative to a reference pose. To pose a mesh, our algorithm efficiently searches among all meshes with specified vertex positions to find the one that is closest to some pose in a nonlinear span of the example feature vectors. Since the search is not restricted to the span of example shapes, this produces compelling deformations even when the constraints require poses that are different from those observed in the examples. Furthermore, because the span is formed by a nonlinear blend of the example feature vectors, the blending component of our system may also be used independently to pose meshes by specifying blending weights or to compute multi-way morph sequences. ", 
        "id": 391, 
        "title": "Mesh-based inverse kinematics."
    }, 
    {
        "abstract": "We consider real-time rendering of scenes in participating media, capturing the effects of light scattering in fog, mist and haze. While a number of sophisticated approaches based on Monte Carlo and finite element simulation have been developed, those methods do not work at interactive rates. The most common real-time methods are essentially simple variants of the OpenGL fog model. While easy to use and specify, that model excludes many important qualitative effects like glows around light sources, the impact of volumetric scattering on the appearance of surfaces such as the diffusing of glossy highlights, and the appearance under complex lighting such as environment maps. In this paper, we present an alternative physically based approach that captures these effects while maintaining realtime performance and the ease-of-use of the OpenGL fog model. Our method is based on an explicit analytic integration of the single scattering light transport equations for an isotropic point light source in a homogeneous participating medium. We can implement the model in modern programmable graphics hardware using a few small numerical lookup tables stored as texture maps. Our model can also be easily adapted to generate the appearances of materials with arbitrary BRDFs, environment map lighting, and precomputed radiance transfer methods, in the presence of participating media. Hence, our techniques can be widely used in real-time rendering.  (a) Clear day  ", 
        "id": 392, 
        "title": "A practical analytic single scattering model for real time rendering."
    }, 
    {
        "abstract": "2TsinghuaUniversity 3ChineseUniversityofHongKong twointersectinglines(green)specifiedbytheuser,(c)intermediateresultafterpropagatingstructureandtextureinformationalongthe Figure1:Imagecompletionwithstructurepropagation.(a)Inputimage,(b)unknownregion(blue)afterremovingthepumpkin,with user-specifiedlines,and(d)finalresultafterfillingintheremainingunknownregionsbytexturepropagation. Abstract pletion,whichwecallstructurepropagation.Inoursystem, Inthispaper,weintroduceanovelapproachtoimagecom-formationbyextendingafewcurvesorlinesegmentsfrom theusermanuallyspecifiesimportantmissingstructurein-structurepropagationissolvedusingDynamicProgram-theknowntotheunknownregions.Ourapproachsynthe-unknownregionusingpatchesselectedaroundthecurvesin theknownregion.Structurepropagationisformulatedas ming.Whenmultipleintersectingcurvesarespecified,we sizesimagepatchesalongtheseuser-specifiedcurvesinthe patches.Aftercompletingstructurepropagation,wefillin theremainingunknownregionsusingpatch-basedtexture synthesis.Weshowthatourapproachworkswellonanum-consistencyconstraints.Ifonlyasinglecurveisspecified, aglobaloptimizationproblembyenforcingstructureand niques.", 
        "id": 393, 
        "title": "Image completion with structure propagation."
    }, 
    {
        "abstract": "The computation of geodesic paths and distances on triangle meshes is a common operation in many computer graphics applications. We present several practical algorithms for computing such geodesics from a source point to one or all other points efficiently. First, we describe an implementation of the exact \"single source, all destination\" algorithm presented by Mitchell, Mount, and Papadimitriou (MMP). We show that the algorithm runs much faster in practice than suggested by worst case analysis. Next, we extend the algorithm with a merging operation to obtain computationally efficient and accurate approximations with bounded error. Finally, to compute the shortest path between two given points, we use a lower-bound property of our approximate geodesic algorithm to efficiently prune the frontier of the MMP algorithm, thereby obtaining an exact solution even more quickly. ", 
        "id": 394, 
        "title": "Fast exact and approximate geodesics on meshes."
    }, 
    {
        "abstract": "", 
        "id": 395, 
        "title": "A physically-based motion retargeting filter."
    }, 
    {
        "abstract": "Many translucent materials consist of evenly-distributed heterogeneous elements which produce a complex appearance under different lighting and viewing directions. For these quasi-homogeneous materials, existing techniques do not address how to acquire their material representations from physical samples in a way that allows arbitrary geometry models to be rendered with these materials. We propose a model for such materials that can be readily acquired from physical samples. This material model can be applied to geometric models of arbitrary shapes, and the resulting objects can be efficiently rendered without expensive subsurface light transport simulation. In developing a material model with these attributes, we capitalize on a key observation about the subsurface scattering characteristics of quasi-homogeneous materials at different scales. Locally, the non-uniformity of these materials leads to inhomogeneous subsurface scattering. For subsurface scattering on a global scale, we show that a lengthy photon path through an even distribution of heterogeneous elements statistically resembles scattering in a homogeneous medium. This observation allows us to represent and measure the global light transport within quasi-homogeneous materials as well as the transfer of light into and out of a material volume through surface mesostructures. We demonstrate our technique with results for several challenging materials that exhibit sophisticated appearance features such as transmission of back illumination through surface mesostructures. ", 
        "id": 396, 
        "title": "Modeling and rendering of quasi-homogeneous materials."
    }, 
    {
        "abstract": "", 
        "id": 397, 
        "title": "Image-based spatio-temporal modeling and view interpolation of dynamic events."
    }, 
    {
        "abstract": "Face Transfer is a method for mapping videorecorded performances of one individual to facial animations of another. It extracts visemes (speech-related mouth articulations), expressions, and three-dimensional (3D) pose from monocular video or film footage. These parameters are then used to generate and drive a detailed 3D textured face mesh for a target identity, which can be seamlessly rendered back into target footage. The underlying face model automatically adjusts for how the target performs facial expressions and visemes. The performance data can be easily edited to change the visemes, expressions, pose, or even the identity of the target--the attributes are separably controllable. This supports a wide variety of video rewrite and puppetry applications. Face Transfer is based on a multilinear model of 3D face meshes that separably parameterizes the space of geometric variations due to different attributes (e.g., identity, expression, and viseme). Separability means that each of these attributes can be independently varied. A multilinear model can be estimated from a Cartesian product of examples (identities  expressions  visemes) with techniques from statistical analysis, but only after careful preprocessing of the geometric data set to secure one-to-one correspondence, to minimize cross-coupling artifacts, and to fill in any missing examples. Face Transfer offers new solutions to these problems and links the estimated model with a face-tracking algorithm to extract pose, expression, and viseme parameters. ", 
        "id": 398, 
        "title": "Face transfer with multilinear models."
    }, 
    {
        "abstract": "Lightcuts is a scalable framework for computing realistic illumination. It handles arbitrary geometry, non-diffuse materials, and illumination from a wide variety of sources including point lights, area lights, HDR environment maps, sun/sky models, and indirect illumination. At its core is a new algorithm for accurately approximating illumination from many point lights with a strongly sublinear cost. We show how a group of lights can be cheaply approximated while bounding the maximum approximation error. A binary light tree and perceptual metric are then used to adaptively partition the lights into groups to control the error vs. cost tradeoff. We also introduce reconstruction cuts that exploit spatial coherence to accelerate the generation of anti-aliased images with complex illumination. Results are demonstrated for five complex scenes and show that lightcuts can accurately approximate hundreds of thousands of point lights using only a few hundred shadow rays. Reconstruction cuts can reduce the number of shadow rays to tens. ", 
        "id": 399, 
        "title": "Lightcuts: a scalable approach to illumination."
    }, 
    {
        "abstract": "We present an interactive system for efficiently extracting foreground objects from a video. We extend previous min-cut based image segmentation techniques to the domain of video with four new contributions. We provide a novel painting-based user interface that allows users to easily indicate the foreground object across space and time. We introduce a hierarchical mean-shift preprocess in order to minimize the number of nodes that min-cut must operate on. Within the min-cut we also define new local cost functions to augment the global costs defined in earlier work. Finally, we extend 2D alpha matting methods designed for images to work with 3D video volumes. We demonstrate that our matting approach preserves smoothness across both space and time. Our interactive video cutout system allows users to quickly extract foreground objects from video sequences for use in a variety of applications including compositing onto new backgrounds and NPR cartoon style rendering. ", 
        "id": 400, 
        "title": "Interactive video cutout."
    }, 
    {
        "abstract": "We present a physically-based method to enforce contact angles at the intersection of fluid free surfaces and solid objects, allowing us to simulate a variety of small-scale fluid phenomena including water drops on surfaces. The heart of this technique is a virtual surface method, which modifies the level set distance field representing the fluid surface in order to maintain an appropriate contact angle. The surface tension that is calculated on the contact line between the solid surface and liquid surface can then capture all interfacial tensions, including liquid-solid, liquid-air and solid-air tensions. We use a simple dynamic contact angle model to select contact angles according to the solid material property, water history, and the fluid front's motion. Our algorithm robustly and accurately treats various drop shape deformations, and handles both flat and curved solid surfaces. Our results show that our algorithm is capable of realistically simulating several small-scale liquid phenomena such as beading and flattened drops, stretched and separating drops, suspended drops on curved surfaces, and capillary action. ", 
        "id": 401, 
        "title": "Water drops on surfaces."
    }, 
    {
        "abstract": "We present a technique, based on precomputed light transport, for interactive rendering of translucent objects under all-frequency environment maps. We consider the complete BSSRDF model proposed by Jensen et al. [2001], which includes both single and diffuse multiple scattering components. The challenge is how to efficiently precompute all-frequency light transport functions due to subsurface scattering. We apply the two-pass hierarchical technique by Jensen et al. [2002] in the space of non-linearly approximated transport vectors, which allows us to efficiently evaluate transport vectors due to diffuse multiple scattering. We then include an approximated single scattering term in the precomputation, which previous interactive systems have ignored. For an isotropic phase function, this approximation produces a diffuse transport vector per vertex, and is combined with the multiple scattering component. For a general phase function, we introduce a technique from BRDF rendering to factor the phase function using a separable decomposition to allow for view-dependent rendering. We show that our rendering results qualitatively match the appearance of translucent objects, achieving a high level of realism at interactive rates. ", 
        "id": 402, 
        "title": "All-frequency interactive relighting of translucent objects with single and multiple scattering."
    }, 
    {
        "abstract": "This paper presents a framework for the real-time rendering of plant leaves with global illumination effects. Realistic rendering of leaves requires a sophisticated appearance model and accurate lighting computation. For leaf appearance we introduce a parametric model that describes leaves in terms of spatially-variant BRDFs and BTDFs. These BRDFs and BTDFs, incorporating analysis of subsurface scattering inside leaf tissues and rough surface scattering on leaf surfaces, can be measured from real leaves. More importantly, this description is compact and can be loaded into graphics hardware for fast run-time shading calculations, which are essential for achieving high frame rates. For lighting computation, we present an algorithm that extends the Precomputed Radiance Transfer (PRT) approach to all-frequency lighting for leaves. In particular, we handle the combined illumination effects due to lowfrequency environment light and high-frequency sunlight. This is done by decomposing the local incident radiance of sunlight into direct and indirect components. The direct component, which contains most of the high frequencies, is not pre-computed with spherical harmonics as in PRT; instead it is evaluated on-the-fly using pre-computed light-visibility convolution data. We demonstrate our framework by the rendering of a variety of leaves and assemblies thereof. ", 
        "id": 403, 
        "title": "Real-time rendering of plant leaves."
    }, 
    {
        "abstract": " Tensor approximation is necessary to obtain compact multilinear models for multi-dimensional visual datasets. Traditionally, each multi-dimensional data item is represented as a vector. Such a scheme flattens the data and partially destroys the internal structures established throughout the multiple dimensions. In this paper, we retain the original dimensionality of the data items to more effectively exploit existing spatial redundancy and allow more efficient computation. Since the size of visual datasets can easily exceed the memory capacity of a single machine, we also present an outof-core algorithm for higher-order tensor approximation. The basic idea is to partition a tensor into smaller blocks and perform tensorrelated operations blockwise. We have successfully applied our techniques to three graphics-related data-driven models, including 6D bidirectional texture functions, 7D dynamic BTFs and 4D volume simulation sequences. Experimental results indicate that our techniques can not only process out-of-core data, but also achieve higher compression ratios and quality than previous methods. ", 
        "id": 404, 
        "title": "Out-of-core tensor approximation of multi-dimensional matrices of visual data."
    }, 
    {
        "abstract": "In this paper, we propose a novel image-based approach to model hair geometry from images taken at multiple viewpoints. Unlike previous hair modeling techniques that require intensive user interactions or rely on special capturing setup under controlled illumination conditions, we use a handheld camera to capture hair images under uncontrolled illumination conditions. Our multi-view approach is natural and flexible for capturing. It also provides inherent strong and accurate geometric constraints to recover hair models. In our approach, the hair fibers are synthesized from local image orientations. Each synthesized fiber segment is validated and optimally triangulated from all visible views. The hair volume and the visibility of synthesized fibers can also be reliably estimated from multiple views. Flexibility of acquisition, little user interaction, and high quality results of recovered complex hair models are the key advantages of our method. ", 
        "id": 405, 
        "title": "Modeling hair from multiple views."
    }, 
    {
        "abstract": " We present a technique for capturing an actor's live-action performance in such a way that the lighting and reflectance of the actor can be designed and modified in postproduction. Our approach is to illuminate the subject with a sequence of time-multiplexed basis lighting conditions, and to record these conditions with a highspeed video camera so that many conditions are recorded in the span of the desired output frame interval. We investigate several lighting bases for representing the sphere of incident illumination using a set of discrete LED light sources, and we estimate and compensate for subject motion using optical flow and image warping based on a set of tracking frames inserted into the lighting basis. To composite the illuminated performance into a new background, we include a time-multiplexed matte within the basis. We also show that the acquired data enables time-varying surface normals, albedo, and ambient occlusion to be estimated, which can be used to transform the actor's reflectance to produce both subtle and stylistic effects.  Figure 2: The lighting apparatus used for capturing a performance under time-multiplexed illumination. Behind the actor is the gray background matte surface, and at left is the high-speed camera.  ", 
        "id": 406, 
        "title": "Performance relighting and reflectance transformation with time-multiplexed illumination."
    }, 
    {
        "abstract": "The advent of inexpensive digital image sensors and the ability to create photographs that combine information from a number of sensed images are changing the way we think about photography. In this paper, we describe a unique array of 100 custom video cameras that we have built, and we summarize our experiences using this array in a range of imaging applications. Our goal was to explore the capabilities of a system that would be inexpensive to produce in the future. With this in mind, we used simple cameras, lenses, and mountings, and we assumed that processing large numbers of images would eventually be easy and cheap. The applications we have explored include approximating a conventional single center of projection video camera with high performance along one or more axes, such as resolution, dynamic range, frame rate, and/or large aperture, and using multiple cameras to approximate a video camera with a large synthetic aperture. This permits us to capture a video light field, to which we can apply spatiotemporal view interpolation algorithms in order to digitally simulate time dilation and camera motion. It also permits us to create video sequences using custom non-uniform synthetic apertures. email:wilburn@graphics.stanford.edu Neel Joshi is now at the University of California, San Diego. Copyright  2005 by the Association for Computing Machinery, Inc. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org.  2005 ACM 0730-0301/05/0700-0765 $5.00  ", 
        "id": 407, 
        "title": "High performance imaging using large camera arrays."
    }, 
    {
        "abstract": "Recursive ray tracing is a simple yet powerful and general approach for accurately computing global light transport and rendering high quality images. While recent algorithmic improvements and optimized parallel software implementations have increased ray tracing performance to realtime levels, no compact and programmable hardware solution has been available yet. This paper describes the architecture and a prototype implementation of a single chip, fully programmable Ray Processing Unit (RPU). It combines the flexibility of general purpose CPUs with the efficiency of current GPUs for data parallel computations. This design allows for realtime ray tracing of dynamic scenes with programmable material, geometry, and illumination shaders. Although, running at only 66 MHz the prototype FPGA implementation already renders images at up to 20 frames per second, which in many cases beats the performance of highly optimized software running on multi-GHz desktop CPUs. The performance and efficiency of the proposed architecture is analyzed using a variety of benchmark scenes. ", 
        "id": 408, 
        "title": "RPU: a programmable ray processing unit for realtime ray tracing."
    }, 
    {
        "abstract": "Many interactive applications strive for realistic renderings, but framerate constraints usually limit realism to effects that run efficiently in graphics hardware. One effect largely ignored in such applications is refraction. We introduce a simple, image-space approach to refractions that easily runs on modern graphics cards. Our method requires two passes on a GPU, and allows refraction of a distant environment through two interfaces, compared to current interactive techniques that are restricted to a single interface. Like all image-based algorithms, aliasing can occur in certain circumstances, but the plausible refractions generated with our approach should suffice for many applications. ", 
        "id": 409, 
        "title": "An approximate image-space approach for interactive refraction."
    }, 
    {
        "abstract": "We present a novel method for computing cache-oblivious layouts of large meshes that improve the performance of interactive visualization and geometric processing algorithms. Given that the mesh is accessed in a reasonably coherent manner, we assume no particular data access patterns or cache parameters of the memory hierarchy involved in the computation. Furthermore, our formulation extends directly to computing layouts of multi-resolution and bounding volume hierarchies of large meshes. We develop a simple and practical cache-oblivious metric for estimating cache misses. Computing a coherent mesh layout is reduced to a combinatorial optimization problem. We designed and implemented an out-of-core multilevel minimization algorithm and tested its performance on unstructured meshes composed of tens to hundreds of millions of triangles. Our layouts can significantly reduce the number of cache misses. We have observed 2-20 times speedups in view-dependent rendering, collision detection, and isocontour extraction without any modification of the algorithms or runtime applications. ", 
        "id": 410, 
        "title": "Cache-oblivious mesh layouts."
    }, 
    {
        "abstract": "", 
        "id": 411, 
        "title": "Hierarchical triangular splines."
    }, 
    {
        "abstract": "", 
        "id": 412, 
        "title": "Feature-based surface parameterization and texture mapping."
    }, 
    {
        "abstract": "We present a soft shadow technique for dynamic scenes with moving objects under the combined illumination of moving local light sources and dynamic environment maps. The main idea of our technique is to precompute for each scene entity a shadow field that describes the shadowing effects of the entity at points around it. The shadow field for a light source, called a source radiance field (SRF), records radiance from an illuminant as cube maps at sampled points in its surrounding space. For an occluder, an object occlusion field (OOF) conversely represents in a similar manner the occlusion of radiance by an object. A fundamental difference between shadow fields and previous shadow computation concepts is that shadow fields can be precomputed independent of scene configuration. This is critical for dynamic scenes because, at any given instant, the shadow information at any receiver point can be rapidly computed as a simple combination of SRFs and OOFs according to the current scene configuration. Applications that particularly benefit from this technique include large dynamic scenes in which many instances of an entity can share a single shadow field. Our technique enables low-frequency shadowing effects in dynamic scenes in real-time and all-frequency shadows at interactive rates. ", 
        "id": 413, 
        "title": "Precomputed shadow fields for dynamic scenes."
    }, 
    {
        "abstract": "We present a novel technique for large deformations on 3D meshes using the volumetric graph Laplacian. We first construct a graph representing the volume inside the input mesh. The graph need not form a solid meshing of the input mesh's interior; its edges simply connect nearby points in the volume. This graph's Laplacian encodes volumetric details as the difference between each point in the graph and the average of its neighbors. Preserving these volumetric details during deformation imposes a volumetric constraint that prevents unnatural changes in volume. We also include in the graph points a short distance outside the mesh to avoid local self-intersections. Volumetric detail preservation is represented by a quadric energy function. Minimizing it preserves details in a least-squares sense, distributing error uniformly over the whole deformed mesh. It can also be combined with conventional constraints involving surface positions, details or smoothness, and efficiently minimized by solving a sparse linear system. We apply this technique in a 2D curve-based deformation system allowing novice users to create pleasing deformations with little effort. A novel application of this system is to apply nonrigid and exaggerated deformations of 2D cartoon characters to 3D meshes. We demonstrate our system's potential with several examples. ", 
        "id": 414, 
        "title": "Large mesh deformation using the volumetric graph Laplacian."
    }, 
    {
        "abstract": "We propose a technique, called TextureMontage, to seamlessly map a patchwork of texture images onto an arbitrary 3D model. A texture atlas can be created through the specification of a set of correspondences between the model and any number of texture images. First, our technique automatically partitions the mesh and the images, driven solely by the choice of feature correspondences. Most charts will then be parameterized over their corresponding image planes through the minimization of a distortion metric based on both geometric distortion and texture mismatch across patch boundaries and images. Lastly, a surface texture inpainting technique is used to fill in the remaining charts of the surface with no corresponding texture patches. The resulting texture mapping satisfies the (sparse or dense) user-specified constraints while minimizing the distortion of the texture images and ensuring a smooth transition across the boundaries of different mesh patches. ", 
        "id": 415, 
        "title": "TextureMontage: Seamless Texturing of Arbitrary Surfaces From Multiple Images."
    }, 
    {
        "abstract": "We present a physics-based simulation method for animating sand. To allow for efficiently scaling up to large volumes of sand, we abstract away the individual grains and think of the sand as a continuum. In particular we show that an existing water simulator can be turned into a sand simulator with only a few small additions to account for inter-grain and boundary friction. We also propose an alternative method for simulating fluids. Our core representation is a cloud of particles, which allows for accurate and flexible surface tracking and advection, but we use an auxiliary grid to efficiently enforce boundary conditions and incompressibility. We further address the issue of reconstructing a surface from particle data to render each frame. ", 
        "id": 416, 
        "title": "Animating sand as a fluid."
    }, 
    {
        "abstract": " Human motion capture embeds rich detail and style which is difficult to generate with competing animation synthesis technologies. However, such recorded data requires principled means for creating responses in unpredicted situations, for example reactions immediately following impact. This paper introduces a novel technique for incorporating unexpected impacts into a motion capture-driven animation system through the combination of a physical simulation which responds to contact forces and a specialized search routine which determines the best plausible re-entry into motion library playback following the impact. Using an actuated dynamic model, our system generates a physics-based response while connecting motion capture segments. Our method allows characters to respond to unexpected changes in the environment based on the specific dynamic effects of a given contact while also taking advantage of the realistic movement made available through motion capture. We show the results of our system under various conditions and with varying responses using martial arts motion capture as a testbed. ", 
        "id": 417, 
        "title": "Dynamic response for motion capture animation."
    }, 
    {
        "abstract": "A piecewise smooth surface, possibly with boundaries, sharp edges, corners, or other features is defined by a set of samples. The basic idea is to model surface patches, curve segments and points explicitly, and then to glue them together based on explicit connectivity information. The geometry is defined as the set of stationary points of a projection operator, which is generalized to allow modeling curves with samples, and extended to account for the connectivity information. Additional tangent constraints can be used to model shapes with continuous tangents across edges and corners. ", 
        "id": 418, 
        "title": "Point-sampled cell complexes."
    }, 
    {
        "abstract": "We present a system for producing multi-viewpoint panoramas of long, roughly planar scenes, such as the facades of buildings along a city street, from a relatively sparse set of photographs captured with a handheld still camera that is moved along the scene. Our work is a significant departure from previous methods for creating multiviewpoint panoramas, which composite thin vertical strips from a video sequence captured by a translating video camera, in that the resulting panoramas are composed of relatively large regions of ordinary perspective. In our system, the only user input required beyond capturing the photographs themselves is to identify the dominant plane of the photographed scene; our system then computes a panorama automatically using Markov Random Field optimization. Users may exert additional control over the appearance of the result by drawing rough strokes that indicate various high-level goals. We demonstrate the results of our system on several scenes, including urban streets, a river bank, and a grocery store aisle. ", 
        "id": 419, 
        "title": "Photographing long scenes with multi-viewpoint panoramas."
    }, 
    {
        "abstract": "We present a lossy compression algorithm for large databases of motion capture data. We approximate short clips of motion using Bezier curves and clustered principal component analysis. This approximation has a smoothing effect on the motion. Contacts with the environment (such as foot strikes) have important detail that needs to be maintained. We compress these environmental contacts using a separate, JPEG like compression algorithm and ensure these contacts are maintained during decompression. Our method can compress 6 hours 34 minutes of human motion capture from 1080 MB data into 35.5 MB with little visible degradation. Compression and decompression is fast: our research implementation can decompress at about 1.2 milliseconds/frame, 7 times faster than real-time (for 120 frames per second animation). Our method also yields smaller compressed representation for the same error or produces smaller error for the same compressed size.", 
        "id": 420, 
        "title": "Compression of motion capture databases."
    }, 
    {
        "abstract": "We introduce a new approach to tone management for photographs. Whereas traditional tone-mapping operators target a neutral and faithful rendition of the input image, we explore pictorial looks by controlling visual qualities such as the tonal balance and the amount of detail. Our method is based on a two-scale non-linear decomposition of an image. We modify the different layers based on their histograms and introduce a technique that controls the spatial variation of detail. We introduce a Poisson correction that prevents potential gradient reversal and preserves detail. In addition to directly controlling the parameters, the user can transfer the look of a model photograph to the picture being edited. ", 
        "id": 421, 
        "title": "Two-scale tone management for photographic look."
    }, 
    {
        "abstract": "", 
        "id": 422, 
        "title": "A semi-Lagrangian contouring method for fluid simulation."
    }, 
    {
        "abstract": "Current systems for editing BRDFs typically allow users to adjust analytic parameters while visualizing the results in a simplified setting (e.g. unshadowed point light). This paper describes a realtime rendering system that enables interactive edits of BRDFs, as rendered in their final placement on objects in a static scene, lit by direct, complex illumination. All-frequency effects (ranging from near-mirror reflections and hard shadows to diffuse shading and soft shadows) are rendered using a precomputation-based approach. Inspired by real-time relighting methods, we create a linear system that fixes lighting and view to allow real-time BRDF manipulation. In order to linearize the image's response to BRDF parameters, we develop an intermediate curve-based representation, which also reduces the rendering and precomputation operations to 1D while maintaining accuracy for a very general class of BRDFs. Our system can be used to edit complex analytic BRDFs (including anisotropic models), as well as measured reflectance data. We improve on the standard precomputed radiance transfer (PRT) rendering computation by introducing an incremental rendering algorithm that takes advantage of frame-to-frame coherence. We show that it is possible to render reference-quality images while only updating 10% of the data at each frame, sustaining frame-rates of 25-30fps. ", 
        "id": 423, 
        "title": "Real-time BRDF editing in complex lighting."
    }, 
    {
        "abstract": "Simulating human hair is recognized as one of the most difficult tasks in computer animation. In this paper, we show that the Kirchhoff equations for dynamic, inextensible elastic rods can be used for accurately predicting hair motion. These equations fully account for the nonlinear behavior of hair strands with respect to bending and twisting. We introduce a novel deformable model for solving them: each strand is represented by a Super-Helix, i.e., a piecewise helical rod which is animated using the principles of Lagrangian mechanics. This results in a realistic and stable simulation, allowing large time steps. Our second contribution is an in-depth validation of the Super-Helix model, carried out through a series of experiments based on the comparison of real and simulated hair motions. We show that our model efficiently handles a wide range of hair types with a high level of realism. ", 
        "id": 424, 
        "title": "Super-helices for predicting the dynamics of natural hair."
    }, 
    {
        "abstract": "We present a system architecture for the 4th generation of PCclass programmable graphics processing units (GPUs). The new pipeline features significant additions and changes to the prior generation pipeline including a new programmable stage capable of generating additional primitives and streaming primitive data to memory, an expanded, common feature set for all of the programmable stages, generalizations to vertex and image memory resources, and new storage formats. We also describe structural modifications to the API, runtime, and shading language to complement the new pipeline. We motivate the design with descriptions of frequently encountered obstacles in current systems. Throughout the paper we present rationale behind prominent design choices and alternatives that were ultimately rejected, drawing on insights collected during a multi-year collaboration with application developers and hardware designers. ", 
        "id": 425, 
        "title": "The Direct3D 10 system."
    }, 
    {
        "abstract": "Harmonic colors are sets of colors that are aesthetically pleasing in terms of human visual perception. In this paper, we present a method that enhances the harmony among the colors of a given photograph or of a general image, while remaining faithful, as much as possible, to the original colors. Given a color image, our method finds the best harmonic scheme for the image colors. It then allows a graceful shifting of hue values so as to fit the harmonic scheme while considering spatial coherence among colors of neighboring pixels using an optimization technique. The results demonstrate that our method is capable of automatically enhancing the color \"look-and-feel\" of an ordinary image. In particular, we show the results of harmonizing the background image to accommodate the colors of a foreground image, or the foreground with respect to the background, in a cut-and-paste setting. Our color harmonization technique proves to be useful in adjusting the colors of an image composed of several parts taken from different sources. ", 
        "id": 426, 
        "title": "Color harmonization."
    }, 
    {
        "abstract": "Articulated shapes are aptly described by reduced deformable models that express required shape deformations using a compact set of control parameters. Although sufficient to describe most shape deformations, these control parameters can be ill-suited for animation tasks, particularly when reduced deformable models are inferred automatically from example shapes. Our algorithm provides intuitive and direct control of reduced deformable models similar to a conventional inverse-kinematics algorithm for jointed rigid structures. We present a fully automated pipeline that transforms a set of unarticulated example shapes into a controllable, articulated model. With only a few manipulations, an animator can automatically and interactively pose detailed shapes at rates independent of their geometric complexity.  bends its limbs at the joints, so most limb vertices move together rigidly. Even non-articulated deformations such as those of a slithering snake, facial expressions, or skin deformations are highly correlated because an individual vertex of a detailed mesh never moves independently with respect to its neighbors. Animators often build a reduced deformable model that represents meaningful deformations by instrumenting a static mesh with control parameters that modify posture, bulge muscles, change facial expressions, and generate other necessary deformations. These controls provide a compact representation of the mesh deformation and allow the animator to generate movement efficiently. However, many animation tasks are more easily accomplished through direct manipulation. In particular, reaching for or interacting with surrounding objects is most effectively expressed through direct control of contact vertices.  ", 
        "id": 427, 
        "title": "Inverse kinematics for reduced deformable models."
    }, 
    {
        "abstract": "", 
        "id": 428, 
        "title": "A Bayesian method for probable surface reconstruction and decimation."
    }, 
    {
        "abstract": "Resampling raw surface meshes is one of the most fundamental operations used by nearly all digital geometry processing systems. The vast majority of this work has focused on triangular remeshing, yet quadrilateral meshes are preferred for many surface PDE problems, especially fluid dynamics, and are best suited for defining Catmull-Clark subdivision surfaces. We describe a fundamentally new approach to the quadrangulation of manifold polygon meshes using Laplacian eigenfunctions, the natural harmonics of the surface. These surface functions distribute their extrema evenly across a mesh, which connect via gradient flow into a quadrangular base mesh. An iterative relaxation algorithm simultaneously refines this initial complex to produce a globally smooth parameterization of the surface. From this, we can construct a well-shaped quadrilateral mesh with very few extraordinary vertices. The quality of this mesh relies on the initial choice of eigenfunction, for which we describe algorithms and hueristics to efficiently and effectively select the harmonic most appropriate for the intended application. ", 
        "id": 429, 
        "title": "Spectral surface quadrangulation."
    }, 
    {
        "abstract": "Sampling distributions with blue noise characteristics are widely used in computer graphics. Although Poisson-disk distributions are known to have excellent blue noise characteristics, they are generally regarded as too computationally expensive to generate in real time. We present a new method for sampling by dart-throwing in O(N log N ) time and introduce a novel and efficient variation for generating Poisson-disk distributions in O(N ) time and space. ", 
        "id": 430, 
        "title": "A spatial data structure for fast Poisson-disk sample generation."
    }, 
    {
        "abstract": "", 
        "id": 431, 
        "title": "The halfway vector disk for BRDF modeling."
    }, 
    {
        "abstract": "", 
        "id": 432, 
        "title": "Animation planning for virtual characters cooperation."
    }, 
    {
        "abstract": "Camera shake during exposure leads to objectionable image blur and ruins many photographs. Conventional blind deconvolution methods typically assume frequency-domain constraints on images, or overly simplified parametric forms for the motion path during camera shake. Real camera motions can follow convoluted paths, and a spatial domain prior can better maintain visually salient image characteristics. We introduce a method to remove the effects of camera shake from seriously blurred images. The method assumes a uniform camera blur over the image and negligible in-plane camera rotation. In order to estimate the blur from the camera shake, the user must specify an image region without saturation effects. We show results for a variety of digital photographs taken from personal photo collections. ", 
        "id": 433, 
        "title": "Removing camera shake from a single photograph."
    }, 
    {
        "abstract": " et al. 2003], a two-handed metaphor [Llamas et al. 2003], or the movement of a 9 dof object [Botsch and Kobbelt 2004].  We present an approach to define shape deformations by constructing and interactively modifying C1 continuous time-dependent divergence-free vector fields. The deformation is obtained by a path line integration of the mesh vertices. This way, the deformation is volume-preserving, free of (local and global) self-intersections, feature preserving, smoothness preserving, and local. Different modeling metaphors support the approach which is able to modify the vector field on-the-fly according to the user input. The approach works at interactive frame rates for moderate mesh sizes, and the numerical integration preserves the volume with a high accuracy.  Most existing deformation approaches have in common that they are defined as a map from the original to the new shape, i.e., it does not contain information about intermediate deformation steps. For many applications, the user wants to explore the deformation in an interactive manner, i.e., she wants to see a smooth change from the original to the desired shape moving along certain paths. This means that the deformation has to be recomputed again and again at interactive frame rates. To do so, parts of the deformation can be precomputed and reused for every intermediate deformation, see for instance [Botsch and Kobbelt 2004; Botsch and Kobbelt 2005].  ", 
        "id": 434, 
        "title": "Vector field based shape deformations."
    }, 
    {
        "abstract": "", 
        "id": 435, 
        "title": "Salient geometric features for partial shape matching and similarity."
    }, 
    {
        "abstract": "Photorealistic rendering of rain streaks with lighting and viewpoint effects is a challenging problem. Raindrops undergo rapid shape distortions as they fall, a phenomenon referred to as oscillations. Due to these oscillations, the reflection of light by, and the refraction of light through, a falling raindrop produce complex brightness patterns within a single motion-blurred rain streak captured by a camera or observed by a human. The brightness pattern of a rain streak typically includes speckles, multiple smeared highlights and curved brightness contours. In this work, we propose a new model for rain streak appearance that captures the complex interactions between the lighting direction, the viewing direction and the oscillating shape of the drop. Our model builds upon a raindrop oscillation model that has been developed in atmospheric sciences. We have measured rain streak appearances under a wide range of lighting and viewing conditions and empirically determined the oscillation parameters that are dominant in raindrops. Using these parameters, we have rendered thousands of rain streaks to create a database that captures the variations in streak appearance with respect to lighting and viewing directions. We have developed an efficient image-based rendering algorithm that uses our streak database to add rain to a single image or a captured video with moving objects and sources. The rendering algorithm is very simple to use as it only requires a coarse depth map of the scene and the locations and properties of the light sources. We have rendered rain in a wide range of scenarios and the results show that our physically-based rain streak model greatly enhances the visual realism of rendered rain. ", 
        "id": 436, 
        "title": "Photorealistic rendering of rain streaks."
    }, 
    {
        "abstract": "We present a method for visualizing short video clips in a single static image, using the visual language of storyboards. These schematic storyboards are composed from multiple input frames and annotated using outlines, arrows, and text describing the motion in the scene. The principal advantage of this storyboard representation over standard representations of video  generally either a static thumbnail image or a playback of the video clip in its entirety  is that it requires only a moment to observe and comprehend but at the same time retains much of the detail of the source video. Our system renders a schematic storyboard layout based on a small amount of user interaction. We also demonstrate an interaction technique to scrub through time using the natural spatial dimensions of the storyboard. Potential applications include video editing, surveillance summarization, assembly instructions, composition of graphic novels, and illustration of camera technique for film studies.", 
        "id": 437, 
        "title": "Schematic storyboarding for video visualization and editing."
    }, 
    {
        "abstract": "(a) Original low-resolution face (b) Synthesized detail (c) Aged Figure 1: Synthesis offacial detail. (a) We begin with a low-resolution mesh obtained from a commercial scanner. (b) Then, we synthesize detail on it using statistics extracted from high-resolution meshes in our database. (c) Finally, we age the face by adjusting the statistics to match those of an elderly man. Note that all figures in this paper use Exaggerated Shading [Rusinkiewicz et al. 2006] to emphasize small geometric details. Abstract Detailed surface geometry contributes greatly to the visual realism of 3D face models. However, acquiring high-resolution face geometry is often tedious and expensive. Consequently, most face models used in games, virtual reality, or computer vision look unrealistically smooth. In this paper, we introduce a new statistical technique for the analysis and synthesis of small three-dimensional facial features, such as wrinkles and pores. We acquire high-resolution face geometry for people across a wide range of ages, genders, and races. For each scan, we separate the skin surface details from a smooth base mesh using displaced subdivision surfaces. Then, we analyze the resulting displacement maps using the texture analy-sis/synthesis framework of Heeger and Bergen, adapted to capture statistics that vary spatially across a face. Finally, we use the extracted statistics to synthesize plausible detail on face meshes of arbitrary subjects. We demonstrate the effectiveness of this method in several applications, including analysis of facial texture in subjects with different ages and genders, interpolation between high-resolution face scans, adding detail to low-resolution face scans, and adjusting the apparent age of faces. In all cases, we are able to re-produce fine geometric details consistent with those observed in high resolution scans.", 
        "id": 438, 
        "title": "A statistical model for synthesis of detailed facial geometry."
    }, 
    {
        "abstract": "For computer graphics rendering, we generally assume that the appearance of surfaces remains static over time. Yet, there are a number of natural processes that cause surface appearance to vary dramatically, such as burning of wood, wetting and drying of rock and fabric, decay of fruit skins, and corrosion and rusting of steel and copper. In this paper, we take a significant step towards measuring, modeling, and rendering time-varying surface appearance. We describe the acquisition of the first time-varying database of 26 samples, encompassing a variety of natural processes including burning, drying, decay, and corrosion. Our main technical contribution is a Space-Time Appearance Factorization (STAF). This model factors space and time-varying effects. We derive an overall temporal appearance variation characteristic curve of the specific process, as well as space-dependent textures, rates, and offsets. This overall temporal curve controls different spatial locations evolve at the different rates, causing spatial patterns on the surface over time. We show that the model accurately represents a variety of phenomena. Moreover, it enables a number of novel rendering applications, such as transfer of the time-varying effect to a new static surface, control to accelerate time evolution in certain areas, extrapolation beyond the acquired sequence, and texture synthesis of time-varying appearance. ", 
        "id": 439, 
        "title": "Time-varying surface appearance: acquisition, modeling and rendering."
    }, 
    {
        "abstract": "This paper presents an interactive GPU-based system for cinematic relighting with multiple-bounce indirect illumination from a fixed view-point. We use a deep frame-buffer containing a set of view samples, whose indirect illumination is recomputed from the direct illumination on a large set of gather samples, distributed around the scene. This direct-to-indirect transfer is a linear transform which is particularly large, given the size of the view and gather sets. This makes it hard to precompute, store and multiply with. We address this problem by representing the transform as a set of sparse matrices encoded in wavelet space. A hierarchical construction is used to impose a wavelet basis on the unstructured gather cloud, and an image-based approach is used to map the sparse matrix computations to the GPU. We precompute the transfer matrices using a hierarchical algorithm and a variation of photon mapping in less than three hours on one processor. We achieve high-quality indirect illumination at 10-20 frames per second for complex scenes with over 2 million polygons, with diffuse and glossy materials, and arbitrary direct lighting models (expressed using shaders). We compute perpixel indirect illumination without the need of irradiance caching or other subsampling techniques. ", 
        "id": 440, 
        "title": "Direct-to-indirect transfer for cinematic relighting."
    }, 
    {
        "abstract": "", 
        "id": 441, 
        "title": "Encoding of high dynamic range video with a model of human cones."
    }, 
    {
        "abstract": "", 
        "id": 442, 
        "title": "Mean value coordinates for arbitrary planar polygons."
    }, 
    {
        "abstract": "", 
        "id": 443, 
        "title": "Hierarchical RLE level set: A compact and versatile deformable surface representation."
    }, 
    {
        "abstract": "We present a system for automatic reassembly of broken 3D solids. Given as input 3D digital models of the broken fragments, we analyze the geometry of the fracture surfaces to find a globally consistent reconstruction of the original object. Our reconstruction pipeline consists of a graph-cuts based segmentation algorithm for identifying potential fracture surfaces, feature-based robust global registration for pairwise matching of fragments, and simultaneous constrained local registration of multiple fragments. We develop several new techniques in the area of geometry processing, including the novel integral invariants for computing multi-scale surface characteristics, registration based on forward search techniques and surface consistency, and a non-penetrating iterated closest point algorithm. We illustrate the performance of our algorithms on a number of real-world examples. ", 
        "id": 444, 
        "title": "Reassembling fractured objects by geometric matching."
    }, 
    {
        "abstract": " In this paper we present a general framework for performing constrained mesh deformation tasks with gradient domain techniques. We present a gradient domain technique that works well with a wide variety of linear and nonlinear constraints. The constraints we introduce include the nonlinear volume constraint for volume preservation, the nonlinear skeleton constraint for maintaining the rigidity of limb segments of articulated figures, and the projection constraint for easy manipulation of the mesh without having to frequently switch between multiple viewpoints. To handle nonlinear constraints, we cast mesh deformation as a nonlinear energy minimization problem and solve the problem using an iterative algorithm. The main challenges in solving this nonlinear problem are the slow convergence and numerical instability of the iterative solver. To address these issues, we develop a subspace technique that builds a coarse control mesh around the original mesh and projects the deformation energy and constraints onto the control mesh vertices using the mean value interpolation. The energy minimization is then carried out in the subspace formed by the control mesh vertices. Running in this subspace, our energy minimization solver is both fast and stable and it provides interactive responses. We demonstrate our deformation constraints and subspace deformation technique with a variety of constrained deformation examples. ", 
        "id": 445, 
        "title": "Subspace gradient domain mesh deformation."
    }, 
    {
        "abstract": "We present a new method for the efficient simulation of large bodies of water, especially effective when three-dimensional surface effects are important. Similar to a traditional two-dimensional height field approach, most of the water volume is represented by tall cells which are assumed to have linear pressure profiles. In order to avoid the limitations typically associated with a height field approach, we simulate the entire top surface of the water volume with a state of the art, fully three-dimensional Navier-Stokes free surface solver. Our philosophy is to use the best available method near the interface (in the three-dimensional region) and to coarsen the mesh away from the interface for efficiency. We coarsen with tall, thin cells (as opposed to octrees or AMR), because they maintain good resolution horizontally allowing for accurate representation of bottom topography.", 
        "id": 446, 
        "title": "Efficient simulation of large bodies of water by coupling two and three dimensional techniques."
    }, 
    {
        "abstract": "We show how to greatly accelerate algorithms that compute Delaunay triangulations of huge, well-distributed point sets in 2D and 3D by exploiting the natural spatial coherence in a stream of points. We achieve large performance gains by introducing spatial finalization into point streams: we partition space into regions, and augment a stream of input points with finalization tags that indicate when a point is the last in its region. By extending an incremental algorithm for Delaunay triangulation to use finalization tags and produce streaming mesh output, we compute a billion-triangle terrain representation for the Neuse River system from 11.2 GB of LIDAR data in 48 minutes using only 70 MB of memory on a laptop with two hard drives. This is a factor of twelve faster than the previous fastest out-of-core Delaunay triangulation software. ", 
        "id": 447, 
        "title": "Streaming computation of Delaunay triangulations."
    }, 
    {
        "abstract": "Simulating sounds produced by realistic vibrating objects is challenging because sound radiation involves complex diffraction and interreflection effects that are very perceptible and important. These wave phenomena are well understood, but have been largely ignored in computer graphics due to the high cost and complexity of computing them at audio rates.  ", 
        "id": 448, 
        "title": "Precomputed acoustic transfer: output-sensitive, accurate sound generation for geometrically complex vibration sources."
    }, 
    {
        "abstract": "In this paper, we present a user-friendly system for seamless image composition, which we call drag-and-drop pasting. We observe that for Poisson image editing [Perez et al. 2003] to work well, the user must carefully draw a boundary on the source image to indicate the region of interest, such that salient structures in source and target images do not conflict with each other along the boundary. To make Poisson image editing more practical and easy to use, we propose a new objective function to compute an optimized boundary condition. A shortest closed-path algorithm is designed to search for the location of the boundary. Moreover, to faithfully preserve the object's fractional boundary, we construct a blended guidance field to incorporate the object's alpha matte. To use our system, the user needs only to simply outline a region of interest in the source image, and then drag and drop it onto the target image. Experimental results demonstrate the effectiveness of our \"drag-and-drop pasting\" system. ", 
        "id": 449, 
        "title": "Drag-and-drop pasting."
    }, 
    {
        "abstract": "We present an algorithm and a system for high-quality natural video matting using a camera array. The system uses high frequencies present in natural scenes to compute mattes by creating a synthetic aperture image that is focused on the foreground object, which reduces the variance of pixels reprojected from the foreground while increasing the variance of pixels reprojected from the background. We modify the standard matting equation to work directly with variance measurements and show how these statistics can be used to construct a trimap that is later upgraded to an alpha matte. The entire process is completely automatic, including an automatic method for focusing the synthetic aperture image on the foreground object and an automatic method to compute the trimap and the alpha matte. The proposed algorithm is very efficient and has a per-pixel running time that is linear in the number of cameras. Our current system runs at several frames per second, and we believe that it is the first system capable of computing high-quality alpha mattes at near real-time rates without the use of active illumination or special backgrounds. ", 
        "id": 450, 
        "title": "Natural video matting using camera arrays."
    }, 
    {
        "abstract": "We introduce SmoothSketcha system for inferring plausible 3D free-form shapes from visible-contour sketches. In our system, a users sketch need not be a simple closed curve as in Igarashis Teddy [1999], but may have cusps and T-junctions, i.e., endpoints of hidden parts of the contour. We follow a process suggested by Williams [1994] for inferring a smooth solid shape from its visible contours: completion of hidden contours, topological shape reconstruction, and smoothly embedding the shape via relaxation. Our main contribution is a practical method to go from a contour drawing to a fairly smooth surface with that drawing as its visible contour. In doing so, we make several technical contributions: extending Williams and Mumfords work [Mumford 1994] on figural completion of hidden contours containing T-junctions to contours containing cusps as well, characterizing a class of visible-contour drawings for which inflation can be proved possible, finding a topological embedding of the combinatorial surface that Williams creates from the figural completion, and creating a fairly smooth solid shape by smoothing the topological embedding using a mass-spring system. We handle many kinds of drawings (including objects with holes), and the generated shapes are plausible interpretations of the sketches. The method can be incorporated into any sketch-based free-form modeling interface like Teddy.", 
        "id": 451, 
        "title": "SmoothSketch: 3D free-form shapes from complex sketches."
    }, 
    {
        "abstract": "Photo editing software allows digital images to be blurred, warped or re-colored at the touch of a button. However, it is not currently possible to change the material appearance of an object except by painstakingly painting over the appropriate pixels. Here we present a method for automatically replacing one material with another, completely different material, starting with only a single high dynamic range image as input. Our approach exploits the fact that human vision is surprisingly tolerant of certain (sometimes enormous) physical inaccuracies, while being sensitive to others. By adjusting our simulations to be careful about those aspects to which the human visual system is sensitive, we are for the first time able to demonstrate significant material changes on the basis of a single photograph as input. ", 
        "id": 452, 
        "title": "Image-based material editing."
    }, 
    {
        "abstract": "", 
        "id": 453, 
        "title": "Discrete conformal mappings via circle patterns."
    }, 
    {
        "abstract": "Deforming surfaces, such as cloth, can be generated through physical simulation, morphing, and even video capture. Such data is currently very difficult to alter after the generation process is complete, and data generated for one purpose generally cannot be adapted to other uses. Such adaptation would be extremely useful, however. Being able to take cloth captured from a flapping flag and attach it to a character to make a cape, or enhance the wrinkles on a simulated garment, would greatly enhance the usability and re-usability of deforming surface data. In addition, it is often necessary to cleanup or tweak simulation results. Doing this by editing each frame individually is a very time consuming and tedious process. Extensive research has investigated how to edit and re-use skeletal motion capture data, but very little has addressed completely non-rigid deforming surfaces. We have developed a novel method that now makes it easy to edit such arbitrary deforming surfaces. Our system enables global signal processing, direct manipulation, multiresolution embossing, and constraint editing on arbitrarily deforming surfaces, such as simulated cloth, motion-captured cloth, morphs, and other animations. The foundation of our method is a novel time-varying multiresolution transform, which adapts to the changing geometry of the surface in a temporally coherent manner.", 
        "id": 454, 
        "title": "Editing arbitrarily deforming surface animations."
    }, 
    {
        "abstract": "This paper presents a method for animating fluid using unstructured tetrahedral meshes that change at each time step. We show that meshes that conform well to changing boundaries and that focus computation in the visually important parts of the domain can be generated quickly and reliably using existing techniques. We also describe a new approach to two-way coupling of fluid and rigid bodies that, while general, benefits from remeshing. Overall, the method provides a flexible environment for creating complex scenes involving fluid animation. ", 
        "id": 455, 
        "title": "Fluid animation with dynamic meshes."
    }, 
    {
        "abstract": "34,897 points, 15.7ms 2,222,739 points per second 22,748 points, 11.67ms 1,949,272 points per second Figure 1: Zooming into a stippled non-photorealistic rendering. Each image shows a subset of the same implicitly infinite point set: while zooming in, more points are shown to maintain the apparent density. Only the local visible area of the point set was evaluated for each image. Abstract Well distributed point sets play an important role in a variety of computer graphics contexts, such as anti-aliasing, global illumination, halftoning, non-photorealistic rendering, point-based modeling and rendering, and geometry processing. In this paper, we introduce a novel technique for rapidly generating large point sets possessing a blue noise Fourier spectrum and high visual quality. Our technique generates non-periodic point sets, distributed over arbitrarily large areas. The local density of a point set may be prescribed by an arbitrary target density function, without any preset bound on the maximum density. Our technique is deterministic and tile-based; thus, any local portion of a potentially infinite point set may be consistently regenerated as needed. The memory footprint of the technique is constant, and the cost to generate any local portion of the point set is proportional to the integral over the target density in that area. These properties make our technique highly suitable for a variety of real-time interactive applications, some of which are demonstrated in the paper. Our technique utilizes a set of carefully constructed progressive and recursive blue noise Wang tiles. The use of Wang tiles enables the generation of infinite non-periodic tilings. The progressive point sets inside each tile are able to produce spatially varying point densities. Recursion allows our technique to adaptively subdivide tiles only where high density is required, and makes it possible to zoom into point sets by an arbitrary amount, while maintaining a constant apparent density.", 
        "id": 456, 
        "title": "Recursive Wang tiles for real-time blue noise."
    }, 
    {
        "abstract": "Modifying motion capture to satisfy the constraints of new animation is difficult when contact is involved, and a critical problem for animation of hands. The compliance with which a character makes contact also reveals important aspects of the movement's purpose. We present a new technique called interaction capture, for capturing these contact phenomena. We capture contact forces at the same time as motion, at a high rate, and use both to estimate a nominal reference trajectory and joint compliance. Unlike traditional methods, our method estimates joint compliance without the need for motorized perturbation devices. New interactions can then be synthesized by physically based simulation. We describe a novel position-based linear complementarity problem formulation that includes friction, breaking contact, and the compliant coupling between contacts at different fingers. The technique is validated using data from previous work and our own perturbation-based estimates. ", 
        "id": 457, 
        "title": "Interaction capture and synthesis."
    }, 
    {
        "abstract": "In this paper, we present a class of imaging systems, called radial imaging systems, that capture a scene from a large number of viewpoints within a single image, using a camera and a curved mirror. These systems can recover scene properties such as geometry, reflectance, and texture. We derive analytic expressions that describe the properties of a complete family of radial imaging systems, including their loci of viewpoints, fields of view, and resolution characteristics. We have built radial imaging systems that, from a single image, recover the frontal 3D structure of an object, generate the complete texture map of a convex object, and estimate the parameters of an analytic BRDF model for an isotropic material. In addition, one of our systems can recover the complete geometry of a convex object by capturing only two images. These results show that radial imaging systems are simple, effective, and convenient devices for a wide range of applications in computer graphics and computer vision. ", 
        "id": 458, 
        "title": "Multiview radial catadioptric imaging for scene capture."
    }, 
    {
        "abstract": "", 
        "id": 459, 
        "title": "An alternative for Wang tiles: colored edges versus colored corners."
    }, 
    {
        "abstract": "Recent progress in the measurement of surface reflectance has created a demand for non-parametric appearance representations that are accurate, compact, and easy to use for rendering. Another crucial goal, which has so far received little attention, is editability: for practical use, we must be able to change both the directional and spatial behavior of surface reflectance (e.g., making one material shinier, another more anisotropic, and changing the spatial \"texture maps\" indicating where each material appears). We introduce an Inverse Shade Tree framework that provides a general approach to estimating the \"leaves\" of a user-specified shade tree from highdimensional measured datasets of appearance. These leaves are sampled 1- and 2-dimensional functions that capture both the directional behavior of individual materials and their spatial mixing patterns. In order to compute these shade trees automatically, we map the problem to matrix factorization and introduce a flexible new algorithm that allows for constraints such as non-negativity, sparsity, and energy conservation. Although we cannot infer every type of shade tree, we demonstrate the ability to reduce multigigabyte measured datasets of the Spatially-Varying Bidirectional Reflectance Distribution Function (SVBRDF) into a compact representation that may be edited in real time.  Acquisition of SVBRDF (Thousands of HDR Images)  Decomposition into Shade Tree       a + c  b + d  ... ...  ", 
        "id": 460, 
        "title": "Inverse shade trees for non-parametric material representation and editing."
    }, 
    {
        "abstract": "Real time animation of human figures in virtual environments is an important problem in the context of computer games and virtual environments. Recently, the use of large collections of captured motion data has increased realism in character animation. However, assuming that the virtual environment is large and complex, the effort of capturing motion data in a physical environment and adapting them to an extended virtual environment is the bottleneck for achieving interactive character animation and control. We present a new technique for allowing our animated characters to navigate through a large virtual environment, which is constructed using a set of building blocks. The building blocks, called motion patches, can be arbitrarily assembled to create novel environments. Each patch is annotated with motion data, which informs what actions are available for animated characters within the block. The versatility and flexibility of our approach are demonstrated through examples in which multiple characters are animated and controlled at interactive rates in large, complex virtual environments. ", 
        "id": 461, 
        "title": "Motion patches: building blocks for virtual environments annotated with motion data."
    }, 
    {
        "abstract": " ", 
        "id": 462, 
        "title": "Heads up!: biomechanical modeling and neuromuscular control of the neck."
    }, 
    {
        "abstract": "The traditional approach in texture synthesis is to compare color neighborhoods with those of an exemplar. We show that quality is greatly improved if pointwise colors are replaced by appearance vectors that incorporate nonlocal information such as feature and radiance-transfer data. We perform dimensionality reduction on these vectors prior to synthesis, to create a new appearance-space exemplar. Unlike a texton space, our appearance space is lowdimensional and Euclidean. Synthesis in this information-rich space lets us reduce runtime neighborhood vectors from 55 grids to just 4 locations. Building on this unifying framework, we introduce novel techniques for coherent anisometric synthesis, surface texture synthesis directly in an ordinary atlas, and texture advection. Remarkably, we achieve all these functionalities in real-time, or 3 to 4 orders of magnitude faster than prior work. ", 
        "id": 463, 
        "title": "Appearance-space texture synthesis."
    }, 
    {
        "abstract": "We explore using hashing to pack sparse data into a compact table while retaining efficient random access. Specifically, we design a perfect multidimensional hash function  one that is precomputed on static data to have no hash collisions. Because our hash function makes a single reference to a small offset table, queries always involve exactly two memory accesses and are thus ideally suited for parallel SIMD evaluation on graphics hardware. Whereas prior hashing work strives for pseudorandom mappings, we instead design the hash function to preserve spatial coherence and thereby improve runtime locality of reference. We demonstrate numerous graphics applications including vector images, texture sprites, alpha channel compression, 3D-parameterized textures, 3D painting, simulation, and collision detection. ", 
        "id": 464, 
        "title": "Perfect spatial hashing."
    }, 
    {
        "abstract": "", 
        "id": 465, 
        "title": "Glift: Generic, efficient, random-access GPU data structures."
    }, 
    {
        "abstract": "We present a modification to subdivision surfaces, which guarantees second-order smoothness everywhere in the surface, including extraordinary points. The idea is to blend the limit surface with a low degree polynomial defined over the characteristic map, in the vicinity of each extraordinary point. We demonstrate our method on Catmull-Clark surfaces, but a similar modification can be applied to other schemes as well. The proposed modification to CatmullClark is simple to implement and can be applied to quad meshes of arbitrary topological type, even when extraordinary vertices share edges. ", 
        "id": 466, 
        "title": "Modified subdivision surfaces with continuous curvature."
    }, 
    {
        "abstract": "By inserting a microlens array into the optical train of a conventional microscope, one can capture light fields of biological specimens in a single photograph. Although diffraction places a limit on the product of spatial and angular resolution in these light fields, we can nevertheless produce useful perspective views and focal stacks from them. Since microscopes are inherently orthographic devices, perspective views represent a new way to look at microscopic specimens. The ability to create focal stacks from a single photograph allows moving or light-sensitive specimens to be recorded. Applying 3D deconvolution to these focal stacks, we can produce a set of cross sections, which can be visualized using volume rendering. In this paper, we demonstrate a prototype light field microscope (LFM), analyze its optical performance, and show perspective views, focal stacks, and reconstructed volumes for a variety of biological specimens. We also show that synthetic focusing followed by 3D deconvolution is equivalent to applying limited-angle tomography directly to the 4D light field.", 
        "id": 467, 
        "title": "Light field microscopy."
    }, 
    {
        "abstract": "This paper presents a new interactive tool for making local adjustments of tonal values and other visual parameters in an image. Rather than carefully selecting regions or hand-painting layer masks, the user quickly indicates regions of interest by drawing a few simple brush strokes and then uses sliders to adjust the brightness, contrast, and other parameters in these regions. The effects of the user's sparse set of constraints are interpolated to the entire image using an edge-preserving energy minimization method designed to prevent the propagation of tonal adjustments to regions of significantly different luminance. The resulting system is suitable for adjusting ordinary and high dynamic range images, and provides the user with much more creative control than existing tone mapping algorithms. Our tool is also able to produce a tone mapping automatically, which may serve as a basis for further local adjustments, if so desired. The constraint propagation approach developed in this paper is a general one, and may also be used to interactively control a variety of other adjustments commonly performed in the digital darkroom. ", 
        "id": 468, 
        "title": "Interactive local adjustment of tonal values."
    }, 
    {
        "abstract": "In architectural freeform design, the relation between shape and fabrication poses new challenges and requires more sophistication from the underlying geometry. The new concept of conical meshes satisfies central requirements for this application: They are quadrilateral meshes with planar faces, and therefore particularly suitable for the design of freeform glass structures. Moreover, they possess a natural offsetting operation and provide a support structure orthogonal to the mesh. Being a discrete analogue of the network of principal curvature lines, they represent fundamental shape characteristics. We show how to optimize a quad mesh such that its faces become planar, or the mesh becomes even conical. Combining this perturbation with subdivision yields a powerful new modeling tool for all types of quad meshes with planar faces, making subdivision attractive for architecture design and providing an elegant way of modeling developable surfaces. ", 
        "id": 469, 
        "title": "Geometric modeling with conical meshes and developable surfaces."
    }, 
    {
        "abstract": "We consider the problem of real-time GPU rendering of algebraic surfaces defined by Bezier tetrahedra. These surfaces are rendered directly in terms of their polynomial representations, as opposed to a collection of approximating triangles, thereby eliminating tessellation artifacts and reducing memory usage. A key step in such algorithms is the computation of univariate polynomial coefficients at each pixel; real roots of this polynomial correspond to possibly visible points on the surface. Our approach leverages the strengths of GPU computation and is highly efficient. Furthermore, we compute these coefficients in Bernstein form to maximize the stability of root finding, and to provide shader instances with an early exit test based on the sign of these coefficients. Solving for roots is done using analytic techniques that map well to a SIMD architecture, but limits us to fourth order algebraic surfaces. The general framework could be extended to higher order with numerical root finding. ", 
        "id": 470, 
        "title": "Real-time GPU rendering of piecewise algebraic surfaces."
    }, 
    {
        "abstract": "The particle level set method has proven successful for the simulation of two separate regions (such as water and air, or fuel and products). In this paper, we propose a novel approach to extend this method to the simulation of as many regions as desired. The various regions can be liquids (or gases) of any type with differing viscosities, densities, viscoelastic properties, etc. We also propose techniques for simulating interactions between materials, whether it be simple surface tension forces or more complex chemical reactions with one material converting to another or two materials combining to form a third. We use a separate particle level set method for each region, and propose a novel projection algorithm that decodes the resulting vector of level set values providing a \"dictionary\" that translates between them and the standard single-valued level set representation. An additional difficulty occurs since discretization stencils (for interpolation, tracing semi-Lagrangian rays, etc.) cross region boundaries naively combining non-smooth or even discontinuous data. This has recently been addressed via ghost values, e.g. for fire or bubbles. We instead propose a new paradigm that allows one to incorporate physical jump conditions in data \"on the fly,\" which is significantly more efficient for multiple regions especially at triple points or near boundaries with solids. ", 
        "id": 471, 
        "title": "Multiple interacting liquids."
    }, 
    {
        "abstract": "We present a simple and efficient method to enhance the perceptual quality of images that contain depth information. Similar to an unsharp mask, the difference between the original depth buffer content and a low-pass filtered copy is utilized to determine information about spatially important areas in a scene. Based on this information we locally enhance the contrast, color, and other parameters of the image. Our technique aims at improving the perception of complex scenes by introducing additional depth cues. The idea is motivated by artwork and findings in the field of neurology, and can be applied to images of any kind, ranging from complex landscape data and technical artifacts, to volume rendering, photograph, and video with depth information. ", 
        "id": 472, 
        "title": "Image enhancement by unsharp masking the depth buffer."
    }, 
    {
        "abstract": "To embrace the imminent transition from traditional low-contrast video (LDR) content to superior high dynamic range (HDR) content, we propose a novel backward-compatible HDR video compression (HDR MPEG) method. We introduce a compact reconstruction function that is used to decompose an HDR video stream into a residual stream and a standard LDR stream, which can be played on existing MPEG decoders, such as DVD players. The reconstruction function is finely tuned to the content of each HDR frame to achieve strong decorrelation between the LDR and residual streams, which minimizes the amount of redundant information. The size of the residual stream is further reduced by removing invisible details prior to compression using our HDR-enabled filter, which models luminance adaptation, contrast sensitivity, and visual masking based on the HDR content. Designed especially for DVD movie distribution, our HDR MPEG compression method features low storage requirements for HDR content resulting in a 30% size increase to an LDR video sequence. The proposed compression method does not impose restrictions or modify the appearance of the LDR or HDR video. This is important for backward compatibility of the LDR stream with current DVD appearance, and also enables independent fine tuning, tone mapping, and color grading of both streams. ", 
        "id": 473, 
        "title": "Backward compatible high dynamic range MPEG video compression."
    }, 
    {
        "abstract": "", 
        "id": 474, 
        "title": "Accurate detection of symmetries in 3D shapes."
    }, 
    {
        "abstract": "", 
        "id": 475, 
        "title": "Animation space: A truly linear framework for character animation."
    }, 
    {
        "abstract": " ulating global illumination is a complex and computationally expensive task.  Global illumination provides important visual cues to an animation, however its computational expense limits its use in practice. In this paper, we present an easy to implement technique for accelerating the computation of indirect illumination for an animated sequence using stochastic ray tracing. We begin by computing a quick but noisy solution using a small number of sample rays at each sample location. The variation of these noisy solutions over time is then used to create a smooth basis. Finally, the noisy solutions are projected onto the smooth basis to produce the final solution. The resulting animation has greatly reduced spatial and temporal noise, and a computational cost roughly equivalent to the noisy, low sample computation. ", 
        "id": 476, 
        "title": "Statistical acceleration for animated global illumination."
    }, 
    {
        "abstract": "\"Symmetry is a complexity-reducing concept [...]; seek it everywhere.\" - Alan J. Perlis Many natural and man-made objects exhibit significant symmetries or contain repeated substructures. This paper presents a new algorithm that processes geometric models and efficiently discovers and extracts a compact representation of their Euclidean symmetries. These symmetries can be partial, approximate, or both. The method is based on matching simple local shape signatures in pairs and using these matches to accumulate evidence for symmetries in an appropriate transformation space. A clustering stage extracts potential significant symmetries of the object, followed by a verification step. Based on a statistical sampling analysis, we provide theoretical guarantees on the success rate of our algorithm. The extracted symmetry graph representation captures important highlevel information about the structure of a geometric model which in turn enables a large set of further processing operations, including shape compression, segmentation, consistent editing, symmetrization, indexing for retrieval, etc. ", 
        "id": 477, 
        "title": "Partial and approximate symmetry detection for 3D geometry."
    }, 
    {
        "abstract": "Simulating multiple scattering correctly is important for accurate rendering of hair. However, a volume of hair is a difficult scene to simulate because scattering from an individual fiber is very structured and forward directed, and because the radiance distributions that arise from many such scattering events remain quite directional. For these reasons, previous methods cannot compute accurate images substantially faster than Monte Carlo path tracing. This paper proposes a new physically accurate method for rendering hair that is based on previous volumetric photon mapping methods. The first pass generates a photon map by tracing particles through the hair geometry, depositing them along paths rather than at scattering events. The second pass ray traces the hair, computing direct illumination and looking up indirect radiance in the photon map. Photons are stored and looked up in 5D position-direction space to allow for the very directional radiance distributions that occur in hair. Together with a new radiance caching method for fibers, our method simulates difficult scattering problems in hair efficiently and with low noise. The new algorithm is validated against path tracing and also compared with a photograph of light scattering in real hair. ", 
        "id": 478, 
        "title": "Simulating multiple scattering in hair using a photon mapping approach."
    }, 
    {
        "abstract": "", 
        "id": 479, 
        "title": "Extended subdivision surfaces: Building a bridge between NURBS and Catmull-Clark surfaces."
    }, 
    {
        "abstract": "CGA shape, a novel shape grammar for the procedural modeling of CG architecture, produces building shells with high visual quality and geometric detail. It produces extensive architectural models for computer games and movies, at low cost. Context sensitive shape rules allow the user to specify interactions between the entities of the hierarchical shape descriptions. Selected examples demonstrate solutions to previously unsolved modeling problems, especially to consistent mass modeling with volumetric shapes of arbitrary orientation. CGA shape is shown to efficiently generate massive urban models with unprecedented level of detail, with the virtual rebuilding of the archaeological site of Pompeii as a case in point. ", 
        "id": 480, 
        "title": "Procedural modeling of buildings."
    }, 
    {
        "abstract": " In this paper, we break new ground by presenting algorithms for fixed-rate compression of high dynamic range textures at low bit rates. First, the S3TC low dynamic range texture compression scheme is extended in order to enable compression of HDR data. Second, we introduce a novel robust algorithm that offers superior image quality. Our algorithm can be efficiently implemented in hardware, and supports textures with a dynamic range of over 109:1. At a fixed rate of 8 bits per pixel, we obtain results virtually indistinguishable from uncompressed HDR textures at 48 bits per pixel. Our research can have a big impact on graphics hardware and real-time rendering, since HDR texturing suddenly becomes affordable. ", 
        "id": 481, 
        "title": "High dynamic range texture compression for graphics hardware."
    }, 
    {
        "abstract": "The visual world around us displays a rich set of volumetric effects due to participating media. The appearance of these media is governed by several physical properties such as particle densities, shapes and sizes, which must be input (directly or indirectly) to a rendering algorithm to generate realistic images. While there has been significant progress in developing rendering techniques (for instance, volumetric Monte Carlo methods and analytic approximations), there are very few methods that measure or estimate these properties for media that are of relevance to computer graphics. In this paper, we present a simple device and technique for robustly estimating the properties of a broad class of participating media that can be either (a) diluted in water such as juices, beverages, paints and cleaning supplies, or (b) dissolved in water such as powders and sugar/salt crystals, or (c) suspended in water such as  impurities. The key idea is to dilute the concentrations of the media so that single scattering effects dominate and multiple scattering becomes negligible, leading to a simple and robust estimation algorithm. Furthermore, unlike previous approaches that require complicated or separate measurement setups for different types or properties of media, our method and setup can be used to measure media with a complete range of absorption and scattering properties from a single HDR photograph. Once the parameters of the diluted medium are estimated, a volumetric Monte Carlo technique may be used to create renderings of any medium concentration and with multiple scattering. We have measured the scattering parameters of forty commonly found materials, that can be immediately used by the computer graphics community. We can also create realistic images of combinations or mixtures of the original measured materials, thus giving the user a wide flexibility in making realistic images of participating media.   e-mail:srinivas@cs.cmu.edu  ", 
        "id": 482, 
        "title": "Acquiring scattering properties of participating media by dilution."
    }, 
    {
        "abstract": "We present fast methods for separating the direct and global illumination components of a scene measured by a camera and illuminated by a light source. In theory, the separation can be done with just two images taken with a high frequency binary illumination pattern and its complement. In practice, a larger number of images are used to overcome the optical and resolution limitations of the camera and the source. The approach does not require the material properties of objects and media in the scene to be known. However, we require that the illumination frequency is high enough to adequately sample the global components received by scene points. We present separation results for scenes that include complex interreflections, subsurface scattering and volumetric scattering. Several variants of the separation approach are also described. When a sinusoidal illumination pattern is used with different phase shifts, the separation can be done using just three images. When the computed images are of lower resolution than the source and the camera, smoothness constraints are used to perform the separation using a single image. Finally, in the case of a static scene that is lit by a simple point source, such as the sun, a moving occluder and a video camera can be used to do the separation. We also show several simple examples of how novel images of a scene can be computed from the separation results.", 
        "id": 483, 
        "title": "Fast separation of direct and global components of a scene using high frequency illumination."
    }, 
    {
        "abstract": "We present hybrid images, a technique that produces static images with two interpretations, which change as a function of viewing distance. Hybrid images are based on the multiscale processing of images by the human visual system and are motivated by masking studies in visual perception. These images can be used to create compelling displays in which the image appears to change as the viewing distance changes. We show that by taking into account perceptual grouping mechanisms it is possible to build compelling hybrid images with stable percepts at each distance. We show examples in which hybrid images are used to create textures that become visible only when seen up-close, to generate facial expressions whose interpretation changes with viewing distance, and to visualize changes over time within a single picture. ", 
        "id": 484, 
        "title": "Hybrid images."
    }, 
    {
        "abstract": "", 
        "id": 485, 
        "title": "Video-guided motion synthesis using example motions."
    }, 
    {
        "abstract": "During dynamic activities, the surface of the human body moves in many subtle but visually significant ways: bending, bulging, jiggling, and stretching. We present a technique for capturing and animating those motions using a commercial motion capture system and approximately 350 markers. Although the number of markers is significantly larger than that used in conventional motion capture, it is only a sparse representation of the true shape of the body. We supplement this sparse sample with a detailed, actorspecific surface model. The motion of the skin can then be computed by segmenting the markers into the motion of a set of rigid parts and a residual deformation (approximated first as a quadratic transformation and then with radial basis functions). We demonstrate the power of this approach by capturing flexing muscles, high frequency motions, and abrupt decelerations on several actors. We compare these results both to conventional motion capture and skinning and to synchronized video of the actors. ", 
        "id": 486, 
        "title": "Capturing and animating skin deformation in human motion."
    }, 
    {
        "abstract": "", 
        "id": 487, 
        "title": "Point-based multiscale surface representation."
    }, 
    {
        "abstract": "Many translucent materials exhibit heterogeneous subsurface scattering, which arises from complex internal structures. The acquisition and representation of these scattering functions is a complex problem that has been only partially addressed in previous techniques. Unlike homogeneous materials, the spatial component of heterogeneous subsurface scattering can vary arbitrarily over surface locations. Storing the spatial component without compression leads to impractically large datasets. In this paper, we address the problem of acquiring and compactly representing the spatial component of heterogeneous subsurface scattering functions. We propose a material model based on matrix factorization that can be mapped onto arbitrary geometry, and, due to its compact form, can be incorporated into most visualization systems with little overhead. We present results of several real-world datasets that are acquired using a projector and a digital camera. ", 
        "id": 488, 
        "title": "A compact factored representation of heterogeneous subsurface scattering."
    }, 
    {
        "abstract": "", 
        "id": 489, 
        "title": "Computing contour generators of evolving implicit surfaces."
    }, 
    {
        "abstract": "Symmetry is an important cue for many applications, including object alignment, recognition, and segmentation. In this paper, we describe a planar reflective symmetry transform (PRST) that captures a continuous measure of the reflectional symmetry of a shape with respect to all possible planes. This transform combines and extends previous work that has focused on global symmetries with respect to the center of mass in 3D meshes and local symmetries with respect to points in 2D images. We provide an efficient Monte Carlo sampling algorithm for computing the transform for surfaces and show that it is stable under common transformations. We also provide an iterative refinement algorithm to find local maxima of the transform precisely. We use the transform to define two new geometric properties, center of symmetry and principal symmetry axes, and show that they are useful for aligning objects in a canonical coordinate system. Finally, we demonstrate that the symmetry transform is useful for several applications in computer graphics, including shape matching, segmentation of meshes into parts, and automatic viewpoint selection. ", 
        "id": 490, 
        "title": "A planar-reflective symmetry transform for 3D shapes."
    }, 
    {
        "abstract": "", 
        "id": 491, 
        "title": "Forward rasterization."
    }, 
    {
        "abstract": "", 
        "id": 492, 
        "title": "Parametrizations for triangular "
    }, 
    {
        "abstract": "In this paper, we propose a semi-automatic technique for modeling plants directly from images. Our image-based approach has the distinct advantage that the resulting model inherits the realistic shape and complexity of a real plant. We designed our modeling system to be interactive, automating the process of shape recovery while relying on the user to provide simple hints on segmentation. Segmentation is performed in both image and 3D spaces, allowing the user to easily visualize its effect immediately. Using the segmented image and 3D data, the geometry of each leaf is then automatically recovered from the multiple views by fitting a deformable leaf model. Our system also allows the user to easily reconstruct branches in a similar manner. We show realistic reconstructions of a variety of plants, and demonstrate examples of plant editing. ", 
        "id": 493, 
        "title": "Image-based plant modeling."
    }, 
    {
        "abstract": "This paper proposes a novel colorization technique that propagates color over regions exhibiting pattern-continuity as well as intensitycontinuity. The proposed method works effectively on colorizing black-and-white manga which contains intensive amount of strokes, hatching, halftoning and screening. Such fine details and discontinuities in intensity introduce many difficulties to intensity-based colorization methods. Once the user scribbles on the drawing, a local, statistical based pattern feature obtained with Gabor wavelet filters is applied to measure the pattern-continuity. The boundary is then propagated by the level set method that monitors the patterncontinuity. Regions with open boundaries or multiple disjointed regions with similar patterns can be sensibly segmented by a single scribble. With the segmented regions, various colorization techniques can be applied to replace colors, colorize with stroke preservation, or even convert pattern to shading. Several results are shown to demonstrate the effectiveness and convenience of the proposed method. ", 
        "id": 494, 
        "title": "Manga colorization."
    }, 
    {
        "abstract": "In a conventional single-exposure photograph, moving objects or moving cameras cause motion blur. The exposure time defines a temporal box filter that smears the moving object across the image by convolution. This box filter destroys important high-frequency spatial details so that deblurring via deconvolution becomes an illposed problem. Rather than leaving the shutter open for the entire exposure duration, we \"flutter\" the camera's shutter open and closed during the chosen exposure time with a binary pseudo-random sequence. The flutter changes the box filter to a broad-band filter that preserves high-frequency spatial details in the blurred image and the corresponding deconvolution becomes a well-posed problem. We demonstrate that manually-specified point spread functions are sufficient for several challenging cases of motion-blur removal including extremely large motions, textured backgrounds and partial occluders. ", 
        "id": 495, 
        "title": "Coded exposure photography: motion deblurring using fluttered shutter."
    }, 
    {
        "abstract": "", 
        "id": 496, 
        "title": "Periodic global parameterization."
    }, 
    {
        "abstract": "Previous methods for soft shadows numerically integrate over many light directions at each receiver point, testing blocker visibility in each direction. We introduce a method for real-time soft shadows in dynamic scenes illuminated by large, low-frequency light sources where such integration is impractical. Our method operates on vectors representing low-frequency visibility of blockers in the spherical harmonic basis. Blocking geometry is modeled as a set of spheres; relatively few spheres capture the low-frequency blocking effect of complicated geometry. At each receiver point, we compute the product of visibility vectors for these blocker spheres as seen from the point. Instead of computing an expensive SH product per blocker as in previous work, we perform inexpensive vector sums to accumulate the log of blocker visibility. SH exponentiation then yields the product visibility vector over all blockers. We show how the SH exponentiation required can be approximated accurately and efficiently for low-order SH, accelerating previous CPUbased methods by a factor of 10 or more, depending on blocker complexity, and allowing real-time GPU implementation. ", 
        "id": 497, 
        "title": "Real-time soft shadows in dynamic scenes using spherical harmonic exponentiation."
    }, 
    {
        "abstract": " We present a novel compression scheme for high dynamic range textures, targeted for hardware implementation. Our method encodes images at a constant 8 bits per pixel, for a compression ratio of 6:1. We demonstrate that our method achieves good visual fidelity, surpassing DXTC texture compression of RGBE data which is the most practical method on existing graphics hardware. The decoding logic for our method is simple enough to be implemented as part of the texture fetch unit in graphics hardware.  ", 
        "id": 498, 
        "title": "High dynamic range texture compression."
    }, 
    {
        "abstract": "The paper defines an automatic procedure for constructing a visually appealing collage from a collection of input images. The aim is that the resulting collage should be representative of the collection, summarising its main themes. It is also assembled largely seamlessly, using graph-cut, Poisson blending of alpha-masks, to hide the joins between input images. This paper makes several new contributions. Firstly, we show how energy terms can be included that: encourage the selection of a representative set of images; that are sensitive to particular object classes; that encourage a spatially e-mail: {carrot, lucasb, youssefh, ablake}@microsoft.com Copyright  2006 by the Association for Computing Machinery, Inc. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org.  2006 ACM 0730-0301/06/0700-0847 $5.00 847  efficient and seamless layout. Secondly the resulting optimization poses a search problem that, on the face of it, is computationally infeasible. Rather than attempt an expensive, integrated optimization procedure, we have developed a sequence of optimization steps, from static ranking of images, through region of interest optimization, optimal packing by constraint satisfaction, and lastly graphcut alpha-expansion. To illustrate the power of AutoCollage, we have used it to create collages of many home photo sets; we also conducted a user study in which AutoCollage outperformed competitive methods.  ", 
        "id": 499, 
        "title": "AutoCollage."
    }, 
    {
        "abstract": " In fields ranging from technical illustration to mapmaking, artists have developed distinctive visual styles designed to convey both detail and overall shape as clearly as possible. We investigate a non-photorealistic shading model, inspired by techniques for cartographic terrain relief, based on dynamically adjusting the effective light position for different areas of the surface. It reveals detail regardless of surface orientation and, by operating at multiple scales, is designed to convey detail at all frequencies simultaneously.  ", 
        "id": 500, 
        "title": "Exaggerated shading for depicting shape and detail."
    }, 
    {
        "abstract": "We provide an image deformation method based on Moving Least Squares using various classes of linear functions including affine, similarity and rigid transformations. These deformations are realistic and give the user the impression of manipulating real-world objects. We also allow the user to specify the deformations using either sets of points or line segments, the later useful for controlling curves and profiles present in the image. For each of these techniques, we provide simple closed-form solutions that yield fast deformations, which can be performed in real-time.  the position and orientation of these handles, the image should deform in an intuitive fashion. We view this deformation as a function f that maps points in the undeformed image to the deformed image. Applying the function f to each point v in the undeformed image creates the deformed image. Now consider an image with a set of handles p that the user moves to new positions q. For f to be useful for deformations it must satisfy the following properties:  Interpolation: The handles p should map directly to q under deformation. (i.e; f (pi) = qi).  ", 
        "id": 501, 
        "title": "Image deformation using moving least squares."
    }, 
    {
        "abstract": "A method is described for texturing surfaces using decals, images placed on the surface using local parameterizations. Decal parameterizations are generated with a novel O(N log N ) discrete approximation to the exponential map which requires only a single additional step in Dijkstra's graph-distance algorithm. Decals are dynamically composited in an interface that addresses many limitations of previous work. Tools for image processing, deformation/feature-matching, and vector graphics are implemented using direct surface interaction. Exponential map decals can contain holes and can also be combined with conformal parameterization to reduce distortion. The exponential map approximation can be computed on any point set, including meshes and sampled implicit surfaces, and is relatively stable under resampling. The decals stick to the surface as it is interactively deformed, allowing the texture to be preserved even if the surface changes topology. These properties make exponential map decals a suitable approach for texturing animated implicit surfaces. ", 
        "id": 502, 
        "title": "Interactive decal compositing with discrete exponential maps."
    }, 
    {
        "abstract": "In this paper, we present a multigrid technique for efficiently deforming large surface and volume meshes. We show that a previous least-squares formulation for distortion minimization reduces to a Laplacian system on a general graph structure for which we derive an analytic expression. We then describe an efficient multigrid algorithm for solving the relevant equations. Here we develop novel prolongation and restriction operators used in the multigrid cycles. Combined with a simple but effective graph coarsening strategy, our algorithm can outperform other multigrid solvers and the factorization stage of direct solvers in both time and memory costs for large meshes. It is demonstrated that our solver can trade off accuracy for speed to achieve greater interactivity, which is attractive for manipulating large meshes. Our multigrid solver is particularly well suited for a mesh editing environment which does not permit extensive precomputation. Experimental evidence of these advantages is provided on a number of meshes with a wide range of size. With our mesh deformation solver, we also successfully demonstrate that visually appealing mesh animations can be generated from both motion capture data and a single base mesh even when they are inconsistent. ", 
        "id": 503, 
        "title": "A fast multigrid algorithm for mesh deformation."
    }, 
    {
        "abstract": "", 
        "id": 504, 
        "title": "Solution space navigation for geometric constraint systems."
    }, 
    {
        "abstract": "We present a system for interactively browsing and exploring large unstructured collections of photographs of a scene using a novel 3D interface. Our system consists of an image-based modeling front end that automatically computes the viewpoint of each photograph as well as a sparse 3D model of the scene and image to model correspondences. Our photo explorer uses image-based rendering techniques to smoothly transition between photographs, while also enabling full 3D navigation and exploration of the set of images and world geometry, along with auxiliary information such as overhead maps. Our system also makes it easy to construct photo tours of scenic or historic locations, and to annotate image details, which are automatically transferred to other relevant images. We demonstrate our system on several large personal photo collections as well as images gathered from Internet photo sharing sites. ", 
        "id": 505, 
        "title": "Photo tourism: exploring photo collections in 3D."
    }, 
    {
        "abstract": "We present novel algorithms to perform collision and distance queries among multiple deformable models in dynamic environments. These include inter-object queries between different objects as well as intra-object queries. We describe a unified approach to compute these queries based on N-body distance computation and use properties of the 2ndorder discrete Voronoi diagram to perform N-body culling. Our algorithms involve no preprocessing and also work well on models with changing topologies. We can perform all proximity queries among complex deformable models consisting of thousands of triangles in a fraction of a second on a high-end PC. Moreover, our Voronoi-based culling algorithm can improve the performance of separation distance and penetration queries by an order of magnitude. ", 
        "id": 506, 
        "title": "Fast proximity computation among deformable models using discrete Voronoi diagrams."
    }, 
    {
        "abstract": "", 
        "id": 507, 
        "title": "Rendering biological iridescences with RGB-based renderers."
    }, 
    {
        "abstract": "In this paper, we propose a novel approach to extract mattes using a pair of flash/no-flash images. Our approach, which we call flash matting, was inspired by the simple observation that the most noticeable difference between the flash and no-flash images is the foreground object if the background scene is sufficiently distant. We apply a new matting algorithm called joint Bayesian flash matting to robustly recover the matte from flash/no-flash images, even for scenes in which the foreground and the background are similar or the background is complex. Experimental results involving a variety of complex indoors and outdoors scenes show that it is easy to extract high-quality mattes using an off-the-shelf, flash-equipped camera. We also describe extensions to flash matting for handling more general scenes.  ", 
        "id": 508, 
        "title": "Flash matting."
    }, 
    {
        "abstract": " We consider real-time rendering of dynamic glossy objects with realistic shadows under distant all-frequency environment lighting. Previous PRT approaches pre-compute light transport for a fixed scene and cannot account for cast shadows on high-glossy objects occluded by dynamic neighbors. In this paper, we extend double/triple product integral to generalized multi-function product integral. We represent shading integral at each vertex as the product integral of multiple functions, involving the lighting, BRDF, local visibility and dynamic occlusions. Our main contribution is a new mathematical representation and analysis of multi-function product integral in the wavelet domain. We show that multi-function product integral in the primal corresponds to the summation of the product of basis coefficients and integral coefficients. We propose a novel generalized Haar integral coefficient theorem to evaluate arbitrary Haar integral coefficients. We present an efficient sub-linear algorithm to render dynamic glossy objects under time-variant allfrequency lighting and arbitrary view conditions in a few seconds on a commodity CPU, orders of magnitude faster than previous techniques. To further accelerate shadow computation, we propose a Just-in-time Radiance Transfer (JRT) technique. JRT is a new generalization to PRT for dynamic scenes. It is compact and flexible, and supports glossy materials. By pre-computing radiance transfer vectors at runtime, we demonstrate rendering dynamic view-dependent all-frequency shadows in real-time.  ", 
        "id": 509, 
        "title": "Generalized wavelet product integral for rendering dynamic glossy objects."
    }, 
    {
        "abstract": "This paper develops locally adapted hierarchical basis functions for effectively preconditioning large optimization problems that arise in computer graphics applications such as tone mapping, gradientdomain blending, colorization, and scattered data interpolation. By looking at the local structure of the coefficient matrix and performing a recursive set of variable eliminations, combined with a simplification of the resulting coarse level problems, we obtain bases better suited for problems with inhomogeneous (spatially varying) data, smoothness, and boundary constraints. Our approach removes the need to heuristically adjust the optimal number of preconditioning levels, significantly outperforms previously proposed approaches, and also maps cleanly onto data-parallel architectures such as modern GPUs. ", 
        "id": 510, 
        "title": "Locally adapted hierarchical basis preconditioning."
    }, 
    {
        "abstract": "We present a real-time crowd model based on continuum dynamics. In our model, a dynamic potential field simultaneously integrates global navigation with moving obstacles such as other people, efficiently solving for the motion of large crowds without the need for explicit collision avoidance. Simulations created with our system run at interactive rates, demonstrate smooth flow under a variety of conditions, and naturally exhibit emergent phenomena that have been observed in real crowds. ", 
        "id": 511, 
        "title": "Continuum crowds."
    }, 
    {
        "abstract": " We present a new model reduction approach to fluid simulation, enabling large, real-time, detailed flows with continuous user interaction. Our reduced model can also handle moving obstacles immersed in the flow. We create separate models for the velocity field and for each moving boundary, and show that the coupling forces may be reduced as well. Our results indicate that surprisingly few basis functions are needed to resolve small but visually important features such as spinning vortices. ", 
        "id": 512, 
        "title": "Model reduction for real-time fluids."
    }, 
    {
        "abstract": " This paper introduces a new data representation and compression technique for precomputed radiance transfer (PRT). The light transfer functions and light sources are modeled with spherical radial basis functions (SRBFs). A SRBF is a rotation-invariant function that depends on the geodesic distance between two points on the unit sphere. Rotating functions in SRBF representation is as straightforward as rotating the centers of SRBFs. Moreover, highfrequency signals are handled by adjusting the bandwidth parameters of SRBFs. To exploit inter-vertex coherence, the light transfer functions are further classified iteratively into disjoint clusters, and tensor approximation is applied within each cluster. Compared with previous methods, the proposed approach enables real-time rendering with comparable quality under high-frequency lighting environments. The data storage is also more compact than previous all-frequency PRT algorithms. ", 
        "id": 513, 
        "title": "All-frequency precomputed radiance transfer using spherical radial basis functions and clustered tensor approximation."
    }, 
    {
        "abstract": "", 
        "id": 514, 
        "title": "A tangent subdivision scheme."
    }, 
    {
        "abstract": "Robust handling of collisions on non-oriented deformable surfaces requires advanced methods for recovering intersecting surfaces. We present a novel method that resolves intersections between two intersecting surface regions by inducing relative displacements which minimize the length of the intersection contour between them. This method, which does not rely on intersection regions, has a broader application field than existing methods, and its implementation is also much simpler, allowing integration into most existing collision response schemes. We demonstrate the efficiency of this method through examples in the context of cloth simulation. ", 
        "id": 515, 
        "title": "Resolving surface collisions through intersection contour minimization."
    }, 
    {
        "abstract": "We present a new approach to interactive ray tracing of moderatesized animated scenes based on traversing frustum-bounded packets of coherent rays through uniform grids. By incrementally computing the overlap of the frustum with a slice of grid cells, we accelerate grid traversal by more than a factor of 10, and achieve ray tracing performance competitive with the fastest known packet-based kd-tree ray tracers. The ability to efficiently rebuild the grid on every frame enables this performance even for fully dynamic scenes that typically challenge interactive ray tracing systems. ", 
        "id": 516, 
        "title": "Ray tracing animated scenes using coherent grid traversal."
    }, 
    {
        "abstract": "", 
        "id": 517, 
        "title": "Intrinsic subdivision with smooth limits for graphics and animation."
    }, 
    {
        "abstract": "Multidimensional lightcuts is a new scalable method for efficiently rendering rich visual effects such as motion blur, participating media, depth of field, and spatial anti-aliasing in complex scenes. It introduces a flexible, general rendering framework that unifies the handling of such effects by discretizing the integrals into large sets of gather and light points and adaptively approximating the sum of all possible gather-light pair interactions. We create an implicit hierarchy, the product graph, over the gatherlight pairs to rapidly and accurately approximate the contribution from hundreds of millions of pairs per pixel while only evaluating a tiny fraction (e.g., 2001,000). We build upon the techniques of the prior Lightcuts method for complex illumination at a point, however, by considering the complete pixel integrals, we achieve much greater efficiency and scalability. Our example results demonstrate efficient handling of volume scattering, camera focus, and motion of lights, cameras, and geometry. For example, enabling high quality motion blur with 256 temporal sampling requires only a 6.7 increase in shading cost in a scene with complex moving geometry, materials, and illumination. ", 
        "id": 518, 
        "title": "Multidimensional lightcuts."
    }, 
    {
        "abstract": " We present the \"Cartoon Animation Filter\", a simple filter that takes an arbitrary input motion signal and modulates it in such a way that the output motion is more \"alive\" or \"animated\". The filter adds a smoothed, inverted, and (sometimes) time shifted version of the second derivative (the acceleration) of the signal back into the original signal. Almost all parameters of the filter are automated. The user only needs to set the desired strength of the filter. The beauty of the animation filter lies in its simplicity and generality. We apply the filter to motions ranging from hand drawn trajectories, to simple animations within PowerPoint presentations, to motion captured DOF curves, to video segmentation results. Experimental results show that the filtered motion exhibits anticipation, follow-through, exaggeration and squash-and-stretch effects which are not present in the original input motion data.  ", 
        "id": 519, 
        "title": "The cartoon animation filter."
    }, 
    {
        "abstract": "", 
        "id": 520, 
        "title": "Fitting B-spline curves to point clouds by curvature-based squared distance minimization."
    }, 
    {
        "abstract": "", 
        "id": 521, 
        "title": "All-frequency relighting of glossy objects."
    }, 
    {
        "abstract": "We present a visual simulation technique called appearance manifolds for modeling the time-variant surface appearance of a material from data captured at a single instant in time. In modeling timevariant appearance, our method takes advantage of the key observation that concurrent variations in appearance over a surface represent different degrees of weathering. By reorganizing these various appearances in a manner that reveals their relative order with respect to weathering degree, our method infers spatial and temporal appearance properties of the material's weathering process that can be used to convincingly generate its weathered appearance at different points in time. Results with natural non-linear reflectance variations are demonstrated in applications such as visual simulation of weathering on 3D models, increasing and decreasing the weathering of real objects, and material transfer with weathering effects. ", 
        "id": 522, 
        "title": "Appearance manifolds for modeling time-variant appearance of materials."
    }, 
    {
        "abstract": "", 
        "id": 523, 
        "title": "Deringing cartoons by image analogies."
    }, 
    {
        "abstract": "Vertex- and face-based subdivision schemes are now routinely used in geometric modeling and computational science, and their primal/dual relationships are well studied. In this paper, we interpret these schemes as defining bases for discrete differential 0- resp. 2-forms, and complete the picture by introducing edge-based subdivision schemes to construct the missing bases for discrete differential 1-forms. Such subdivision schemes map scalar coefficients on edges from the coarse to the refined mesh and are intrinsic to the surface. Our construction is based on treating vertex-, edge-, and face-based subdivision schemes as a joint triple and enforcing that subdivision commutes with the topological exterior derivative. We demonstrate our construction for the case of arbitrary topology triangle meshes. Using Loop's scheme for 0-forms and generalized half-box splines for 2forms results in a unique generalized spline scheme for 1-forms, easily incorporated into standard subdivision surface codes. We also provide corresponding boundary stencils. Once a metric is supplied, the scalar 1-form coefficients define a smooth tangent vector field on the underlying subdivision surface. Design of tangent vector fields is made particularly easy with this machinery as we demonstrate. ", 
        "id": 524, 
        "title": "Edge subdivision schemes and the construction of smooth vector fields."
    }, 
    {
        "abstract": " Median filtering is a cornerstone of modern image processing and is used extensively in smoothing and de-noising applications. The fastest commercial implementations (e.g. in Adobe Photoshop CS2) exhibit O(r) runtime in the radius of the filter, which limits their usefulness in realtime or resolution-independent contexts. We introduce a CPU-based, vectorizable O(log r) algorithm for median filtering, to our knowledge the most efficient yet developed. Our algorithm extends to images of any bit-depth, and can also be adapted to perform bilateral filtering. On 8-bit data our median filter outperforms Photoshop's implementation by up to a factor of fifty.  ", 
        "id": 525, 
        "title": "Fast median and bilateral filtering."
    }, 
    {
        "abstract": "We have measured 3D face geometry, skin reflectance, and subsurface scattering using custom-built devices for 149 subjects of varying age, gender, and race. We developed a novel skin reflectance model whose parameters can be estimated from measurements. The model decomposes the large amount of measured skin data into a spatially-varying analytic BRDF, a diffuse albedo map, and diffuse subsurface scattering. Our model is intuitive, physically plausible, and  since we do not use the original measured data  easy to edit as well. High-quality renderings come close to reproducing real photographs. The analysis of the model parameters for our sample population reveals variations according to subject age, gender, skin type, and external factors (e.g., sweat, cold, or makeup). Using our statistics, a user can edit the overall appearance of a face (e.g., changing skin type and age) or change small-scale features using texture synthesis (e.g., adding moles and freckles). We are making the collected statistics publicly available to the research community for applications in face synthesis and analysis.", 
        "id": 526, 
        "title": "Analysis of human faces using a measurement-based skin reflectance model."
    }, 
    {
        "abstract": "We present an automatic, real-time video and image abstraction framework that abstracts imagery by modifying the contrast of visually important features, namely luminance and color opponency. We reduce contrast in low-contrast regions using an approximation to anisotropic diffusion, and artificially increase contrast in higher contrast regions with difference-of-Gaussian edges. The abstraction step is extensible and allows for artistic or data-driven control. Abstracted images can optionally be stylized using soft color quantization to create cartoon-like effects with good temporal coherence. Our framework design is highly parallel, allowing for a GPU-based, real-time implementation. We evaluate the effectiveness of our abstraction framework with a user-study and find that participants are faster at naming abstracted faces of known persons compared to photographs. Participants are also better at remembering abstracted images of arbitrary scenes in a memory task. ", 
        "id": 527, 
        "title": "Real-time video abstraction."
    }, 
    {
        "abstract": "This paper addresses the problem of computing the triangles visible from a region in space. The proposed aggressive visibility solution is based on stochastic ray shooting and can take any triangular model as input. We do not rely on connectivity information, volumetric occluders, or the availability of large occluders, and can therefore process any given input scene. The proposed algorithm is practically memoryless, thereby alleviating the large memory consumption problems prevalent in several previous algorithms. The strategy of our algorithm is to use ray mutations in ray space to cast rays that are likely to sample new triangles. Our algorithm improves the sampling efficiency of previous work by over two orders of magnitude. ", 
        "id": 528, 
        "title": "Guided visibility sampling."
    }, 
    {
        "abstract": "", 
        "id": 529, 
        "title": "Animating Chinese paintings through stroke-based decomposition."
    }, 
    {
        "abstract": "", 
        "id": 530, 
        "title": "Vector field design on surfaces."
    }, 
    {
        "abstract": "In order to produce bright images, projectors have large apertures and hence narrow depths of field. In this paper, we present methods for robust scene capture and enhanced image display based on projection defocus analysis. We model a projector's defocus using a linear system. This model is used to develop a novel temporal defocus analysis method to recover depth at each camera pixel by estimating the parameters of its projection defocus kernel in frequency domain. Compared to most depth recovery methods, our approach is more accurate near depth discontinuities. Furthermore, by using a coaxial projector-camera system, we ensure that depth is computed at all camera pixels, without any missing parts. We show that the recovered scene geometry can be used for refocus synthesis and for depth-based image composition. Using the same projector defocus model and estimation technique, we also propose a defocus compensation method that filters a projection image in a spatiallyvarying, depth-dependent manner to minimize its defocus blur after it is projected onto the scene. This method effectively increases the depth of field of a projector without modifying its optics. Finally, we present an algorithm that exploits projector defocus to reduce the strong pixelation artifacts produced by digital projectors, while preserving the quality of the projected image. We have experimentally verified each of our methods using real scenes. ", 
        "id": 531, 
        "title": "Projection defocus analysis for scene capture and image display."
    }, 
    {
        "abstract": " We introduce mesh quilting, a geometric texture synthesis algorithm in which a 3D texture sample given in the form of a triangle mesh is seamlessly applied inside a thin shell around an arbitrary surface through local stitching and deformation. We show that such geometric textures allow interactive and versatile editing and animation, producing compelling visual effects that are difficult to achieve with traditional texturing methods. Unlike pixel-based image quilting, mesh quilting is based on stitching together 3D geometry elements. Our quilting algorithm finds corresponding geometry elements in adjacent texture patches, aligns elements through local deformation, and merges elements to seamlessly connect texture patches. For mesh quilting on curved surfaces, a critical issue is to reduce distortion of geometry elements inside the 3D space of the thin shell. To address this problem we introduce a low-distortion parameterization of the shell space so that geometry elements can be synthesized even on very curved objects without the visual distortion present in previous approaches. We demonstrate how mesh quilting can be used to generate convincing decorations for a wide range of geometric textures. ", 
        "id": 532, 
        "title": "Mesh quilting for geometric texture synthesis."
    }, 
    {
        "abstract": "", 
        "id": 533, 
        "title": "Level set driven flows."
    }, 
    {
        "abstract": "We present novel adaptive sampling algorithms for particle-based fluid simulation. We introduce a sampling condition based on geometric local feature size that allows focusing computational resources in geometrically complex regions, while reducing the number of particles deep inside the fluid or near thick flat surfaces. Further performance gains are achieved by varying the sampling density according to visual importance. In addition, we propose a novel fluid surface definition based on approximate particletosurface distances that are carried along with the particles and updated appropriately. The resulting surface reconstruction method has several advantages over existing methods, including stability under particle resampling and suitability for representing smooth flat surfaces. We demonstrate how our adaptive sampling and distancebased surface reconstruction algorithms lead to significant improvements in time and memory as compared to single resolution particle simulations, without significantly affecting the fluid flow behavior. ", 
        "id": 534, 
        "title": "Adaptively sampled particle fluids."
    }, 
    {
        "abstract": " We describe a hierarchical approach to improving the efficiency of  gradient-domain compositing, a technique that constructs seamless  composites by combining the gradients of images into a vector field  that is then integrated to form a composite. While gradient-domain  compositing is powerful and widely used, it suffers from poor scal-  ability. Computing an n pixel composite requires solving a linear  system with n variables; solving such a large system quickly over-  whelms the main memory of a standard computer when performed  for multi-megapixel composites, which are common in practice. In  this paper we show how to perform gradient-domain compositing  approximately by solving an O(p) linear system, where p is the to-  tal length of the typical cases, p  isseaOm(s bne)t.wWeeenaicmhiaegvee  regions in the composite; for this reduction by transform-  ing the problem into a space where much of the solution is smooth,  and then utilize the pattern of this smoothness to adaptively sub-  divide the problem domain using quadtrees. We demonstrate the  merits of our approach by performing panoramic stitching and im-  age region copy-and-paste in significantly reduced time and mem-  ory while achieving visually identical results.  ", 
        "id": 535, 
        "title": "Efficient gradient-domain compositing using quadtrees."
    }, 
    {
        "abstract": "The development of high dynamic range (HDR) imagery has brought us to the verge of arguably the largest change in image display technologies since the transition from black-and-white to color television. Novel capture and display hardware will soon enable consumers to enjoy the HDR experience in their own homes. The question remains, however, of what to do with existing images and movies, which are intrinsically low dynamic range (LDR). Can this enormous volume of legacy content also be displayed effectively on HDR displays? We have carried out a series of rigorous psychophysical investigations to determine how LDR images are best displayed on a state-of-the-art HDR monitor, and to identify which stages of the HDR imaging pipeline are perceptually most critical. Our main findings are: (1) As expected, HDR displays outperform LDR ones. (2) Surprisingly, HDR images that are tonemapped for display on standard monitors are often no better than the best single LDR exposure from a bracketed sequence. (3) Most importantly of all, LDR data does not necessarily require sophisticated treatment to produce a compelling HDR experience. Simply boosting the range of an LDR image linearly to fit the HDR display can equal or even surpass the appearance of a true HDR image. Thus the potentially tricky process of inverse tone mapping can be largely circumvented. ", 
        "id": 536, 
        "title": "Do HDR displays support LDR content?: a psychophysical evaluation."
    }, 
    {
        "abstract": "There are many types of illustrations that are easier to create in planar-map-based illustration systems than in the more common stacking-based systems. One weakness shared by all existing planar-map-based systems is that the editability of the drawing is severely hampered once coloring has begun. The paths that define the areas to be filled become divided wherever they intersect, making it difficult or impossible to edit them as a whole. Live Paint is a new metaphor that allows planar-map-based coloring while maintaining all the original paths unchanged. When a user makes a change, the regions and edges defined by the new paths take on fill and stroke attributes from the previous regions and edges. This results in greater editing flexibility and ease of use. Live Paint uses a set of heuristics to match each region and edge in a changed illustration with a region or edge in the previous version, a task that is more difficult than it at first appears. It then transfers fill and stroke attributes accordingly. ", 
        "id": 537, 
        "title": "Dynamic planar map illustration."
    }, 
    {
        "abstract": "Handle-based mesh deformation is essentially a nonlinear problem. To allow scalability, the original deformation problem can be approximately represented by a compact set of control variables. We show the direct relation between the locations of handles on the mesh and the local rigidity under deformation, and introduce the notion of handle-aware rigidity. Then, we present a reduced model whose control variables are intelligently distributed across the surface, respecting the rigidity information and the geometry. Specifically, for each handle, the control variables are the transformations of the isolines of a harmonic scalar field representing the deformation propagation from that handle. The isolines constitute a virtual skeletal structure similar to the bones in skinning deformation, thus correctly capturing the low-frequency shape deformation. To interpolate the transformations from the isolines to the original mesh, we design a method which is local, linear and geometry-dependent. This novel interpolation scheme and the transformation-based reduced domain allow each iteration of the nonlinear solver to be fully computed over the reduced domain. This makes the per-iteration cost dependent on only the number of isolines and enables compelling deformation of highly detailed shapes at interactive rates. In addition, we show how the handle-driven isolines provide an efficient means for deformation transfer without full shape correspondence. ", 
        "id": 538, 
        "title": "Handle-aware isolines for scalable shape editing."
    }, 
    {
        "abstract": "Effective resizing of images should not only use geometric constraints, but consider the image content as well. We present a simple image operator called seam carving that supports content-aware image resizing for both reduction and expansion. A seam is an optimal 8-connected path of pixels on a single image from top to bottom, or left to right, where optimality is defined by an image energy function. By repeatedly carving out or inserting seams in one direction we can change the aspect ratio of an image. By applying these operators in both directions we can retarget the image to a new size. The selection and order of seams protect the content of the image, as defined by the energy function. Seam carving can also be used for image content enhancement and object removal. We support various visual saliency measures for defining the energy of an image, and can also include user input to guide the process. By storing the order of seams in an image we create multi-size images, that are able to continuously change in real time to fit a given size.", 
        "id": 539, 
        "title": "Seam carving for content-aware image resizing."
    }, 
    {
        "abstract": " Animating an articulated 3D character currently requires manual rigging to specify its internal skeletal structure and to define how the input motion deforms its surface. We present a method for animating characters automatically. Given a static character mesh and a generic skeleton, our method adapts the skeleton to the character and attaches it to the surface, allowing skeletal motion data to animate the character. Because a single skeleton can be used with a wide range of characters, our method, in conjunction with a library of motions for a few skeletons, enables a user-friendly animation system for novices and children. Our prototype implementation, called Pinocchio, typically takes under a minute to rig a character on a modern midrange PC.  ", 
        "id": 540, 
        "title": "Automatic rigging and animation of 3D characters."
    }, 
    {
        "abstract": " ", 
        "id": 541, 
        "title": "A finite element method for animating large viscoplastic flow."
    }, 
    {
        "abstract": "Physical simulation has emerged as a compelling animation technique, yet current approaches to coupling simulations of fluids and solids with irregular boundary geometry are inefficient or cannot handle some relevant scenarios robustly. We propose a new variational approach which allows robust and accurate solution on relatively coarse Cartesian grids, allowing possibly orders of magnitude faster simulation. By rephrasing the classical pressure projection step as a kinetic energy minimization, broadly similar to modern approaches to rigid body contact, we permit a robust coupling between fluid and arbitrary solid simulations that always gives a wellposed symmetric positive semi-definite linear system. We provide several examples of efficient fluid-solid interaction and rigid body coupling with sub-grid cell flow. In addition, we extend the framework with a new boundary condition for free-surface flow, allowing fluid to separate naturally from solids. ", 
        "id": 542, 
        "title": "A fast variational framework for accurate solid-fluid coupling."
    }, 
    {
        "abstract": " Uniform Sampling  We present methods for generating novel time-lapse videos that address the inherent sampling issues that arise with traditional photographic techniques. Starting with video-rate footage as input, our post-process downsamples the source material into a time-lapse video and provides user controls for retaining, removing, and resampling events. We employ two techniques for selecting and combining source frames to form the output. First, we present a nonuniform sampling method, based on dynamic programming, which optimizes the sampling of the input video to match the user's desired duration and visual objectives. We present multiple error metrics for this optimization, each resulting in different sampling characteristics. To complement the non-uniform sampling, we present the virtual shutter, a non-linear filtering technique that synthetically extends the exposure time of time-lapse frames.  Uniform Sampling With Motion Tails Non-Uniform Sampling  ", 
        "id": 543, 
        "title": "Computational time-lapse video."
    }, 
    {
        "abstract": "We combine the often opposing forces of artistic freedom and mathematical determinism to enrich a given animation or simulation of a surface with physically based detail. We present a process called tracking, which takes as input a rough animation or simulation and enhances it with physically simulated detail. Building on the foundation of constrained Lagrangian mechanics, we propose weak-form constraints for tracking the input motion. This method allows the artist to choose where to add details such as characteristic wrinkles and folds of various thin shell materials and dynamical effects of physical forces. We demonstrate multiple applications ranging from enhancing an artist's animated character to guiding a simulated inanimate object. ", 
        "id": 544, 
        "title": "TRACKS: toward directable thin shells."
    }, 
    {
        "abstract": "We present a novel multi-scale representation and acquisition method for the animation of high-resolution facial geometry and wrinkles. We first acquire a static scan of the face including reflectance data at the highest possible quality. We then augment a traditional marker-based facial motion-capture system by two synchronized video cameras to track expression wrinkles. The resulting model consists of high-resolution geometry, motion-capture data, and expression wrinkles in 2D parametric form. This combination represents the facial shape and its salient features at multiple scales. During motion synthesis the motion-capture data deforms the high-resolution geometry using a linear shell-based mesh-deformation method. The wrinkle geometry is added to the facial base mesh using nonlinear energy optimization. We present the results of our approach for performance replay as well as for wrinkle editing.", 
        "id": 545, 
        "title": "Multi-scale capture of facial geometry and motion."
    }, 
    {
        "abstract": "In this paper, we present a method for creating watercolor-like animation, starting from video as input. The method involves two main steps: applying textures that simulate a watercolor appearance; and creating a simplified, abstracted version of the video to which the texturing operations are applied. Both of these steps are subject to highly visible temporal artifacts, so the primary technical contributions of the paper are extensions of previous methods for texturing and abstraction to provide temporal coherence when applied to video sequences. To maintain coherence for textures, we employ texture advection along lines of optical flow. We furthermore extend previous approaches by incorporating advection in both forward and reverse directions through the video, which allows for minimal texture distortion, particularly in areas of disocclusion that are otherwise highly problematic. To maintain coherence for abstraction, we employ mathematical morphology extended to the temporal domain, using filters whose temporal extents are locally controlled by the degree of distortions in the optical flow. Together, these techniques provide the first practical and robust approach for producing watercolor animations from video, which we demonstrate with a number of examples. ", 
        "id": 546, 
        "title": "Video watercolorization using bidirectional texture advection."
    }, 
    {
        "abstract": "We describe a new way to render 3D scenes in a variety of nonphotorealistic styles, based on patterns whose structure and motion are defined in 2D. In doing so, we sacrifice the ability of patterns that wrap onto 3D surfaces to convey shape through their structure and motion. In return, we gain several advantages, chiefly that 2D patterns are more visually abstract  a quality often sought by artists, which explains their widespread use in hand-drawn images. Extending such styles to 3D graphics presents a challenge: how should a 2D pattern move? Our solution is to transform it each frame by a 2D similarity transform that closely follows the underlying 3D shape. The resulting motion is often surprisingly effective, and has a striking cartoon quality that matches the visual style. ", 
        "id": 547, 
        "title": "Dynamic 2D patterns for shading 3D scenes."
    }, 
    {
        "abstract": " Procedural methods for animating turbulent fluid are often preferred over simulation, both for speed and for the degree of animator control. We offer an extremely simple approach to efficiently generating turbulent velocity fields based on Perlin noise, with a formula that is exactly incompressible (necessary for the characteristic look of everyday fluids), exactly respects solid boundaries (not allowing fluid to flow through arbitrarily-specified surfaces), and whose amplitude can be modulated in space as desired. In addition, we demonstrate how to combine this with procedural primitives for flow around moving rigid objects, vortices, etc.  ", 
        "id": 548, 
        "title": "Curl-noise for procedural fluid flow."
    }, 
    {
        "abstract": "A key challenge in reconstructing high-quality 3D scans is registering data from different viewpoints. Existing global (multiview) alignment algorithms are restricted to rigid-body transformations, and cannot adequately handle non-rigid warps frequently present in real-world datasets. Moreover, algorithms that can compensate for such warps between pairs of scans do not easily generalize to the multiview case. We present an algorithm for obtaining a globally optimal alignment of multiple overlapping datasets in the presence of low-frequency non-rigid deformations, such as those caused by device nonlinearities or calibration error. The process first obtains sparse correspondences between views using a locally weighted, stability-guaranteeing variant of iterative closest points (ICP). Global positions for feature points are found using a relaxation method, and the scans are warped to their final positions using thin-plate splines. Our framework efficiently handles large datasets -- thousands of scans comprising hundreds of millions of samples -- for both rigid and non-rigid alignment, with the nonrigid case requiring little overhead beyond rigid-body alignment. We demonstrate that, relative to rigid-body registration, it improves the quality of alignment and better preserves detail in 3D datasets from a variety of scanners exhibiting non-rigid distortion. ", 
        "id": 549, 
        "title": "Global non-rigid alignment of 3-D scans."
    }, 
    {
        "abstract": "In this paper, we present a technique for generating animation from a variety of user-defined constraints. We pose constraint-based motion synthesis as a maximum a posterior (MAP) problem and develop an optimization framework that generates natural motion satisfying user constraints. The system automatically learns a statistical dynamic model from motion capture data and then enforces it as a motion prior. This motion prior, together with user-defined constraints, comprises a trajectory optimization problem. Solving this problem in the low-dimensional space yields optimal natural motion that achieves the goals specified by the user. We demonstrate the effectiveness of this approach by generating whole-body and facial motion from a variety of spatial-temporal constraints. ", 
        "id": 550, 
        "title": "Constraint-based motion optimization using a statistical dynamic model."
    }, 
    {
        "abstract": "We present a new data structure--the bilateral grid, that enables fast edge-aware image processing. By working in the bilateral grid, algorithms such as bilateral filtering, edge-aware painting, and local histogram equalization become simple manipulations that are both local and independent. We parallelize our algorithms on modern GPUs to achieve real-time frame rates on high-definition video. We demonstrate our method on a variety of applications such as image editing, transfer of photographic look, and contrast enhancement of medical images. ACM Reference Format Chen, J., Paris, S., Durand, F. 2007. Real-Time Edge-Aware Image Processing with the Bilateral Grid. ACM Trans. Graph. 26, 3, Article 103 (July 2007), 9 pages. DOI = 10.1145/1239451.1239554 http://doi.acm. org/10.1145/1239451.1239554. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org.  2007 ACM 0730-0301/2007/03-ART103 $5.00 DOI 10.1145/1239451.1239554 http://doi.acm.org/10.1145/1239451.1239554  ", 
        "id": 551, 
        "title": "Real-time edge-aware image processing with the bilateral grid."
    }, 
    {
        "abstract": " We present a discrete particle based method capable of creating very realistic animations of bubbles in fluids. It allows for the generation (nucleation) of bubbles from gas dissolved in the fluid, the motion of the discrete bubbles including bubble collisions and drag interactions with the liquid which could be undergoing complex free surface motion, the formation and motion of coupled foams and the final dissipation of bubbles. This allows comprehensive simulations of dynamic bubble behavior. The underlying fluid simulation is based on the mesh-free Smoothed Particle Hydrodynamics method. Each particle representing the liquid contains an amount of dissolved gas. Gas is transferred from the continuum fluid model to the discrete bubble model at nucleation sites on the surface of solid bodies. The rate of gas transport to the nucleation sites controls the rate of bubble generation, producing very natural time variations in bubble numbers. Rising bubbles also grow by gathering more gas from the surrounding liquid as they move. This model contains significant bubble scale physics and allows, in principle, the capturing of many important processes that cannot be directly modeled by traditional methods. The method is used here to realistically animate the pouring of a glass of beer, starting with a stream of fresh beer entering the glass, the formation of a dense cloud of bubbles, which rise to create a good head as the beer reaches the top of the glass. ", 
        "id": 552, 
        "title": "Bubbling and frothing liquids."
    }, 
    {
        "abstract": "Many renderers perform poorly on scenes that contain a lot of detailed geometry. The load on the renderer can be alleviated by simplification techniques, which create less expensive representations of geometry that is small on the screen. Current simplification techniques for high-quality surface-based rendering tend to work best with element detail (i.e., detail due to the complexity of individual elements) but not as well with aggregate detail (i.e., detail due to the large number of elements). To address this latter type of detail, we introduce a stochastic technique related to some approaches used for point-based renderers. Scenes are rendered by randomly selecting a subset of the geometric elements and altering those elements statistically to preserve the overall appearance of the scene. The amount of simplification can depend on a number of factors, including screen size, motion blur, and depth of field. I.3.7 [Three-Dimensional Graphics and Realism]: Animation-- Simplification  Figure 1: A plant with 320,000 leaves.  ", 
        "id": 553, 
        "title": "Stochastic simplification of aggregate detail."
    }, 
    {
        "abstract": "This paper describes an approach to building real-time highlycontrollable characters. A kinematic character controller is built on-the-fly during a capture session, and updated after each new motion clip is acquired. Active learning is used to identify which motion sequence the user should perform next, in order to improve the quality and responsiveness of the controller. Because motion clips are selected adaptively, we avoid the difficulty of manually determining which ones to capture, and can build complex controllers from scratch while significantly reducing the number of necessary motion samples. ", 
        "id": 554, 
        "title": "Active learning for real-time motion controllers."
    }, 
    {
        "abstract": "We reformulate the rendering equation to alleviate the need for explicit visibility computation, thus enabling interactive global illumination on graphics hardware. This is achieved by treating visibility implicitly and propagating an additional quantity, called antiradiance, to compensate for light transmitted extraneously. Our new algorithm shifts visibility computation to simple local iterations by maintaining additional directional antiradiance information with samples in the scene. It is easy to parallelize on a GPU. By correctly treating discretization and filtering, we can compute indirect illumination in scenes with dynamic objects much faster than traditional methods. Our results show interactive update of indirect illumination with moving characters and lights. ", 
        "id": 555, 
        "title": "Implicit visibility and antiradiance for interactive global illumination."
    }, 
    {
        "abstract": "", 
        "id": 556, 
        "title": "Stable, circulation-preserving, simplicial fluids."
    }, 
    {
        "abstract": "", 
        "id": 557, 
        "title": "Velocity-based shock propagation for multibody dynamics animation."
    }, 
    {
        "abstract": "Shape deformation is a common practice in digital image editing, but can unrealistically stretch or compress texture detail. We propose an image editing system that decouples feature position from pixel color generation, by resynthesizing texture from the source image to preserve its detail and orientation around a new feature curve location. We introduce a new distortion to patch-based texture synthesis that aligns texture features with image features. A dense correspondence field between source and target images generated by the control curves then guides texture synthesis. ", 
        "id": 558, 
        "title": "Detail preserving shape deformation in image editing."
    }, 
    {
        "abstract": " In this paper we propose a new method for upsampling images which is capable of generating sharp edges with reduced inputresolution grid-related artifacts. The method is based on a statistical edge dependency relating certain edge features of two different resolutions, which is generically exhibited by real-world images. While other solutions assume some form of smoothness, we rely on this distinctive edge dependency as our prior knowledge in order to increase image resolution. In addition to this relation we require that intensities are conserved; the output image must be identical to the input image when downsampled to the original resolution. Altogether the method consists of solving a constrained optimization problem, attempting to impose the correct edge relation and conserve local intensities with respect to the low-resolution input image. Results demonstrate the visual importance of having such edge features properly matched, and the method's capability to produce images in which sharp edges are successfully reconstructed. ", 
        "id": 559, 
        "title": "Image upsampling via imposed edge statistics."
    }, 
    {
        "abstract": "We present a new image-based technique for enhancing the shape and surface details of an object. The input to our system is a small set of photographs taken from a fixed viewpoint, but under varying lighting conditions. For each image we compute a multiscale decomposition based on the bilateral filter and then reconstruct an enhanced image that combines detail information at each scale across all the input images. Our approach does not require any information about light source positions, or camera calibration, and can produce good results with 3 to 5 input images. In addition our system provides a few high-level parameters for controlling the amount of enhancement and does not require pixel-level user input. We show that the bilateral filter is a good choice for our multiscale algorithm because it avoids the halo artifacts commonly associated with the traditional Laplacian image pyramid. We also develop a new scheme for computing our multiscale bilateral decomposition that is simple to implement, fast O(N2 log N) and accurate. ", 
        "id": 560, 
        "title": "Multiscale shape and detail enhancement from multi-light image collections."
    }, 
    {
        "abstract": "Tangent vector fields are an essential ingredient in controlling surface appearance for applications ranging from anisotropic shading to texture synthesis and non-photorealistic rendering. To achieve a desired effect one is typically interested in smoothly varying fields that satisfy a sparse set of user-provided constraints. Using tools from Discrete Exterior Calculus, we present a simple and efficient algorithm for designing such fields over arbitrary triangle meshes. By representing the field as scalars over mesh edges (i.e., discrete 1-forms), we obtain an intrinsic, coordinatefree formulation in which field smoothness is enforced through discrete Laplace operators. Unlike previous methods, such a formulation leads to a linear system whose sparsity permits efficient pre-factorization. Constraints are incorporated through weighted least squares and can be updated rapidly enough to enable interactive design, as we demonstrate in the context of anisotropic texture synthesis.  ", 
        "id": 561, 
        "title": "Design of tangent vector fields."
    }, 
    {
        "abstract": "This paper introduces a theoretical model for computing the scattering properties of participating media and translucent materials. The model takes as input a description of the components of a medium and computes all the parameters necessary to render it. These parameters are the extinction and scattering coefficients, the phase function, and the index of refraction. Our theory is based on a robust generalization of the Lorenz-Mie theory. Previous models using Lorenz-Mie theory have been limited to non-absorbing media with spherical particles such as paints and clouds. Our generalized theory is capable of handling both absorbing host media and non-spherical particles, which significantly extends the classes of media and materials that can be modeled. We use the theory to compute optical properties for different types of ice and ocean water, and we derive a novel appearance model for milk parameterized by the fat and protein contents. Our results show that we are able to match measured scattering properties in cases where the classical Lorenz-Mie theory breaks down, and we can compute properties for media that cannot be measured using existing techniques in computer graphics.", 
        "id": 562, 
        "title": "Computing the scattering properties of participating media using Lorenz-Mie theory."
    }, 
    {
        "abstract": "", 
        "id": 563, 
        "title": "Adaptive sampling of reflectance fields."
    }, 
    {
        "abstract": " Many textiles do not noticeably stretch under their own weight. Unfortunately, for better performance many cloth solvers disregard this fact. We propose a method to obtain very low strain along the warp and weft direction using Constrained Lagrangian Mechanics and a novel fast projection method. The resulting algorithm acts as a velocity filter that easily integrates into existing simulation code. ", 
        "id": 564, 
        "title": "Efficient simulation of inextensible cloth."
    }, 
    {
        "abstract": " The emergent field of computational photography is proving that, by coupling generalized imaging optics with software processing, the quality and flexibility of imaging systems can be increased. In this paper, we capture and manipulate multiple images of a scene taken with different aperture settings (f -numbers). We design and implement a prototype optical system and associated algorithms to capture four images of the scene in a single exposure, each taken with a different aperture setting. Our system can be used with commercially available DSLR cameras and photographic lenses without modification to either. We leverage the fact that defocus blur is a function of scene depth and f /# to estimate a depth map. We demonstrate several applications of our multi-aperture camera, such as post-exposure editing of the depth of field, including extrapolation beyond the physical limits of the lens, synthetic refocusing, and depth-guided deconvolution. ", 
        "id": 565, 
        "title": "Multi-aperture photography."
    }, 
    {
        "abstract": "In this paper we present a new Point Set Surface (PSS) definition based on moving least squares (MLS) fitting of algebraic spheres. Our surface representation can be expressed by either a projection procedure or in implicit form. The central advantages of our approach compared to existing planar MLS include significantly improved stability of the projection under low sampling rates and in the presence of high curvature. The method can approximate or interpolate the input point set and naturally handles planar point clouds. In addition, our approach provides a reliable estimate of the mean curvature of the surface at no additional cost and allows for the robust handling of sharp features and boundaries. It processes a simple point set as input, but can also take significant advantage of surface normals to improve robustness, quality and performance. We also present an novel normal estimation procedure which exploits the properties of the spherical fit for both direction estimation and orientation propagation. Very efficient computational procedures enable us to compute the algebraic sphere fitting with up to 40 million points per second on latest generation GPUs. ", 
        "id": 566, 
        "title": "Algebraic point set surfaces."
    }, 
    {
        "abstract": " Lee et al. 2005].  Functions with densely interconnected expression graphs, which arise in computer graphics applications such as dynamics, spacetime optimization, and PRT, can be difficult to efficiently differentiate using existing symbolic or automatic differentiation techniques. Our new algorithm, D*, computes efficient symbolic derivatives for these functions by symbolically executing the expression graph at compile time to eliminate common subexpressions and by exploiting the special nature of the graph that represents the derivative of a function. This graph has a sum of products form; the new algorithm computes a factorization of this derivative graph along with an efficient grouping of product terms into subexpressions. For the problems in our test suite D* generates symbolic derivatives which are up to 4.6103 times faster than those computed by the symbolic math program Mathematica and up to 2.2105 times faster than the non-symbolic automatic differentiation program CppAD. In some cases the D* derivatives rival the best manually derived solutions. ", 
        "id": 567, 
        "title": "Efficient symbolic differentiation for graphics applications."
    }, 
    {
        "abstract": "Filtering is critical for representing detail, such as color textures or normal maps, across a variety of scales. While MIP-mapping texture maps is commonplace, accurate normal map filtering remains a challenging problem because of nonlinearities in shading--we cannot simply average nearby surface normals. In this paper, we show analytically that normal map filtering can be formalized as a spherical convolution of the normal distribution function (NDF) and the BRDF, for a large class of common BRDFs such as Lambertian, microfacet and factored measurements. This theoretical result explains many previous filtering techniques as special cases, and leads to a generalization to a broader class of measured and analytic BRDFs. Our practical algorithms leverage a significant body of work that has studied lighting-BRDF convolution. We show how spherical harmonics can be used to filter the NDF for Lambertian and low-frequency specular BRDFs, while spherical von MisesFisher distributions can be used for high-frequency materials.  (a) V-groove  zoomed in (b)  (c) V-groove  (d) NDF (e) standard  NDF  BRDF effective  BRDF  (f) convolution  zoomed out  Figure 1: Consider a simple V-groove. Initially in closeup (a), each face is a single pixel. As we zoom out, and average into a single pixel (c), standard MIP-mapping averages the normal to an effectively flat surface (e). However, our method uses the full normal distribution function or NDF (d), that preserves the original normals. This NDF can be linearly convolved with the BRDF (f) to obtain an effective BRDF, accurate for shading.  ", 
        "id": 568, 
        "title": "Frequency domain normal map filtering."
    }, 
    {
        "abstract": "2.2m triangles: 300 rows, 900 columns, 16.9 s 388k triangles: 432 rows, 864 columns, 13.5 s 869k triangles: 100 rows, 200 columns, 3.8 s Figure 1: In the above images, over 1.9 million surface samples are shaded from over 100 thousand point lights in a few seconds. This is achieved by sampling a few hundred rows and columns from the large unknown matrix of surface-light interactions. Abstract Rendering complex scenes with indirect illumination, high dynamic range environment lighting, and many direct light sources remains a challenging problem. Prior work has shown that all these effects can be approximated by many point lights. This paper presents a scalable solution to the many-light problem suitable for a GPU implementation. We view the problem as a large matrix of sample-light interactions; the ideal final image is the sum of the matrix columns. We propose an algorithm for approximating this sum by sampling entire rows and columns of the matrix on the GPU using shadow mapping. The key observation is that the inherent structure of the transfer matrix can be revealed by sampling just a small number of rows and columns. Our prototype implementation can compute the light transfer within a few seconds for scenes with indirect and environment illumination, area lights, complex geometry and arbitrary shaders. We believe this approach can be very useful for rapid previewing in applications like cinematic and architectural lighting design.", 
        "id": 569, 
        "title": "Matrix row-column sampling for the many-light problem."
    }, 
    {
        "abstract": "Culling techniques have always been a central part of computer graphics, but graphics hardware still lack efficient and flexible support for culling. To improve the situation, we introduce the programmable culling unit, which is as flexible as the fragment program unit and capable of quickly culling entire blocks of fragments. Furthermore, it is very easy for the developer to use the PCU as culling programs can be automatically derived from fragment programs containing a discard instruction. Our PCU can be integrated into an existing fragment program unit with a modest hardware overhead of only about 10%. Using the PCU, we have observed shader speedups between 1.4 and 2.1 for relevant scenes.  to produce the output (e.g., color, depth, stencil) of a fragment. The focus of our research is on the latter. To make shader programs run faster, one can insert KIL (fragment discard) instructions at appropriate places, in order to provide an early-out. In practice, these instructions seldom make the execution faster on contemporary GPUs, due to the underlying hardware design. In addition, a GPU designer can employ pipelining and parallelization techniques for faster shader instruction execution. Note, however, that the fastest instruction is the one that never is executed to begin with. Hence, the target of our paper is to avoid executing, i.e., cull, a substantial amount of instructions which do not contribute to the final image.  ", 
        "id": 570, 
        "title": "PCU: the programmable culling unit."
    }, 
    {
        "abstract": "What can you do with a million images? In this paper we present a new image completion algorithm powered by a huge database of photographs gathered from the Web. The algorithm patches up holes in images by finding similar image regions in the database that are not only seamless but also semantically valid. Our chief insight is that while the space of images is effectively infinite, the space of semantically differentiable scenes is actually not that large. For many image completion tasks we are able to find similar scenes which contain image fragments that will convincingly complete the image. Our algorithm is entirely data-driven, requiring no annotations or labelling by the user. Unlike existing image completion methods, our algorithm can generate a diverse set of results for each input image and we allow users to select among them. We demonstrate the superiority of our algorithm over existing image completion approaches. ", 
        "id": 571, 
        "title": "Scene completion using millions of photographs."
    }, 
    {
        "abstract": "VideoTrace is a system for interactively generating realistic 3D models of objects from video--models that might be inserted into a video game, a simulation environment, or another video sequence. The user interacts with VideoTrace by tracing the shape of the object to be modelled over one or more frames of the video. By interpreting the sketch drawn by the user in light of 3D information obtained from computer vision techniques, a small number of simple 2D interactions can be used to generate a realistic 3D model. Each of the sketching operations in VideoTrace provides an intuitive and powerful means of modelling shape from video, and executes quickly enough to be used interactively. Immediate feedback allows the user to model rapidly those parts of the scene which are of interest and to the level of detail required. The combination of automated and manual reconstruction allows VideoTrace to model parts of the scene not visible, and to succeed in cases where purely automated approaches would fail. ", 
        "id": 572, 
        "title": "VideoTrace: rapid interactive scene modelling from video."
    }, 
    {
        "abstract": "The present contribution aims at creating color images printed with fluorescent inks that are only visible under UV light. The considered fluorescent inks absorb light in the UV wavelength range and reemit part of it in the visible wavelength range. In contrast to normal color printing which relies on the spectral absorption of light by the inks, at low concentration fluorescent inks behave additively, i.e. their light emission spectra sum up. We first analyze to which extent different fluorescent inks can be superposed. Due to the quenching effect, at high concentrations of the fluorescent molecules, the fluorescent effect diminishes. With an ink-jet printer capable of printing pixels at reduced dot sizes, we reduce the concentration of the individual fluorescent inks and are able to create from the blue, red and greenish-yellow inks the new colorants white and magenta. In order to avoid quenching effects, we propose a color halftoning method relying on diagonally oriented pre-computed screen dots, which are printed side by side. For gamut mapping and color separation, we create a 3D representation of the fluorescent ink gamut in CIELAB space by predicting halftone fluorescent emission spectra according to the spectral Neugebauer model. Thanks to gamut mapping and juxtaposed halftoning, we create color images, which are invisible under daylight and have, under UV light, a high resemblance with the original images. ", 
        "id": 573, 
        "title": "Color images visible under UV light."
    }, 
    {
        "abstract": " ", 
        "id": 574, 
        "title": "Wrinkled flames and cellular patterns."
    }, 
    {
        "abstract": "", 
        "id": 575, 
        "title": "Character animation from 2D pictures and 3D motion data."
    }, 
    {
        "abstract": "We present a new method for real-time rendering of sophisticated lighting effects in and around refractive objects. It enables us to realistically display refractive objects with complex material properties, such as arbitrarily varying refractive index, inhomogeneous attenuation, as well as spatially-varying anisotropic scattering and reflectance properties. User-controlled changes of lighting positions only require a few seconds of update time. Our method is based on a set of ordinary differential equations derived from the eikonal equation, the main postulate of geometric optics. This set of equations allows for fast casting of bent light rays with the complexity of a particle tracer. Based on this concept, we also propose an efficient light propagation technique using adaptive wavefront tracing. Efficient GPU implementations for our algorithmic concepts enable us to render a combination of visual effects that were previously not reproducible in real-time. ", 
        "id": 576, 
        "title": "Eikonal rendering: efficient light transport in refractive objects."
    }, 
    {
        "abstract": " We propose a numerical method for modeling highly deformable nonlinear incompressible solids that conserves the volume locally near each node in a finite element mesh. Our method works with arbitrary constitutive models, is applicable to both passive and active materials (e.g. muscles), and works with simple tetrahedra without the need for multiple quadrature points or stabilization techniques. Although simple linear tetrahedra typically suffer from locking when modeling incompressible materials, our method enforces incompressibility per node (in a one-ring), and we demonstrate that it is free from locking. We correct errors in volume without introducing oscillations by treating position and velocity in separate implicit solves. Finally, we propose a novel method for treating both object contact and self-contact as linear constraints during the incompressible solve, alleviating issues in enforcing multiple possibly conflicting constraints.  ", 
        "id": 577, 
        "title": "Volume conserving finite element simulations of deformable models."
    }, 
    {
        "abstract": "", 
        "id": 578, 
        "title": "Mesh Ensemble Motion Graphs: Data-driven mesh animation with constraints."
    }, 
    {
        "abstract": "We describe a set of rendering techniques for an autostereoscopic light field display able to present interactive 3D graphics to multiple simultaneous viewers 360 degrees around the display. The display consists of a high-speed video projector, a spinning mirror covered by a holographic diffuser, and FPGA circuitry to decode specially rendered DVI video signals. The display uses a standard programmable graphics card to render over 5,000 images per second of interactive 3D graphics, projecting 360-degree views with 1.25 degree separation up to 20 updates per second. We describe the system's projection geometry and its calibration process, and we present a multiple-center-of-projection rendering technique for creating perspective-correct images from arbitrary viewpoints around the display. Our projection technique allows correct vertical perspective and parallax to be rendered for any height and distance when these parameters are known, and we demonstrate this effect with interactive raster graphics using a tracking system to measure the viewer's height and distance. We further apply our projection technique to the display of photographed light fields with accurate horizontal and vertical parallax. We conclude with a discussion of the display's visual accommodation performance and discuss techniques for displaying color imagery. ", 
        "id": 579, 
        "title": "Rendering for an interactive 360degree light field display."
    }, 
    {
        "abstract": "In this paper we consider the problem of creating and controlling volume deformations used to articulate characters for use in highend applications such as computer generated feature films. We introduce a method we call harmonic coordinates that significantly improves upon existing volume deformation techniques. Our deformations are controlled using a topologically flexible structure, called a cage, that consists of a closed three dimensional mesh. The cage can optionally be augmented with additional interior vertices, edges, and faces to more precisely control the interior behavior of the deformation. We show that harmonic coordinates are generalized barycentric coordinates that can be extended to any dimension. Moreover, they are the first system of generalized barycentric coordinates that are non-negative even in strongly concave situations, and their magnitude falls off with distance as measured within the cage. ", 
        "id": 580, 
        "title": "Harmonic coordinates for character articulation."
    }, 
    {
        "abstract": "Three-dimensional shape can be drawn using a variety of feature lines, but none of the current definitions alone seem to capture all visually-relevant lines. We introduce a new definition of feature lines based on two perceptual observations. First, human perception is sensitive to the variation of shading, and since shape perception is little affected by lighting and reflectance modification, we should focus on normal variation. Second, view-dependent lines better convey smooth surfaces. From this we define view-dependent curvature as the variation of the surface normal with respect to a viewing screen plane, and apparent ridges as the loci of points that maximize a view-dependent curvature. We present a formal definition of apparent ridges and an algorithm to render line drawings of 3D meshes. We show that our apparent ridges encompass or enhance aspects of several other feature lines. ", 
        "id": 581, 
        "title": "Apparent ridges for line drawing."
    }, 
    {
        "abstract": " We present a method for modifying the topology of a 3D model with user control. The heart of our method is a guided topology editing algorithm. Given a source model and a user-provided target shape, the algorithm modifies the source so that the resulting model is topologically consistent with the target. Our algorithm permits removing or adding various topological features (e.g., handles, cavities and islands) in a common framework and ensures that each topological change is made by minimal modification to the source model. To create the target shape, we have also designed a convenient 2D sketching interface for drawing 3D line skeletons. As demonstrated in a suite of examples, the use of sketching allows more accurate removal of topological artifacts than previous methods, and enables creative designs with specific topological goals. ", 
        "id": 582, 
        "title": "Editing the topology of 3D models by sketching."
    }, 
    {
        "abstract": "", 
        "id": 583, 
        "title": "Bicubic polar subdivision."
    }, 
    {
        "abstract": "This paper proposes a simple and fast operator, the \"Hidden\" Point Removal operator, which determines the visible points in a point cloud, as viewed from a given viewpoint. Visibility is determined without reconstructing a surface or estimating normals. It is shown that extracting the points that reside on the convex hull of a transformed point cloud, amounts to determining the visible points. This operator is general  it can be applied to point clouds at various dimensions, on both sparse and dense point clouds, and on viewpoints internal as well as external to the cloud. It is demonstrated that the operator is useful in visualizing point clouds, in view-dependent reconstruction and in shadow casting.  ", 
        "id": 584, 
        "title": "Direct visibility of point sets."
    }, 
    {
        "abstract": " While measured Bidirectional Texture Functions (BTF) enable impressive realism in material appearance, they offer little control, which limits their use for content creation. In this work, we interactively manipulate BTFs and create new BTFs from flat textures. We present an out-of-core approach to manage the size of BTFs and introduce new editing operations that modify the appearance of a material. These tools achieve their full potential when selectively applied to subsets of the BTF through the use of new selection operators. We further analyze the use of our editing operators for the modification of important visual characteristics such as highlights, roughness, and fuzziness. Results compare favorably to the direct alteration of micro-geometry and reflectances of synthetic reference data.  Original  Wool Stripe  Golden Wool  ", 
        "id": 585, 
        "title": "Interactive editing and modeling of bidirectional texture functions."
    }, 
    {
        "abstract": "We present a novel framework to treat shapes in the setting of Riemannian geometry. Shapes  triangular meshes or more generally straight line graphs in Euclidean space  are treated as points in a shape space. We introduce useful Riemannian metrics in this space to aid the user in design and modeling tasks, especially to explore the space of (approximately) isometric deformations of a given shape. Much of the work relies on an efficient algorithm to compute geodesics in shape spaces; to this end, we present a multiresolution framework to solve the interpolation problem  which amounts to solving a boundary value problem  as well as the extrapolation problem  an initial value problem  in shape space. Based on these two operations, several classical concepts like parallel transport and the exponential map can be used in shape space to solve various geometric modeling and geometry processing tasks. Applications include shape morphing, shape deformation, deformation transfer, and intuitive shape exploration. ", 
        "id": 586, 
        "title": "Geometric modeling in shape space."
    }, 
    {
        "abstract": "Liquid and gas interactions often produce bubbles that stay for a long time without bursting on the surface, making a dry foam structure. Such long lasting bubbles simulated by the level set method can suffer from a small but steady volume error that accumulates to a visible amount of volume change. We propose to address this problem by using the volume control method. We track the volume change of each connected region, and apply a carefully computed divergence that compensates undesired volume changes. To compute the divergence, we construct a mathematical model of the volume change, choose control strategies that regulate the modeled volume error, and establish methods to compute the control gains that provide robust and fast reduction of the volume error, and (if desired) the control of how the volume changes over time. ", 
        "id": 587, 
        "title": "Simulation of bubbles in foam with the volume control method."
    }, 
    {
        "abstract": "Image analysis and enhancement tasks such as tone mapping, colorization, stereo depth, and photomontage, often require computing a solution (e.g., for exposure, chromaticity, disparity, labels) over the pixel grid. Computational and memory costs often require that a smaller solution be run over a downsampled image. Although general purpose upsampling methods can be used to interpolate the low resolution solution to the full resolution, these methods generally assume a smoothness prior for the interpolation. We demonstrate that in cases, such as those above, the available high resolution input image may be leveraged as a prior in the context of a joint bilateral upsampling procedure to produce a better high resolution solution. We show results for each of the applications above and compare them to traditional upsampling methods. ", 
        "id": 588, 
        "title": "Joint bilateral upsampling."
    }, 
    {
        "abstract": "We present a novel method for synthesizing solid textures from 2D texture exemplars. First, we extend 2D texture optimization techniques to synthesize 3D texture solids. Next, the non-parametric texture optimization approach is integrated with histogram matching, which forces the global statistics of the synthesized solid to match those of the exemplar. This improves the convergence of the synthesis process and enables using smaller neighborhoods. In addition to producing compelling texture mapped surfaces, our method also effectively models the material in the interior of solid objects. We also demonstrate that our method is well-suited for synthesizing textures with a large number of channels per texel. ", 
        "id": 589, 
        "title": "Solid texture synthesis from 2D exemplars."
    }, 
    {
        "abstract": " range. We present a novel viewing paradigm for high resolution, wide angle, and/or high dynamic range (HDR) imagery.  We present a system to capture and view \"Gigapixel images\": very high resolution, high dynamic range, and wide angle imagery consisting of several billion pixels each. A specialized camera mount, in combination with an automated pipeline for alignment, exposure compensation, and stitching, provide the means to acquire Gigapixel images with a standard camera and lens. More importantly, our novel viewer enables exploration of such images at interactive rates over a network, while dynamically and smoothly interpolating the projection between perspective and curved projections, and simultaneously modifying the tone-mapping to ensure an optimal view of the portion of the scene being viewed. ", 
        "id": 590, 
        "title": "Capturing and viewing gigapixel images."
    }, 
    {
        "abstract": "The isosurface stuffing algorithm fills an isosurface with a uniformly sized tetrahedral mesh whose dihedral angles are bounded between 10.7 and 164.8, or (with a change in parameters) between 8.9 and 158.8. The algorithm is whip fast, numerically robust, and easy to implement because, like Marching Cubes, it generates tetrahedra from a small set of precomputed stencils. A variant of the algorithm creates a mesh with internal grading: on the boundary, where high resolution is generally desired, the elements are fine and uniformly sized, and in the interior they may be coarser and vary in size. This combination of features makes isosurface stuffing a powerful tool for dynamic fluid simulation, large-deformation mechanics, and applications that require interactive remeshing or use objects defined by smooth implicit surfaces. It is the first algorithm that rigorously guarantees the suitability of tetrahedra for finite element methods in domains whose shapes are substantially more challenging than boxes. Our angle bounds are guaranteed by a computer-assisted proof. If the isosurface is a smooth 2-manifold with bounded curvature, and the tetrahedra are sufficiently small, then the boundary of the mesh is guaranteed to be a geometrically and topologically accurate approximation of the isosurface. ", 
        "id": 591, 
        "title": "Isosurface stuffing: fast tetrahedral meshes with good dihedral angles."
    }, 
    {
        "abstract": "We present a system for inserting new objects into existing photographs by querying a vast image-based object library, precomputed using a publicly available Internet object database. The central goal is to shield the user from all of the arduous tasks typically involved in image compositing. The user is only asked to do two simple things: 1) pick a 3D location in the scene to place a new object; 2) select an object to insert using a hierarchical menu. We pose the problem of object insertion as a data-driven, 3D-based, context-sensitive object retrieval task. Instead of trying to manipulate the object to change its orientation, color distribution, etc. to fit the new image, we simply retrieve an object of a specified class that has all the required properties (camera pose, lighting, resolution, etc) from our large object library. We present new automatic algorithms for improving object segmentation and blending, estimating true 3D object size and orientation, and estimating scene lighting conditions. We also present an intuitive user interface that makes object insertion fast and simple even for the artistically challenged. ", 
        "id": 592, 
        "title": "Photo clip art."
    }, 
    {
        "abstract": "We describe a GPU-based algorithm for rendering a 3D model as a line drawing, based on the insight that a line drawing can be understood as an abstraction of a shaded image. We thus render lines along tone boundaries or thin dark areas in the shaded image. We extend this notion to the dual: we render highlight lines along thin bright areas and tone boundaries. We combine the lines with toon shading to capture broad regions of tone. The resulting line drawings effectively convey both shape and material cues. The lines produced by the method can include silhouettes, creases, and ridges, along with a generalization of suggestive contours that responds to lighting as well as viewing changes. The method supports automatic level of abstraction, where the size of depicted shape features adjusts appropriately as the camera zooms in or out. Animated models can be rendered in real time because costly mesh curvature calculations are not needed.  Recently, DeCarlo et al. [2003; 2004] described \"suggestive contours,\" a new type of line that can be combined with silhouettes to produce effective line drawings of smooth shapes. They described two algorithms for rendering these. The first is an object-space algorithm that computes a subset of points on the surface where radial curvature is zero. The second is an image-space algorithm that operates on a diffuse-shaded rendering of the scene using a single point light at the camera. It outputs lines where the tone has a sufficiently sharp local minimum in one direction. While suggestive contours convey shape well, they have some limitations. The object space algorithm does not account for how large the object appears in the image, and so may depict features that are too large or small for the current view. Suggestive contours do not depend on lighting or material properties, which is undesirable when we want the lines to reinforce existing lighting and material cues, as when some form of shading is used in combination with the lines. (See Figure 1.)  ", 
        "id": 593, 
        "title": "Line drawings via abstracted shading."
    }, 
    {
        "abstract": "", 
        "id": 594, 
        "title": "Resolution-matched shadow maps."
    }, 
    {
        "abstract": "", 
        "id": 595, 
        "title": "A framework for precomputed and captured light transport."
    }, 
    {
        "abstract": "A conventional camera captures blurred versions of scene information away from the plane of focus. Camera systems have been proposed that allow for recording all-focus images, or for extracting depth, but to record both simultaneously has required more extensive hardware and reduced spatial resolution. We propose a simple modification to a conventional camera that allows for the simultaneous recovery of both (a) high resolution image information and (b) depth information adequate for semi-automatic extraction of a layered depth representation of the image. Our modification is to insert a patterned occluder within the aperture of the camera lens, creating a coded aperture. We introduce a criterion for depth discriminability which we use to design the preferred aperture pattern. Using a statistical model of images, we can recover both depth information and an all-focus image from single photographs taken with the modified camera. A layered depth map is then extracted, requiring user-drawn strokes to clarify layer assignments in some cases. The resulting sharp image and layered depth map can be combined for various photographic applications, including automatic scene segmentation, post-exposure refocusing, or re-rendering of the scene from an alternate viewpoint. ", 
        "id": 596, 
        "title": "Image and depth from a conventional camera with a coded aperture."
    }, 
    {
        "abstract": " We introduce a Locally Optimal Projection operator (LOP) for surface approximation from point-set data. The operator is parameterization free, in the sense that it does not rely on estimating a local normal, fitting a local plane, or using any other local parametric representation. Therefore, it can deal with noisy data which clutters the orientation of the points. The method performs well in cases of ambiguous orientation, e.g., if two folds of a surface lie near each other, and other cases of complex geometry in which methods based upon local plane fitting may fail. Although defined by a global minimization problem, the method is effectively local, and it provides a second order approximation to smooth surfaces. Hence allowing good surface approximation without using any explicit or implicit approximation space. Furthermore, we show that LOP is highly robust to noise and outliers and demonstrate its effectiveness by applying it to raw scanned data of complex shapes.  (a) (b)  ", 
        "id": 597, 
        "title": "Parameterization-free projection for geometry reconstruction."
    }, 
    {
        "abstract": "", 
        "id": 598, 
        "title": "Volume and shape preservation via moving frame manipulation."
    }, 
    {
        "abstract": "We present a system for authoring and viewing interactive cutaway illustrations of complex 3D models using conventions of traditional scientific and technical illustration. Our approach is based on the two key ideas that 1) cuts should respect the geometry of the parts being cut, and 2) cutaway illustrations should support interactive exploration. In our approach, an author instruments a 3D model with auxiliary parameters, which we call rigging, that define how cutaways of that structure are formed. We provide an authoring interface that automates most of the rigging process. We also provide a viewing interface that allows viewers to explore rigged models using high-level interactions. In particular, the viewer can just select a set of target structures, and the system will automatically generate a cutaway illustration that exposes those parts. We have tested our system on a variety of CAD and anatomical models, and our results demonstrate that our approach can be used to create and view effective interactive cutaway illustrations for a variety of complex objects with little user effort.", 
        "id": 599, 
        "title": "Interactive cutaway illustrations of complex 3D models."
    }, 
    {
        "abstract": "", 
        "id": 600, 
        "title": "Volume illustration using wang cubes."
    }, 
    {
        "abstract": "", 
        "id": 601, 
        "title": "Context-aware textures."
    }, 
    {
        "abstract": "Blockwise or Clustered Principal Component Analysis (CPCA) is commonly used to achieve real-time rendering of shadows and glossy reflections with precomputed radiance transfer (PRT). The vertices or pixels are partitioned into smaller coherent regions, and light transport in each region is approximated by a locally lowdimensional subspace using PCA. Many earlier techniques such as surface light field and reflectance field compression use a similar paradigm. However, there has been no clear theoretical understanding of how light transport dimensionality increases with local patch size, nor of the optimal block size or number of clusters. In this paper, we develop a theory of locally low dimensional light transport, by using Szego's eigenvalue theorem to analytically derive the eigenvalues of the covariance matrix for canonical cases. We show mathematically that for symmetric patches of area A, the number of basis functions for glossy reflections increases linearly with A, while for simple cast shadows, it often increases as A. These results are confirmed numerically on a number of test scenes. Next, we carry out an analysis of the cost of rendering, trading off local dimensionality and the number of patches, deriving an optimal block size. Based on this analysis, we provide useful practical insights for setting parameters in CPCA and also derive a new adaptive subdivision algorithm. Moreover, we show that rendering time e-mail: {dhruv,ravir,belhumeur}@cs.columbia.edu e-mail: ira.kemelmacher@weizmann.ac.il ACM Reference Format Mahajan, D., Shlizerman, I., Ramamoorthi, R., Belhumeur, P. 2007. A Theory of Locally Low Dimensional Light Transport. ACM Trans. Graph. 26, 3, Article 62 (July 2007), 10 pages. DOI = 10.1145/1239451.1239513 http://doi.acm.org/10.1145/1239451.1239513. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org.  2007 ACM 0730-0301/2007/03-ART62 $5.00 DOI 10.1145/1239451.1239513 http://doi.acm.org/10.1145/1239451.1239513  scales sub-linearly with the resolution of the image, allowing for interactive all-frequency relighting of 1024  1024 images. ", 
        "id": 602, 
        "title": "A theory of locally low dimensional light transport."
    }, 
    {
        "abstract": "In game environments, animated character motion must rapidly adapt to changes in player input  for example, if a directional signal from the player's gamepad is not incorporated into the character's trajectory immediately, the character may blithely run off a ledge. Traditional schemes for data-driven character animation lack the split-second reactivity required for this direct control; while they can be made to work, motion artifacts will result. We describe an on-line character animation controller that assembles a motion stream from short motion fragments, choosing each fragment based on current player input and the previous fragment. By adding a simple model of player behavior we are able to improve an existing reinforcement learning method for precalculating good fragment choices. We demonstrate the efficacy of our model by comparing the animation selected by our new controller to that selected by existing methods and to the optimal selection, given knowledge of the entire path. This comparison is performed over real-world data collected from a game prototype. Finally, we provide results indicating that occasional low-quality transitions between motion segments are crucial to high-quality on-line motion generation; this is an important result for others crafting animation systems for directly-controlled characters, as it argues against the common practice of transition thresholding. ", 
        "id": 603, 
        "title": "Responsive characters from motion fragments."
    }, 
    {
        "abstract": "Many applications in Computer Graphics contain computationally expensive calculations. These calculations are often performed at many points to produce a full solution, even though the subspace of reasonable solutions may be of a relatively low dimension. The calculation of facial articulation and rendering of scenes with global illumination are two example applications that require these sort of computations. In this paper, we present Key Point Subspace Acceleration and Soft Caching, a technique for accelerating these types of computations. Key Point Subspace Acceleration (KPSA) is a statistical acceleration scheme that uses examples to compute a statistical subspace and a set of characteristic key points. The full calculation is then computed only at these key points and these points are used to provide a subspace based estimate of the entire calculation. The soft caching process is an extension to the KPSA technique where the key points are also used to provide a confidence estimate for the ACM Reference Format Meyer, M., Anderson, J. 2007. Key Point Subspace Acceleration and Soft Caching. ACM Trans. Graph. 26, 3, Article 74 (July 2007), 8 pages. DOI = 10.1145/1239451.1239525 http://doi.acm.org/10.1145/1239451.1 239525. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org.  2007 ACM 0730-0301/2007/03-ART74 $5.00 DOI 10.1145/1239451.1239525 http://doi.acm.org/10.1145/1239451.1239525  KPSA result. In cases with high anticipated error the calculation will then \"fail through\" to a full evaluation of all points (a cache miss), while frames with low error can use the accelerated statistical evaluation (a cache hit). ", 
        "id": 604, 
        "title": "Key Point Subspace Acceleration and soft caching."
    }, 
    {
        "abstract": "We present a symmetrization algorithm for geometric objects. Our algorithm enhances approximate symmetries of a model while minimally altering its shape. Symmetrizing deformations are formulated as an optimization process that couples the spatial domain with a transformation configuration space, where symmetries can be expressed more naturally and compactly as parametrized point-pair mappings. We derive closed-form solution for the optimal symmetry transformations, given a set of corresponding sample pairs. The resulting optimal displacement vectors are used to drive a constrained deformation model that pulls the shape towards symmetry. We show how our algorithm successfully symmetrizes both the geometry and the discretization of complex 2D and 3D shapes and discuss various applications of such symmetrizing deformations.", 
        "id": 605, 
        "title": "Symmetrization."
    }, 
    {
        "abstract": "cole Polytechnique Fdrale de Lausanne (a) Acquired Image (b) Computed Depth (c) Refocused (Far) (d) Refocused (Near) (e) Alternate Lighting Figure 1: Active refocusing of images. (a) Image acquired by projecting a sparse set of illumination dots on the scene. (b) The dots are automatically removed from the acquired image, and the defocus of the dots and a color segmentation of the image are used to compute an approximate depth map of the scene with sharp boundaries. (c and d) The depth map and the dot-removed image are used to smoothly refocus the scene. (e) The refocusing can also be done for an image taken immediately before or after but illuminated as desired. Abstract We present a system for refocusing images and videos of dynamic scenes using a novel, single-view depth estimation method. Our method for obtaining depth is based on the defocus of a sparse set of dots projected onto the scene. In contrast to other active illumination techniques, the projected pattern of dots can be removed from each captured image and its brightness easily controlled in order to avoid underor over-exposure. The depths corresponding to the projected dots and a color segmentation of the image are used to compute an approximate depth map of the scene with clean region boundaries. The depth map is used to refocus the acquired image after the dots are removed, simulating realistic depth of field effects. Experiments on a wide variety of scenes, including close-ups and live action, demonstrate the effectiveness of our method.", 
        "id": 606, 
        "title": "Active refocusing of images and videos."
    }, 
    {
        "abstract": "(a) creation (b) cut (c) adding a part (d) pull (e) result of sewing Figure 1: Designing an original plush toy using our system. The user interactively edits the 3D model on the screen using a sketching interface. Internally, the system generates 2D cloth pattern and shows the 3D model as a result of applying simple simulation to the pattern. Abstract We introduce Plushie, an interactive system that allows nonprofessional users to design their own original plush toys. To design a plush toy, one needs to construct an appropriate two-dimensional (2D) pattern. However, it is difficult for non-professional users to appropriately design a 2D pattern. Some recent systems automatically generate a 2D pattern for a given three-dimensional (3D) model, but constructing a 3D model is itself a challenge. Furthermore, an arbitrary 3D model cannot necessarily be realized as a real plush toy, and the final sewn result can be very different from the original 3D model. We avoid this mismatch by constructing appropriate 2D patterns and applying simple physical simulation to it on the fly during 3D modeling. In this way, the model on the screen is always a good approximation of the final sewn result, which makes the design process much more efficient. We use a sketching interface for 3D modeling and also provide various editing operations tailored for plush toy design. Internally, the system constructs a 2D cloth pattern in such a way that the simulation result matches the users input stroke. Our goal is to show that relatively simple algorithms can provide fast, satisfactory results to the user whereas the pursuit of optimal layout and simulation accuracy lies outside this papers scope. We successfully demonstrated that non-professional users could design plush toys or balloon easily using Plushie.", 
        "id": 607, 
        "title": "Plushie: an interactive design system for plush toys."
    }, 
    {
        "abstract": "We present a purely Eulerian framework for geometry processing of surfaces and foliations. Contrary to current Eulerian methods used in graphics, we use conservative methods and a variational interpretation, offering a unified framework for routine surface operations such as smoothing, offsetting, and animation. Computations are performed on a fixed volumetric grid without recourse to Lagrangian techniques such as triangle meshes, particles, or path tracing. At the core of our approach is the use of the Coarea Formula to express area integrals over isosurfaces as volume integrals. This enables the simultaneous processing of multiple isosurfaces, while a single interface can be treated as the special case of a dense foliation. We show that our method is a powerful alternative to conventional geometric representations in delicate cases such as the handling of high-genus surfaces, weighted offsetting, foliation smoothing of medical datasets, and incompressible fluid animation. ", 
        "id": 608, 
        "title": "A variational approach to Eulerian geometry processing."
    }, 
    {
        "abstract": "This paper describes algorithms to automatically derive 3D models of high visual quality from single facade images of arbitrary resolutions. We combine the procedural modeling pipeline of shape grammars with image analysis to derive a meaningful hierarchical facade subdivision. Our system gives rise to three exciting applications: urban reconstruction based on low resolution oblique aerial imagery, reconstruction of facades based on higher resolution ground-based imagery, and the automatic derivation of shape grammar rules from facade images to build a rule base for procedural modeling technology. ", 
        "id": 609, 
        "title": "Image-based procedural modeling of facades."
    }, 
    {
        "abstract": "This paper presents a system for designing freeform surfaces with a collection of 3D curves. The user first creates a rough 3D model by using a sketching interface. Unlike previous sketching systems, the user-drawn strokes stay on the model surface and serve as handles for controlling the geometry. The user can add, remove, and deform these control curves easily, as if working with a 2D line drawing. The curves can have arbitrary topology; they need not be connected to each other. For a given set of curves, the system automatically constructs a smooth surface embedding by applying functional optimization. Our system provides real-time algorithms for both control curve deformation and the subsequent surface optimization. We show that one can create sophisticated models using this system, which have not yet been seen in previous sketching or functional optimization systems. ", 
        "id": 610, 
        "title": "FiberMesh: designing freeform surfaces with 3D curves."
    }, 
    {
        "abstract": "We present a method for producing 3D tree models from input photographs with only limited user intervention. An approximate voxel-based tree volume is estimated using image information. The density values of the voxels are used to produce initial positions for a set of particles. Performing a 3D flow simulation, the particles are traced downwards to the tree basis and are combined to form twigs and branches. If possible, the trunk and the first-order branches are determined in the input photographs and are used as attractors for particle simulation. The geometry of the tree skeleton is produced using botanical rules for branch thicknesses and branching angles. Finally, leaves are added. Different initial seeds for particle simulation lead to a variety, yet similar-looking branching structures for a single set of photographs. ", 
        "id": 611, 
        "title": "Approximate image-based tree-modeling using particle flows."
    }, 
    {
        "abstract": "", 
        "id": 612, 
        "title": "Out-of-core and compressed level set methods."
    }, 
    {
        "abstract": " We present a new general-purpose method for fast hierarchical importance sampling with blue-noise properties. Our approach is based on self-similar tiling of the plane or the surface of a sphere with rectifiable polyominoes. Sampling points are associated with polyominoes, one point per polyomino. Each polyomino is recursively subdivided until the desired local density of samples is reached. A numerical code generated during the subdivision process is used for thresholding to accept or reject the sample. The exact position of the sampling point within the polyomino is determined according to a structural index, which indicates the polyomino's local neighborhood. The variety of structural indices and associated sampling point positions are computed during the offline optimization process, and tabulated. Consequently, the sampling itself is extremely fast. The method allows both deterministic and pseudo-non-deterministic sampling. It can be successfully applied in a large variety of graphical applications, where fast sampling with good spectral and visual properties is required. The prime application is rendering. ", 
        "id": 613, 
        "title": "Sampling with polyominoes."
    }, 
    {
        "abstract": "Designing rotational symmetries on surfaces is a necessary task for a wide variety of graphics applications, such as surface parameterization and remeshing, painterly rendering and pen-and-ink sketching, and texture synthesis. In these applications, the topology of a rotational symmetry field such as singularities and separatrices can have a direct impact on the quality of the results. In this paper, we present a design system that provides control over the topology of rotational symmetry fields on surfaces.  At the core of our analysis and design implementations is the observation that N-way rotational symmetries can be described by symmetric N-th order tensors, which allows an efficient vector-based representation that not only supports coherent definitions of arithmetic operations on rotational symmetries but also enables many analysis and design operations for vector fields to be adapted to rotational symmetry fields. To demonstrate the effectiveness of our approach, we apply our design system to pen-and-ink sketching and geometry remeshing.  As the foundation of our system, we provide comprehensive analysis for rotational symmetry fields on surfaces and present efficient algorithms to identify singularities and separatrices. We also describe design operations that allow a rotational symmetry field to be created and modified in an intuitive fashion by using the idea of basis fields and relaxation. In particular, we provide control over the topology of a rotational symmetry field by allowing the user to remove singularities from the field or to move them to more desirable locations.  ", 
        "id": 614, 
        "title": "Rotational symmetry field design on surfaces."
    }, 
    {
        "abstract": "Reeb graphs are a fundamental data structure for understanding and representing the topology of shapes. They are used in computer graphics, solid modeling, and visualization for applications ranging from the computation of similarities and finding defects in complex models to the automatic selection of visualization parameters. We introduce an on-line algorithm that reads a stream of elements (vertices, triangles, tetrahedra, etc.) and continuously maintains the Reeb graph of all elements already read. The algorithm is robust in handling non-manifold meshes and general in its applicability to input models of any dimension. Optionally, we construct a skeleton-like embedding of the Reeb graph, and/or remove topological noise to reduce the output size. For more information about the project see: http://pascucci.org/research/topology/reeb-graph/ ACM Reference Format Pascucci, V., Scorzelli, G., Bremer, P., Mascarenhas, A. 2007. Robust On-line Computation of Reeb Graphs: Simplicity and Speed. ACM Trans. Graph. 26, 3, Article 58 (July 2007), 9 pages. DOI = 10.1145/1239451.1239509 http://doi.acm.org/10.1145/1239451.1239509. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org.  2007 ACM 0730-0301/2007/03-ART58 $5.00 DOI 10.1145/1239451.1239509 http://doi.acm.org/10.1145/1239451.1239509  For interactive multi-resolution navigation we also build a hierarchical data structure which allows real-time extraction of approximated Reeb graphs containing all topological features above a given error threshold. Our extensive experiments show both high performance and practical linear scalability for meshes ranging from thousands to hundreds of millions of triangles. We apply our algorithm to the largest, most general, triangulated surfaces available to us, including 3D, 4D and 5D simplicial meshes. To demonstrate one important application we use Reeb graphs to find and highlight topological defects in meshes, including some widely believed to be \"clean.\" ", 
        "id": 615, 
        "title": "Robust on-line computation of Reeb graphs: simplicity and speed."
    }, 
    {
        "abstract": "We propose a novel post-production facial performance relighting system for human actors. Our system uses just a dataset of viewdependent facial appearances with a neutral expression, captured for a static subject using a Light Stage apparatus. For the actual performance, however, a potentially different actor is captured under known, but static, illumination. During post-production, the reflectance field of the reference dataset actor is transferred onto the dynamic performance, enabling image-based relighting of the entire sequence. Our approach makes post-production relighting more practical and could easily be incorporated in a traditional production pipeline since it does not require additional hardware during principal photography. Additionally, we show that our system is suitable for real-time post-production illumination editing. ", 
        "id": 616, 
        "title": "Post-production facial performance relighting using reflectance transfer."
    }, 
    {
        "abstract": "", 
        "id": 617, 
        "title": "Lighting with paint."
    }, 
    {
        "abstract": "We investigate a new approach to editing spatiallyand temporally-varying measured materials that adopts a stroke-based workflow. In our system, a user specifies a small number of editing constraints with a 3-D painting interface which are smoothly propagated to the entire dataset through an optimization that enforces similar edits are applied to areas with similar appearance. The sparse nature of this appearance-driven optimization permits the use of efficient solvers, allowing the designer to interactively refine the constraints. We have found this approach supports specifying a wide range of complex edits that would not be easy with existing techniques which present the user with a fixed segmentation of the data. Furthermore, it is independent of the underlying reflectance model and we show edits to both analytic and non-parametric representations in examples from several material databases.", 
        "id": 618, 
        "title": "AppWand: editing measured materials using appearance-driven optimization."
    }, 
    {
        "abstract": "Figure 1: This architectural free form structure  built of beams of constant height meeting in optimized nodes and covered with planar glass facets  was designed using the theory and algorithms presented in this paper. Our method also allows for the construction of secondary parallel offsets at a variable distance, here physically realized as a structure designed to cast shadows which is optimized to reduce heat load for particular sun positions. Abstract The geometric challenges in the architectural design of freeform shapes come mainly from the physical realization of beams and nodes. We approach them via the concept of parallel meshes, and present methods of computation and optimization. We discuss planar faces, beams of controlled height, node geometry, and multi-layer constructions. Beams of constant height are achieved with the new type of edge offset meshes. Mesh parallelism is also the main ingredient in a novel discrete theory of curvatures. These methods are applied to the construction of quadrilateral, pentagonal and hexagonal meshes, discrete minimal surfaces, discrete constant mean curvature surfaces, and their geometric transforms. We show how to design geometrically optimal shapes, and how to find a meaningful meshing and beam layout for existing shapes.", 
        "id": 619, 
        "title": "Geometry of multi-layer freeform structures for architecture."
    }, 
    {
        "abstract": "We present an automated approach for high-quality preview of feature-film rendering during lighting design. Similar to previous work, we use a deep-framebuffer shaded on the GPU to achieve interactive performance. Our first contribution is to generate the deep-framebuffer and corresponding shaders automatically through data-flow analysis and compilation of the original scene. Cache compression reduces automatically-generated deep-framebuffers to reasonable size for complex production scenes and shaders. We also propose a new structure, the indirect framebuffer, that decouples shading samples from final pixels and allows a deep-framebuffer to handle antialiasing, motion blur and transparency efficiently. Progressive refinement enables fast feedback at coarser resolution. We demonstrate our approach in real-world production.", 
        "id": 620, 
        "title": "The lightspeed automatic interactive lighting preview system."
    }, 
    {
        "abstract": "", 
        "id": 621, 
        "title": "A first-order analysis of lighting, shading, and shadows."
    }, 
    {
        "abstract": "Efficient, realistic rendering of complex scenes is one of the grand challenges in computer graphics. Perceptually based rendering addresses this challenge by taking advantage of the limits of human vision. However, existing methods, based on predicting visible image differences, are too conservative because some kinds of image differences do not matter to human observers. In this paper, we introduce the concept of visual equivalence, a new standard for image fidelity in graphics. Images are visually equivalent if they convey the same impressions of scene appearance, even if they are visibly different. To understand this phenomenon, we conduct a series of experiments that explore how object geometry, material, and illumination interact to provide information about appearance, and we characterize how two kinds of transformations on illumination maps (blurring and warping) affect these appearance attributes. We then derive visual equivalence predictors (VEPs): metrics for predicting when images rendered with transformed illumination maps will be visually equivalent to images rendered with reference maps. We also run a confirmatory study to validate the effectiveness of these VEPs for general scenes. Finally, we show how VEPs can be used to improve the efficiency of two rendering algorithms: Light-cuts and precomputed radiance transfer. This work represents some promising first steps towards developing perceptual metrics based on higher order aspects of visual coding.", 
        "id": 622, 
        "title": "Visual equivalence: towards a new standard for image fidelity."
    }, 
    {
        "abstract": "In this paper, we present a high speed optical motion capture method that can measure three dimensional motion, orientation, and incident illumination at tagged points in a scene. We use tracking tags that work in natural lighting conditions and can be imperceptibly embedded in attire or other objects. Our system supports an unlimited number of tags in a scene, with each tag uniquely identified to eliminate marker reacquisition issues. Our tags also provide incident illumination data which can be used to match scene lighting when inserting synthetic elements. The technique is therefore ideal for on-set motion capture or real-time broadcasting of virtual sets.  Unlike previous methods that employ high speed cameras or scanning lasers, we capture the scene appearance using the simplest possible optical devices  a light-emitting diode (LED) with a passive binary mask used as the transmitter and a photosensor used as the receiver. We strategically place a set of optical transmitters to spatio-temporally encode the volume of interest. Photosensors attached to scene points demultiplex the coded optical signals from multiple transmitters, allowing us to compute not only receiver location and orientation but also their incident illumination and the reflectance of the surfaces to which the photosensors are attached. We use our untethered tag system, called Prakash, to demonstrate methods of adding special effects to captured videos that cannot be accomplished using pure vision techniques that rely on camera images.  MERL, 201 Broadway, Cambridge, MA, USA University of Tokyo 0/ Universiteit Hasselt, Belgium U of Electro-Communications, Tokyo Georgia Institute of Technology Syracuse University Brown University Columbia University U of North Carolina at Chapel Hill Bauhaus University, Weimar e-mail:raskar(at)merl.com,web:http://www.merl.com/people/raskar/ ACM Reference Format Raskar, R., Nii, H., deDecker, B., Hashimoto, Y., Summet, J., Moore, D., Zhao, Y., Westhues, J., Dietz, P., Barnwell, J., Nayar, S., Inami, M., Bekaert, P., Noland, M., Branzoi, V., Bruns, E. 2007. Prakash: Lighting Aware Motion Capture using Photosensing Markers and Multiplexed Illuminators. ACM Trans. Graph. 26, 3, Article 36 (July 2007), 11 pages. DOI = 10.1145/1239451.1239487 http://doi.acm.org/10.1145/1239451.1 239487. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org.  2007 ACM 0730-0301/2007/03-ART36 $5.00 DOI 10.1145/1239451.1239487 http://doi.acm.org/10.1145/1239451.1239487  ", 
        "id": 623, 
        "title": "Prakash: lighting aware motion capture using photosensing markers and multiplexed illuminators."
    }, 
    {
        "abstract": "", 
        "id": 624, 
        "title": "Evaluating motion graphs for character animation."
    }, 
    {
        "abstract": "New generations of display devices promise to provide significantly improved dynamic range over conventional display technology. In the long run, evolving camera technology and file formats will provide high fidelity content for these display devices. In the near term, however, the vast majority of images and video will only be available in low dynamic range formats. In this paper we describe a method for boosting the dynamic range of legacy video and photographs for viewing on high dynamic range displays. Our emphasis is on real-time processing of video streams, such as web streams or the signal from a DVD player. We place particular emphasis on robustness of the method, and its ability to deal with a wide range of content without user adjusted parameters or visible artifacts. The method can be implemented on both graphics hardware and on signal processors that are directly integrated in the HDR displays. ", 
        "id": 625, 
        "title": "Ldr2Hdr: on-the-fly reverse tone mapping of legacy video and photographs."
    }, 
    {
        "abstract": "We introduce a simple technique that enables robust approximation of volumetric, large-deformation dynamics for real-time or large-scale offline simulations. We propose Lattice Shape Matching, an extension of deformable shape matching to regular lattices with embedded geometry; lattice vertices are smoothed by convolution of rigid shape matching operators on local lattice regions, with the effective mechanical stiffness specified by the amount of smoothing via region width. Since the nave method can be very slow for stiff models  per-vertex costs scale cubically with region width  we provide a fast summation algorithm, Fast Lattice Shape Matching (FastLSM), that exploits the inherent summation redundancy of shape matching and can provide large-region matching at constant per-vertex cost. With this approach, large lattices can be simulated in linear time. We present several examples and benchmarks of an efficient CPU implementation, including many dozens of soft bodies simulated at real-time rates on a typical desktop machine.", 
        "id": 626, 
        "title": "FastLSM: fast lattice shape matching for robust real-time deformation."
    }, 
    {
        "abstract": " Many compelling applications would become feasible if novice users had the ability to synthesize high quality human motion based only on a simple sketch and a few easily specified constraints. We approach this problem by representing the desired motion as an interpolation of two time-scaled paths through a motion graph. The graph is constructed to support interpolation and pruned for efficient search. We use an anytime version of A search to find a globally optimal solution in this graph that satisfies the user's specification. Our approach retains the natural transitions of motion graphs and the ability to synthesize physically realistic variations provided by interpolation. We demonstrate the power of this approach by synthesizing optimal or near optimal motions that include a variety of behaviors in a single motion.  ", 
        "id": 627, 
        "title": "Construction and optimal search of interpolated motion graphs."
    }, 
    {
        "abstract": "We present novel algorithms that optimize the order in which triangles are rendered, to improve post-transform vertex cache efficiency as well as for view-independent overdraw reduction. The resulting triangle orders perform on par with previous methods, but are orders magnitude faster to compute. The improvements in processing speed allow us to perform the optimization right after a model is loaded, when more information on the host hardware is available. This allows our vertex cache optimization to often outperform other methods. In fact, our algorithms can even be executed interactively, allowing for re-optimization in case of changes to geometry or topology, which happen often in CAD/CAM applications. We believe that most real-time rendering applications will immediately benefit from these new results. ", 
        "id": 628, 
        "title": "Fast triangle reordering for vertex locality and reduced overdraw."
    }, 
    {
        "abstract": "The reconstruction of a complete watertight model from scan data is still a difficult process. In particular, since scanned data is often incomplete, the reconstruction of the expected shape is an illposed problem. Techniques that reconstruct poorly-sampled areas without any user intervention fail in many cases to faithfully reconstruct the topology of the model. The method that we introduce in this paper is topology-aware: it uses minimal user input to make correct decisions at regions where the topology of the model cannot be automatically induced with a reasonable degree of confidence. We first construct a continuous function over a threedimensional domain. This function is constructed by minimizing a penalty function combining the data points, user constraints, and a regularization term. The optimization problem is formulated in a mesh-independent manner, and mapped onto a specific mesh using the finite-element method. The zero level-set of this function is a first approximation of the reconstructed surface. At complex undersampled regions, the constraints might be insufficient. Hence, we analyze the local topological stability of the zero level-set to detect weak regions of the surface. These regions are suggested to the user for adding local inside/outside constraints by merely scribbling over a 2D tablet. Each new user constraint modifies the minimization problem, which is solved incrementally. The process is repeated, converging to a topology-stable reconstruction. Reconstructions of models acquired by a structured-light scanner with a small number of scribbles demonstrate the effectiveness of the method. ACM Reference Format Sharf, A., Lewiner, T., Shklarski, G., Toledo, S., Cohen-Or, D. 2007. Interactive Topology-aware Surface Reconstruction. ACM Trans. Graph. 26, 3, Article 43 (July 2007), 9 pages. DOI = 10.1145/1239451.1239494 http://doi.acm.org/10.1145/1239451.1239494. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org.  2007 ACM 0730-0301/2007/03-ART43 $5.00 DOI 10.1145/1239451.1239494 http://doi.acm.org/10.1145/1239451.1239494  ", 
        "id": 629, 
        "title": "Interactive topology-aware surface reconstruction."
    }, 
    {
        "abstract": "", 
        "id": 630, 
        "title": "Distinctive regions of 3D surfaces."
    }, 
    {
        "abstract": " We present mesh puppetry, a variational framework for detailpreserving mesh manipulation through a set of high-level, intuitive, and interactive design tools. Our approach builds upon traditional rigging by optimizing skeleton position and vertex weights in an integrated manner. New poses and animations are created by specifying a few desired constraints on vertex positions, balance of the character, length and rigidity preservation, joint limits, and/or selfcollision avoidance. Our algorithm then adjusts the skeleton and solves for the deformed mesh simultaneously through a novel cascading optimization procedure, allowing realtime manipulation of meshes with 50K+ vertices for fast design of pleasing and realistic poses. We demonstrate the potential of our framework through an interactive deformation platform and various applications such as deformation transfer and motion retargeting.  ", 
        "id": 631, 
        "title": "Mesh puppetry: cascading optimization of mesh deformation with inverse kinematics."
    }, 
    {
        "abstract": "Physically based simulation of human motions is an important issue in the context of computer animation, robotics and biomechanics. We present a new technique for allowing our physically-simulated planar biped characters to imitate human behaviors. Our contribution is twofold. We developed an optimization method that transforms any (either motion-captured or kinematically synthesized) biped motion into a physically-feasible, balance-maintaining simulated motion. Our optimization method allows us to collect a rich set of training data that contains stylistic, personality-rich human behaviors. Our controller learning algorithm facilitates the creation and composition of robust dynamic controllers that are learned from training data. We demonstrate a planar articulated character that is dynamically simulated in real time, equipped with an integrated repertoire of motor skills, and controlled interactively to perform desired motions. ", 
        "id": 632, 
        "title": "Simulating biped behaviors from human motion data."
    }, 
    {
        "abstract": " We present an algorithm that generates natural and intuitive deformations via direct manipulation for a wide range of shape representations and editing scenarios. Our method builds a space deformation represented by a collection of affine transformations organized in a graph structure. One transformation is associated with each graph node and applies a deformation to the nearby space. Positional constraints are specified on the points of an embedded object. As the user manipulates the constraints, a nonlinear minimization problem is solved to find optimal values for the affine transformations. Feature preservation is encoded directly in the objective function by measuring the deviation of each transformation from a true rotation. This algorithm addresses the problem of \"embedded deformation\" since it deforms space through direct manipulation of objects embedded within it, while preserving the embedded objects' features. We demonstrate our method by editing meshes, polygon soups, mesh animations, and animated particle systems. ", 
        "id": 633, 
        "title": "Embedded deformation for shape manipulation."
    }, 
    {
        "abstract": "We describe a method for converting time-lapse photography captured with outdoor cameras into Factored Time-Lapse Video (FTLV): a video in which time appears to move faster (i.e., lapsing) and where data at each pixel has been factored into shadow, illumination, and reflectance components. The factorization allows a user to easily relight the scene, recover a portion of the scene geometry (normals), and to perform advanced image editing operations. Our method is easy to implement, robust, and provides a compact representation with good reconstruction characteristics. We show results using several publicly available time-lapse sequences. ", 
        "id": 634, 
        "title": "Factored time-lapse video."
    }, 
    {
        "abstract": "Recently, gradient meshes have been introduced as a powerful vector graphics representation to draw multicolored mesh objects with smooth transitions. Using tools from Abode Illustrator and Corel CorelDraw, a user can manually create gradient meshes even for photo-realistic vector arts, which can be further edited, stylized and animated. In this paper, we present an easy-to-use interactive tool, called optimized gradient mesh, to semi-automatically and quickly create gradient meshes from a raster image. We obtain the optimized gradient mesh by formulating an energy minimization problem. The user can also interactively specify a few vector lines to guide the mesh generation. The resulting optimized gradient mesh is an editable and scalable mesh that otherwise would have taken many hours for a user to manually create. ", 
        "id": 635, 
        "title": "Image vectorization using optimized gradient meshes."
    }, 
    {
        "abstract": "Figure 1: Image sequence of Venus rendered with a dynamic BRDF. Ground truth renderings of the corresponding materials are shown on spheres at the bottom-right of the images. The changes in Venus reflectance properties produce corresponding indirect lighting effects on the surrounding walls. Here, precomputation of 12.3 hours with 389 Mbytes memory is used for the 39.7K vertices. The rendering performance is 2.62 fps when the viewpoint, BRDF, and lighting are all simultaneously changing; 10.94 fps when only the viewpoint and BRDF are dynamic; and 57.09 fps when only the viewpoint changes. Abstract We present a technique for interactive relighting in which source radiance, viewing direction, and BRDFs can all be changed on the fly. In handling dynamic BRDFs, our method efficiently accounts for the effects of BRDF modification on the reflectance and incident radiance at a surface point. For reflectance, we develop a BRDF tensor representation that can be factorized into adjustable terms for lighting, viewing, and BRDF parameters. For incident radiance, there exists a non-linear relationship between indirect lighting and BRDFs in a scene, which makes linear light transport frameworks such as PRT unsuitable. To overcome this problem, we introduce precomputed transfer tensors (PTTs) which decompose indirect lighting into precomputable components that are each a function of BRDFs in the scene, and can be rapidly combined at run time to correctly determine incident radiance. We additionally describe a method for efficient handling of high-frequency specular reflections by separating them from the BRDF tensor representation and processing them using precomputed visibility information. With relighting based on PTTs, interactive performance with indirect lighting is demonstrated in applications to BRDF animation and material tuning. ", 
        "id": 636, 
        "title": "Interactive relighting with dynamic BRDFs."
    }, 
    {
        "abstract": "The ability of a camera to record a high dynamic range image, whether by taking one snapshot or a sequence, is limited by the presence of veiling glare the tendency of bright objects in the scene to reduce the contrast everywhere within the field of view. Veiling glare is a global illumination effect that arises from multiple scattering of light inside the cameras body and lens optics. By measuring separately the direct and indirect components of the intra-camera light transport, one can increase the maximum dynamic range a particular camera is capable of recording. In this paper, we quantify the presence of veiling glare and related optical artifacts for several types of digital cameras, and we describe two methods for removing them: deconvolution by a measured glare spread function, and a novel direct-indirect separation of the lens transport using a structured occlusion mask. In the second method, we selectively block the light that contributes to veiling glare, thereby attaining significantly higher signal-to-noise ratios than with decon-volution. Finally, we demonstrate our separation method for several combinations of cameras and realistic scenes.", 
        "id": 637, 
        "title": "Veiling glare in high dynamic range imaging."
    }, 
    {
        "abstract": "In this paper, we propose an approach for generating 3D models of natural-looking trees from images that has the additional benefit of requiring little user intervention. While our approach is primarily image-based, we do not model each leaf directly from images due to the large leaf count, small image footprint, and widespread occlusions. Instead, we populate the tree with leaf replicas from segmented source images to reconstruct the overall tree shape. In addition, we use the shape patterns of visible branches to predict those of obscured branches. We demonstrate our approach on a variety of trees.  cloud of the tree. Rather than applying specific rules for branch generation, we use the local shapes of branches that are observed to interpolate those of obscured branches. Finally, the leaves are generated by segmenting the source images and computing their depths using the pre-computed 3D points or the recovered branches. One such result can be seen in Figure 1. Note that in this paper, we differentiate between bushes and trees--we consider \"bushes\" as terrestrial flora with large discernible leaves (relative to the bush size), and \"trees\" as large terrestrial flora with small leaves (relative to the tree size). The spectrum of bushes and trees with varying leaf sizes is shown in Figure 2.  ", 
        "id": 638, 
        "title": "Image-based tree modeling."
    }, 
    {
        "abstract": "Recent progress in non-photorealistic rendering (NPR) has led to many stylized shading techniques that efficiently convey visual information about the objects depicted. Another crucial goal of NPR is to give artists simple and direct ways to express the abstract ideas born of their imaginations. In particular, the ability to add intentional, but often unrealistic, shading effects is indispensable for many applications. We propose a set of simple stylized shading algorithms that allow the user to freely add localized light and shade to a model in a manner that is consistent and seamlessly integrated with conventional lighting techniques. The algorithms provide an intuitive, direct manipulation method based on a paint-brush metaphor, to control and edit the light and shade locally as desired. Our prototype system demonstrates how our method can enhance both the quality and range of applicability of conventional stylized shading for offline animation and interactive applications.", 
        "id": 639, 
        "title": "Locally controllable stylized shading."
    }, 
    {
        "abstract": "We present a new approach to realtime character animation with interactive control. Given a corpus of motion capture data and a desired task, we automatically compute near-optimal controllers using a low-dimensional basis representation. We show that these controllers produce motion that fluidly responds to several dimensions of user control and environmental constraints in realtime. Our results indicate that very few basis functions are required to create high-fidelity character controllers which permit complex user navigation and obstacle-avoidance tasks. ", 
        "id": 640, 
        "title": "Near-optimal character animation with continuous control."
    }, 
    {
        "abstract": "Animation techniques for controlling passive simulation are commonly based on an optimization paradigm: the user provides goals a priori, and sophisticated numerical methods minimize a cost function that represents these goals. Unfortunately, for multibody systems with discontinuous contact events these optimization problems can be highly nontrivial to solve, and many-hour offline optimizations, unintuitive parameters, and convergence failures can frustrate end-users and limit usage. On the other hand, users are quite adaptable, and systems which provide interactive feedback via an intuitive interface can leverage the user's own abilities to quickly produce interesting animations. However, the online computation necessary for interactivity limits scene complexity in practice. We introduce Many-Worlds Browsing, a method which circumvents these limits by exploiting the speed of multibody simulators to compute numerous example simulations in parallel (offline and online), and allow the user to browse and modify them interactively. We demonstrate intuitive interfaces through which the user can select among the examples and interactively adjust those parts of the scene that do not match his requirements. We show that using a combination of our techniques, unusual and interesting results can be generated for moderately sized scenes with under an hour of user time. Scalability is demonstrated by sampling much larger scenes using modest offline computations.  ", 
        "id": 641, 
        "title": "Many-worlds browsing for control of multibody dynamics."
    }, 
    {
        "abstract": "Visual observation is our principal source of information in determining the nature of objects, including shape, material or roughness. The physiological and cognitive processes that resolve visual input into an estimate of the material of an object are influenced by the illumination and the shape of the object. This affects our ability to select materials by observing them on a point-lit sphere, as is common in current 3D modeling applications.  ", 
        "id": 642, 
        "title": "The influence of shape on the perception of material reflectance."
    }, 
    {
        "abstract": "We describe a theoretical framework for reversibly modulating 4D light fields using an attenuating mask in the optical path of a lens based camera. Based on this framework, we present a novel design to reconstruct the 4D light field from a 2D camera image without any additional refractive elements as required by previous light field cameras. The patterned mask attenuates light rays inside the camera instead of bending them, and the attenuation recoverably encodes the rays on the 2D sensor. Our mask-equipped camera focuses just as a traditional camera to capture conventional 2D photos at full sensor resolution, but the raw pixel values also hold a modulated 4D light field. The light field can be recovered by rearranging the tiles of the 2D Fourier transform of sensor values into 4D planes, and computing the inverse Fourier transform. In addition, one can also recover the full resolution image information for the in-focus parts of the scene. We also show how a broadband mask placed at the lens enables us to compute refocused images at full sensor resolution for layered Lambertian scenes. This partial encoding of 4D ray-space data enables editing of image contents by depth, yet does not require computational recovery of the complete 4D light field. ", 
        "id": 643, 
        "title": "Dappled photography: mask enhanced cameras for heterodyned light fields and coded aperture refocusing."
    }, 
    {
        "abstract": "Commercial motion-capture systems produce excellent in-studio reconstructions, but offer no comparable solution for acquisition in everyday environments. We present a system for acquiring motions almost anywhere. This wearable system gathers ultrasonic time-of-flight and inertial measurements with a set of inexpensive miniature sensors worn on the garment. After recording, the information is combined using an Extended Kalman Filter to reconstruct joint configurations of a body. Experimental results show that even motions that are traditionally difficult to acquire are recorded with ease within their natural settings. Although our prototype does not reliably recover the global transformation, we show that the resulting motions are visually similar to the original ones, and that the combined acoustic and inertial system reduces the drift commonly observed in purely inertial systems. Our final results suggest that this system could become a versatile input device for a variety of augmented-reality applications. ", 
        "id": 644, 
        "title": "Practical motion capture in everyday surroundings."
    }, 
    {
        "abstract": "", 
        "id": 645, 
        "title": "Ray tracing deformable scenes using dynamic bounding volume hierarchies."
    }, 
    {
        "abstract": "We present Soft Scissors, an interactive tool for extracting alpha mattes of foreground objects in realtime. We recently proposed a novel offline matting algorithm capable of extracting high-quality mattes for complex foreground objects such as furry animals [Wang and Cohen 2007]. In this paper we both improve the quality of our offline algorithm and give it the ability to incrementally update the matte in an online interactive setting. Our realtime system efficiently estimates foreground color thereby allowing both the matte and the final composite to be revealed instantly as the user roughly paints along the edge of the foreground object. In addition, our system can dynamically adjust the width and boundary conditions of the scissoring paint brush to approximately capture the boundary of the foreground object that lies ahead on the scissor's path. These advantages in both speed and accuracy create the first interactive tool for high quality image matting and compositing. ", 
        "id": 646, 
        "title": "Soft scissors: an interactive tool for realtime high quality matting."
    }, 
    {
        "abstract": " Enveloping, or the mapping of skeletal controls to the deformations of a surface, is key to driving realistic animated characters. Despite its widespread use, enveloping still relies on slow or inaccurate deformation methods. We propose a method that is both fast, accurate and example-based. Our technique introduces a rotational regression model that captures common skinning deformations such as muscle bulging, twisting, and challenging areas such as the shoulders. Our improved treatment of rotational quantities is made practical by model reduction that ensures real-time solution of leastsquares problems, independent of the mesh size. Our method is significantly more accurate than linear blend skinning and almost as fast, suggesting its use as a replacement for linear blend skinning when examples are available.  Ground truth Our method  1 Hz 440 Hz  ", 
        "id": 647, 
        "title": "Real-time enveloping with rotational regression."
    }, 
    {
        "abstract": "We present a system for semi-automatic creation of bas-relief sculpture. As an artistic medium, relief spans the continuum between 2D drawing or painting and full 3D sculpture. Bas-relief (or low relief) presents the unique challenge of squeezing shapes into a nearly-flat surface while maintaining as much as possible the perception of the full 3D scene. Our solution to this problem adapts methods from the tone-mapping literature, which addresses the similar problem of squeezing a high dynamic range image into the (low) dynamic range available on typical display devices. However, the bas-relief medium imposes its own unique set of requirements, such as maintaining small, fixed-size depth discontinuities. Given a 3D model, camera, and a few parameters describing the relative attenuation of different frequencies in the shape, our system creates a relief that gives the illusion of the 3D shape from a given vantage point while conforming to a greatly compressed height. ", 
        "id": 648, 
        "title": "Digital bas-relief from 3D scenes."
    }, 
    {
        "abstract": " We present a novel architecture for hardware-accelerated rendering of point primitives. Our pipeline implements a refined version of EWA splatting, a high quality method for antialiased rendering of point sampled representations. A central feature of our design is the seamless integration of the architecture into conventional, OpenGL-like graphics pipelines so as to complement triangle-based rendering. The specific properties of the EWA algorithm required a variety of novel design concepts including a ternary depth test and using an on-chip pipelined heap data structure for making the memory accesses of splat primitives more coherent. In addition, we developed a computationally stable evaluation scheme for perspectively corrected splats. We implemented our architecture both on reconfigurable FPGA boards and as an ASIC prototype, and we integrated it into an OpenGL-like software implementation. Our evaluation comprises a detailed performance analysis using scenes of varying complexity. ", 
        "id": 649, 
        "title": "A hardware architecture for surface splatting."
    }, 
    {
        "abstract": "We capture the shape of moving cloth using a custom set of color markers printed on the surface of the cloth. The output is a sequence of triangle meshes with static connectivity and with detail at the scale of individual markers in both smooth and folded regions. We compute markers' coordinates in space using correspondence across multiple synchronized video cameras. Correspondence is determined from color information in small neighborhoods and refined using a novel strain pruning process. Final correspondence does not require neighborhood information. We use a novel data driven hole-filling technique to fill occluded regions. Our results include several challenging examples: a wrinkled shirt sleeve, a dancing pair of pants, and a rag tossed onto a cup. Finally, we demonstrate that cloth capture is reusable by animating a pair of pants using human motion capture data. ", 
        "id": 650, 
        "title": "Capturing and animating occluded cloth."
    }, 
    {
        "abstract": "", 
        "id": 651, 
        "title": "Natural shadow matting."
    }, 
    {
        "abstract": "We present a simple interactive approach to specify 3D shape in a single view using \"shape palettes\". The interaction is as follows: draw a simple 2D primitive in the 2D view and then specify its 3D orientation by drawing a corresponding primitive on a shape palette. The shape palette is presented as an image of some familiar shape whose local 3D orientation is readily understood and can be easily marked over. The 3D orientation from the shape palette is transferred to the 2D primitive based on the markup. As we will demonstrate, only sparse markup is needed to generate expressive and detailed 3D surfaces. This markup approach can be used to model freehand 3D surfaces drawn in a single view, or combined with image-snapping tools to quickly extract surfaces from images and photographs. ", 
        "id": 652, 
        "title": "ShapePalettes: interactive normal transfer via sketching."
    }, 
    {
        "abstract": "", 
        "id": 653, 
        "title": "Knowledge and heuristic-based modeling of laser-scanned trees."
    }, 
    {
        "abstract": " We present a set of graphical and combinatorial algorithms for designing mazes based on images. The designer traces regions of interest in an image and annotates the regions with style parameters. They can optionally specify a solution path, which provides a rough guide for laying out the maze's actual solution. The system uses novel extensions to well-known maze construction algorithms to build mazes that approximate the tone of the source image, express the desired style in each region, and conform to the user's solution path.  ", 
        "id": 654, 
        "title": "Image-guided maze construction."
    }, 
    {
        "abstract": "Many graphics applications, including computer games and 3D animated films, make heavy use of deforming mesh sequences. In this paper, we generalize gradient domain editing to deforming mesh sequences. Our framework is keyframe based. Given sparse and irregularly distributed constraints at unevenly spaced keyframes, our solution first adjusts the meshes at the keyframes to satisfy these constraints, and then smoothly propagate the constraints and deformations at keyframes to the whole sequence to generate new deforming mesh sequence. To achieve convenient keyframe editing, we have developed an efficient alternating least-squares method. It harnesses the power of subspace deformation and two-pass linear methods to achieve high-quality deformations. We have also developed an effective algorithm to define boundary conditions for all frames using handle trajectory editing. Our deforming mesh editing framework has been successfully applied to a number of editing scenarios with increasing complexity, including footprint editing, path editing, temporal filtering, handle-based deformation mixing, and spacetime morphing. This work was done while Qifeng Tan was an intern at Microsoft Research Asia. ACM Reference Format Xu, W., Zhou, K., Yu, Y., Tan, Q., Peng, Q., Guo, B. 2007. Gradient Domain Editing of Deforming Mesh Sequences. ACM Trans. Graph. 26, 3, Article 84 (July 2007), 10 pages. DOI = 10.1145/1239451.1239535 http://doi.acm.org/10.1145/1239451.1239535. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org.  2007 ACM 0730-0301/2007/03-ART84 $5.00 DOI 10.1145/1239451.1239535 http://doi.acm.org/10.1145/1239451.1239535  ", 
        "id": 655, 
        "title": "Gradient domain editing of deforming mesh sequences."
    }, 
    {
        "abstract": "Physics-based simulation and control of biped locomotion is difficult because bipeds are unstable, underactuated, high-dimensional dynamical systems. We develop a simple control strategy that can be used to generate a large variety of gaits and styles in real-time, including walking in all directions (forwards, backwards, sideways, turning), running, skipping, and hopping. Controllers can be authored using a small number of parameters, or their construction can be informed by motion capture data. The controllers are applied to 2D and 3D physically-simulated character models. Their robustness is demonstrated with respect to pushes in all directions, unexpected steps and slopes, and unexpected variations in kinematic and dynamic parameters. Direct transitions between controllers are demonstrated as well as parameterized control of changes in direction and speed. Feedback-error learning is applied to learn predictive torque models, which allows for the low-gain control that typifies many natural motions as well as producing smoother simulated motion. ", 
        "id": 656, 
        "title": "SIMBICON: simple biped locomotion control."
    }, 
    {
        "abstract": "Taking satisfactory photos under dim lighting conditions using a hand-held camera is challenging. If the camera is set to a long exposure time, the image is blurred due to camera shake. On the other hand, the image is dark and noisy if it is taken with a short exposure time but with a high camera gain. By combining information extracted from both blurred and noisy images, however, we show in this paper how to produce a high quality image that cannot be obtained by simply denoising the noisy image, or deblurring the blurred image alone. Our approach is image deblurring with the help of the noisy image. First, both images are used to estimate an accurate blur kernel, which otherwise is difficult to obtain from a single blurred image. Second, and again using both images, a residual deconvolution is proposed to significantly reduce ringing artifacts inherent to image deconvolution. Third, the remaining ringing artifacts in smooth image regions are further suppressed by a gain-controlled deconvolution process. We demonstrate the effectiveness of our approach using a number of indoor and outdoor images taken by off-the-shelf hand-held cameras in poor lighting environments.  taken are blurred or noisy. The brightness of the image can be increased in three ways. First, to reduce the shutter speed. But with a shutter speed below a safe shutter speed (the reciprocal of the focal length of the lens, in the unit of seconds), camera shake will result in a blurred image. Second, to use a large aperture. A large aperture will however reduce the depth of field. Moreover, the range of apertures in many cameras is very limited. Third, to set a high ISO. However, the high ISO image is very noisy because the noise is amplified as the camera's gain increases. To take a sharp image in a dim lighting environment, the best settings are: safe shutter speed, the largest aperture, and the highest ISO. Even with this combination, the captured image may still be dark and very noisy. Typically, two kinds of degraded image can be taken in the low light conditions. One is a blurred image which is taken with a slow shutter speed and a low ISO setting, as shown in Figure 1(a). With enough light, it has the correct color, intensity and a high SignalNoise Ratio (SNR). But it is blurry due to camera shake. The other is an underexposed and noisy image with a fast shutter speed and a high ISO setting, as shown in Figure 1(b). It is sharp but very noisy due to insufficient exposure and high camera gain. The colors of this image are also partially lost due to low contrast.  ", 
        "id": 657, 
        "title": "Image deblurring with blurred/noisy image pairs."
    }, 
    {
        "abstract": "We present a new method for the real-time simulation of fluid surface waves and their interactions with floating objects. The method is based on the new concept of wave particles, which offers a simple, fast, and unconditionally stable approach to wave simulation. We show how graphics hardware can be used to convert wave particles to a height field surface, which is warped horizontally to account for local wave-induced flow. The method is appropriate for most fluid simulation situations that do not involve significant global flow. It is demonstrated to work well in constrained areas, including wave reflections off of boundaries, and in unconstrained areas, such as an ocean surface. Interactions with floating objects are easily integrated by including wave forces on the objects and wave generation due to object motion. Theoretical foundations and implementation details are provided, and experiments demonstrate that we achieve plausible realism. Timing studies show that the method is scalable to allow simulation of wave interaction with several hundreds of objects at real-time rates. ", 
        "id": 658, 
        "title": "Wave particles."
    }, 
    {
        "abstract": "We present a fast continuous collision detection (CCD) algorithm for articulated models using Taylor models and temporal culling. Our algorithm is a generalization of conservative advancement (CA) from convex models [Mirtich 1996] to articulated models with non-convex links. Given the initial and final configurations of a moving articulated model, our algorithm creates a continuous motion with constant translational and rotational velocities for each link, and checks for interferences between the articulated model under continuous motion and other models in the environment and for self-collisions. If collisions occur, our algorithm reports the first time of contact (TOC) as well as collision witness features. We have implemented our CCD algorithm and applied it to several challenging scenarios including locomotion generation, articulated-body dynamics and character motion planning. Our algorithm can perform CCDs including self-collision detection for articulated models consisting of many links and tens of thousands of triangles in 1.22 ms on average running on a 3.6 GHz Pentium 4 PC. This is an improvement on the performance of prior algorithms of more than an order of magnitude. ", 
        "id": 659, 
        "title": "Continuous collision detection for articulated models using Taylor models and temporal culling."
    }, 
    {
        "abstract": " We present an algorithm for interactive deformation of subdivision surfaces, including displaced subdivision surfaces and subdivision surfaces with geometric textures. Our system lets the user directly manipulate the surface using freely-selected surface points as handles. During deformation the control mesh vertices are automatically adjusted such that the deforming surface satisfies the handle position constraints while preserving the original surface shape and details. To best preserve surface details, we develop a gradient domain technique that incorporates the handle position constraints and detail preserving objectives into the deformation energy. For displaced subdivision surfaces and surfaces with geometric textures, the deformation energy is highly nonlinear and cannot be handled with existing iterative solvers. To address this issue, we introduce a shell deformation solver, which replaces each numerically unstable iteration step with two stable mesh deformation operations. Our deformation algorithm only uses local operations and is thus suitable for GPU implementation. The result is a real-time deformation system running orders of magnitude faster than the state-of-the-art multigrid mesh deformation solver. We demonstrate our technique with a variety of examples, including examples of creating visually pleasing character animations in real-time by driving a subdivision surface with motion capture data. ", 
        "id": 660, 
        "title": "Direct manipulation of subdivision surfaces on GPUs."
    }, 
    {
        "abstract": "This paper proposes a new marker-less approach to capturing human performances from multi-view video. Our algorithm can jointly reconstruct spatio-temporally coherent geometry, motion and textural surface appearance of actors that perform complex and rapid moves. Furthermore, since our algorithm is purely mesh-based and makes as few as possible prior assumptions about the type of subject being tracked, it can even capture performances of people wearing wide apparel, such as a dancer wearing a skirt. To serve this purpose our method efficiently and effectively combines the power of surfaceand volume-based shape deformation techniques with a new mesh-based analysis-through-synthesis framework. This framework extracts motion constraints from video and makes the laser-scan of the tracked subject mimic the recorded performance. Also small-scale time-varying shape detail is recovered by applying model-guided multi-view stereo to refine the model surface. Our method delivers captured performance data at high level of detail, is highly versatile, and is applicable to many complex types of scenes that could not be handled by alternative marker-based or marker-free recording techniques.", 
        "id": 661, 
        "title": "Performance capture from sparse multi-view video."
    }, 
    {
        "abstract": "We introduce 4PCS, a fast and robust alignment scheme for 3D point sets that uses wide bases, which are known to be resilient to noise and outliers. The algorithm allows registering raw noisy data, possibly contaminated with outliers, without pre-filtering or denoising the data. Further, the method significantly reduces the number of trials required to establish a reliable registration between the underlying surfaces in the presence of noise, without any assumptions about starting alignment. Our method is based on a novel technique to extract all coplanar 4-points sets from a 3D point set that are approximately congruent, under rigid transformation, to a given set of coplanar 4-points. This extraction procedure runs in roughly O(n2 + k) time, where n is the number of candidate points and k is the number of reported 4-points sets. In practice, when noise level is low and there is sufficient overlap, using local descriptors the time complexity reduces to O(n + k). We also propose an extension to handle similarity and affine transforms. Our technique achieves an order of magnitude asymptotic acceleration compared to common randomized alignment techniques. We demonstrate the robustness of our algorithm on several sets of multiple range scans with varying degree of noise, outliers, and extent of overlap. ", 
        "id": 662, 
        "title": "4-points congruent sets for robust pairwise surface registration."
    }, 
    {
        "abstract": "", 
        "id": 663, 
        "title": "Subdivision shading."
    }, 
    {
        "abstract": "", 
        "id": 664, 
        "title": "A virtual restoration stage for real-world objects."
    }, 
    {
        "abstract": "", 
        "id": 665, 
        "title": "Interactive example-based urban layout synthesis."
    }, 
    {
        "abstract": "", 
        "id": 666, 
        "title": "Optimizing cubature for efficient integration of subspace deformations."
    }, 
    {
        "abstract": "Shadow computation in dynamic scenes under complex illumination is a challenging problem. Methods based on precomputation provide accurate, real-time solutions, but are hard to extend to dynamic scenes. Specialized approaches for soft shadows can deal with dynamic objects but are not fast enough to handle more than one light source. In this paper, we present a technique for rendering dynamic objects under arbitrary environment illumination, which does not require any precomputation. The key ingredient is a fast, approximate technique for computing soft shadows, which achieves several hundred frames per second for a single light source. This allows for approximating environment illumination with a sparse collection of area light sources and yields real-time frame rates. ", 
        "id": 667, 
        "title": "Real-time, all-frequency shadows in dynamic scenes."
    }, 
    {
        "abstract": "image editing material editing original user input final edits Figure 1: To edit the appearance of images and measured materials, users quickly perform rough adjustments that our algorithm refines to maintain the intricate patterns of the originals. Top Left: A few painted strokes are propagated to all regions of similar appearance (darker areas indicate unedited regions). Image c Jaap Hart. All rights reserved. Bottom Left: Arbitrary, imprecise edits to the whole image are refined to respect appearance patterns while maintaining the artists intention. Right: Rough edits on a material dataset from [Lawrence et al. 2006]. Abstract We present an intuitive and efficient method for editing the appearance of complex spatially-varying datasets, such as images and measured materials. In our framework, users specify rough adjustments that are refined interactively by enforcing the policy that similar edits are applied to spatially-close regions of similar appearance. Rather than proposing a specific user interface, our method allows artists to quickly and imprecisely specify the initial edits with any method or workflow they feel most comfortable with. An energy optimization formulation is used to propagate the initial rough adjustments to the final refined ones by enforcing the editing policy over all pairs of points in the dataset. We show that this formulation is equivalent to solving a large linear system defined by a dense matrix. We derive an approximate algorithm to compute such a solution interactively by taking advantage of the inherent structure of the matrix. We demonstrate our approach by editing images, HDR radiance maps, and measured materials. Finally, we show that our framework generalizes prior methods while providing significant improvements in generality, robustness and efficiency.", 
        "id": 668, 
        "title": "AppProp: all-pairs appearance-space edit propagation."
    }, 
    {
        "abstract": "", 
        "id": 669, 
        "title": "Motion overview of human actions."
    }, 
    {
        "abstract": "", 
        "id": 670, 
        "title": "Time-resolved 3d capture of non-stationary gas flows."
    }, 
    {
        "abstract": "Extraction of curve-skeletons is a fundamental problem with many applications in computer graphics and visualization. In this paper, we present a simple and robust skeleton extraction method based on mesh contraction. The method works directly on the mesh domain, without pre-sampling the mesh model into a volumetric representation. The method first contracts the mesh geometry into a zero-volume skeletal shape by applying implicit Laplacian smoothing with global positional constraints. The contraction does not alter the mesh connectivity and retains the key features of the original mesh. The contracted mesh is then converted into a 1D curveskeleton through a connectivity surgery process to remove all the collapsed faces while preserving the shape of the contracted mesh and the original topology. The centeredness of the skeleton is refined by exploiting the induced skeleton-mesh mapping. In addition to producing a curve skeleton, the method generates other valuable information about the object's geometry, in particular, the skeletonvertex correspondence and the local thickness, which are useful for various applications. We demonstrate its effectiveness in mesh segmentation and skinning animation. ", 
        "id": 671, 
        "title": "Skeleton extraction by mesh contraction."
    }, 
    {
        "abstract": "The diversity of display technologies and introduction of high dynamic range imagery introduces the necessity of comparing images of radically different dynamic ranges. Current quality assessment metrics are not suitable for this task, as they assume that both reference and test images have the same dynamic range. Image fidelity measures employed by a majority of current metrics, based on the difference of pixel intensity or contrast values between test and reference images, result in meaningless predictions if this assumption does not hold. We present a novel image quality metric capable of operating on an image pair where both images have arbitrary dynamic ranges. Our metric utilizes a model of the human visual system, and its central idea is a new definition of visible distortion based on the detection and classification of visible changes in the image structure. Our metric is carefully calibrated and its performance is validated through perceptual experiments. We demonstrate possible applications of our metric to the evaluation of direct and inverse tone mapping operators as well as the analysis of the image appearance on displays with various characteristics. ", 
        "id": 672, 
        "title": "Dynamic range independent image quality assessment."
    }, 
    {
        "abstract": "", 
        "id": 673, 
        "title": "Extracting depth and matte using a color-filtered aperture."
    }, 
    {
        "abstract": "", 
        "id": 674, 
        "title": "Real-time control of physically based simulations using gentle forces."
    }, 
    {
        "abstract": "", 
        "id": 675, 
        "title": "Video puppetry: a performative interface for cutout animation."
    }, 
    {
        "abstract": "", 
        "id": 676, 
        "title": "A precomputed polynomial representation for interactive BRDF editing with global illumination."
    }, 
    {
        "abstract": "We present a discrete treatment of adapted framed curves, parallel transport, and holonomy, thus establishing the language for a discrete geometric model of thin flexible rods with arbitrary cross section and undeformed configuration. Our approach differs from existing simulation techniques in the graphics and mechanics literature both in the kinematic description--we represent the material frame by its angular deviation from the natural Bishop frame-- as well as in the dynamical treatment--we treat the centerline as dynamic and the material frame as quasistatic. Additionally, we describe a manifold projection method for coupling rods to rigidbodies and simultaneously enforcing rod inextensibility. The use of quasistatics and constraints provides an efficient treatment for stiff twisting and stretching modes; at the same time, we retain the dynamic bending of the centerline and accurately reproduce the coupling between bending and twisting modes. We validate the discrete rod model via quantitative buckling, stability, and coupled-mode experiments, and via qualitative knot-tying comparisons.  Notably lacking is the application of DDG to physical modeling of elastic rods--curve-like elastic bodies that have one dimension (\"length\") much larger than the others (\"cross-section\"). Rods have many interesting potential applications in animating knots, sutures, plants, and even kinematic skeletons. They are ideal for modeling deformations characterized by stretching, bending, and twisting. Stretching and bending are captured by the deformation of a curve called the centerline, while twisting is captured by the rotation of a material frame associated to each point on the centerline. 1.1 Goals and contributions Our goal is to develop a principled model that is (a) simple to implement and efficient to execute and (b) easy to validate and test for convergence, in the sense that solutions to static problems and trajectories of dynamic problems in the discrete setup approach the solutions of the corresponding smooth problem. In pursuing this goal, this paper advances our understanding of discrete differential geometry, physical modeling, and physical simulation.  ", 
        "id": 677, 
        "title": "Discrete elastic rods."
    }, 
    {
        "abstract": "", 
        "id": 678, 
        "title": "Superimposing dynamic range."
    }, 
    {
        "abstract": "In this paper, we present a complete system for automatic face replacement in images. Our system uses a large library of face images created automatically by downloading images from the internet, extracting faces using face detection software, and aligning each extracted face to a common coordinate system. This library is constructed off-line, once, and can be efficiently accessed during face replacement. Our replacement algorithm has three main stages. First, given an input image, we detect all faces that are present, align them to the coordinate system used by our face library, and select candidate face images from our face library that are similar to the input face in appearance and pose. Second, we adjust the pose, lighting, and color of the candidate face images to match the appearance of those in the input image, and seamlessly blend in the results. Third, we rank the blended candidate replacements by computing a match distance over the overlap region. Our approach requires no 3D model, is fully automatic, and generates highly plausible results across a wide range of skin tones, lighting conditions, and viewpoints. We show how our approach can be used for a variety of applications including face de-identification and the creation of appealing group photographs from a set of images. We conclude with a user study that validates the high quality of our replacement results, and a discussion on the current limitations of our system. ", 
        "id": 679, 
        "title": "Face swapping: automatically replacing faces in photographs."
    }, 
    {
        "abstract": " M modes {{ ... { { {{ Amplitude  Audio rendering of impact sounds, such as those caused by falling objects or explosion debris, adds realism to interactive 3D audiovisual applications, and can be convincingly achieved using modal sound synthesis. Unfortunately, mode-based computations can become prohibitively expensive when many objects, each with many modes, are impacted simultaneously. We introduce a fast sound synthesis approach, based on short-time Fourier Tranforms, that exploits the inherent sparsity of modal sounds in the frequency domain. For our test scenes, this \"fast mode summation\" can give speedups of 5-8 times compared to a time-domain solution, with slight degradation in quality. We discuss different reconstruction windows, affecting the quality of impact sound \"attacks\". Our Fourier-domain processing method allows us to introduce a scalable, real-time, audio processing pipeline for both recorded and modal sounds, with auditory masking and sound source clustering. To avoid abrupt computation peaks, such as during the simultaneous impacts of an explosion, we use crossmodal perception results on audiovisual synchrony to effect temporal scheduling. We also conducted a pilot perceptual user evaluation of our method. Our implementation results show that we can treat complex audiovisual scenes in real time with high quality. ", 
        "id": 680, 
        "title": "Fast modal sounds with scalable frequency-domain synthesis."
    }, 
    {
        "abstract": "", 
        "id": 681, 
        "title": "Phong Tessellation."
    }, 
    {
        "abstract": "A lot of research has recently focused on the problem of capturing the geometry and motion of garments. Such work usually relies on special markers printed on the fabric to establish temporally coherent correspondences between points on the garment's surface at different times. Unfortunately, this approach is tedious and prevents the capture of off-the-shelf clothing made from interesting fabrics.  In this paper, we describe a marker-free approach to capturing garment motion that avoids these downsides. We establish temporally coherent parameterizations between incomplete geometries that we extract at each timestep with a multiview stereo algorithm. We then fill holes in the geometry using a template. This approach, for the first time, allows us to capture the geometry and motion of unpatterned, off-the-shelf garments made from a range of different fabrics.  ", 
        "id": 682, 
        "title": "Markerless garment capture."
    }, 
    {
        "abstract": "Although mature technologies exist for acquiring images, geometry, and normals of small objects, they remain cumbersome and time-consuming for non-experts to employ on a large scale. In an archaeological setting, a practical acquisition system for routine use on every artifact and fragment would open new possibilities for archiving, analysis, and dissemination. We present an inexpensive system for acquiring all three types of information, and associated metadata, for small objects such as fragments of wall paintings. The acquisition system requires minimal supervision, so that a single, non-expert user can scan at least 10 fragments per hour. To achieve this performance, we introduce new algorithms to robustly and automatically align range scans, register 2-D scans to 3-D geometry, and compute normals from 2-D scans. As an illustrative application, we present a novel 3-D matching algorithm that efficiently searches for matching fragments using the scanned geometry. ", 
        "id": 683, 
        "title": "A system for high-volume acquisition and matching of fresco fragments: reassembling Theran wall paintings."
    }, 
    {
        "abstract": "", 
        "id": 684, 
        "title": "Adaptive cutaways for comprehensible rendering of polygonal scenes."
    }, 
    {
        "abstract": "This paper addresses the problem of interactively modeling large street networks. We introduce an intuitive and flexible modeling framework in which a user can create a street network from scratch or modify an existing street network. This is achieved through designing an underlying tensor field and editing the graph representing the street network. The framework is intuitive because it uses tensor fields to guide the generation of a street network. The framework is flexible because it allows the user to combine various global and local modeling operations such as brush strokes, smoothing, constraints, noise and rotation fields. Our results will show street networks and three-dimensional urban geometry of high visual quality.", 
        "id": 685, 
        "title": "Interactive procedural street modeling."
    }, 
    {
        "abstract": "", 
        "id": 686, 
        "title": "Sketching reality: Realistic interpretation of architectural designs."
    }, 
    {
        "abstract": "", 
        "id": 687, 
        "title": "Sketch-based tree modeling using Markov random field."
    }, 
    {
        "abstract": "", 
        "id": 688, 
        "title": "Fast, realistic lighting and material design using nonlinear cut approximation."
    }, 
    {
        "abstract": "Illusory motion in a still image is a fascinating research topic in the study of human motion perception. Physiologists and psychologists have attempted to understand this phenomenon by constructing simple, color repeated asymmetric patterns (RAP) and have found several useful rules to enhance the strength of illusory motion. Based on their knowledge, we propose a computational method to generate self-animating images. First, we present an optimized RAP placement on streamlines to generate illusory motion for a given static vector field. Next, a general coloring scheme for RAP is proposed to render streamlines. Furthermore, to enhance the strength of illusion and respect the shape of the region, a smooth vector field with opposite directional flow is automatically generated given an input image. Examples generated by our method are shown as evidence of the illusory effect and the potential applications for entertainment and design purposes. ", 
        "id": 689, 
        "title": "Self-animating images: illusory motion using repeated asymmetric patterns."
    }, 
    {
        "abstract": "Motivated by perceptual principles, we derive a new color space in which the associated metric approximates perceived distances and color displacements capture relationships that are robust to spectral changes in illumination. The resulting color space can be used with existing image processing algorithms with little or no change to the methods. ", 
        "id": 690, 
        "title": "A perception-based color space for illumination-invariant image processing."
    }, 
    {
        "abstract": "This paper presents the results of a study in which artists made line drawings intended to convey specific 3D shapes. The study was designed so that drawings could be registered with rendered images of 3D models, supporting an analysis of how well the locations of the artists' lines correlate with other artists', with current computer graphics line definitions, and with the underlying differential properties of the 3D surface. Lines drawn by artists in this study largely overlapped one another (75% are within 1mm of another line), particularly along the occluding contours of the object. Most lines that do not overlap contours overlap large gradients of the image intensity, and correlate strongly with predictions made by recent line drawing algorithms in computer graphics. 14% were not well described by any of the local properties considered in this study. The result of our work is a publicly available data set of aligned drawings, an analysis of where lines appear in that data set based on local properties of 3D models, and algorithms to predict where artists will draw lines for new scenes. ", 
        "id": 691, 
        "title": "Where do people draw lines?"
    }, 
    {
        "abstract": "", 
        "id": 692, 
        "title": "Synthesis of constrained walking skills."
    }, 
    {
        "abstract": "We present a novel image-based method for compositing real and synthetic objects in the same scene with a high degree of visual realism. Ours is the first technique to allow global illumination and near-field lighting effects between both real and synthetic objects at interactive rates, without needing a geometric and material model of the real scene. We achieve this by using a light field interface between real and synthetic components—thus, indirect illumination can be simulated using only two 4D light fields, one captured from and one projected onto the real scene. Multiple bounces of interreflections are obtained simply by iterating this approach. The interactivity of our technique enables its use with time-varying scenes, including dynamic objects. This is in sharp contrast to the alternative approach of using 6D or 8D light transport functions of real objects, which are very expensive in terms of acquisition and storage and hence not suitable for real-time applications. In our method, 4D radiance fields are simultaneously captured and projected by using a lens array, video camera, and digital projector. The method supports full global illumination with restricted object placement, and accommodates moderately specular materials. We implement a complete system and show several example scene compositions that demonstrate global illumination effects between dynamic real and synthetic objects. Our implementation requires a single point light source and dark background.",
        "id": 693,
        "title": "Light field transfer: global illumination between real and synthetic objects."
    }, 
    {
        "abstract": "", 
        "id": 694, 
        "title": "Quadrilateral mesh simplification."
    }, 
    {
        "abstract": " Many applications such as topology repair, model editing, surface parameterization, and feature recognition benefit from computing loops on surfaces that wrap around their `handles' and `tunnels'. Computing such loops while optimizing their geometric lengths is difficult. On the other hand, computing such loops without considering geometry is easy but may not be very useful. In this paper we strike a balance by computing topologically correct loops that are also geometrically relevant. Our algorithm is a novel application of the concepts from topological persistence introduced recently in computational topology. The usability of the computed loops is demonstrated with some examples in feature identification and topology simplification. ", 
        "id": 695, 
        "title": "Computing geometry-aware handle and tunnel loops in 3D models."
    }, 
    {
        "abstract": "", 
        "id": 696, 
        "title": "Laughing out loud: control for modeling anatomically inspired laughter using audio."
    }, 
    {
        "abstract": "Clouds play an important role for creating realistic images of outdoor scenes. In order to generate realistic clouds, many methods have been developed for modeling and animating clouds. One of the most effective approaches for synthesizing realistic clouds is to simulate cloud formation processes based on the atmospheric fluid dynamics. Although this approach can create realistic clouds, the resulting shapes and motion depend on many simulation parameters and the initial status. Therefore, it is very difficult to adjust those parameters so that the clouds form the desired shapes. This paper addresses this problem and presents a method for controlling the simulation of cloud formation. In this paper, we focus on controlling cumuliform cloud formation. The user specifies the overall shape of the clouds. Then, our method automatically adjusts parameters during the simulation in order to generate clouds forming the specified shape. Our method can generate realistic clouds while their shapes closely match to the desired shape. ", 
        "id": 697, 
        "title": "Feedback control of cumuliform cloud formation based on computational fluid dynamics."
    }, 
    {
        "abstract": "", 
        "id": 698, 
        "title": "A layered, heterogeneous reflectance model for acquiring and rendering human skin."
    }, 
    {
        "abstract": "We present a new discretization for the physics-based animation of developable surfaces. Constrained to not deform at all in-plane but free to bend out-of-plane, these are an excellent approximation for many materials, including most cloth, paper, and stiffer materials. Unfortunately the conforming (geometrically continuous) discretizations used in graphics break down in this limit. Our nonconforming approach solves this problem, allowing us to simulate surfaces with zero in-plane deformation as a hard constraint. However, it produces discontinuous meshes, so we further couple this with a \"ghost\" conforming mesh for collision processing and rendering. We also propose a new second order accurate constrained mechanics time integration method that greatly reduces the numerical damping present in the usual first order methods used in graphics, for virtually no extra cost and sometimes significant speed-up. ", 
        "id": 699, 
        "title": "Animating developable surfaces using nonconforming elements."
    }, 
    {
        "abstract": "Many recent computational photography techniques decompose an image into a piecewise smooth base layer, containing large scale variations in intensity, and a residual detail layer capturing the smaller scale details in the image. In many of these applications, it is important to control the spatial scale of the extracted details, and it is often desirable to manipulate details at multiple scales, while avoiding visual artifacts. In this paper we introduce a new way to construct edge-preserving multi-scale image decompositions. We show that current base-detail decomposition techniques, based on the bilateral filter, are limited in their ability to extract detail at arbitrary scales. Instead, we advocate the use of an alternative edge-preserving smoothing operator, based on the weighted least squares optimization framework, which is particularly well suited for progressive coarsening of images and for multi-scale detail extraction. After describing this operator, we show how to use it to construct edge-preserving multi-scale decompositions, and compare it to the bilateral filter, as well as to other schemes. Finally, we demonstrate the effectiveness of our edge-preserving decompositions in the context of LDR and HDR tone mapping, detail enhancement, and other applications.", 
        "id": 700, 
        "title": "Edge-preserving decompositions for multi-scale tone and detail manipulation."
    }, 
    {
        "abstract": "In this paper we present a new method for estimating the optical transmission in hazy scenes given a single input image. Based on this estimation, the scattered light is eliminated to increase scene visibility and recover haze-free scene contrasts. In this new approach we formulate a refined image formation model that accounts for surface shading in addition to the transmission function. This allows us to resolve ambiguities in the data by searching for a solution in which the resulting shading and transmission functions are locally statistically uncorrelated. A similar principle is used to estimate the color of the haze. Results demonstrate the new method abilities to remove the haze layer as well as provide a reliable transmission estimate which can be used for additional applications such as image refocusing and novel view synthesis. ", 
        "id": 701, 
        "title": "Single image dehazing."
    }, 
    {
        "abstract": "Achieving intuitive control of animated surface deformation while observing a specific style is an important but challenging task in computer graphics. Solutions to this task can find many applications in data-driven skin animation, computer puppetry, and computer games. In this paper, we present an intuitive and powerful animation interface to simultaneously control the deformation of a large number of local regions on a deformable surface with a minimal number of control points. Our method learns suitable deformation subspaces from training examples, and generate new deformations on the fly according to the movements of the control points. Our contributions include a novel deformation regression method based on kernel Canonical Correlation Analysis (CCA) and a Poisson-based translation solving technique for easy and fast deformation control based on examples. Our run-time algorithm can be implemented on GPUs and can achieve a few hundred frames per second even for large datasets with hundreds of training examples.  ", 
        "id": 702, 
        "title": "Real-time data driven deformation using kernel canonical correlation analysis."
    }, 
    {
        "abstract": "", 
        "id": 703, 
        "title": "A psychophysically validated metric for bidirectional texture data reduction."
    }, 
    {
        "abstract": "Humans usually associate an upright orientation with objects, placing them in a way that they are most commonly seen in our surroundings. While it is an open challenge to recover the functionality of a shape from its geometry alone, this paper shows that it is often possible to infer its upright orientation by analyzing its geometry. Our key idea is to reduce the two-dimensional (spherical) orientation space to a small set of orientation candidates using functionality-related geometric properties of the object, and then determine the best orientation using an assessment function of several functional geometric attributes defined with respect to each candidate. Specifically we focus on obtaining the upright orientation for man-made objects that typically stand on some flat surface (ground, floor, table, etc.), which include the vast majority of objects in our everyday surroundings. For these types of models orientation candidates can be defined according to static equilibrium. For each candidate, we introduce a set of discriminative attributes linking shape to function. We learn an assessment function of these attributes from a training set using a combination of Random Forest classifier and Support Vector Machine classifier. Experiments demonstrate that our method generalizes well and achieves about 90% prediction accuracy for both a 10-fold cross-validation over the training set and a validation with an independent test set. ", 
        "id": 704, 
        "title": "Upright orientation of man-made objects."
    }, 
    {
        "abstract": " Traditional flat screen displays present 2D images. 3D and 4D displays have been proposed making use of lenslet arrays to shape a fixed outgoing light field for horizontal or bidirectional parallax. In this article, we present different designs of multi-dimensional displays which passively react to the light of the environment behind. The prototypes physically implement a reflectance field and generate different light fields depending on the incident illumination, for example light falling through a window. We discretize the incident light field using an optical system, and modulate it with a 2D pattern, creating a flat display which is view and illuminationdependent. It is free from electronic components. For distant light and a fixed observer position, we demonstrate a passive optical configuration which directly renders a 4D reflectance field in the realworld illumination behind it. We further propose an optical setup that allows for projecting out different angular distributions depending on the incident light direction. Combining multiple of these devices we build a display that renders a 6D experience, where the incident 2D illumination influences the outgoing light field, both in the spatial and in the angular domain. Possible applications of this technology are time-dependent displays driven by sunlight, object virtualization and programmable light benders / ray blockers without moving parts. ", 
        "id": 705, 
        "title": "Towards passive 6D reflectance field displays."
    }, 
    {
        "abstract": "", 
        "id": 706, 
        "title": "A survey of spatial deformation from a user-centered perspective."
    }, 
    {
        "abstract": "", 
        "id": 707, 
        "title": "IGT: inverse geometric textures."
    }, 
    {
        "abstract": "", 
        "id": 708, 
        "title": "Practical modeling and acquisition of layered facial reflectance."
    }, 
    {
        "abstract": " We present a system for free- form surface modeling that allows a user to modify a shape by changing its rendered, shaded image using stroke- based drawing tools. User input is translated into a set of tangent and positional constraints on the surface. A new shape, whose rendered image closely approximates user input, is computed using an efficient and stable surface optimization procedure. We demonstrate how several types of free- form surface edits which may be difficult to cast in terms of standard deformation approaches can be easily performed using our system.  Figure 1: In our system, users edit 3D models by drawing 2D shading strokes.  ", 
        "id": 709, 
        "title": "Shading-based surface editing."
    }, 
    {
        "abstract": "Capturing detailed surface geometry currently requires specialized equipment such as laser range scanners, which despite their high accuracy, leave gaps in the surfaces that must be reconciled with photographic capture for relighting applications. Using only a standard digital camera and a single view, we present a method for recovering models of predominantly diffuse textured surfaces that can be plausibly relit and viewed from any angle under any illumination. Our multiscale shape-from-shading technique uses diffuse-lit/flash-lit image pairs to produce an albedo map and textured height field. Using two lighting conditions enables us to subtract one from the other to estimate albedo. In the absence of a flash-lit image of a surface for which we already have a similar exemplar pair, we approximate both albedo and diffuse shading images using histogram matching. Our depth estimation is based on local visibility. Unlike other depth-from-shading approaches, all operations are performed on the diffuse shading image in image space, and we impose no constant albedo restrictions. An experimental validation shows our method works for a broad range of textured surfaces, and viewers are frequently unable to identify our results as synthetic in a randomized presentation. Furthermore, in side-by-side comparisons, subjects found a rendering of our depth map equally plausible to one generated from a laser range scan. We see this method as a significant advance in acquiring surface detail for texturing using a standard digital camera, with applications in architecture, archaeological reconstruction, games and special effects.", 
        "id": 710, 
        "title": "A perceptually validated model for surface depth hallucination."
    }, 
    {
        "abstract": " to other textures to provide detail and a more natural look.  Programmable graphics hardware makes it possible to generate procedural noise textures on the fly for interactive rendering. However, filtering and antialiasing procedural noise involves a tradeoff between aliasing artifacts and loss of detail. In this paper we present a technique, targeted at interactive applications, that provides highquality anisotropic filtering for noise textures. We generate noise tiles directly in the frequency domain by partitioning the frequency domain into oriented subbands. We then compute weighted sums of the subband textures to accurately approximate noise with a desired spectrum. This allows us to achieve high-quality anisotropic filtering. Our approach is based solely on 2D textures, avoiding the memory overhead of techniques based on 3D noise tiles. We devise a technique to compensate for texture distortions to generate uniform noise on arbitrary meshes. We develop a GPU-based implementation of our technique that achieves similar rendering performance as state-of-the-art algorithms for procedural noise. In addition, it provides anisotropic filtering and achieves superior image quality. ", 
        "id": 711, 
        "title": "Anisotropic noise."
    }, 
    {
        "abstract": "", 
        "id": 712, 
        "title": "Randomized cuts for 3D mesh analysis."
    }, 
    {
        "abstract": "Tourist maps are essential resources for visitors to an unfamiliar city because they visually highlight landmarks and other points of interest. Yet, hand-designed maps are static representations that cannot adapt to the needs and tastes of the individual tourist. In this paper we present an automated system for designing tourist maps that selects and highlights the information that is most important to tourists. Our system determines the salience of map elements using bottom-up vision-based image analysis and top-down webbased information extraction techniques. It then generates a map that emphasizes the most important elements, using a combination of multiperspective rendering to increase visibility of streets and landmarks, and cartographic generalization techniques such as simplification, deformation, and displacement to emphasize landmarks and de-emphasize less important buildings. We show a number of automatically generated tourist maps of San Francisco and compare them to existing automated and manual approaches. ", 
        "id": 713, 
        "title": "Automatic generation of tourist maps."
    }, 
    {
        "abstract": "", 
        "id": 714, 
        "title": "VirtualStudio2Go: digital video composition for real environments."
    }, 
    {
        "abstract": "", 
        "id": 715, 
        "title": "Depicting procedural caustics in single images."
    }, 
    {
        "abstract": "We present a new adaptive sampling strategy for ray tracing. Our technique is specifically designed to handle multidimensional sample domains, and it is well suited for efficiently generating images with effects such as soft shadows, motion blur, and depth of field. These effects are problematic for existing image based adaptive sampling techniques as they operate on pixels, which are possibly noisy results of a Monte Carlo ray tracing process. Our sampling technique operates on samples in the multidimensional space given by the rendering equation and as a consequence the value of each sample is noise-free. Our algorithm consists of two passes. In the first pass we adaptively generate samples in the multidimensional space, focusing on regions where the local contrast between samples is high. In the second pass we reconstruct the image by integrating the multidimensional function along all but the image dimensions. We perform a high quality anisotropic reconstruction by determining the extent of each sample in the multidimensional space using a structure tensor. We demonstrate our method on scenes with a 3 to 5 dimensional space, including soft shadows, motion blur, and depth of field. The results show that our method uses fewer samples than Mittchell's adaptive sampling technique while producing images with less noise. ", 
        "id": 716, 
        "title": "Multidimensional adaptive sampling and reconstruction for ray tracing."
    }, 
    {
        "abstract": "", 
        "id": 717, 
        "title": "Progressive photon mapping."
    }, 
    {
        "abstract": "Example-based texture synthesis algorithms have gained widespread popularity for their ability to take a single input image and create a perceptually similar non-periodic texture. However, previous methods rely on single input exemplars that can capture only a limited band of spatial scales. For example, synthesizing a continent-like appearance at a variety of zoom levels would require an impractically high input resolution. In this paper, we develop a multiscale texture synthesis algorithm. We propose a novel example-based representation, which we call an exemplar graph, that simply requires a few low-resolution input exemplars at different scales. Moreover, by allowing loops in the graph, we can create infinite zooms and infinitely detailed textures that are impossible with current example-based methods. We also introduce a technique that ameliorates inconsistencies in the user's input, and show that the application of this method yields improved interscale coherence and higher visual quality. We demonstrate optimizations for both CPU and GPU implementations of our method, and use them to produce animations with zooming and panning at multiple scales, as well as static gigapixel-sized images with features spanning many spatial scales. ", 
        "id": 718, 
        "title": "Multiscale texture synthesis."
    }, 
    {
        "abstract": "Robust treatment of complex collisions is a challenging problem in cloth simulation. Some state of the art methods resolve collisions iteratively, invoking a fail-safe when a bound on iteration count is exceeded. The best-known fail-safe rigidifies the contact region, causing simulation artifacts. We present a fail-safe that cancels impact but not sliding motion, considerably reducing artificial dissipation. We equip the proposed fail-safe with an approximation of Coulomb friction, allowing finer control of sliding dissipation. ", 
        "id": 719, 
        "title": "Robust treatment of simultaneous collisions."
    }, 
    {
        "abstract": "Character animation in video games--whether manually keyframed or motion captured--has traditionally relied on codifying skeletons early in a game's development, and creating animations rigidly tied to these fixed skeleton morphologies. This paper introduces a novel system for animating characters whose morphologies are unknown at the time the animation is created. Our authoring tool allows animators to describe motion using familiar posing and key-framing methods. The system records the data in a morphology-independent form, preserving both the animation's structural relationships and its stylistic information. At runtime, the generalized data are applied to specific characters to yield pose goals that are supplied to a robust and efficient inverse kinematics solver. This system allows us to animate characters with highly varying skeleton morphologies that did not exist when the animation was authored, and, indeed, may be radically different than anything the original animator envisioned. ", 
        "id": 720, 
        "title": "Real-time motion retargeting to highly varied user-created morphologies."
    }, 
    {
        "abstract": "", 
        "id": 721, 
        "title": "A photometric approach for estimating normals and tangents."
    }, 
    {
        "abstract": " We propose a hybrid method for simulating multiphase fluids such as bubbly water. The appearance of subgrid visual details is improved by incorporating a new bubble model based on smoothed particle hydrodynamics (SPH) into an Eulerian grid-based simulation that handles background flows of large bodies of water and air. To overcome the difficulty in simulating small bubbles in the context of the multiphase flows on a coarse grid, we heuristically model the interphase properties of water and air by means of the interactions between bubble particles. As a result, we can animate lively motion of bubbly water with small scale details efficiently.  ", 
        "id": 722, 
        "title": "Bubbles alive."
    }, 
    {
        "abstract": "We present BSGP, a new programming language for general purpose computation on the GPU. A BSGP program looks much the same as a sequential C program. Programmers only need to supply a bare minimum of extra information to describe parallel processing on GPUs. As a result, BSGP programs are easy to read, write, and maintain. Moreover, the ease of programming does not come at the cost of performance. A well-designed BSGP compiler converts BSGP programs to kernels and combines them using optimally allocated temporary streams. In our benchmark, BSGP programs achieve similar or better performance than well-optimized CUDA programs, while the source code complexity and programming time are significantly reduced. To test BSGP's code efficiency and ease of programming, we implemented a variety of GPU applications, including a highly sophisticated X3D parser that would be extremely difficult to develop with existing GPU programming languages. ", 
        "id": 723, 
        "title": "BSGP: bulk-synchronous GPU programming."
    }, 
    {
        "abstract": "White balance is a crucial step in the photographic pipeline. It ensures the proper rendition of images by eliminating color casts due to differing illuminants. Digital cameras and editing programs provide white balance tools that assume a single type of light per image, such as daylight. However, many photos are taken under mixed lighting. We propose a white balance technique for scenes with two light types that are specified by the user. This covers many typical situations involving indoor/outdoor or flash/ambient light mixtures. Since we work from a single image, the problem is highly underconstrained. Our method recovers a set of dominant material colors which allows us to estimate the local intensity mixture of the two light types. Using this mixture, we can neutralize the light colors and render visually pleasing images. Our method can also be used to achieve post-exposure relighting effects. ", 
        "id": 724, 
        "title": "Light mixture estimation for spatially varying white balance."
    }, 
    {
        "abstract": "", 
        "id": 725, 
        "title": "Spectral quadrangulation with orientation and alignment control."
    }, 
    {
        "abstract": " The quality of a 3D range scan should not depend on the surface properties of the object. Most active range scanning techniques, however, assume a diffuse reflector to allow for a robust detection of incident light patterns. In our approach we embed the object into a fluorescent liquid. By analyzing the light rays that become visible due to fluorescence rather than analyzing their reflections off the surface, we can detect the intersection points between the projected laser sheet and the object surface for a wide range of different materials. For transparent objects we can even directly depict a slice through the object in just one image by matching its refractive index to the one of the embedding liquid. This enables a direct sampling of the object geometry without the need for computational reconstruction. This way, a high-resolution 3D volume can be assembled simply by sweeping a laser plane through the object. We demonstrate the effectiveness of our light sheet range scanning approach on a set of objects manufactured from a variety of materials and material mixes, including dark, translucent and transparent objects. ", 
        "id": 726, 
        "title": "Fluorescent immersion range scanning."
    }, 
    {
        "abstract": "", 
        "id": 727, 
        "title": "Radiance caching for participating media."
    }, 
    {
        "abstract": "", 
        "id": 728, 
        "title": "Reusable skinning templates using cage-based deformations."
    }, 
    {
        "abstract": "Knitted fabric is widely used in clothing because of its unique and stretchy behavior, which is fundamentally different from the behavior of woven cloth. The properties of knits come from the nonlinear, three-dimensional kinematics of long, inter-looping yarns, and despite significant advances in cloth animation we still do not know how to simulate knitted fabric faithfully. Existing cloth simulators mainly adopt elastic-sheet mechanical models inspired by woven materials, focusing less on the model itself than on important simulation challenges such as efficiency, stability, and robustness. We define a new computational model for knits in terms of the motion of yarns, rather than the motion of a sheet. Each yarn is modeled as an inextensible, yet otherwise flexible, B-spline tube. To simulate complex knitted garments, we propose an implicit-explicit integrator, with yarn inextensibility constraints imposed using efficient projections. Friction among yarns is approximated using rigid-body velocity filters, and key yarn-yarn interactions are mediated by stiff penalty forces. Our results show that this simple model predicts the key mechanical properties of different knits, as demonstrated by qualitative comparisons to observed deformations of actual samples in the laboratory, and that the simulator can scale up to substantial animations with complex dynamic motion. ", 
        "id": 729, 
        "title": "Simulating knitted cloth at the yarn level."
    }, 
    {
        "abstract": "Oscillatory motion is ubiquitous in computer graphics, yet existing animation techniques are ill-suited to its authoring. We introduce a new type of spline for this purpose, known as a \"Wiggly Spline.\" The spline generalizes traditional piecewise cubics when its resonance and damping are set to zero, but creates oscillatory animation when its resonance and damping are changed. The spline provides a combination of direct manipulation and physical realism. To create overlapped and propagating motion, we generate phase shifts of the Wiggly Spline, and use these to control appropriate degrees of freedom in a model. The phase shifts can be created directly by procedural techniques or through a paint-like interface. A further option is to derive the phase shifts statistically by analyzing a time-series of a simulation. In this case, the Wiggly Spline makes it possible to canonicalize a simulation, generalize it by providing frequency and damping controls and control it through direct manipulation. ", 
        "id": 730, 
        "title": "Animating oscillatory motion with overlap: wiggly splines."
    }, 
    {
        "abstract": "", 
        "id": 731, 
        "title": "Staggered projections for frictional contact in multibody systems."
    }, 
    {
        "abstract": "", 
        "id": 732, 
        "title": "Geometric skinning with approximate dual quaternion blending."
    }, 
    {
        "abstract": "We introduce a new tool to solve the large linear systems arising from gradient-domain image processing. Specifically, we develop a streaming multigrid solver, which needs just two sequential passes over out-of-core data. This fast solution is enabled by a combination of three techniques: (1) use of second-order finite elements (rather than traditional finite differences) to reach sufficient accuracy in a single V-cycle, (2) temporally blocked relaxation, and (3) multi-level streaming to pipeline the restriction and prolongation phases into single streaming passes. A key contribution is the extension of the B-spline finite-element method to be compatible with the forward-difference gradient representation commonly used with images. Our streaming solver is also efficient for inmemory images, due to its fast convergence and excellent cache behavior. Remarkably, it can outperform spatially adaptive solvers that exploit application-specific knowledge. We demonstrate seamless stitching and tone-mapping of gigapixel images in about an hour on a notebook PC. ", 
        "id": 733, 
        "title": "Streaming multigrid for gradient-domain operations on large images."
    }, 
    {
        "abstract": "Fascinating and elegant shapes may be folded from a single planar sheet of material without stretching, tearing or cutting, if one incorporates curved folds into the design. We present an optimizationbased computational framework for design and digital reconstruction of surfaces which can be produced by curved folding. Our work not only contributes to applications in architecture and industrial design, but it also provides a new way to study the complex and largely unexplored phenomena arising in curved folding. ", 
        "id": 734, 
        "title": "Curved folding."
    }, 
    {
        "abstract": "We present a novel wavelet method for the simulation of fluids at high spatial resolution. The algorithm enables large- and smallscale detail to be edited separately, allowing high-resolution detail to be added as a post-processing step. Instead of solving the Navier-Stokes equations over a highly refined mesh, we use the wavelet decomposition of a low-resolution simulation to determine the location and energy characteristics of missing high-frequency components. We then synthesize these missing components using a novel incompressible turbulence function, and provide a method to maintain the temporal coherence of the resulting structures. There is no linear system to solve, so the method parallelizes trivially and requires only a few auxiliary arrays. The method guarantees that the new frequencies will not interfere with existing frequencies, allowing animators to set up a low resolution simulation quickly and later add details without changing the overall fluid motion. ", 
        "id": 735, 
        "title": "Wavelet turbulence for fluid simulation."
    }, 
    {
        "abstract": "", 
        "id": 736, 
        "title": "Line-art illustration of dynamic and specular surfaces."
    }, 
    {
        "abstract": "", 
        "id": 737, 
        "title": "Free-form motion processing."
    }, 
    {
        "abstract": "", 
        "id": 738, 
        "title": "Demarcating curves for shape illustration."
    }, 
    {
        "abstract": "", 
        "id": 739, 
        "title": "Deep photo: model-based photograph enhancement and viewing."
    }, 
    {
        "abstract": "", 
        "id": 740, 
        "title": "Non-homogeneous resizing of complex models."
    }, 
    {
        "abstract": "Animating a crowd of characters is an important problem in computer graphics. The latest techniques enable highly realistic group motions to be produced in feature animation films and video games. However, interactive methods have not emerged yet for editing the existing group motion of multiple characters. We present an approach to editing group motion as a whole while maintaining its neighborhood formation and individual moving trajectories in the original animation as much as possible. The user can deform a group motion by pinning or dragging individuals. Multiple group motions can be stitched or merged to form a longer or larger group motion while avoiding collisions. These editing operations rely on a novel graph structure, in which vertices represent positions of individuals at specific frames and edges encode neighborhood formations and moving trajectories. We employ a shape-manipulation technique to minimize the distortion of relative arrangements among adjacent vertices while editing the graph structure. The usefulness and flexibility of our approach is demonstrated through examples in which the user creates and edits complex crowd animations interactively using a collection of group motion clips.", 
        "id": 741, 
        "title": "Group motion editing."
    }, 
    {
        "abstract": "", 
        "id": 742, 
        "title": "Shield fields: modeling and capturing 3D occluders."
    }, 
    {
        "abstract": "Spline joints are a novel class of joints that can model general scleronomic constraints for multibody dynamics based on the minimalcoordinates formulation. The main idea is to introduce spline curves and surfaces in the modeling of joints: We model 1-DOF joints using splines on SE(3), and construct multi-DOF joints as the product of exponentials of splines in Euclidean space. We present efficient recursive algorithms to compute the derivatives of the spline joint, as well as geometric algorithms to determine optimal parameters in order to achieve the desired joint motion. Our spline joints can be used to create interesting new simulated mechanisms for computer animation and they can more accurately model complex biomechanical joints such as the knee and shoulder. ", 
        "id": 743, 
        "title": "Spline joints for multibody dynamics."
    }, 
    {
        "abstract": "We introduce a meshless hierarchical representation for solving light transport problems. Precomputed radiance transfer (PRT) and finite elements require a discrete representation of illumination over the scene. Non-hierarchical approaches such as per-vertex values are simple to implement, but lead to long precomputation. Hierarchical bases like wavelets lead to dramatic acceleration, but in their basic form they work well only on flat or smooth surfaces. We introduce a hierarchical function basis induced by scattered data approximation. It is decoupled from the geometric representation, allowing the hierarchical representation of illumination on complex objects. We present simple data structures and algorithms for constructing and evaluating the basis functions. Due to its hierarchical nature, our representation adapts to the complexity of the illumination, and can be queried at different scales. We demonstrate the power of the new basis in a novel precomputed direct-to-indirect light transport algorithm that greatly increases the complexity of scenes that can be handled by PRT approaches. ", 
        "id": 744, 
        "title": "A meshless hierarchical representation for light transport."
    }, 
    {
        "abstract": "This paper presents the simulation of a fluid flowing through a porous deformable material. We introduce the physical principles governing porous flow, expressed by the Law of Darcy, into the Smoothed Particle Hydrodynamics (SPH) framework for simulating fluids and deformable objects. Contrary to previous SPH approaches, we simulate porous flow at a macroscopic scale, making abstraction of individual pores or cavities inside the material. Thus, the number of computational elements is kept low, while at the same time realistic simulations can be achieved. Our algorithm models the changing behavior of the wet material as well as the full two-way coupling between the fluid and the porous material. This enables various new effects, such as the simulation of sponge-like elastic bodies and water-absorbing sticky cloth. ", 
        "id": 745, 
        "title": "Porous flow in particle-based fluid simulations."
    }, 
    {
        "abstract": "", 
        "id": 746, 
        "title": "SOHO: Orthogonal and symmetric Haar wavelets on the sphere."
    }, 
    {
        "abstract": "Object motion during camera exposure often leads to noticeable blurring artifacts. Proper elimination of this blur is challenging because the blur kernel is unknown, varies over the image as a function of object velocity, and destroys high frequencies. In the case of motions along a 1D direction (e.g. horizontal) we show that these challenges can be addressed using a camera that moves during the exposure. Through the analysis of motion blur as space-time integration, we show that a parabolic integration (corresponding to constant sensor acceleration) leads to motion blur that is invariant to object velocity. Thus, a single deconvolution kernel can be used to remove blur and create sharp images of scenes with objects moving at different speeds, without requiring any segmentation and without knowledge of the object speeds. Apart from motion invariance, we prove that the derived parabolic motion preserves image frequency content nearly optimally. That is, while static objects are degraded relative to their image from a static camera, a reliable reconstruction of all moving objects within a given velocities range is made possible. We have built a prototype camera and present successful deblurring results over a wide variety of human motions. ", 
        "id": 747, 
        "title": "Motion-invariant photography."
    }, 
    {
        "abstract": " When human raters are presented with a collection of shapes and asked to rank them according to their aesthetic appeal, the results often indicate that there is a statistical consensus among the raters. Yet it might be difficult to define a succinct set of rules that capture the aesthetic preferences of the raters. In this work, we explore a data-driven approach to aesthetic enhancement of such shapes. Specifically, we focus on the challenging problem of enhancing the aesthetic appeal (or the attractiveness) of human faces in frontal photographs (portraits), while maintaining close similarity with the original. The key component in our approach is an automatic facial attractiveness engine trained on datasets of faces with accompanying facial attractiveness ratings collected from groups of human raters. Given a new face, we extract a set of distances between a variety of facial feature locations, which define a point in a high-dimensional \"face space\". We then search the face space for a nearby point with a higher predicted attractiveness rating. Once such a point is found, the corresponding facial distances are embedded in the plane and serve as a target to define a 2D warp field which maps the original facial features to their adjusted locations. The effectiveness of our technique was experimentally validated by independent rating experiments, which indicate that it is indeed capable of increasing the facial attractiveness of most portraits that we have experimented with.  ", 
        "id": 748, 
        "title": "Data-driven enhancement of facial attractiveness."
    }, 
    {
        "abstract": "We present a system for creating and viewing interactive exploded views of complex 3D models. In our approach, a 3D input model is organized into an explosion graph that encodes how parts explode with respect to each other. We present an automatic method for computing explosion graphs that takes into account part hierarchies in the input models and handles common classes of interlocking parts. Our system also includes an interface that allows users to interactively explore our exploded views using both direct controls and higher-level interaction modes.  ", 
        "id": 749, 
        "title": "Automated generation of interactive 3D exploded view diagrams."
    }, 
    {
        "abstract": "In this paper, we present a system including a novel component called programmable aperture and two associated post-processing algorithms for high-quality light field acquisition. The shape of the programmable aperture can be adjusted and used to capture light field at full sensor resolution through multiple exposures without any additional optics and without moving the camera. High acquisition efficiency is achieved by employing an optimal multiplexing scheme, and quality data is obtained by using the two postprocessing algorithms designed for self calibration of photometric distortion and for multi-view depth estimation. View-dependent depth maps thus generated help boost the angular resolution of light field. Various post-exposure photographic effects are given to demonstrate the effectiveness of the system and the quality of the captured light field. ", 
        "id": 750, 
        "title": "Programmable aperture photography: multiplexed light field acquisition."
    }, 
    {
        "abstract": "", 
        "id": 751, 
        "title": "Deducing interpolating subdivision schemes from approximating subdivision schemes."
    }, 
    {
        "abstract": "We introduce Green Coordinates for closed polyhedral cages. The coordinates are motivated by Green's third integral identity and respect both the vertices position and faces orientation of the cage. We show that Green Coordinates lead to space deformations with a shape-preserving property. In particular, in 2D they induce conformal mappings, and extend naturally to quasi-conformal mappings in 3D. In both cases we derive closed-form expressions for the coordinates, yielding a simple and fast algorithm for cage-based space deformation. We compare the performance of Green Coordinates with those of Mean Value Coordinates and Harmonic Coordinates and show that the advantage of the shape-preserving property is not achieved at the expense of speed or simplicity. We also show that the new coordinates extend the mapping in a natural analytic manner to the exterior of the cage, allowing the employment of partial cages. ", 
        "id": 752, 
        "title": "Green Coordinates."
    }, 
    {
        "abstract": "We introduce a real-time interactive visual editing paradigm for shape grammars, allowing the creation of rulebases from scratch without text file editing. In previous work, shape-grammar based procedural techniques were successfully applied to the creation of architectural models. However, those methods are text based, and may therefore be difficult to use for artists with little computer science background. Therefore the goal was to enable a visual workflow combining the power of shape grammars with traditional modeling techniques. We extend previous shape grammar approaches by providing direct and persistent local control over the generated instances, avoiding the combinatorial explosion of grammar rules for modifications that should not affect all instances. The resulting visual editor is flexible: All elements of a complex state-of-the-art grammar can be created and modified visually. ", 
        "id": 753, 
        "title": "Interactive visual editing of grammars for procedural architecture."
    }, 
    {
        "abstract": "", 
        "id": 754, 
        "title": "Intrinsic colorization."
    }, 
    {
        "abstract": "", 
        "id": 755, 
        "title": "Logarithmic perspective shadow maps."
    }, 
    {
        "abstract": "", 
        "id": 756, 
        "title": "Approximating Catmull-Clark subdivision surfaces with bicubic patches."
    }, 
    {
        "abstract": "", 
        "id": 757, 
        "title": "Facial performance synthesis using deformation-driven polynomial displacement maps."
    }, 
    {
        "abstract": "We propose a tone mapping operator that can minimize visible contrast distortions for a range of output devices, ranging from e-paper to HDR displays. The operator weights contrast distortions according to their visibility predicted by the model of the human visual system. The distortions are minimized given a display model that enforces constraints on the solution. We show that the problem can be solved very efficiently by employing higher order image statistics and quadratic programming. Our tone mapping technique can adjust image or video content for optimum contrast visibility taking into account ambient illumination and display characteristics. We discuss the differences between our method and previous approaches to the tone mapping problem.", 
        "id": 758, 
        "title": "Display adaptive tone mapping."
    }, 
    {
        "abstract": " We present an image editing program which allows artists to paint in the gradient domain with real-time feedback on megapixelsized images. Along with a pedestrian, though powerful, gradientpainting brush and gradient-clone tool, we introduce an edge brush designed for edge selection and replay. These brushes, coupled with special blending modes, allow users to accomplish global lighting and contrast adjustments using only local image manipulations  e.g. strengthening a given edge or removing a shadow boundary. Such operations would be tedious in a conventional intensity-based paint program and hard for users to get right in the gradient domain without real-time feedback. The core of our paint program is a simple-to-implement GPU multigrid method which allows integration of megapixel-sized full-color gradient fields at over 20 frames per second on modest hardware. By way of evaluation, we present example images produced with our program and characterize the iteration time and convergence rate of our integration method. ", 
        "id": 759, 
        "title": "Real-time gradient-domain painting."
    }, 
    {
        "abstract": "When simulating large crowds, it is inevitable that the models and motions of many virtual characters will be cloned. However, the perceptual impact of this trade-off has never been studied. In this paper, we consider the ways in which an impression of variety can be created and the perceptual consequences of certain design choices. In a series of experiments designed to test people's perception of variety in crowds, we found that clones of appearance are far easier to detect than motion clones. Furthermore, we established that cloned models can be masked by color variation, random orientation, and motion. Conversely, the perception of cloned motions remains unaffected by the model on which they are displayed. Other factors that influence the ability to detect clones were examined, such as proximity, model type and characteristic motion. Our results provide novel insights and useful thresholds that will assist in creating more realistic, heterogeneous crowds. ", 
        "id": 760, 
        "title": "Clone attack! Perception of crowd variety."
    }, 
    {
        "abstract": "", 
        "id": 761, 
        "title": "Continuous model synthesis."
    }, 
    {
        "abstract": "Previous research has shown that a global multiple scattering simulation is needed to achieve physically realistic renderings of hair, particularly light-colored hair with low absorption. However, previous methods have either sacrificed accuracy or have been too computationally expensive for practical use. In this paper we describe a physically based, volumetric rendering method that computes multiple scattering solutions, including directional effects, much faster than previous accurate methods. Our two-pass method first traces light paths through a volumetric representation of the hair, contributing power to a 3D grid of spherical harmonic coefficients that store the directional distribution of scattered radiance everywhere in the hair volume. Then, in a ray tracing pass, multiple scattering is computed by integrating the stored radiance against the scattering functions of visible fibers using an efficient matrix multiplication. Single scattering is computed using conventional direct illumination methods. In our comparisons the new method produces quality similar to that of the best previous methods, but computes multiple scattering more than 10 times faster.  Photon mapping methods have proven successful for hair rendering [Moon and Marschner 2006; Zinke 2008], but they are slow and require a large amount of storage for the photons. This paper proposes a new method for computing multiple scattering in hair. Like photon mapping, it uses a light tracing and a ray tracing pass, but it stores the position- and direction-dependent scattered radiance distribution in a 3D grid of coefficients for spherical harmonic basis functions. Compared to a photon map, this representation for radiance is more compact and better organized in memory, and it allows fast integration by sparse matrix multiplication during rendering. At the same time, we avoid the high cost of tracing paths from fiber to fiber by replacing the hair geometry with a voxel grid that stores density and orientation statistics, through which paths are traced by volumetric methods. The end result of adopting smooth representations for the essentially smooth phenomena of volume scattering in hair is that our new method outperforms an implementation of photon mapping based on the same ray tracing infrastructure [Moon and Marschner 2006] by a factor of 20 while achieving results of equivalent quality.  ", 
        "id": 762, 
        "title": "Efficient multiple scattering in hair using spherical harmonics."
    }, 
    {
        "abstract": "", 
        "id": 763, 
        "title": "Fast animation of turbulence using energy transport and procedural synthesis."
    }, 
    {
        "abstract": "", 
        "id": 764, 
        "title": "Gesture modeling and animation based on a probabilistic re-creation of speaker style."
    }, 
    {
        "abstract": "", 
        "id": 765, 
        "title": "Random-access rendering of general vector graphics."
    }, 
    {
        "abstract": "We describe a new vector-based primitive for creating smooth-shaded images, called the diffusion curve. A diffusion curve partitions the space through which it is drawn, defining different colors on either side. These colors may vary smoothly along the curve. In addition, the sharpness of the color transition from one side of the curve to the other can be controlled. Given a set of diffusion curves, the final image is constructed by solving a Poisson equation whose constraints are specified by the set of gradients across all diffusion curves. Like all vector-based primitives, diffusion curves conveniently support a variety of operations, including geometry-based editing, keyframe animation, and ready stylization. Moreover, their representation is compact and inherently resolution-independent. We describe a GPU-based implementation for rendering images defined by a set of diffusion curves in realtime. We then demonstrate an interactive drawing system for allowing artists to create artworks using diffusion curves, either by drawing the curves in a freehand style, or by tracing existing imagery. The system is simple and intuitive: we show results created by artists after just a few minutes of instruction. Furthermore, we describe a completely automatic conversion process for taking an image and turning it into a set of diffusion curves that closely approximate the original image content.", 
        "id": 766, 
        "title": "Diffusion curves: a vector representation for smooth-shaded images."
    }, 
    {
        "abstract": " A close inspection of the texture regions (e.g. Figure 1(b)) reveals  This paper presents an optimization-based halftoning technique that preserves the structure and tone similarities between the original and the halftone images. By optimizing an objective function consisting of both the structure and the tone metrics, the generated halftone images preserve visually sensitive texture details as well  that the halftoning technique destroys the characteristic pattern, and sometimes introduces aliasing artifacts (e.g. Figure 3). Figure 1(c) shows the halftoning result of the technique that we introduce in the paper. As can be clearly seen, this image reproduces the correct tone, and at the same time it is faithful to the original texture look.  as the local tone. It possesses the blue-noise property and does not  Common halftoning techniques suppress the appearance of artifacts  introduce annoying patterns. Unlike the existing edge-enhancement  at the cost of over-blurring fine texture details. Several methods  halftoning, the proposed method does not suffer from the deficiencies of edge detector. Our method is tested on various types of  have been proposed to deal better with texture. These methods [Eschbach and Knox 1991; Hwang et al. 2004; Kwak et al. 2006]  images. In multiple experiments and the user study, our method  rely on edge enhancement techniques. However, edge enhancement  consistently obtains the best scores among all tested methods.  provides only a partial solution. As can be observed in Figure 7, it  is not sufficient to satisfy the human sensitivity to textures, such as  ", 
        "id": 767, 
        "title": "Structure-aware halftoning."
    }, 
    {
        "abstract": "", 
        "id": 768, 
        "title": "Real-time rendering of textures with feature curves."
    }, 
    {
        "abstract": "We accurately capture the shape and appearance of a person's hairstyle. We use triangulation and a sweep with planes of light for the geometry. Multiple projectors and cameras address the challenges raised by the reflectance and intricate geometry of hair. We introduce the use of structure tensors to infer the hidden geometry between the hair surface and the scalp. Our triangulation approach affords substantial accuracy improvement and we are able to measure elaborate hair geometry including complex curls and concavities. To reproduce the hair appearance, we capture a six-dimensional reflectance field. We introduce a new reflectance interpolation technique that leverages an analytical reflectance model to alleviate cross-fading artifacts caused by linear methods. Our results closely match the real hairstyles and can be used for animation. ", 
        "id": 769, 
        "title": "Hair photobooth: geometric and photometric acquisition of real hairstyles."
    }, 
    {
        "abstract": " (muscle contraction without movement at the joint).  In this paper, we present a data-driven technique for synthesizing skin deformation from skeletal motion. We first create a database of dynamic skin deformations by recording the motion of the surface of the skin with a very large set of motion capture markers. We then build a statistical model of the deformations by dividing them into two parts: static and dynamic. Static deformations are modeled as a function of pose. Dynamic deformations are caused by the actions of the muscles as they move the joints and the inertia of muscles and fat. We approximate these effects by fitting a set of dynamic equations to the pre-recorded data. We demonstrate the viability of this approach by generating skin deformations from the skeletal motion of an actor. We compare the generated animation both to synchronized video of the actor and to ground truth animation created directly from the large marker set.  A number of data-driven approaches to this problem have been published in the past few years. For example, Park and Hodgins [2006], Anguelov and colleagues [2005], and Sand and colleagues [2003] have used various data capture techniques to create animated figures with deforming body shapes. Park and Hodgins in particular captured and animated the jiggling and shaking that accompany dynamic motions. With their method, however, each new animated motion had to be captured with a marker set consisting of 300-400 markers. This marker set was time-consuming to apply and uncomfortable for the actor. In this paper, we develop techniques that use a database of pre-recorded dense marker data collected using their technique to construct static and dynamic models of the skin and muscle deformations. These models can then be used to animate deformations for skeletal motions that were recorded with a traditional marker set of 40-50 markers.  ", 
        "id": 770, 
        "title": "Data-driven modeling of skin and muscle deformation."
    }, 
    {
        "abstract": "", 
        "id": 771, 
        "title": "Real-time Reyes-style adaptive surface subdivision."
    }, 
    {
        "abstract": "We introduce a computational framework for discovering regular or repeated geometric structures in 3D shapes. We describe and classify possible regular structures and present an effective algorithm for detecting such repeated geometric patterns in point- or meshbased models. Our method assumes no prior knowledge of the geometry or spatial location of the individual elements that define the pattern. Structure discovery is made possible by a careful analysis of pairwise similarity transformations that reveals prominent lattice structures in a suitable model of transformation space. We introduce an optimization method for detecting such uniform grids specifically designed to deal with outliers and missing elements. This yields a robust algorithm that successfully discovers complex regular structures amidst clutter, noise, and missing geometry. The accuracy of the extracted generating transformations is further improved using a novel simultaneous registration method in the spatial domain. We demonstrate the effectiveness of our algorithm on a variety of examples and show applications to compression, model repair, and geometry synthesis. ", 
        "id": 772, 
        "title": "Discovering structural regularity in 3D geometry."
    }, 
    {
        "abstract": " Motivated by applications in architecture and manufacturing, we discuss the problem of covering a freeform surface by single curved panels. This leads to the new concept of semi-discrete surface representation, which constitutes a link between smooth and discrete surfaces. The basic entity we are working with is the developable strip model. It is the semi-discrete equivalent of a quad mesh with planar faces, or a conjugate parametrization of a smooth surface. We present a B-spline based optimization framework for efficient computing with D-strip models. In particular we study conical and circular models, which semi-discretize the network of principal curvature lines, and which enjoy elegant geometric properties. Together with geodesic models and cylindrical models they offer a rich source of solutions for surface panelization problems.  ", 
        "id": 773, 
        "title": "Freeform surfaces from single curved panels."
    }, 
    {
        "abstract": "", 
        "id": 774, 
        "title": "Richness-preserving manga screening."
    }, 
    {
        "abstract": "Aggregates of individual objects, such as forests, crowds, and piles of fruit, are a common source of complexity in computer graphics scenes. When viewing an aggregate, observers attend less to individual objects and focus more on overall properties such as nu-merosity, variety, and arrangement. Paradoxically, rendering and modeling costs increase with aggregate complexity, exactly when observers are attending less to individual objects. In this paper we take some first steps to characterize the limits of visual coding of aggregates to efficiently represent their appearance in scenes. We describe psychophysical experiments that explore the roles played by the geometric and material properties of individual objects in observers abilities to discriminate different aggregate collections. Based on these experiments we derive metrics to predict when two aggregates have the same appearance, even when composed of different objects. In a follow-up experiment we confirm that these metrics can be used to predict the appearance of a range of realistic aggregates. Finally, as a proof-of-concept we show how these new aggregate perception metrics can be applied to simplify scenes by allowing substitution of geometrically simpler aggregates for more complex ones without changing appearance.", 
        "id": 775, 
        "title": "Perception of complex aggregates."
    }, 
    {
        "abstract": "Glare arises due to multiple scattering of light inside the camera's body and lens optics and reduces image contrast. While previous approaches have analyzed glare in 2D image space, we show that glare is inherently a 4D ray-space phenomenon. By statistically analyzing the ray-space inside a camera, we can classify and remove glare artifacts. In ray-space, glare behaves as high frequency noise and can be reduced by outlier rejection. While such analysis can be performed by capturing the light field inside the camera, it results in the loss of spatial resolution. Unlike light field cameras, we do not need to reversibly encode the spatial structure of the rayspace, leading to simpler designs. We explore masks for uniform and non-uniform ray sampling and show a practical solution to analyze the 4D statistics without significantly compromising image resolution. Although diffuse scattering of the lens introduces 4D low-frequency glare, we can produce useful solutions in a variety of common scenarios. Our approach handles photography looking into the sun and photos taken without a hood, removes the effect of lens smudges and reduces loss of contrast due to camera body reflections. We show various applications in contrast enhancement and glare manipulation. ", 
        "id": 776, 
        "title": "Glare aware photography: 4D ray sampling for reducing glare effects of camera lenses."
    }, 
    {
        "abstract": "We introduce a new representation for video which facilitates a number of common editing tasks. The representation has some of the power of a full reconstruction of 3D surface models from video, but is designed to be easy to recover from a priori unseen and uncalibrated footage. By modelling the image-formation process as a 2D-to-2D transformation from an object's texture map to the image, modulated by an object-space occlusion mask, we can recover a representation which we term the \"unwrap mosaic\". Many editing operations can be performed on the unwrap mosaic, and then re-composited into the original sequence, for example resizing objects, repainting textures, copying/cutting/pasting objects, and attaching effects layers to deforming objects. ", 
        "id": 777, 
        "title": "Unwrap mosaics: a new representation for video editing."
    }, 
    {
        "abstract": "", 
        "id": 778, 
        "title": "N-symmetry direction field design."
    }, 
    {
        "abstract": "", 
        "id": 779, 
        "title": "Imperfect shadow maps for efficient computation of indirect illumination."
    }, 
    {
        "abstract": "We present a new approach for enhancing local scene contrast by unsharp masking over arbitrary surfaces under any form of illumination. Our adaptation of a well-known 2D technique to 3D interactive scenarios is designed to aid viewers in tasks like understanding complex or detailed geometric models, medical visualization and navigation in virtual environments. Our holistic approach enhances the depiction of various visual cues, including gradients from surface shading, surface reflectance, shadows, and highlights, to ease estimation of viewpoint, lighting conditions, shapes of objects and their world-space organization. Motivated by recent perceptual findings on 3D aspects of the Cornsweet illusion, we create scene coherent enhancements by treating cues in terms of their 3D context; doing so has a stronger effect than approaches that operate in a 2D image context and also achieves temporal coherence. We validate our unsharp masking in 3D with psychophysical experiments showing that the enhanced images are perceived to have better contrast and are preferred over unenhanced originals. Our operator runs at real-time rates on a GPU and the effect is easily controlled interactively within the rendering pipeline.  cues, aiding the interpretation of 3D scenes and complex geometry, which is the common task in applications such as medical diagnostics, computer simulations, geographical navigation, game playing and film creation. The main problem is in deciding which cues to emphasize and how to do so with a predictable effect. The goal of this work is to construct a perceptually founded approach for local contrast enhancement of arbitrary interactive 3D scenes. Such an approach should provide easier shape recognition, better visual separation between objects and a clarification of their spatial arrangement solely by increasing the apparent contrast of specific visual cues. Instead of identifying and modifying cues separately, we look at their common cause, changes (or gradients) in reflected light. These light gradients include all cues caused by variations in surface geometry, material properties, incoming light properties and the spatial arrangement of objects. For example, where a surface receives different amounts of incoming light (possibly in shadow), where reflectance properties change, and where specular highlights occur. In this work we strive to simultaneously increase the contrast of all such gradients without breaking coherence with the depicted scene.  ", 
        "id": 780, 
        "title": "3D unsharp masking for scene coherent enhancement."
    }, 
    {
        "abstract": "We propose a novel solid/fluid coupling method that treats the coupled system in a fully implicit manner making it stable for arbitrary time steps, large density ratios, etc. In contrast to previous work in computer graphics, we derive our method using a simple back-of-the-envelope approach which lumps the solid and fluid momenta together, and which we show exactly conserves the momentum of the coupled system. Notably, our method uses the standard Cartesian fluid discretization and does not require (moving) conforming tetrahedral meshes or ALE frameworks. Furthermore, we use a standard Lagrangian framework for the solid, thus supporting arbitrary solid constitutive models, both implicit and explicit time integration, etc. The method is quite general, working for smoke, water, and multiphase fluids as well as both rigid and deformable solids, and both volumes and thin shells. Rigid shells and cloth are handled automatically without special treatment, and we support fully one-sided discretizations without leaking. Our equations are fully symmetric, allowing for the use of fast solvers, which is a natural result of properly conserving momentum. Finally, for simple explicit time integration of rigid bodies, we show that our equations reduce to a form similar to previous work via a single block Gaussian elimination operation, but that this approach scales poorly, i.e. as though in four spatial dimensions rather than three.", 
        "id": 781, 
        "title": "Two-way coupling of fluids to rigid and deformable solids and shells."
    }, 
    {
        "abstract": "Video, like images, should support content aware resizing. We present video retargeting using an improved seam carving operator. Instead of removing 1D seams from 2D images we remove 2D seam manifolds from 3D space-time volumes. To achieve this we replace the dynamic programming method of seam carving with graph cuts that are suitable for 3D volumes. In the new formulation, a seam is given by a minimal cut in the graph and we show how to construct a graph such that the resulting cut is a valid seam. That is, the cut is monotonic and connected. In addition, we present a novel energy criterion that improves the visual quality of the retargeted images and videos. The original seam carving operator is focused on removing seams with the least amount of energy, ignoring energy that is introduced into the images and video by applying the operator. To counter this, the new criterion is looking forward in time removing seams that introduce the least amount of energy into the retargeted result. We show how to encode the improved criterion into graph cuts (for images and video) as well as dynamic programming (for images). We apply our technique to images and videos and present results of various applications.", 
        "id": 782, 
        "title": "Improved seam carving for video retargeting."
    }, 
    {
        "abstract": "", 
        "id": 783, 
        "title": "Efficient traversal of mesh edges using adjacency primitives."
    }, 
    {
        "abstract": "This paper addresses the long-standing problem of the unavoidable gaps that arise when expressing the intersection of two NURBS surfaces using conventional trimmed-NURBS representation. The solution converts each trimmed NURBS into an untrimmed T-Spline, and then merges the untrimmed T-Splines into a single, watertight model. The solution enables watertight fillets of NURBS models, as well as arbitrary feature curves that do not have to follow isoparameter curves. The resulting T-Spline representation can be exported without error as a collection of NURBS surfaces.  (a) Spout translated away from (b) Body and spout trimmed using body; intersection curve in white. trimming curves.  ", 
        "id": 784, 
        "title": "Watertight trimmed NURBS."
    }, 
    {
        "abstract": "23 This paper presents a many-core visual computing architecture code named Larrabee, a new software rendering pipeline, a manycore programming model, and performance analysis for several applications. Larrabee uses multiple in-order x86 CPU cores that are augmented by a wide vector processor unit, as well as some fixed function logic blocks. This provides dramatically higher performance per watt and per unit of area than out-of-order CPUs on highly parallel workloads. It also greatly increases the flexibility and programmability of the architecture as compared to standard GPUs. A coherent on-die 2nd level cache allows efficient inter-processor communication and high-bandwidth local data access by CPU cores. Task scheduling is performed entirely with software in Larrabee, rather than in fixed function logic. The customizable software graphics rendering pipeline for this architecture uses binning in order to reduce required memory bandwidth, minimize lock contention, and increase opportunities for parallelism relative to standard GPUs. The Larrabee native programming model supports a variety of highly parallel applications that use irregular data structures. Performance analysis on those applications demonstrates Larrabee's potential for a broad range of parallel computation. CCS: I.3.1 [Computer Graphics]: Hardware Architecture-Graphics Processors, Parallel Processing; I.3.3 [Computer Graphics]: Picture/Image Generation--Display Algorithms; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Color, shading, shadowing, and texture ", 
        "id": 785, 
        "title": "Larrabee: a many-core x86 architecture for visual computing."
    }, 
    {
        "abstract": "Our goal is to simulate the full hair geometry, consisting of approximately one hundred thousand hairs on a typical human head. This will require scalable methods that can simulate every hair as opposed to only a few guide hairs. Novel to this approach is that the individual hair/hair interactions can be modeled with physical parameters (friction, static attraction, etc.) at the scale of a single hair as opposed to clumped or continuum interactions. In this vein, we first propose a new altitude spring model for preventing collapse in the simulation of volumetric tetrahedra, and we show that it is also applicable both to bending in cloth and torsion in hair. We demonstrate that this new torsion model for hair behaves in a fashion similar to more sophisticated models with significantly reduced computational cost. For added efficiency, we introduce a semi-implicit discretization of standard springs that makes them truly linear in multiple spatial dimensions and thus unconditionally stable without requiring Newton-Raphson iteration. We also simulate complex hair/hair interactions including sticking and clumping behavior, collisions with objects (e.g. head and shoulders) and self-collisions. Notably, in line with our goal to simulate the full head of hair, we do not generate any new hairs at render time.", 
        "id": 786, 
        "title": "A mass spring model for hair simulation."
    }, 
    {
        "abstract": "We present a new algorithm for removing motion blur from a single image. Our method computes a deblurred image using a unified probabilistic model of both blur kernel estimation and unblurred image restoration. We present an analysis of the causes of common artifacts found in current deblurring methods, and then introduce several novel terms within this probabilistic model that are inspired by our analysis. These terms include a model of the spatial randomness of noise in the blurred image, as well a new local smoothness prior that reduces ringing artifacts by constraining contrast in the unblurred image wherever the blurred image exhibits low contrast. Finally, we describe an efficient optimization scheme that alternates between blur kernel estimation and unblurred image restoration until convergence. As a result of these steps, we are able to produce high quality deblurred results in low computation time. We are even able to produce results of comparable quality to techniques that require additional input images beyond a single blurry photograph, and to methods that require additional hardware. ", 
        "id": 787, 
        "title": "High-quality motion deblurring from a single image."
    }, 
    {
        "abstract": "", 
        "id": 788, 
        "title": "Fast image/video upsampling."
    }, 
    {
        "abstract": "", 
        "id": 789, 
        "title": "Space-time surface reconstruction using incompressible flow."
    }, 
    {
        "abstract": "", 
        "id": 790, 
        "title": "Accelerometer-based user interfaces for the control of a physically simulated character."
    }, 
    {
        "abstract": "In this paper we present an approach to enrich skeleton-driven animations with physically-based secondary deformation in real time. To achieve this goal, we propose a novel, surface-based deformable model that can interactively emulate the dynamics of both lowand high-frequency volumetric effects. Given a surface mesh and a few sample sequences of its physical behavior, a set of motion parameters of the material are learned during an off-line preprocessing step. The deformable model is then applicable to any given skeleton-driven animation of the surface mesh. Additionally, our dynamic skinning technique can be entirely implemented on GPUs and executed with great efficiency. Thus, with minimal changes to the conventional graphics pipeline, our approach can drastically enhance the visual experience of skeleton-driven animations by adding secondary deformation in real time.  (a) (b) (c)  ", 
        "id": 791, 
        "title": "Example-based dynamic skinning in real time."
    }, 
    {
        "abstract": "", 
        "id": 792, 
        "title": "Interaction patches for multi-character animation."
    }, 
    {
        "abstract": " Animating natural human motion in dynamic environments is difficult because of complex geometric and physical interactions. Simulation provides an automatic solution to parts of this problem, but it needs control systems to produce lifelike motions. This paper describes the systematic computation of controllers that can reproduce a range of locomotion styles in interactive simulations. Given a reference motion that describes the desired style, a derived control system can reproduce that style in simulation and in new environments. Because it produces high-quality motions that are both geometrically and physically consistent with simulated surroundings, interactive animation systems could begin to use this approach along with more established kinematic methods. ", 
        "id": 793, 
        "title": "Interactive simulation of stylized human locomotion."
    }, 
    {
        "abstract": "", 
        "id": 794, 
        "title": "Interactive 3D architectural modeling from unordered photo collections."
    }, 
    {
        "abstract": "", 
        "id": 795, 
        "title": "Automated reprojection-based pixel shader optimization."
    }, 
    {
        "abstract": " When a scene is photographed many times by different people, the viewpoints often cluster along certain paths. These paths are largely specific to the scene being photographed, and follow interesting regions and viewpoints. We seek to discover a range of such paths and turn them into controls for image-based rendering. Our approach takes as input a large set of community or personal photos, reconstructs camera viewpoints, and automatically computes orbits, panoramas, canonical views, and optimal paths between views. The scene can then be interactively browsed in 3D using these controls or with six degree-of-freedom free-viewpoint control. As the user browses the scene, nearby views are continuously selected and transformed, using control-adaptive reprojection techniques.  ", 
        "id": 796, 
        "title": "Finding paths through the world's photos."
    }, 
    {
        "abstract": "We present a new algorithm for conformal mesh parameterization. It is based on a precise notion of discrete conformal equivalence for triangle meshes which mimics the notion of conformal equivalence for smooth surfaces. The problem of finding a flat mesh that is discretely conformally equivalent to a given mesh can be solved efficiently by minimizing a convex energy function, whose Hessian turns out to be the well known cot-Laplace operator. This method can also be used to map a surface mesh to a parameter domain which is flat except for isolated cone singularities, and we show how these can be placed automatically in order to reduce the distortion of the parameterization. We present the salient features of the theory and elaborate the algorithms with a number of examples.  ", 
        "id": 797, 
        "title": "Conformal equivalence of triangle meshes."
    }, 
    {
        "abstract": "We describe an automatic technique for generating the motion of tendons and muscles under the skin of a traditionally animated character. This is achieved by integrating the traditional animation pipeline with a novel biomechanical simulator capable of dynamic simulation with complex routing constraints on muscles and tendons. We also describe an algorithm for computing the activation levels of muscles required to track the input animation. We demonstrate the results with several animations of the human hand. ", 
        "id": 798, 
        "title": "Musculotendon simulation for hand animation."
    }, 
    {
        "abstract": "We present a new technique for interactive relighting of dynamic refractive objects with complex material properties. We describe our technique in terms of a rendering pipeline in which each stage runs entirely on the GPU. The rendering pipeline converts surfaces to volumetric data, traces the curved paths of photons as they refract through the volume, and renders arbitrary views of the resulting radiance distribution. Our rendering pipeline is fast enough to permit interactive updates to lighting, materials, geometry, and viewing parameters without any precomputation. Applications of our technique include the visualization of caustics, absorption, and scattering while running physical simulations or while manipulating surfaces in real time. ", 
        "id": 799, 
        "title": "Interactive relighting of dynamic refractive objects."
    }, 
    {
        "abstract": "", 
        "id": 800, 
        "title": "Texture amendment: reducing texture distortion in constrained parameterization."
    }, 
    {
        "abstract": "We present a method for representing solid objects with spatiallyvarying oriented textures by repeatedly pasting solid texture exemplars. The underlying concept is to extend the 2D texture patchpasting approach of lapped textures to 3D solids using a tetrahedral mesh and 3D texture patches. The system places texture patches according to the user-defined volumetric tensor fields over the mesh to represent oriented textures. We have also extended the original technique to handle nonhomogeneous textures for creating solid models whose textural patterns change gradually along the depth fields. We identify several texture types considering the amount of anisotropy and spatial variation and provide a tailored user interface for each. With our simple framework, large-scale realistic solid models can be created easily with little memory and computational cost. We demonstrate the effectiveness of our approach with several examples including trees, fruits, and vegetables. ", 
        "id": 801, 
        "title": "Lapped solid textures: filling a model with anisotropic textures."
    }, 
    {
        "abstract": "", 
        "id": 802, 
        "title": "Single image tree modeling."
    }, 
    {
        "abstract": "", 
        "id": 803, 
        "title": "Magnets in motion."
    }, 
    {
        "abstract": "A semi-automatic approach is presented that enables the generation of a high-quality 3D model of a static object from an image sequence that was taken by a moving, uncalibrated consumer camera. A bounding box is placed around the object, and orthographic projections onto the sides of the bounding box are automatically generated out of the image sequence. These ortho-images can be imported as background maps in the orthographic views (e.g., the top, side, and front view) of any modeling package. Modelers can now use these ortho-images to guide their modeling by tracing the shape of the object over the ortho-images. This greatly improves the accuracy and efficiency of the manual modeling process. An additional advantage over existing semi-automatic systems is that modelers can use the modeling package that they are trained in and can thereby increase their productivity by applying the advanced modeling features the package offers. The results presented show that accurate 3D models can even be generated for translucent or specular surfaces, and the approach is therefore still applicable in cases where todays fully automatic image-based approaches or laser scanners would fail.", 
        "id": 804, 
        "title": "3D-modeling by ortho-image generation from image sequences."
    }, 
    {
        "abstract": "Physically based simulation of rigid body dynamics is commonly done by time-stepping systems forward in time. In this paper, we propose methods to allow time-stepping rigid body systems backward in time. Unfortunately, reverse-time integration of rigid bodies involving frictional contact is mathematically ill-posed, and can lack unique solutions. We instead propose time-reversed rigid body integrators that can sample possible solutions when unique ones do not exist. We also discuss challenges related to dissipation-related energy gain, sensitivity to initial conditions, stacking, constraints and articulation, rolling, sliding, skidding, bouncing, high angular velocities, rapid velocity growth from micro-collisions, and other problems encountered when going against the usual flow of time. ", 
        "id": 805, 
        "title": "Backward steps in rigid body simulation."
    }, 
    {
        "abstract": "Details in mesh animations are difficult to generate but they have great impact on visual quality. In this work, we demonstrate a practical software system for capturing such details from multi-view video recordings. Given a stream of synchronized video images that record a human performance from multiple viewpoints and an articulated template of the performer, our system captures the motion of both the skeleton and the shape. The output mesh animation is enhanced with the details observed in the image silhouettes. For example, a performance in casual loose-fitting clothes will generate mesh animations with flowing garment motions. We accomplish this with a fast pose tracking method followed by nonrigid deformation of the template to fit the silhouettes. The entire process takes less than sixteen seconds per frame and requires no markers or texture cues. Captured meshes are in full correspondence making them readily usable for editing operations including texturing, deformation transfer, and deformation model learning.  Input images Output meshes  ", 
        "id": 806, 
        "title": "Articulated mesh animation from multi-view silhouettes."
    }, 
    {
        "abstract": "", 
        "id": 807, 
        "title": "Synthesis and evaluation of linear motion transitions."
    }, 
    {
        "abstract": "", 
        "id": 808, 
        "title": "Computation of rotation minimizing frames."
    }, 
    {
        "abstract": "", 
        "id": 809, 
        "title": "Optimized scale-and-stretch for image resizing."
    }, 
    {
        "abstract": "We reduce transmission bandwidth and memory space for images by factoring their repeated content. A transform map and a condensed epitome are created such that all image blocks can be reconstructed from transformed epitome patches. The transforms may include affine deformation and color scaling to account for perspective and tonal variations across the image. The factored representation allows efficient random-access through a simple indirection, and can therefore be used for real-time texture mapping without expansion in memory. Our scheme is orthogonal to traditional image compression, in the sense that the epitome is amenable to further compression such as DXT. Moreover it allows a new mode of progressivity, whereby generic features appear before unique detail. Factoring is also effective across a collection of images, particularly in the context of image-based rendering. Eliminating redundant content lets us include textures that are several times as large in the same memory space. ", 
        "id": 810, 
        "title": "Factoring repeated content within and among images."
    }, 
    {
        "abstract": "", 
        "id": 811, 
        "title": "Modeling and rendering of heterogeneous translucent materials using the diffusion equation."
    }, 
    {
        "abstract": "We present a new technique for the visual modeling of spatiallyvarying anisotropic reflectance using data captured from a single view. Reflectance is represented using a microfacet-based BRDF which tabulates the facets' normal distribution (NDF) as a function of surface location. Data from a single view provides a 2D slice of the 4D BRDF at each surface point from which we fit a partial NDF. The fitted NDF is partial because the single view direction coupled with the set of light directions covers only a portion of the \"half-angle\" hemisphere. We complete the NDF at each point by applying a novel variant of texture synthesis using similar, overlapping partial NDFs from other points. Our similarity measure allows azimuthal rotation of partial NDFs, under the assumption that reflectance is spatially redundant but the local frame may be arbitrarily oriented. Our system includes a simple acquisition device that collects images over a 2D set of light directions by scanning a linear array of LEDs over a flat sample. Results demonstrate that our approach preserves spatial and directional BRDF details and generates a visually compelling match to measured materials. ", 
        "id": 812, 
        "title": "Modeling anisotropic surface reflectance with example-based microfacet synthesis."
    }, 
    {
        "abstract": "", 
        "id": 813, 
        "title": "Parallel algorithms for approximation of distance maps on parametric surfaces."
    }, 
    {
        "abstract": "Sampling is important for a variety of graphics applications include rendering, imaging, and geometry processing. However, producing sample sets with desired efficiency and blue noise statistics has been a major challenge, as existing methods are either sequential with limited speed, or are parallel but only through pre-computed datasets and thus fall short in producing samples with blue noise statistics. We present a Poisson disk sampling algorithm that runs in parallel and produces all samples on the fly with desired blue noise properties. Our main idea is to subdivide the sample domain into grid cells and we draw samples concurrently from multiple cells that are sufficiently far apart so that their samples cannot conflict one another. We present a parallel implementation of our algorithm running on a GPU with constant cost per sample and constant number of computation passes for a target number of samples. Our algorithm also works in arbitrary dimension, and allows adaptive sampling from a user-specified importance field. Furthermore, our algorithm is simple and easy to implement, and runs faster than existing techniques. ", 
        "id": 814, 
        "title": "Parallel Poisson disk sampling."
    }, 
    {
        "abstract": "", 
        "id": 815, 
        "title": "Realistic rendering of birefringency in uniaxial crystals."
    }, 
    {
        "abstract": "The quality and speed of most texture synthesis algorithms depend on a 2D input sample that is small and contains enough texture variations. However, little research exists on how to acquire such a sample. For homogeneous patterns this can be achieved via manual cropping, but no adequate solution exists for inhomogeneous or globally varying textures, i.e. patterns that are local but not stationary, such as rusting over an iron statue with appearance conditioned on varying moisture levels. We present inverse texture synthesis to address this issue. Our inverse synthesis runs in the opposite direction with respect to traditional forward synthesis: given a large globally varying texture, our algorithm automatically produces a small texture compaction that best summarizes the original. This small compaction can be used to reconstruct the original texture or to re-synthesize new textures under user-supplied controls. More important, our technique allows real-time synthesis of globally varying textures on a GPU, where the texture memory is usually too small for large textures. We propose an optimization framework for inverse texture synthesis, ensuring that each input region is properly encoded in the output compaction. Our optimization process also automatically computes orientation fields for anisotropic textures containing both lowand high-frequency regions, a situation difficult to handle via existing techniques.", 
        "id": 816, 
        "title": "Inverse texture synthesis."
    }, 
    {
        "abstract": " We introduce a method for efficiently animating a wide range of deformable materials. We combine a high resolution surface mesh with a tetrahedral finite element simulator that makes use of frequent re-meshing. This combination allows for fast and detailed simulations of complex elastic and plastic behavior. We significantly expand the range of physical parameters that can be simulated with a single technique, and the results are free from common artifacts such as volume-loss, smoothing, popping, and the absence of thin features like strands and sheets. Our decision to couple a high resolution surface with low-resolution physics leads to efficient simulation and detailed surface features, and our approach to creating the tetrahedral mesh leads to an order-of-magnitude speedup over previous techniques in the time spent re-meshing. We compute masses, collisions, and surface tension forces on the scale of the fine mesh, which helps avoid visual artifacts due to the differing mesh resolutions. The result is a method that can simulate a large array of different material behaviors with high resolution features in a short amount of time.  ", 
        "id": 817, 
        "title": "Fast viscoelastic behavior with thin features."
    }, 
    {
        "abstract": "", 
        "id": 818, 
        "title": "Interactive normal reconstruction from a single image."
    }, 
    {
        "abstract": "", 
        "id": 819, 
        "title": "Image-based fa&ccedil;ade modeling."
    }, 
    {
        "abstract": "", 
        "id": 820, 
        "title": "Animating animal motion from still."
    }, 
    {
        "abstract": "", 
        "id": 821, 
        "title": "Animating responsive characters with dynamic constraints in near-unactuated coordinates."
    }, 
    {
        "abstract": "Modeling the large space of possible human motions requires scalable techniques. Generalizing from example motions or example controllers is one way to provide the required scalability. We present techniques for generalizing a controller for physics-based walking to significantly different tasks, such as climbing a large step up, or pushing a heavy object. Continuation methods solve such problems using a progressive sequence of problems that trace a path from an existing solved problem to the final desired-butunsolved problem. Each step in the continuation sequence makes progress towards the target problem while further adapting the solution. We describe and evaluate a number of choices in applying continuation methods to adapting walking gaits for tasks involving interaction with the environment. The methods have been successfully applied to automatically adapt a regular cyclic walk to climbing a 65cm step, stepping over a 55cm sill, pushing heavy furniture, walking up steep inclines, and walking on ice. The continuation path further provides parameterized solutions to these problems. ", 
        "id": 822, 
        "title": "Continuation methods for adapting simulated skills."
    }, 
    {
        "abstract": " Ringing is the most disturbing artifact in the image deconvolution. In this paper, we present a progressive inter-scale and intra-scale non-blind image deconvolution approach that significantly reduces ringing. Our approach is built on a novel edgepreserving deconvolution algorithm called bilateral RichardsonLucy (BRL) which uses a large spatial support to handle large blur. We progressively recover the image from a coarse scale to a fine scale (inter-scale), and progressively restore image details within every scale (intra-scale). To perform the inter-scale deconvolution, we propose a joint bilateral Richardson-Lucy (JBRL) algorithm so that the recovered image in one scale can guide the deconvolution in the next scale. In each scale, we propose an iterative residual deconvolution to progressively recover image details. The experimental results show that our progressive deconvolution can produce images with very little ringing for large blur kernels.  ", 
        "id": 823, 
        "title": "Progressive inter-scale and intra-scale non-blind image deconvolution."
    }, 
    {
        "abstract": "", 
        "id": 824, 
        "title": "Real-time KD-tree construction on graphics hardware."
    }, 
    {
        "abstract": " We present a real-time algorithm called compensated ray marching for rendering of smoke under dynamic low-frequency environment lighting. Our approach is based on a decomposition of the input smoke animation, represented as a sequence of volumetric density fields, into a set of radial basis functions (RBFs) and a sequence of residual fields. To expedite rendering, the source radiance distribution within the smoke is computed from only the lowfrequency RBF approximation of the density fields, since the highfrequency residuals have little impact on global illumination under low-frequency environment lighting. Furthermore, in computing source radiances the contributions from single and multiple scattering are evaluated at only the RBF centers and then approximated at other points in the volume using an RBF-based interpolation. A slice-based integration of these source radiances along each view ray is then performed to render the final image. The high-frequency residual fields, which are a critical component in the local appearance of smoke, are compensated back into the radiance integral during this ray march to generate images of high detail. The runtime algorithm, which includes both light transfer simulation and ray marching, can be easily implemented on the GPU, and thus allows for real-time manipulation of viewpoint and lighting, as well as interactive editing of smoke attributes such as extinction cross section, scattering albedo, and phase function. Only moderate preprocessing time and storage is needed. This approach provides the first method for real-time smoke rendering that includes single and multiple scattering while generating results comparable in quality to offline algorithms like ray tracing. ", 
        "id": 825, 
        "title": "Real-time smoke rendering using compensated ray marching."
    }, 
    {
        "abstract": "When rendering light colored hair, multiple fiber scattering is essential for the right perception of the overall hair color. In this context, we present a novel technique to efficiently approximate multiple fiber scattering for a full head of human hair or a similar fiber based geometry. In contrast to previous ad-hoc approaches, our method relies on the physically accurate concept of the Bidirectional Scat- e-mail: zinke@cs.uni-bonn.de.de e-mail: cem@cemyuksel.com e-mail: weber@cs.uni-bonn.de.de e-mail: keyser@cs.tamu.edu  tering Distribution Functions and gives physically plausible results with no need for parameter tweaking. We show that complex scattering effects can be approximated very well by using aggressive simplifications based on this theoretical model. When compared to unbiased Monte-Carlo path tracing, our approximations preserve photo-realism in most settings but with rendering times at least twoorders of magnitude lower. Time and space complexity are much lower compared to photon mapping-based techniques and we can even achieve realistic results in real-time on a standard PC with consumer graphics hardware. ", 
        "id": 826, 
        "title": "Dual scattering approximation for fast multiple scattering in hair."
    }, 
    {
        "abstract": "We propose a method for accelerating a broad class of non-linear filters that includes the bilateral, non-local means, and other related filters. These filters can all be expressed in a similar way: First, assign each value to be filtered a position in some vector space. Then, replace every value with a weighted linear combination of all values, with weights determined by a Gaussian function of distance between the positions. If the values are pixel colors and the positions are (x, y) coordinates, this describes a Gaussian blur. If the positions are instead (x, y, r, g, b) coordinates in a five-dimensional space-color volume, this describes a bilateral filter. If we instead set the positions to local patches of color around the associated pixel, this describes non-local means. We describe a Monte-Carlo kd-tree sampling algorithm that efficiently computes any filter that can be expressed in this way, along with a GPU implementation of this technique. We use this algorithm to implement an accelerated bilateral filter that respects full 3D color distance; accelerated non-local means on single images, volumes, and unaligned bursts of images for denoising; and a fast adaptation of non-local means to geometry. If we have n values to filter, and each is assigned a position in a d-dimensional space, then our space complexity is O(dn) and our time complexity is O(dn log n), whereas existing methods are typically either exponential in d or quadratic in n.", 
        "id": 827, 
        "title": "Gaussian KD-trees for fast high-dimensional filtering."
    }, 
    {
        "abstract": "We show that motion blur in successive video frames is invertible even if the point-spread function (PSF) due to motion smear in a single photo is non-invertible. Blurred photos exhibit nulls (zeros) in the frequency transform of the PSF, leading to an ill-posed deconvolution. Hardware solutions to avoid this require specialized devices such as the coded exposure camera or accelerating sensor motion. We employ ordinary video cameras and introduce the notion of null-filling along with joint-invertibility of multiple blurfunctions. The key idea is to record the same object with varying PSFs, so that the nulls in the frequency component of one frame can be filled by other frames. The combined frequency transform becomes null-free, making deblurring well-posed. We achieve jointlyinvertible blur simply by changing the exposure time of successive frames. We address the problem of automatic deblurring of objects moving with constant velocity by solving the four critical components: preservation of all spatial frequencies, segmentation of moving parts, motion estimation of moving parts, and non-degradation of the static parts of the scene. We demonstrate several challenging cases of object motion blur including textured backgrounds and partial occluders. ", 
        "id": 828, 
        "title": "Invertible motion blur in video."
    }, 
    {
        "abstract": "Figure 1: Examples of woven objects constructed with ribbons: Venus consists of five distinct cycles. The bunny has eight cycles, the rocker arm has only two cycles, and the genus-three object has 16 cycles. The first three models are created by the Quadcover method [Kalberer et al. 2007], courtesy of Wenping Wang and Li Yupei. The genus-three object is created using TopMod3D [Akleman et al. 2008]. Abstract In this paper, we show how to create plain-weaving over an arbitrary surface. To create a plain-weaving on a surface, we need to create cycles that cross other cycles (or themselves) by alternatingly going over and under. We use the fact that it is possible to create such cycles, starting from any given manifold-mesh surface by simply twisting every edge of the manifold mesh. We have developed a new method that converts plain-weaving cycles to 3D thread structures. Using this method, it is possible to cover a surface without large gaps between threads by controlling the sizes of the gaps. We have developed a system that converts any manifold mesh to a plain-woven object, by interactively controlling the shapes of the threads with a set of parameters. We have demonstrated that by using this system, we can create a wide variety of plain-weaving patterns, some of which may not have been seen before.", 
        "id": 829, 
        "title": "Cyclic plain-weaving on polygonal mesh surfaces with graph rotation systems."
    }, 
    {
        "abstract": "", 
        "id": 830, 
        "title": "Real-time parallel hashing on the GPU."
    }, 
    {
        "abstract": "", 
        "id": 831, 
        "title": "Interpolatory point set surfaces - convexity and Hermite data."
    }, 
    {
        "abstract": "", 
        "id": 832, 
        "title": "Subtle gaze direction."
    }, 
    {
        "abstract": "Although tremendous success has been achieved for interactive object cutout in still images, accurately extracting dynamic objects in video remains a very challenging problem. Previous video cutout systems present two major limitations: (1) reliance on global statistics, thus lacking the ability to deal with complex and diverse scenes; and (2) treating segmentation as a global optimization, thus lacking a practical workflow that can guarantee the convergence of the systems to the desired results. We present Video SnapCut, a robust video object cutout system that significantly advances the state-of-the-art. In our system segmentation is achieved by the collaboration of a set of local classifiers, each adaptively integrating multiple local image features. We show how this segmentation paradigm naturally supports local user editing and propagates them across time. The object cutout system is completed with a novel coherent video matting technique. A comprehensive evaluation and comparison is presented, demonstrating the effectiveness of the proposed system at achieving high quality results, as well as the robustness of the system against various types of inputs. ", 
        "id": 833, 
        "title": "Video SnapCut: robust video object cutout using localized classifiers."
    }, 
    {
        "abstract": "We present a new general-purpose method for optimizing existing point sets. The resulting distributions possess high-quality blue noise characteristics and adapt precisely to given density functions. Our method is similar to the commonly used Lloyd's method while avoiding its drawbacks. We achieve our results by utilizing the concept of capacity, which for each point is determined by the area of its Voronoi region weighted with an underlying density function. We demand that each point has the same capacity. In combination with a dedicated optimization algorithm, this capacity constraint enforces that each point obtains equal importance in the distribution. Our method can be used as a drop-in replacement for Lloyd's method, and combines enhancement of blue noise characteristics and density function adaptation in one operation. ", 
        "id": 834, 
        "title": "Capacity-constrained point distributions: a variant of Lloyd's method."
    }, 
    {
        "abstract": "Transferring existing mesh deformation from one character to another is a simple way to accelerate the laborious process of mesh animation. In many cases, it is useful to preserve the semantic characteristics of the motion instead of its literal deformation. For example, when applying the walking motion of a human to a flamingo, the knees should bend in the opposite direction. Semantic deformation transfer accomplishes this task with a shape space that enables interpolation and projection with standard linear algebra. Given several example mesh pairs, semantic deformation transfer infers a correspondence between the shape spaces of the two characters. This enables automatic transfer of new poses and animations.", 
        "id": 835, 
        "title": "Semantic deformation transfer."
    }, 
    {
        "abstract": " Keyframe animation is a common technique to generate animations of deformable characters and other soft bodies. With spline interpolation, however, it can be difficult to achieve secondary motion effects such as plausible dynamics when there are thousands of degrees of freedom to animate. Physical methods can provide more realism with less user effort, but it is challenging to apply them to quickly create specific animations that closely follow prescribed animator goals. We present a fast space-time optimization method to author physically based deformable object simulations that conform to animator-specified keyframes. We demonstrate our method with FEM deformable objects and mass-spring systems. Our method minimizes an objective function that penalizes the sum of keyframe deviations plus the deviation of the trajectory from physics. With existing methods, such minimizations operate in high dimensions, are slow, memory consuming, and prone to local minima. We demonstrate that significant computational speedups and robustness improvements can be achieved if the optimization problem is properly solved in a low-dimensional space. Selecting a low-dimensional space so that the intent of the animator is accommodated, and that at the same time space-time optimization is convergent and fast, is difficult. We present a method that generates a quality low-dimensional space using the given keyframes. It is then possible to find quality solutions to difficult space-time optimization problems robustly and in a manner of minutes. ", 
        "id": 836, 
        "title": "Deformable object animation using reduced optimal control."
    }, 
    {
        "abstract": " likeness of the contents of the original image but with new dimen-  sions [Rubinstein et al. 2008; Wang et al. 2008]. Other algorithms  This paper presents interactive image editing tools using a new  for image completion let a user simply erase an unwanted portion  randomized algorithm for quickly finding approximate nearest- of an image, and the computer automatically synthesizes a fill re-  neighbor matches between image patches. Previous research in  gion that plausibly matches the remainder of the image [Criminisi  graphics and vision has leveraged such nearest-neighbor searches to  et al. 2003; Komodakis and Tziritas 2007]. Image reshuffling al-  provide a variety of high-level digital image editing tools. However,  gorithms make it possible to grab portions of the image and move  the cost of computing a field of such matches for an entire image  them around  the computer automatically synthesizes the remain-  has eluded previous efforts to provide interactive performance. Our  der of the image so as to resemble the original while respecting the  algorithm offers substantial performance improvements over the  moved regions [Simakov et al. 2008; Cho et al. 2008].  previous state of the art (20-100x), enabling its use in interactive  editing tools. The key insights driving the algorithm are that  In each of these scenarios, user interaction is essential, for several  some good patch matches can be found via random sampling, and  reasons: First, these algorithms sometimes require user intervention  that natural coherence in the imagery allows us to propagate such  to obtain the best results. Retargeting algorithms, for example,  matches quickly to surrounding areas. We offer theoretical analysis  sometimes provide user controls to specify that one or more regions  of the convergence properties of the algorithm, as well as empirical  (e.g., faces) should be left relatively unaltered. Likewise, the best  and practical evidence for its high quality and performance. This  completion algorithms offer tools to guide the result by providing  one simple algorithm forms the basis for a variety of tools  image  hints for the computer [Sun et al. 2005]. These methods provide  retargeting, completion and reshuffling  that can be used together  such controls because the user is attempting to optimize a set of  in the context of a high-level image editing application. Finally, we  goals that are known to him and not to the computer. Second,  propose additional intuitive constraints on the synthesis process that  the user often cannot even articulate these goals a priori. The  offer the user a level of control unavailable in previous methods.  artistic process of creating the desired image demands the use of  trial and error, as the user seeks to optimize the result with respect  ", 
        "id": 837, 
        "title": "PatchMatch: a randomized correspondence algorithm for structural image editing."
    }, 
    {
        "abstract": " A space deformation is a mapping from a source region to a target region within Euclidean space, which best satisfies some userspecified constraints. It can be used to deform shapes embedded in the ambient space and represented in various forms  polygon meshes, point clouds or volumetric data. For a space deformation method to be useful, it should possess some natural properties: e.g. detail preservation, smoothness and intuitive control. A harmonic map from a domain   Rd to Rd is a mapping whose d components are harmonic functions. Harmonic mappings are smooth and regular, and if their components are coupled in some special way, the mapping can be detail-preserving, making it a natural choice for space deformation applications. The challenge is to find a harmonic mapping of the domain, which will satisfy constraints specified by the user, yet also be detail-preserving, and intuitive to control. We generate harmonic mappings as a linear combination of a set of harmonic basis functions, which have a closed-form expression when the source region boundary is piecewise linear. This is done by defining an energy functional of the mapping, and minimizing it within the linear span of these basis functions. The resulting mapping is harmonic, and a natural \"As-Rigid-As-Possible\" deformation of the source region. Unlike other space deformation methods, our approach does not require an explicit discretization of the domain. It is shown to be much more efficient, yet generate comparable deformations to state-ofthe-art methods. We describe an optimization algorithm to minimize the deformation energy, which is robust, provably convergent, and easy to implement. ", 
        "id": 838, 
        "title": "Variational harmonic maps for space deformation."
    }, 
    {
        "abstract": "", 
        "id": 839, 
        "title": "A tool to create illuminant and reflectance spectra for light-driven graphics and visualization."
    }, 
    {
        "abstract": " This paper introduces a data-driven representation and modeling technique for simulating non-linear heterogeneous soft tissue. It simplifies the construction of convincing deformable models by avoiding complex selection and tuning of physical material parameters, yet retaining the richness of non-linear heterogeneous behavior. We acquire a set of example deformations of a real object, and represent each of them as a spatially varying stress-strain relationship in a finite-element model. We then model the material by non-linear interpolation of these stress-strain relationships in strain-space. Our method relies on a simple-to-build capture system and an efficient run-time simulation algorithm based on incremental loading, making it suitable for interactive computer graphics applications. We present the results of our approach for several nonlinear materials and biological soft tissue, with accurate agreement of our model to the measured data. ", 
        "id": 840, 
        "title": "Capture and modeling of non-linear heterogeneous soft tissue."
    }, 
    {
        "abstract": "In this paper we propose a global visibility algorithm which computes from-region visibility for all view cells simultaneously in a progressive manner. We cast rays to sample visibility interactions and use the information carried by a ray for all view cells it intersects. The main contribution of the paper is a set of adaptive sampling strategies based on ray mutations that exploit the spatial coherence of visibility. Our method achieves more than an order of magnitude speedup compared to per-view cell sampling. This provides a practical solution to visibility preprocessing and also enables a new type of interactive visibility analysis application, where it is possible to quickly inspect and modify a coarse global visibility solution that is constantly refined.  carried out as a preprocess in applications that need to know visibility information in advance and where online visibility cannot be used. These applications include polygon budget computations, level design for computer games, line-of-sight analysis, planning geometry and texture transmissions for networked virtual environments, acquisition planning for object scanning, or path planning for artificial intelligence in computer games. Recently it has been shown that sampling is a robust solution to PVS computation. In particular the Guided Visibility Sampling (GVS) algorithm introduced by Wonka et al. [Wonka et al. 2006] efficiently computes a PVS for a view cell using ray casting. While GVS is very efficient at sampling from a single view cell, it does not exploit the coherence among different view cells and does not work in progressive fashion with respect to all view cells.  ", 
        "id": 841, 
        "title": "Adaptive global visibility sampling."
    }, 
    {
        "abstract": "We present a novel method for quadrangulating a given triangle mesh. After constructing an as smooth as possible symmetric cross field satisfying a sparse set of directional constraints (to capture the geometric structure of the surface), the mesh is cut open in order to enable a low distortion unfolding. Then a seamless globally smooth parametrization is computed whose iso-parameter lines follow the cross field directions. In contrast to previous methods, sparsely distributed directional constraints are sufficient to automatically determine the appropriate number, type and position of singularities in the quadrangulation. Both steps of the algorithm (cross field and parametrization) can be formulated as a mixed-integer problem which we solve very efficiently by an adaptive greedy solver. We show several complex examples where high quality quad meshes are generated in a fully automatic manner.", 
        "id": 842, 
        "title": "Mixed-integer quadrangulation."
    }, 
    {
        "abstract": "", 
        "id": 843, 
        "title": "User-assisted intrinsic images."
    }, 
    {
        "abstract": "", 
        "id": 844, 
        "title": "Artistic rendering of mountainous terrain."
    }, 
    {
        "abstract": "Any projection of a 3D scene into a wide-angle image unavoidably results in distortion. Current projection methods either bend straight lines in the scene, or locally distort the shapes of scene objects. We present a method that minimizes this distortion by adapting the projection to content in the scene, such as salient scene regions and lines, in order to preserve their shape. Our optimization technique computes a spatially-varying projection that respects user-specified constraints while minimizing a set of energy terms that measure wide-angle image distortion. We demonstrate the effectiveness of our approach by showing results on a variety of wide-angle photographs, as well as comparisons to standard projections. ", 
        "id": 845, 
        "title": "Optimizing content-preserving projections for wide-angle images."
    }, 
    {
        "abstract": "We present a subdivision framework that adds extraordinary vertices to NURBS of arbitrarily high degree. The surfaces can represent any odd degree NURBS patch exactly. Our rules handle non-uniform knot vectors, and are not restricted to midpoint knot insertion. In the absence of multiple knots at extraordinary points, the limit surfaces have bounded curvature.  Computer-Aided Design. In addition to bicubic patches, CAD models sometimes use the additional continuity available from biquintic, occasionally biseptic, and very rarely higher degree B-splines. Highclass surfaces also use non-uniform parametrizations for handling boundaries, selectively reducing continuity, and integrating surface features at varying scales. No subdivision scheme, however, has been able to provide the full complement of NURBS features alongside the flexibility of extraordinary points.  ", 
        "id": 846, 
        "title": "NURBS with extraordinary points: high-degree, non-uniform, rational subdivision schemes."
    }, 
    {
        "abstract": "", 
        "id": 847, 
        "title": "Harmonic shells: a practical nonlinear sound model for near-rigid thin shells."
    }, 
    {
        "abstract": "", 
        "id": 848, 
        "title": "Structure-aware error diffusion."
    }, 
    {
        "abstract": "", 
        "id": 849, 
        "title": "Sketch2Photo: internet image montage."
    }, 
    {
        "abstract": "This paper describes a benchmark for evaluation of 3D mesh segmentation algorithms. The benchmark comprises a data set with 4,300 manually generated segmentations for 380 surface meshes of 19 different object categories, and it includes software for analyzing 11 geometric properties of segmentations and producing 4 quantitative metrics for comparison of segmentations. The paper investigates the design decisions made in building the benchmark, analyzes properties of human-generated and computer-generated segmentations, and provides quantitative comparisons of 7 recently published mesh segmentation algorithms. Our results suggest that people are remarkably consistent in the way that they segment most 3D surface meshes, that no one automatic segmentation algorithm is better than the others for all types of objects, and that algorithms based on non-local shape features seem to produce segmentations that most closely resemble ones made by humans.  processing algorithms, including skeleton extraction [Biasotti et al. 2003; Katz and Tal 2003], modeling [Funkhouser et al. 2004], morphing [Zockler et al. 2000; Gregory et al. 1999], shape-based retrieval [Zuckerberger 2002], and texture mapping [Levy et al. 2002]. All of these applications benefit from mesh segmentations that match human intuition. While many automatic mesh segmentation algorithms have been developed over the last several years, there has been little work on quantitative evaluation of how well they perform. The main problem has been the lack of a \"gold standard.\" There has been no benchmark set of 3D models and no agreed-upon metrics of success. Rather, most new algorithms are tested on their own set of 3D meshes, and results are presented only as images with different segments shown in different colors. In a few cases, more than one algorithm have been compared on the same set of meshes (e.g., [Attene et al. 2006a]), but the evaluation is qualitative (images shown side-by-side).  ", 
        "id": 850, 
        "title": "A benchmark for 3D mesh segmentation."
    }, 
    {
        "abstract": " We present algorithms for simulating and visualizing the insertion and steering of needles through deformable tissues for surgical training and planning. Needle insertion is an essential component of many clinical procedures such as biopsies, injections, neurosurgery, and brachytherapy cancer treatment. The success of these procedures depends on accurate guidance of the needle tip to a clinical target while avoiding vital tissues. Needle insertion deforms body tissues, making accurate placement difficult. Our interactive needle insertion simulator models the coupling between a steerable needle and deformable tissue. We introduce (1) a novel algorithm for local remeshing that quickly enforces the conformity of a tetrahedral mesh to a curvilinear needle path, enabling accurate computation of contact forces, (2) an efficient method for coupling a 3D finite element simulation with a 1D inextensible rod with stick-slip friction, and (3) optimizations that reduce the computation time for physically based simulations. We can realistically and interactively simulate needle insertion into a prostate mesh of 13,375 tetrahedra and 2,763 vertices at a 25 Hz frame rate on an 8-core 3.0 GHz Intel Xeon PC. The simulation models prostate brachytherapy with needles of varying stiffness, steering needles around obstacles, and supports motion planning for robotic needle insertion. We evaluate the accuracy of the simulation by comparing against real-world experiments in which flexible, steerable needles were inserted into gel tissue phantoms. ", 
        "id": 851, 
        "title": "Interactive simulation of surgical needle insertion and steering."
    }, 
    {
        "abstract": "", 
        "id": 852, 
        "title": "Noise brush: interactive high quality image-noise separation."
    }, 
    {
        "abstract": "", 
        "id": 853, 
        "title": "Fitting solid meshes to animated surfaces using linear elasticity."
    }, 
    {
        "abstract": "", 
        "id": 854, 
        "title": "Fast motion deblurring."
    }, 
    {
        "abstract": "This paper investigates the ability of sparse line drawings to depict 3D shape. We perform a study in which people are shown an image of one of twelve 3D objects depicted with one of six styles and asked to orient a gauge to coincide with the surface normal at many positions on the object's surface. The normal estimates are compared with each other and with ground truth data provided by a registered 3D surface model to analyze accuracy and precision. The paper describes the design decisions made in collecting a large data set (275,000 gauge measurements) and provides analysis to answer questions about how well people interpret shapes from drawings. Our findings suggest that people interpret certain shapes almost as well from a line drawing as from a shaded image, that current computer graphics line drawing techniques can effectively depict shape and even match the effectiveness of artist's drawings, and that errors in depiction are often localized and can be traced to particular properties of the lines used. The data collected for this study will become a publicly available resource for further studies of this type. ", 
        "id": 855, 
        "title": "How well do line drawings depict shape?"
    }, 
    {
        "abstract": "", 
        "id": 856, 
        "title": "Robust task-based control policies for physics-based characters."
    }, 
    {
        "abstract": "", 
        "id": 857, 
        "title": "Display supersampling."
    }, 
    {
        "abstract": "", 
        "id": 858, 
        "title": "A variational approach for automatic generation of panoramic maps."
    }, 
    {
        "abstract": "", 
        "id": 859, 
        "title": "Optimized image resizing using seam carving and scaling."
    }, 
    {
        "abstract": "We present a new model of the homogeneous BSSRDF based on large-scale simulations. Our model captures the appearance of materials that are not accurately represented using existing single scattering models or multiple isotropic scattering models (e.g. the diffusion approximation). We use an analytic function to model the 2D hemispherical distribution of exitant light at a point on the surface, and a table of parameter values of this function computed at uniformly sampled locations over the remaining dimensions of the BSSRDF domain. This analytic function is expressed in elliptic coordinates and has six parameters which vary smoothly with surface position, incident angle, and the underlying optical properties of the material (albedo, mean free path length, phase function and the relative index of refraction). Our model agrees well with measured data, and is compact, requiring only 250MB to represent the full spatialand angular-distribution of light across a wide spectrum of materials. In practice, rendering a single material requires only about 100KB to represent the BSSRDF.", 
        "id": 860, 
        "title": "An empirical BSSRDF model."
    }, 
    {
        "abstract": "(a) Our Method 4 samples per pixel (b) Stratified Sampling 4 samples/pixel (c) Multidimensional Adaptive Sampling 4 samples/pixel (d) Our Method 4 samples/pixel (e) Ground Truth 256 samples/pixel Figure 1: (a) Our method using an average of only 4 samples per pixel over the image. A static rendering of the scene is inset in the lower right and closeups are shown in (b-e). Stratified sampling in (b) is very noisy at this low sample count. Multidimensional Adaptive Sampling [Hachisuka et al. 2008] in (c) performs much better, but still has some noise, especially in fast-moving high-frequency textures, such as the mural (top) and ground (bottom closeup). Our technique in (d) produces a high-quality image with minimal noise that closely matches ground truth (e). Figure 7 shows details for our sheared filter. Abstract Motion blur is crucial for high-quality rendering, but is also very expensive. Our first contribution is a frequency analysis of motion-blurred scenes, including moving objects, specular reflections, and shadows. We show that motion induces a shear in the frequency domain, and that the spectrum of moving scenes can be approximated by a wedge. This allows us to compute adaptive space-time sampling rates, to accelerate rendering. For uniform velocities and standard axis-aligned reconstruction, we show that the product of spatial and temporal bandlimits or sampling rates is constant, independent of velocity. Our second contribution is a novel sheared reconstruction filter that is aligned to the first-order direction of motion and enables even lower sampling rates. We present a rendering algorithm that computes a sheared reconstruction filter per pixel, without any intermediate Fourier representation. This often permits synthesis of motion-blurred images with far fewer rendering samples than standard techniques require.", 
        "id": 861, 
        "title": "Frequency analysis and sheared reconstruction for rendering motion blur."
    }, 
    {
        "abstract": "Artists often need to import and embellish 3D models coming from CAD-CAM into 2D vector graphics software to produce, e.g., brochures or manuals. Current automatic solutions tend to result, at best, in a 2D triangle soup and artists often have to trace over 3D renderings. We describe a method to convert 3D models into 2D layered vector illustrations that respect visibility and facilitate further editing. Our core contribution is a visibility method that can partition a mesh into large components that can be layered according to visibility. Because self-occluding objects and objects forming occlusion cycles cannot be represented by layers without being cut, we introduce a new cut algorithm that uses a graph representation of the mesh and curvature-aware geodesic distances. ", 
        "id": 862, 
        "title": "A visibility algorithm for converting 3D meshes into editable 2D vector graphics."
    }, 
    {
        "abstract": "(d) Target image (e) Poisson cloning (f) Mean-value cloning Figure 1: Poisson cloning smoothly interpolates the error along the boundary of the source and the target regions across the entire cloned region (the resulting membrane is shown in (b)), yielding a seamless composite (e). A qualitatively similar membrane (c) may be achieved via transfinite interpolation, without solving a linear system. (f) Seamless cloning obtained instantly using the mean-value interpolant. Abstract Seamless cloning of a source image patch into a target image is an important and useful image editing operation, which has received considerable research attention in recent years. This operation is typically carried out by solving a Poisson equation with Dirich-let boundary conditions, which smoothly interpolates the discrepancies between the boundary of the source patch and the target across the entire cloned area. In this paper we introduce an alternative, coordinate-based approach, where rather than solving a large linear system to perform the aforementioned interpolation, the value of the interpolant at each interior pixel is given by a weighted combination of values along the boundary. More specifically, our approach is based on Mean-Value Coordinates (MVC). The use of coordinates is advantageous in terms of speed, ease of implementation, small memory footprint, and parallelizability, enabling real-time cloning of large regions, and interactive cloning of video streams. We demonstrate a number of applications and extensions of the coordinate-based framework.", 
        "id": 863, 
        "title": "Coordinates for instant image cloning."
    }, 
    {
        "abstract": "", 
        "id": 864, 
        "title": "Participating media illumination using light propagation maps."
    }, 
    {
        "abstract": "We propose a new family of second-generation wavelets constructed using a robust data-prediction lifting scheme. The support of these new wavelets is constructed based on the edge content of the image and avoids having pixels from both sides of an edge. Multi-resolution analysis, based on these new edge-avoiding wavelets, shows a better decorrelation of the data compared to common linear translation-invariant multi-resolution analyses. The reduced inter-scale correlation allows us to avoid halo artifacts in band-independent multi-scale processing without taking any special precautions. We thus achieve nonlinear data-dependent multiscale edge-preserving image filtering and processing at computation times which are linear in the number of image pixels. The new wavelets encode, in their shape, the smoothness information of the image at every scale. We use this to derive a new edge-aware interpolation scheme that achieves results, previously computed by solving an inhomogeneous Laplace equation, through an explicit computation. We thus avoid the difficulties in solving large and poorly-conditioned systems of equations. We demonstrate the effectiveness of the new wavelet basis for various computational photography applications such as multi-scale dynamic-range compression, edge-preserving smoothing and detail enhancement, and image colorization. ", 
        "id": 865, 
        "title": "Edge-avoiding wavelets and their applications."
    }, 
    {
        "abstract": "", 
        "id": 866, 
        "title": "DiagSplit: parallel, crack-free, adaptive tessellation for micropolygon rendering."
    }, 
    {
        "abstract": "Man-made objects are largely dominated by a few typical features that carry special characteristics and engineered meanings. State-of-the-art deformation tools fall short at preserving such characteristic features and global structure. We introduce iWIRES, a novel approach based on the argument that man-made models can be distilled using a few special 1D wires and their mutual relations. We hypothesize that maintaining the properties of such a small number of wires allows preserving the defining characteristics of the entire object. We introduce an analyze-and-edit approach, where prior to editing, we perform a light-weight analysis of the input shape to extract a descriptive set of wires. Analyzing the individual and mutual properties of the wires, and augmenting them with geometric attributes makes them intelligent and ready to be manipulated. Editing the object by modifying the intelligent wires leads to a powerful editing framework that retains the original design intent and object characteristics. We show numerous results of manipulation of man-made shapes using our editing technique.", 
        "id": 867, 
        "title": "iWIRES: an analyze-and-edit approach to shape manipulation."
    }, 
    {
        "abstract": "", 
        "id": 868, 
        "title": "Structured annotations for 2D-to-3D modeling."
    }, 
    {
        "abstract": "", 
        "id": 869, 
        "title": "A BSP-based algorithm for dimensionally nonhomogeneous planar implicit curves with topological guarantees."
    }, 
    {
        "abstract": "", 
        "id": 870, 
        "title": "Continuity mapping for multi-chart textures."
    }, 
    {
        "abstract": "We present a demonstration-based system for automatically generating succinct step-by-step visual tutorials of photo manipulations. An author first demonstrates the manipulation using an instrumented version of GIMP that records all changes in interface and application state. From the example recording, our system automatically generates tutorials that illustrate the manipulation using images, text, and annotations. It leverages automated image labeling (recognition of facial features and outdoor scene structures in our implementation) to generate more precise text descriptions of many of the steps in the tutorials. A user study comparing our automatically generated tutorials to hand-designed tutorials and screencapture video recordings finds that users are 2044% faster and make 6095% fewer errors using our tutorials. While our system focuses on tutorial generation, we also present some initial work on generating content-dependent macros that use image recognition to automatically transfer selection operations from the example image used in the demonstration to new target images. While our macros are limited to transferring selection operations we demonstrate automatic transfer of several common retouching techniques including eye recoloring, whitening teeth and sunset enhancement. ", 
        "id": 871, 
        "title": "Generating photo manipulation tutorials by demonstration."
    }, 
    {
        "abstract": "", 
        "id": 872, 
        "title": "Removing image artifacts due to dirty camera lenses and thin occluders."
    }, 
    {
        "abstract": "", 
        "id": 873, 
        "title": "Stochastic progressive photon mapping."
    }, 
    {
        "abstract": "We develop a method for reliable simulation of elastica in complex contact scenarios. Our focus is on firmly establishing three parameter-independent guarantees: that simulations of wellposed problems (a) have no interpenetrations, (b) obey causality, momentum- and energy-conservation laws, and (c) complete in finite time. We achieve these guarantees through a novel synthesis of asynchronous variational integrators, kinetic data structures, and a discretization of the contact barrier potential by an infinite sum of nested quadratic potentials. In a series of two- and threedimensional examples, we illustrate that this method more easily handles challenging problems involving complex contact geometries, sharp features, and sliding during extremely tight contact.  Safety, correctness, progress Robust simulation of complex contact scenarios is critical to applications spanning graphics (training, virtual worlds, entertainment) and engineering (product design, safety analysis, experimental validation). Challenging scenarios involve dynamics with frequent and distributed points of contact, interaction with sharp boundaries, resting and sliding contact, and combinations thereof. Useful resolution of these scenarios requires consideration of the fundamental issues of geometric safety, physical correctness, and computational progress, with the respective meanings that (a) for well-posed problems the simulation does not enter an invalid (interpenetrating) state, (b) collision response obeys physical laws of causality and conservation (of mass, momentum, energy, etc.), and (c) the algorithm completes a simulation in finite, preferrably short, time.  ", 
        "id": 874, 
        "title": "Asynchronous contact mechanics."
    }, 
    {
        "abstract": "", 
        "id": 875, 
        "title": "Virtual spherical lights for many-light rendering of glossy scenes."
    }, 
    {
        "abstract": "", 
        "id": 876, 
        "title": "Automatic pre-tessellation culling."
    }, 
    {
        "abstract": "", 
        "id": 877, 
        "title": "BiDi screen: a thin, depth-sensing LCD for 3D interaction using light fields."
    }, 
    {
        "abstract": "The simulation of believable, photorealistic fire is difficult because fire is highly detailed, fast-moving, and turbulent. Traditional gridbased simulation models require large grids and long simulation times to capture even the coarsest levels of detail. In this paper, we propose a novel combination of coarse particle grid simulation with very fine, view-oriented refinement simulations performed on a GPU. We also propose a simple, GPU-based volume rendering scheme. The resulting images of fire produced by the proposed techniques are extremely detailed and can be integrated seamlessly into film-resolution images. Our refinement technique takes advantage of perceptive limitations and likely viewing behavior to split the refinement stage into separable, parallel tasks. Multiple independent GPUs are employed to rapidly refine final simulations for rendering, allowing for rapid artist turnaround time and very high resolutions. Directability is achieved by allowing virtually any user-defined particle behavior as an input to the initial coarse simulation. The physical criteria enforced by the coarse stage are minimal and could be easily implemented using any of the wide variety of commercially available fluid simulation tools. The GPU techniques utilized by our refinement stage are simple and widely available on even consumer-grade GPUs, lowering the overall implementation cost of the proposed system. ", 
        "id": 878, 
        "title": "Directable, high-resolution simulation of fire on the GPU."
    }, 
    {
        "abstract": "", 
        "id": 879, 
        "title": "Debugging GPU stream programs through automatic dataflow recording and visualization."
    }, 
    {
        "abstract": "", 
        "id": 880, 
        "title": "Consolidation of unorganized point clouds for surface reconstruction."
    }, 
    {
        "abstract": "", 
        "id": 881, 
        "title": "Generalizing motion edits with Gaussian processes."
    }, 
    {
        "abstract": "Most game interfaces today are largely symbolic, translating simplified input such as keystrokes into the choreography of full-body character movement. In this paper, we describe a system that directly uses human motion performance to provide a radically different, and much more expressive interface for controlling virtual characters. Our system takes a data feed from a motion capture system as input, and in real-time translates the performance into corresponding actions in a virtual world. The difficulty with such an approach arises from the need to manage the discrepancy between the real and virtual world, leading to two important subproblems 1) recognizing the user's intention, and 2) simulating the appropriate action based on the intention and virtual context. We solve this issue by first enabling the virtual world's designer to specify possible activities in terms of prominent features of the world along with associated motion clips depicting interactions. We then integrate the prerecorded motions with online performance and dynamic simulation to synthesize seamless interaction of the virtual character in a simulated virtual world. The result is a flexible interface through which a user can make freeform control choices while the resulting character motion maintains both physical realism and the user's personal style. ", 
        "id": 882, 
        "title": "Performance-based control interface for character animation."
    }, 
    {
        "abstract": "", 
        "id": 883, 
        "title": "Optimization-based interactive motion synthesis."
    }, 
    {
        "abstract": "", 
        "id": 884, 
        "title": "Capturing hair assemblies fiber by fiber."
    }, 
    {
        "abstract": "", 
        "id": 885, 
        "title": "A GPU Laplacian solver for diffusion curves and Poisson image editing."
    }, 
    {
        "abstract": "", 
        "id": 886, 
        "title": "Rendering surface details with diffusion curves."
    }, 
    {
        "abstract": "", 
        "id": 887, 
        "title": "Symmetric architecture modeling with a single image."
    }, 
    {
        "abstract": "We present a set of algorithms and an associated display system capable of producing correctly rendered eye contact between a three-dimensionally transmitted remote participant and a group of observers in a 3D teleconferencing system. The participant's face is scanned in 3D at 30Hz and transmitted in real time to an autostereoscopic horizontal-parallax 3D display, displaying him or her over more than a 180 field of view observable to multiple observers. To render the geometry with correct perspective, we create a fast vertex shader based on a 6D lookup table for projecting 3D scene vertices to a range of subject angles, heights, and distances. We generalize the projection mathematics to arbitrarily shaped display surfaces, which allows us to employ a curved concave display surface to focus the high speed imagery to individual observers. To achieve two-way eye contact, we capture 2D video from a cross-polarized camera reflected to the position of the virtual participant's eyes, and display this 2D video feed on a large screen in front of the real participant, replicating the viewpoint of their virtual self. To achieve correct vertical perspective, we further leverage this image to track the position of each audience member's eyes, allowing the 3D display to render correct vertical perspective for each of the viewers around the device. The result is a one-to-many 3D teleconferencing system able to reproduce the effects of gaze, attention, and eye contact generally missing in traditional teleconferencing systems. ", 
        "id": 888, 
        "title": "Achieving eye contact in a one-to-many 3D video teleconferencing system."
    }, 
    {
        "abstract": "", 
        "id": 889, 
        "title": "Ray casting of multiple volumetric datasets with polyhedral boundaries on manycore GPUs."
    }, 
    {
        "abstract": "", 
        "id": 890, 
        "title": "Data-driven curvature for real-time line drawing of dynamic scenes."
    }, 
    {
        "abstract": " We present a method for simulating highly detailed cutting and fracturing of thin shells using low-resolution simulation meshes. Instead of refining or remeshing the underlying simulation domain to resolve complex cut paths, we adapt the extended finite element method (XFEM) and enrich our approximation by customdesigned basis functions, while keeping the simulation mesh unchanged. The enrichment functions are stored in enrichment textures, which allows for fracture and cutting discontinuities at a resolution much finer than the underlying mesh, similar to image textures for increased visual resolution. Furthermore, we propose harmonic enrichment functions to handle multiple, intersecting, arbitrarily shaped, progressive cuts per element in a simple and unified framework. Our underlying shell simulation is based on discontinuous Galerkin (DG) FEM, which relaxes the restrictive requirement of C1 continuous basis functions and thus allows for simpler, C0 continuous XFEM enrichment functions. ", 
        "id": 891, 
        "title": "Enrichment textures for detailed cutting of shells."
    }, 
    {
        "abstract": "Lighting design is a complex but fundamental task in computer cinematography, involving the adjustment of light parameters to define final scene appearance. Many user interfaces have been proposed to simplify lighting design. They can be generally categorized in three paradigms: direct light parameter manipulation, indirect light feature manipulation (e.g., shadow dragging), and goal-based optimization of lighting through painting. To this date, no formal evaluation of the relative effectiveness of these paradigms has been performed.  objective and subjective data and found that subjects can light well with direct and indirect interfaces, preferring the latter. Paint-based goal specification was found to be significantly worse than the other paradigms, especially since users tend to sketch rather than accurately paint goal images, an input that painting algorithms were not designed for. We also found that given enough time, novices can perform relatively complex lighting tasks, unhindered by geometry or lighting complexity. Finally, we believe that our study will impact the design of future lighting interfaces and it will serve as the basis for designing additional experiments to reach a comprehensive evaluation of lighting interfaces.  In this paper, we present a first step toward evaluating the benefits of these three paradigms in the form of a user study with a focus on novice users. 20 subjects participated in the experiment by performing various trials on simple scenes with up to 8 point lights, designed to test two lighting tasks: precise adjustment of lighting and the artistic exploration of lighting configurations. We collected ACM Reference Format Kerr, W., Pellacini, F. 2009. Toward Evaluating Lighting Design Interface Paradigms for Novice Users. ACM Trans. Graph. 28, 3, Article 26 (August 2009), 9 pages. DOI = 10.1145/1531326.1531332 http://doi.acm.org/10.1145/1531326.1531332. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org.  2009 ACM 0730-0301/2009/03-ART26 $10.00 DOI 10.1145/1531326.1531332 http://doi.acm.org/10.1145/1531326.1531332  ", 
        "id": 892, 
        "title": "Toward evaluating lighting design interface paradigms for novice users."
    }, 
    {
        "abstract": "We propose an approach for efficiently simulating elastic objects made of non-homogeneous, non-isotropic materials. Based on recent developments in homogenization theory, a methodology is introduced to approximate a deformable object made of arbitrary fine structures of various linear elastic materials with a dynamicallysimilar coarse model. This numerical coarsening of the material properties allows for simulation of fine, heterogeneous structures on very coarse grids while capturing the proper dynamics of the original dynamical system, thus saving orders of magnitude in computational time. Examples including inhomogeneous and/or anisotropic materials can be realistically simulated in realtime with a numerically-coarsened model made of a few mesh elements.  ", 
        "id": 893, 
        "title": "Numerical coarsening of inhomogeneous elastic materials."
    }, 
    {
        "abstract": "", 
        "id": 894, 
        "title": "An edge-based computationally efficient formulation of Saint Venant-Kirchhoff tetrahedral finite elements."
    }, 
    {
        "abstract": "The ability to interactively edit human motion data is essential for character animation. We present a novel motion editing technique that allows the user to manipulate synchronized multiple character motions interactively. Our Laplacian motion editing method formulates the interaction among multiple characters as a collection of linear constraints and enforces the constraints, while the user directly manipulates the motion of characters in both spatial and temporal domains. Various types of manipulation handles are provided to specify absolute/relative spatial location, direction, time, duration, and synchronization of multiple characters. The capability of non-sequential discrete editing is incorporated into our motion editing interfaces, so continuous and discrete editing is performed simultaneously and seamlessly. We demonstrate that the synchronized multiple character motions are synthesized and manipulated at interactive rates using spatiotemporal constraints. ", 
        "id": 895, 
        "title": "Synchronized multi-character motion editing."
    }, 
    {
        "abstract": "", 
        "id": 896, 
        "title": "Skipping steps in deformable simulation with online model reduction."
    }, 
    {
        "abstract": "", 
        "id": 897, 
        "title": "Robust color-to-gray via nonlinear global mapping."
    }, 
    {
        "abstract": "", 
        "id": 898, 
        "title": "Stretching and wiggling liquids."
    }, 
    {
        "abstract": "Display technology is advancing quickly with peak luminance increasing significantly, enabling high-dynamic-range displays. However, perceptual color appearance under extended luminance levels has not been studied, mainly due to the unavailability of psychophysical data. Therefore, we conduct a psychophysical study in order to acquire appearance data for many different luminance levels (up to 16,860 cd/m2) covering most of the dynamic range of the human visual system. These experimental data allow us to quantify human color perception under extended luminance levels, yielding a generalized color appearance model. Our proposed appearance model is efficient, accurate and invertible. It can be used to adapt the tone and color of images to different dynamic ranges for crossmedia reproduction while maintaining appearance that is close to human perception. ", 
        "id": 899, 
        "title": "Modeling human color perception under extended luminance levels."
    }, 
    {
        "abstract": "", 
        "id": 900, 
        "title": "Lie group integrators for animation and control of vehicles."
    }, 
    {
        "abstract": "", 
        "id": 901, 
        "title": "A system for retargeting of streaming video."
    }, 
    {
        "abstract": "Camera flashes produce intrusive bursts of light that disturb or dazzle. We present a prototype camera and flash that uses infra-red and ultra-violet light mostly outside the visible range to capture pictures in low-light conditions. This \"dark\" flash is at least two orders of magnitude dimmer than conventional flashes for a comparable exposure. Building on ideas from flash/no-flash photography, we capture a pair of images, one using the dark flash, other using the dim ambient illumination alone. We then exploit the correlations between images recorded at different wavelengths to denoise the ambient image and restore fine details to give a high quality result, even in very weak illumination. The processing techniques can also be used to denoise images captured with conventional cameras. ", 
        "id": 902, 
        "title": "Dark flash photography."
    }, 
    {
        "abstract": "Noise is an essential tool for texturing and modeling. Designing interesting textures with noise calls for accurate spectral control, since noise is best described in terms of spectral content. Texturing requires that noise can be easily mapped to a surface, while high-quality rendering requires anisotropic filtering. A noise function that is procedural and fast to evaluate offers several additional advantages. Unfortunately, no existing noise combines all of these properties. In this paper we introduce a noise based on sparse convolution and the Gabor kernel that enables all of these properties. Our noise offers accurate spectral control with intuitive parameters such as orientation, principal frequency and bandwidth. Our noise supports two-dimensional and solid noise, but we also introduce setup-free surface noise. This is a method for mapping noise onto a surface, complementary to solid noise, that maintains the appearance of the noise pattern along the object and does not require a texture parameterization. Our approach requires only a few bytes of storage, does not use discretely sampled data, and is nonperiodic. It supports anisotropy and anisotropic filtering. We demonstrate our noise using an interactive tool for noise design. ", 
        "id": 903, 
        "title": "Procedural noise using sparse Gabor convolution."
    }, 
    {
        "abstract": "Gradient mesh vector graphics representation, used in commercial software, is a regular grid with specified position and color, and their gradients, at each grid point. Gradient meshes can compactly represent smoothly changing data, and are typically used for single objects. This paper advances the state of the art for gradient meshes in several significant ways. Firstly, we introduce a topology-preserving gradient mesh representation which allows an arbitrary number of holes. This is important, as objects in images often have holes, either due to occlusion, or their 3D structure. Secondly, our algorithm uses the concept of image manifolds, adapting surface parameterization and fitting techniques to generate the gradient mesh in a fully automatic manner. Existing gradient-mesh algorithms require manual interaction to guide grid construction, and to cut objects with holes into disk-like regions. Our new algorithm is empirically at least 10 times faster than previous approaches. Furthermore, image segmentation can be used with our new algorithm to provide automatic gradient mesh generation for a whole image. Finally, fitting errors can be simply controlled to balance quality with storage.", 
        "id": 904, 
        "title": "Automatic and topology-preserving gradient mesh generation for image vectorization."
    }, 
    {
        "abstract": "", 
        "id": 905, 
        "title": "Webcam clip art: appearance and illuminant transfer from time-lapse sequences."
    }, 
    {
        "abstract": "", 
        "id": 906, 
        "title": "Modeling spatial and temporal variation in motion data."
    }, 
    {
        "abstract": "", 
        "id": 907, 
        "title": "Depth-of-field rendering with multiview synthesis."
    }, 
    {
        "abstract": "", 
        "id": 908, 
        "title": "Compact character controllers."
    }, 
    {
        "abstract": "", 
        "id": 909, 
        "title": "Comprehensive biomechanical modeling and simulation of the upper body."
    }, 
    {
        "abstract": "", 
        "id": 910, 
        "title": "Real-time prosody-driven synthesis of body language."
    }, 
    {
        "abstract": "Depth of field (DOF), the range of scene depths that appear sharp in a photograph, poses a fundamental tradeoff in photography-- wide apertures are important to reduce imaging noise, but they also increase defocus blur. Recent advances in computational imaging modify the acquisition process to extend the DOF through deconvolution. Because deconvolution quality is a tight function of the frequency power spectrum of the defocus kernel, designs with high spectra are desirable. In this paper we study how to design effective extended-DOF systems, and show an upper bound on the maximal power spectrum that can be achieved. We analyze defocus kernels in the 4D light field space and show that in the frequency domain, only a low-dimensional 3D manifold contributes to focus. Thus, to maximize the defocus spectrum, imaging systems should concentrate their limited energy on this manifold. We review several computational imaging systems and show either that they spend energy outside the focal manifold or do not achieve a high spectrum over the DOF. Guided by this analysis we introduce the lattice-focal lens, which concentrates energy at the low-dimensional focal manifold and achieves a higher power spectrum than previous designs. We have built a prototype lattice-focal lens and present extended depth of field results. ", 
        "id": 911, 
        "title": "4D frequency analysis of computational cameras for depth of field extension."
    }, 
    {
        "abstract": "", 
        "id": 912, 
        "title": "Robust single-view geometry and motion reconstruction."
    }, 
    {
        "abstract": " The goal of our work is to develop an efficient, automatic algorithm for discovering point correspondences between surfaces that are approximately and/or partially isometric.  Our approach is based on three observations. First, isometries are a subset of the Mobius group, which has low-dimensionality  six degrees of freedom for topological spheres, and three for topological discs. Second, computing the Mobius transformation that interpolates any three points can be computed in closed-form after a mid-edge flattening to the complex plane. Third, deviations from isometry can be modeled by a transportation-type distance between corresponding points in that plane. Motivated by these observations, we have developed a Mobius Voting algorithm that iteratively: 1) samples a triplet of three random points from each of two point sets, 2) uses the Mobius transformations defined by those triplets to map both point sets into a canonical coordinate frame on the complex plane, and 3) produces \"votes\" for predicted correspondences between the mutually closest points with magnitude representing their estimated deviation from isometry. The result of this process is a fuzzy correspondence matrix, which is converted to a permutation matrix with simple matrix operations and output as a discrete set of point correspondences with confidence values. The main advantage of this algorithm is that it can find intrinsic point correspondences in cases of extreme deformation. During experiments with a variety of data sets, we find that it is able to find dozens of point correspondences between different object types in different poses fully automatically. ", 
        "id": 913, 
        "title": "M\u00f6bius voting for surface correspondence."
    }, 
    {
        "abstract": "", 
        "id": 914, 
        "title": "2D piecewise algebraic splines for implicit modeling."
    }, 
    {
        "abstract": "This paper introduces an optimization-based approach to synthesizing hand manipulations from a starting grasping pose. We describe an automatic method that takes as input an initial grasping pose and partial object trajectory, and produces as output physically plausible hand animation that effects the desired manipulation. In response to different dynamic situations during manipulation, our algorithm can generate a range of possible hand manipulations including changes in joint configurations, changes in contact points, and changes in the grasping force. Formulating hand manipulation as an optimization problem is key to our algorithm's ability to generate a large repertoire of hand motions from limited user input. We introduce an objective function that accentuates the detailed hand motion and contacts adjustment. Furthermore, we describe an optimization method that solves for hand motion and contacts efficiently while taking into account long-term planning of contact forces. Our algorithm does not require any tuning of parameters, nor does it require any prescribed hand motion sequences. ", 
        "id": 915, 
        "title": "Dextrous manipulation from a grasping pose."
    }, 
    {
        "abstract": "We describe a technique that transforms a video from a hand-held video camera so that it appears as if it were taken with a directed camera motion. Our method adjusts the video to appear as if it were taken from nearby viewpoints, allowing 3D camera movements to be simulated. By aiming only for perceptual plausibility, rather than accurate reconstruction, we are able to develop algorithms that can effectively recreate dynamic scenes from a single source video. Our technique first recovers the original 3D camera motion and a sparse set of 3D, static scene points using an off-the-shelf structure-frommotion system. Then, a desired camera path is computed either automatically (e.g., by fitting a linear or quadratic path) or interactively. Finally, our technique performs a least-squares optimization that computes a spatially-varying warp from each input video frame into an output frame. The warp is computed to both follow the sparse displacements suggested by the recovered 3D structure, and avoid deforming the content in the video frame. Our experiments on stabilizing challenging videos of dynamic scenes demonstrate the effectiveness of our technique. ", 
        "id": 916, 
        "title": "Content-preserving warps for 3D video stabilization."
    }, 
    {
        "abstract": " In this paper, we present Paint Selection, a progressive painting-based tool for local selection in images. Paint Selection facilitates users to progressively make a selection by roughly painting the object of interest using a brush. More importantly, Paint Selection is efficient enough that instant feedback can be provided to users as they drag the mouse. We demonstrate that high quality selections can be quickly and effectively \"painted\" on a variety of multi-megapixel images. ", 
        "id": 917, 
        "title": "Paint selection."
    }, 
    {
        "abstract": "", 
        "id": 918, 
        "title": "On centroidal voronoi tessellation - energy smoothness and fast computation."
    }, 
    {
        "abstract": "", 
        "id": 919, 
        "title": "3D polyomino puzzle."
    }, 
    {
        "abstract": "", 
        "id": 920, 
        "title": "Approximating subdivision surfaces with Gregory patches for hardware tessellation."
    }, 
    {
        "abstract": "We demonstrate a real-time simulation system capable of automatically balancing a standing character, while at the same time tracking a reference motion and responding to external perturbations. The system is general to non-human morphologies and results in natural balancing motions employing the entire body (for example, wind-milling). Our novel balance routine seeks to control the linear and angular momenta of the character. We demonstrate how momentum is related to the center of mass and center of pressure of the character and derive control rules to change these centers for balance. The desired momentum changes are reconciled with the objective of tracking the reference motion through an optimization routine which produces target joint accelerations. A hybrid inverse/forward dynamics algorithm determines joint torques based on these joint accelerations and the ground reaction forces. Finally, the joint torques are applied to the free-standing character simulation. We demonstrate results for following both motion capture and keyframe data as well as both human and non-human morphologies in presence of a variety of conditions and disturbances. ", 
        "id": 921, 
        "title": "Momentum control for balance."
    }, 
    {
        "abstract": "We describe a method for plausible interpolation of images, with a wide range of applications like temporal up-sampling for smooth playback of lower frame rate video, smooth view interpolation, and animation of still images. The method is based on the intuitive idea, that a given pixel in the interpolated frames traces out a path in the source images. Therefore, we simply move and copy pixel gradients from the input images along this path. A key innovation is to allow arbitrary (asymmetric) transition points, where the path moves from one image to the other. This flexible transition preserves the frequency content of the originals without ghosting or blurring, and maintains temporal coherence. Perhaps most importantly, our framework makes occlusion handling particularly simple. The transition points allow for matches away from the occluded regions, at any suitable point along the path. Indeed, occlusions do not need to be handled explicitly at all in our initial graph-cut optimization. Moreover, a simple comparison of computed path lengths after the optimization, allows us to robustly identify occluded regions, and compute the most plausible interpolation in those areas. Finally, we show that significant improvements are obtained by moving gradients and using Poisson reconstruction. ", 
        "id": 922, 
        "title": "Moving gradients: a path-based method for plausible image interpolation."
    }, 
    {
        "abstract": "", 
        "id": 923, 
        "title": "Evaluation of reverse tone mapping through varying exposure conditions."
    }, 
    {
        "abstract": "", 
        "id": 924, 
        "title": "Printing spatially-varying reflectance."
    }, 
    {
        "abstract": "", 
        "id": 925, 
        "title": "Motion field texture synthesis."
    }, 
    {
        "abstract": " Hair simulation remains one of the most challenging aspects of creating virtual characters. Most research focuses on handling the massive geometric complexity of hundreds of thousands of interacting hairs. This is accomplished either by using brute force simulation or by reducing degrees of freedom with guide hairs. This paper presents a hybrid Eulerian/Lagrangian approach to handling both self and body collisions with hair efficiently while still maintaining detail. Bulk interactions and hair volume preservation is handled efficiently and effectively with a FLIP based fluid solver while intricate hair-hair interaction is handled with Lagrangian selfcollisions. Thus the method has the efficiency of continuum/guide based hair models with the high detail of Lagrangian self-collision approaches. ", 
        "id": 926, 
        "title": "Detail preserving continuum simulation of straight hair."
    }, 
    {
        "abstract": " In a conventional 2d painting or compositing program, graphical objects are stacked in a user-specified global order, as if each were printed on an image-sized sheet of transparent film. In this paper we show how to relax this restriction so that users can make stacking decisions on a per-overlap basis, as if the layers were pictures cut from a magazine. This allows for complex and visually exciting overlapping patterns, without painstaking layer-splitting, depth-value painting, region coloring, or mask-drawing. Instead, users are presented with a layers dialog which acts locally. Behind the scenes, we divide the image into overlap regions and track the ordering of layers in each region. We formalize this structure as a graph of stacking lists, define the set of orderings where layers do not interpenetrate as consistent, and prove that our local stacking operators are both correct and sufficient to reach any consistent stacking. We also provide a method for updating the local stacking when objects change shape or position due to user editing  this scheme prevents layer updates from producing undesired intersections. Our method extends trivially to both animation compositing and local visibility adjustment in depth-peeled 3d scenes; the latter of which allows for the creation of impossible figures which can be viewed and manipulated in real-time. ", 
        "id": 927, 
        "title": "Local layering."
    }, 
    {
        "abstract": "Populated virtual environments need to be simulated with as much variety as possible. By identifying the most salient parts of the scene and characters, available resources can be concentrated where they are needed most. In this paper, we investigate which body parts of virtual characters are most looked at in scenes containing duplicate characters or clones. Using an eye-tracking device, we recorded fixations on body parts while participants were asked to indicate whether clones were present or not. We found that the head and upper torso attract the majority of first fixations in a scene and are attended to most. This is true regardless of the orientation, presence or absence of motion, sex, age, size, and clothing style of the character. We developed a selective variation method to exploit this knowledge and perceptually validated our method. We found that selective colour variation is as effective at generating the illusion of variety as full colour variation. We then evaluated the effectiveness of four variation methods that varied only salient parts of the characters. We found that head accessories, top texture and face texture variation are all equally effective at creating variety, whereas facial geometry alterations are less so. Performance implications and guidelines are presented.", 
        "id": 928, 
        "title": "Eye-catching crowds: saliency based selective variation."
    }, 
    {
        "abstract": "", 
        "id": 929, 
        "title": "Abstraction of man-made shapes."
    }, 
    {
        "abstract": "", 
        "id": 930, 
        "title": "Emerging images."
    }, 
    {
        "abstract": "", 
        "id": 931, 
        "title": "Shadow art."
    }, 
    {
        "abstract": "Our goal is to generate novel realistic images of faces using a model trained from real examples. This model consists of two components: First we consider face images as samples from a texture with spatially varying statistics and describe this texture with a local non-parametric model. Second, we learn a parametric global model of all of the pixel values. To generate realistic faces, we combine the strengths of both approaches and condition the local non-parametric model on the global parametric model. We demonstrate that with appropriate choice of local and global models it is possible to reliably generate new realistic face images that do not correspond to any individual in the training data. We extend the model to cope with considerable intra-class variation (pose and illumination). Finally, we apply our model to editing real facial images: we demonstrate image in-painting, interactive techniques for improving synthesized images and modifying facial expressions. ", 
        "id": 932, 
        "title": "Visio-lization: generating novel facial images."
    }, 
    {
        "abstract": "We show a new camera based interaction solution where an ordinary camera can detect small optical tags from a relatively large distance. Current optical tags, such as barcodes, must be read within a short range and the codes occupy valuable physical space on products. We present a new low-cost optical design so that the tags can be shrunk to 3mm visible diameter, and unmodified ordinary cameras several meters away can be set up to decode the identity plus the relative distance and angle. The design exploits the bokeh effect of ordinary cameras lenses, which maps rays exiting from an out of focus scene point into a disk like blur on the camera sensor. This bokeh-code or Bokode is a barcode design with a simple lenslet over the pattern. We show that a code with 15m features can be read using an off-the-shelf camera from distances of up to 2 meters. We use intelligent binary coding to estimate the relative distance and angle to the camera, and show potential for applications in augmented reality and motion capture. We analyze the constraints and performance of the optical system, and discuss several plausible application scenarios.", 
        "id": 933, 
        "title": "Bokode: imperceptible visual tags for camera based interaction from a distance."
    }, 
    {
        "abstract": "Dynamically simulated characters are difficult to control because they are underactuated--they have no direct control over their global position and orientation. In order to succeed, control policies must look ahead to determine stabilizing actions, but such planning is complicated by frequent ground contacts that produce a discontinuous search space. This paper introduces a locomotion system that generates high-quality animation of agile movements using nonlinear controllers that plan through such contact changes. We demonstrate the general applicability of this approach by emulating walking and running motions in rigid-body simulations. Then we consolidate these controllers under a higher-level planner that interactively controls the character's direction. ", 
        "id": 934, 
        "title": "Contact-aware nonlinear control of dynamic characters."
    }, 
    {
        "abstract": "Numerical viscosity has long been a problem in fluid animation. Existing methods suffer from intrinsic artificial dissipation and often apply complicated computational mechanisms to combat such effects. Consequently, dissipative behavior cannot be controlled or modeled explicitly in a manner independent of time step size, complicating the use of coarse previews and adaptive-time stepping methods. This paper proposes simple, unconditionally stable, fully Eulerian integration schemes with no numerical viscosity that are capable of maintaining the liveliness of fluid motion without recourse to corrective devices. Pressure and fluxes are solved efficiently and simultaneously in a time-reversible manner on simplicial grids, and the energy is preserved exactly over long time scales in the case of inviscid fluids. These integrators can be viewed as an extension of the classical energy-preserving Harlow-Welch / CrankNicolson scheme to simplicial grids. ", 
        "id": 935, 
        "title": "Energy-preserving integrators for fluid animation."
    }, 
    {
        "abstract": " vision, surface, non-stationary  Popular subdivision algorithms like Catmull-Clark and Loop are C2 almost everywhere, but suffer from shape artifacts and reduced smoothness exactly near the so-called \"extraordinary vertices\" that motivate their use. Subdivision theory explains that inherently, for standard stationary subdivision algorithms, curvature-continuity and the ability to model all quadratic shapes requires a degree of at least bi-6. The existence of a simple-to-implement C2 subdivision algorithm generating surfaces of good shape and piecewise degree bi-3 in the polar setting is therefore a welcome surprise. This paper presents such an algorithm, the underlying insights, and a detailed analysis. In bi-3 C2 polar subdivision the weights depend, as in standard schemes, only on the valence, but the valence at one central polar vertex increases to match Catmull-Clark-refinement. ", 
        "id": 936, 
        "title": "Bi-3 C2 polar subdivision."
    }, 
    {
        "abstract": "", 
        "id": 937, 
        "title": "Aggregate dynamics for dense crowd simulation."
    }, 
    {
        "abstract": "In this paper we introduce a new approach for the embedding of linear elastic deformable models. Our technique results in significant improvements in the efficient physically based simulation of highly detailed objects. First, our embedding takes into account topological details, that is, disconnected parts that fall into the same coarse element are simulated independently. Second, we account for the varying material properties by computing stiffness and interpolation functions for coarse elements which accurately approximate the behaviour of the embedded material. Finally, we also take into account empty space in the coarse embeddings, which provides a better simulation of the boundary. The result is a straightforward approach to simulating complex deformable models with the ease and speed associated with a coarse regular embedding, and with a quality of detail that would only be possible at much finer resolution. ", 
        "id": 938, 
        "title": "Preserving topology and elasticity for embedded deformable models."
    }, 
    {
        "abstract": "", 
        "id": 939, 
        "title": "Adaptive wavelet rendering."
    }, 
    {
        "abstract": "E PRESENT a method for generating realistic models of temperate-climate trees and shrubs. This method is based on the biological hypothesis that the form of a developing tree emerges from a self-organizing process dominated by the competition of buds and branches for light or space, and regulated by internal signaling mechanisms. Simulations of this process robustly generate a wide range of realistic trees and bushes. The generated forms can be controlled with a variety of interactive techniques, including procedural brushes, sketching, and editing operations such as pruning and bending of branches. We illustrate the usefulness and versatility of the proposed method with diverse tree models, forest scenes, animations of tree development, and examples of combined interactive-procedural tree modeling.", 
        "id": 940, 
        "title": "Self-organizing tree models for image synthesis."
    }, 
    {
        "abstract": "", 
        "id": 941, 
        "title": "Photorealistic models for pupil light reflex and iridal pattern deformation."
    }, 
    {
        "abstract": "", 
        "id": 942, 
        "title": "Compressive light transport sensing."
    }, 
    {
        "abstract": "", 
        "id": 943, 
        "title": "Synthetic turbulence using artificial boundary layers."
    }, 
    {
        "abstract": "", 
        "id": 944, 
        "title": "The graph camera."
    }, 
    {
        "abstract": "", 
        "id": 945, 
        "title": "Micro-rendering for scalable, parallel final gathering."
    }, 
    {
        "abstract": "", 
        "id": 946, 
        "title": "Interactive reflection editing."
    }, 
    {
        "abstract": "", 
        "id": 947, 
        "title": "Layered shape synthesis: automatic generation of control maps for non-stationary textures."
    }, 
    {
        "abstract": "Recently, there has been great interest in multi-touch interfaces. Such devices have taken the form of camera-based systems such as Microsoft Surface [de los Reyes et al. 2007] and Perceptive Pixel's FTIR display [Han 2005] as well as hand-held devices using capacitive sensors such as the Apple iPhone [Jobs et al. 2008]. However, optical systems are inherently bulky while most capacitive systems are only practical in small form factors and are limited in their application since they respond only to human touch and are insensitive to variations in pressure [Westerman 1999]. We have created the UnMousePad, a flexible and inexpensive multitouch input device based on a newly developed pressure-sensing principle called Interpolating Force Sensitive Resistance. IFSR sensors can acquire high-quality anti-aliased pressure images at high frame rates. They can be paper-thin, flexible, and transparent and can easily be scaled to fit on a portable device or to cover an entire table, floor or wall. The UnMousePad can sense three orders of magnitude of pressure variation, and can be used to distinguish multiple fingertip touches while simultaneously tracking pens and styli with a positional accuracy of 87 dpi, and can sense the pressure distributions of objects placed on its surface. In addition to supporting multi-touch interaction, IFSR is a general pressure imaging technology that can be incorporated into shoes, tennis racquets, hospital beds, factory assembly lines and many other applications. The ability to measure high-quality pressure images at low cost has the potential to dramatically improve the way that people interact with machines and the way that machines interact with the world. e-mail: ilya@cs.nyu.edu e-mail:perlin@cs.nyu.edu ACM Reference Format Rosenberg, I., Perlin, K. 2009. The UnMousePad  An Interpolating Multi-Touch Force-Sensing Input Pad. ACM Trans. Graph. 28, 3, Article 65 (August 2009), 9 pages. DOI = 10.1145/1531326.1531371 http://doi.acm.org/10.1145/1531326.1531371. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org.  2009 ACM 0730-0301/2009/03-ART65 $10.00 DOI 10.1145/1531326.1531371 http://doi.acm.org/10.1145/1531326.1531371  ", 
        "id": 948, 
        "title": "The UnMousePad: an interpolating multi-touch force-sensing input pad."
    }, 
    {
        "abstract": "Content aware resizing gained popularity lately and users can now choose from a battery of methods to retarget their media. However, no single retargeting operator performs well on all images and all target sizes. In a user study we conducted, we found that users prefer to combine seam carving with cropping and scaling to produce results they are satisfied with. This inspires us to propose an algorithm that combines different operators in an optimal manner. We define a resizing space as a conceptual multi-dimensional space combining several resizing operators, and show how a path in this space defines a sequence of operations to retarget media. We define a new image similarity measure, which we term Bi-Directional Warping (BDW), and use it with a dynamic programming algorithm to find an optimal path in the resizing space. In addition, we show a simple and intuitive user interface allowing users to explore the resizing space of various image sizes interactively. Using key-frames and interpolation we also extend our technique to retarget video, providing the flexibility to use the best combination of operators at different times in the sequence.  images and video. Recently, content aware methods such as seam carving and non-uniform warping were proposed to supplement content oblivious methods such as scaling or cropping. A content aware retargeting operator relies on an importance map to preserve the important parts of the media at the expense of the less-important ones. Importance measures include image gradients, saliency and entropy, as well as high level cues such as face detectors, motion detectors and more. However, content aware methods do not succeed in all cases and for all sizes. For example, in case the important object occupies large portions of the image or video frame, content aware resizing might distort it. Often, the best resizing method depends on the image itself: one method might work best on one image, while another on a different image. In such cases using a combination of several methods (operators) might achieve better results than any specific one alone (Figure 1). In this paper we propose to combine several operators together, instead of searching for the best operator that will work on all images. Our approach is supported by a user study we conducted that clearly shows that users prefer to use more than one operator to achieve better results.  ", 
        "id": 949, 
        "title": "Multi-operator media retargeting."
    }, 
    {
        "abstract": "", 
        "id": 950, 
        "title": "Packing circles and spheres on surfaces."
    }, 
    {
        "abstract": "", 
        "id": 951, 
        "title": "Analytic drawing of 3D scaffolds."
    }, 
    {
        "abstract": " This paper presents a highly efficient direct trimming technique for NURBS surfaces, which is applicable to tessellation-based rendering as well as ray tracing systems. The central idea is to split the trim curves into monotonic segments with respect to the two parameter dimensions of the surface patches. We use an optimized bisection method to classify a point with respect to each monotonic trim curve segment without performing an actual intersection test. Our hierarchical acceleration structure allows the use of a large number of such curve segments and performs the bisection method only for points contained in the bounding boxes of the curve segments. We have integrated our novel point classification scheme into a GPU-based NURBS ray casting system and implemented the entire trimmed NURBS rendering algorithm in a single OpenGL GLSL shader. The shader can handle surfaces and trim curves of arbitrary degrees, which allows the use of original CAD data without incorporating any approximations. Performance data confirms that our trimming approach can deal with hundreds of thousands of trim curves at interactive rates. Our point classification scheme can be applied to other application domains dealing with complex curved regions including flood fills, font rendering and vector graphics mapped on arbitrary surfaces. ", 
        "id": 952, 
        "title": "Direct trimming of NURBS surfaces on the GPU."
    }, 
    {
        "abstract": "", 
        "id": 953, 
        "title": "Out-of-core multigrid solver for streaming meshes."
    }, 
    {
        "abstract": "Controllers are necessary for physically-based synthesis of character animation. However, creating controllers requires either manual tuning or expensive computer optimization. We introduce linear Bellman combination as a method for reusing existing controllers. Given a set of controllers for related tasks, this combination creates a controller that performs a new task. It naturally weights the contribution of each component controller by its relevance to the current state and goal of the system. We demonstrate that linear Bellman combination outperforms naive combination often succeeding where naive combination fails. Furthermore, this combination is provably optimal for a new task if the component controllers are also optimal for related tasks. We demonstrate the applicability of linear Bellman combination to interactive character control of stepping motions and acrobatic maneuvers. ", 
        "id": 954, 
        "title": "Linear Bellman combination for control of character animation."
    }, 
    {
        "abstract": "We present a novel, incompressible fluid simulation method based on the Lagrangian Smoothed Particle Hydrodynamics (SPH) model. In our method, incompressibility is enforced by using a predictioncorrection scheme to determine the particle pressures. For this, the information about density fluctuations is actively propagated through the fluid and pressure values are updated until the targeted density is satisfied. With this approach, we avoid the computational expenses of solving a pressure Poisson equation, while still being able to use large time steps in the simulation. The achieved results show that our predictive-corrective incompressible SPH (PCISPH) method clearly outperforms the commonly used weakly compressible SPH (WCSPH) model by more than an order of magnitude while the computations are in good agreement with the WCSPH results. ", 
        "id": 955, 
        "title": "Predictive-corrective incompressible SPH."
    }, 
    {
        "abstract": "", 
        "id": 956, 
        "title": "Fourier depth of field."
    }, 
    {
        "abstract": "In this paper we present SubEdit, a representation for editing the BSSRDF of heterogeneous subsurface scattering acquired from real-world samples. Directly editing measured raw data is difficult due to the non-local impact of heterogeneous subsurface scattering on the appearance. Our SubEdit representation decouples these non-local effects into the product of two local scattering profiles defined at respectively the incident and outgoing surface locations. This allows users to directly manipulate the appearance of single surface locations and to robustly make selections. To further facilitate editing, we reparameterize the scattering profiles into the local appearance concepts of albedo, scattering range, and profile shape. Our method preserves the visual quality of the measured material after editing by maintaining the consistency of subsurface transport for all edits. SubEdit fits measured data well while remaining efficient enough to support interactive rendering and manipulation. We illustrate the suitability of SubEdit as a representation for editing by applying various complex modifications on a wide variety of measured heterogeneous subsurface scattering materials.", 
        "id": 957, 
        "title": "SubEdit: a representation for editing measured heterogeneous subsurface scattering."
    }, 
    {
        "abstract": "", 
        "id": 958, 
        "title": "Edge-preserving multiscale image decomposition based on local extrema."
    }, 
    {
        "abstract": "", 
        "id": 959, 
        "title": "GRAMPS: A programming model for graphics pipelines."
    }, 
    {
        "abstract": "", 
        "id": 960, 
        "title": "Affine double- and triple-product wavelet integrals for rendering."
    }, 
    {
        "abstract": "We present an algorithm for curve skeleton extraction from imperfect point clouds where large portions of the data may be missing. Our construction is primarily based on a novel notion of generalized rotational symmetry axis (ROSA) of an oriented point set. Specifically, given a subset S of oriented points, we introduce a variational definition for an oriented point that is most rotationally symmetric with respect to S. Our formulation effectively utilizes normal information to compensate for the missing data and leads to robust curve skeleton computation over regions of a shape that are generally cylindrical. We present an iterative algorithm via planar cuts to compute the ROSA of a point cloud. This is complemented by special handling of non-cylindrical joint regions to obtain a centered, topologically clean, and complete 1D skeleton. We demonstrate that quality curve skeletons can be extracted from a variety of shapes captured by incomplete point clouds. Finally, we show how our algorithm assists in shape completion under these challenges by developing a skeleton-driven point cloud completion scheme. ", 
        "id": 961, 
        "title": "Curve skeleton extraction from incomplete point cloud."
    }, 
    {
        "abstract": "", 
        "id": 962, 
        "title": "Exploratory modeling with collaborative design spaces."
    }, 
    {
        "abstract": "We present a simple algorithm to compute the Hausdorff distance between complicated, polygonal models at interactive rates. The algorithm requires no assumptions about the underlying topology and geometry. To avoid the high computational and implementation complexity of exact Hausdorff distance calculation, we approximate the Hausdorff distance within a user-specified error bound. The main ingredient of our approximation algorithm is a novel polygon subdivision scheme, called Voronoi subdivision, combined with culling between the models based on bounding volume hierarchy (BVH). This cross-culling method relies on tight yet simple computation of bounds on the Hausdorff distance, and it discards unnecessary polygon pairs from each of the input models alternatively based on the distance bounds. This algorithm can approximate the Hausdorff distance between polygonal models consisting of tens of thousands triangles with a small error bound in real-time, and outperforms the existing algorithm by more than an order of magnitude. We apply our Hausdorff distance algorithm to the measurement of shape similarity, and the computation of penetration depth for physically-based animation. In particular, the penetration depth computation using Hausdorff distance runs at highly interactive rates for complicated dynamics scene. ", 
        "id": 963, 
        "title": "Interactive Hausdorff distance computation for general polygonal models."
    }, 
    {
        "abstract": " In this paper, we present SkyFinder, an interactive search system of over a half million sky images downloaded from the Internet. Using a set of automatically extracted, semantic sky attributes (category, layout, richness, horizon, etc.), the user can find a desired sky image, such as \"a landscape with rich clouds at sunset\" or \"a whole blue sky with white clouds\". The system is fully automatic and scalable. It computes all sky attributes offline, then provides an interactive online search engine. Moreover, we build a sky graph based on the sky attributes, so that the user can smoothly explore and find a path within the space of skies. We also show how our system can be used for controllable sky replacement. ", 
        "id": 964, 
        "title": "SkyFinder: attribute-based sky image search."
    }, 
    {
        "abstract": "We present a practical approach to isotropic tetrahedral meshing of 3D domains bounded by piecewise smooth surfaces. Building upon recent theoretical and practical advances, our algorithm interleaves Delaunay refinement and mesh optimization to generate quality meshes that satisfy a set of user-defined criteria. This interleaving is shown to be more conservative in number of Steiner point insertions than refinement alone, and to produce higher quality meshes than optimization alone. A careful treatment of boundaries and their features is presented, offering a versatile framework for designing smoothly graded tetrahedral meshes. ", 
        "id": 965, 
        "title": "Interleaving Delaunay refinement and optimization for practical isotropic tetrahedron mesh generation."
    }, 
    {
        "abstract": "Texturing 3D models using casual images has gained importance in the last decade, with the advent of huge databases of images. We present a novel approach for performing this task, which manages to account for the 3D geometry of the photographed object. Our method overcomes the limitation of both the constrainedparameterization approach, which does not account for the photography effects, and the photogrammetric approach, which cannot handle arbitrary images. The key idea of our algorithm is to formulate the mapping estimation as a Moving-Least-Squares problem for recovering local camera parameters at each vertex. The algorithm is realized in a FlexiStickers application, which enables fast interactive texture mapping using a small number of constraints. ", 
        "id": 966, 
        "title": "FlexiStickers: photogrammetric texture mapping using casual images."
    }, 
    {
        "abstract": "", 
        "id": 967, 
        "title": "Interactive design of urban spaces using geometrical and behavioral modeling."
    }, 
    {
        "abstract": "", 
        "id": 968, 
        "title": "Automatic bounding of programmable shaders for efficient global illumination."
    }, 
    {
        "abstract": "Recent research on the human visual system shows that our perception of object shape relies in part on compression and stretching of the reflected lighting environment onto its surface. We use this property to enhance the shape depiction of 3D objects by locally warping the environment lighting around main surface features. Contrary to previous work, which require specific illumination, material characteristics and/or stylization choices, our approach enhances surface shape without impairing the desired appearance. Thanks to our novel local shape descriptor, salient surface features are explicitly extracted in a view-dependent fashion at various scales without the need of any pre-process. We demonstrate our system on a variety of rendering settings, using object materials ranging from diffuse to glossy, to mirror or refractive, with direct or global illumination, and providing styles that range from photorealistic to non-photorealistic. The warping itself is very fast to compute on modern graphics hardware, enabling real-time performance in direct illumination scenarios. ", 
        "id": 969, 
        "title": "Light warping for enhanced surface depiction."
    }, 
    {
        "abstract": "", 
        "id": 970, 
        "title": "Dynamic shape capture using multi-view photometric stereo."
    }, 
    {
        "abstract": "", 
        "id": 971, 
        "title": "A simple approach to nonlinear tensile stiffness for accurate cloth simulation."
    }, 
    {
        "abstract": "amber cuboctahedron bumpy sphere straight-line approximation Figure1: The bending andfocusing of light in refractive media creates distinctive rich details. The top row shows single scatter surface caustics in glass and water. The bottom row shows complex volumetric refractive caustics in amber and glass. All images were generated using the method in this paper, except the bottom right which used the common straight-line approximation that neglects shadow ray refraction. Abstract Light scattering in refractive media is an important optical phenomenon for computer graphics. While recent research has focused on multiple scattering, there has been less work on accurate solutions for single or low-order scattering. Refraction through a complex boundary allows a single external source to be visible in multiple directions internally with different strengths; these are hard to find with existing techniques. This paper presents techniques to quickly find paths that connect points inside and outside a medium while obeying the laws of refraction. We introduce: a half-vector based formulation to support the most common geometric representation, triangles with interpolated normals; hierarchical pruning to scale to triangular meshes; and, both a solver with strong accuracy guarantees, and a faster method that is empirically accurate. A GPU version achieves interactive frame rates in several examples.", 
        "id": 972, 
        "title": "Single scattering in refractive media with triangle mesh boundaries."
    }, 
    {
        "abstract": "We present a fully automatic method for generating gaits and morphologies for legged animal locomotion. Given a specific animal's shape we can determine an efficient gait with which it can move. Similarly, we can also adapt the animal's morphology to be optimal for a specific locomotion task. We show that determining such gaits is possible without the need to specify a good initial motion, and without manually restricting the allowed gaits of each animal. Our approach is based on a hybrid optimization method which combines an efficient derivative-aware spacetime constraints optimization with a derivative-free approach able to find non-local solutions in high-dimensional discontinuous spaces. We demonstrate the effectiveness of this approach by synthesizing dynamic locomotions of bipeds, a quadruped, and an imaginary five-legged creature. ", 
        "id": 973, 
        "title": "Optimal gait and form for animal locomotion."
    }, 
    {
        "abstract": "", 
        "id": 974, 
        "title": "Efficient reconstruction of nonrigid shape and motion from real-time 3D scanner data."
    }, 
    {
        "abstract": " We propose a kernel Nystrom method for reconstructing the light transport matrix from a relatively small number of acquired images. Our work is based on the generalized Nystrom method for low rank matrices. We introduce the light transport kernel and incorporate it into the Nystrom method to exploit the nonlinear coherence of the light transport matrix. We also develop an adaptive scheme for efficiently capturing the sparsely sampled images from the scene. Our experiments indicate that the kernel Nystrom method can achieve good reconstruction of the light transport matrix with a few hundred images and produce high quality relighting results. The kernel Nystrom method is effective for modeling scenes with complex lighting effects and occlusions which have been challenging for existing techniques.  ", 
        "id": 975, 
        "title": "Kernel Nystr\u00f6m method for light transport."
    }, 
    {
        "abstract": "", 
        "id": 976, 
        "title": "Optimizing walking controllers."
    }, 
    {
        "abstract": "", 
        "id": 977, 
        "title": "Motion-aware temporal coherence for video resizing."
    }, 
    {
        "abstract": "We present an image-based reconstruction framework to model real water scenes captured by stereoscopic video. In contrast to many image-based modeling techniques that rely on user interaction to obtain high-quality 3D models, we instead apply automatically calculated physically-based constraints to refine the initial model. The combination of image-based reconstruction with physically-based simulation allows us to model complex and dynamic objects such as fluid. Using a depth map sequence as initial conditions, we use a physically based approach that automatically fills in missing regions, removes outliers, and refines the geometric shape so that the final 3D model is consistent to both the input video data and the laws of physics. Physically-guided modeling also makes interpolation or extrapolation in the space-time domain possible, and even allows the fusion of depth maps that were taken at different times or viewpoints. We demonstrated the effectiveness of our framework with a number of real scenes, all captured using only a single pair of cameras. ", 
        "id": 978, 
        "title": "Physically guided liquid surface modeling from videos."
    }, 
    {
        "abstract": "Articulated hand-tracking systems have been widely used in virtual reality but are rarely deployed in consumer applications due to their price and complexity. In this paper, we propose an easy-to-use and inexpensive system that facilitates 3-D articulated user-input using the hands. Our approach uses a single camera to track a hand wearing an ordinary cloth glove that is imprinted with a custom pattern. The pattern is designed to simplify the pose estimation problem, allowing us to employ a nearest-neighbor approach to track hands at interactive rates. We describe several proof-of-concept applications enabled by our system that we hope will provide a foundation for new interactions in modeling, animation control and augmented reality. ", 
        "id": 979, 
        "title": "Real-time hand-tracking with a color glove."
    }, 
    {
        "abstract": "", 
        "id": 980, 
        "title": "All-frequency rendering of dynamic, spatially-varying reflectance."
    }, 
    {
        "abstract": " This paper presents a GPU-based method for interactive global illumination that integrates complex effects such as multi-bounce indirect lighting, glossy reflections, caustics, and arbitrary specular paths. Our method builds upon scattered data sampling and interpolation on the GPU. We start with raytraced shading points and partition them into coherent shading clusters using adaptive seeding followed by k-means. At each cluster center we apply final gather to evaluate its incident irradiance using GPU-based photon mapping. We approximate the entire photon tree as a compact illumination cut, thus reducing the final gather cost for each ray. The sampled irradiance values are then interpolated at all shading points to produce rendering. Our method exploits the spatial coherence of illumination to reduce sampling cost. We sample sparsely and the distribution of sample points conforms with the underlying illumination changes. Therefore our method is both fast and preserves high rendering quality. Although the same property has been exploited by previous caching and adaptive sampling methods, these methods typically require sequential computation of sample points, making them ill-suited for the GPU. In contrast, we select sample points adaptively in a single pass, enabling parallel computation. As a result, our algorithm runs entirely on the GPU, achieving interactive rates for scenes with complex illumination effects. ", 
        "id": 981, 
        "title": "An efficient GPU-based approach for interactive global illumination."
    }, 
    {
        "abstract": "We present an example-based approach to hair modeling because creating hairstyles either manually or through image-based acquisition is a costly and time-consuming process. We introduce a hierarchical hair synthesis framework that views a hairstyle both as a 3D vector field and a 2D arrangement of hair strands on the scalp. Since hair forms wisps, a hierarchical hair clustering algorithm has been developed for detecting wisps in example hairstyles. The coarsest level of the output hairstyle is synthesized using traditional 2D texture synthesis techniques. Synthesizing finer levels of the hierarchy is based on cluster oriented detail transfer. Finally, we compute a discrete tangent vector field from the synthesized hair at every level of the hierarchy to remove undesired inconsistencies among hair trajectories. Improved hair trajectories can be extracted from the vector field. Based on our automatic hair synthesis method, we have also developed simple user-controlled synthesis and editing techniques including feature-preserving combing as well as detail transfer between different hairstyles. ", 
        "id": 982, 
        "title": "Example-based hair geometry synthesis."
    }, 
    {
        "abstract": "", 
        "id": 983, 
        "title": "Collision-free construction of animated feathers using implicit constraint surfaces."
    }, 
    {
        "abstract": "We propose a system for manufacturing physical surfaces that, in aggregate, exhibit a desired surface appearance. Our system begins with a user specification of a BRDF, or simply a highlight shape, and infers the required distribution of surface slopes. We sample this distribution, optimize for a maximally-continuous and valley-minimizing height field, and finally mill the surface using a computer-controlled machine tool. We demonstrate a variety of surfaces, ranging from reproductions of measured BRDFs to materials with unconventional highlights. ", 
        "id": 984, 
        "title": "Fabricating microgeometry for custom surface reflectance."
    }, 
    {
        "abstract": "", 
        "id": 985, 
        "title": "Procedural modeling of structurally-sound masonry buildings."
    }, 
    {
        "abstract": "We present a new approach to fluid simulation that balances the speed of model reduction with the flexibility of grid-based methods. We construct a set of composable reduced models, or tiles, which capture spatially localized fluid behavior. We then precompute coupling terms so that these models can be rearranged at runtime. To enforce consistency between tiles, we introduce constraint reduction. This technique modifies a reduced model so that a given set of linear constraints can be fulfilled. Because dynamics and constraints can be solved entirely in the reduced space, our method is extremely fast and scales to large domains. ", 
        "id": 986, 
        "title": "Modular bases for fluid dynamics."
    }, 
    {
        "abstract": "A regular map is a tiling of a closed surface into faces, bounded by edges that join pairs of vertices, such that these elements exhibit a maximal symmetry. For genus 0 and 1 (spheres and tori) it is well known how to generate and present regular maps, the Platonic solids are a familiar example. We present a method for the generation of space models of regular maps for genus 2 and higher. The method is based on a generalization of the method for tori. Shapes with the proper genus are derived from regular maps by tubification: edges are replaced by tubes. Tessellations are produced using group theory and hyperbolic geometry. The main results are a generic procedure to produce such tilings, and a collection of intriguing shapes and images. Furthermore, we show how to produce shapes of genus 2 and higher with a highly regular structure.  The first puzzle is trivial: We get a cube, blown up to a sphere, which is an example of a regular map. A cube is 246 = 48-fold symmetric, since each triangle shown in Figure 1 can be mapped to another one by rotation and turning the surface inside-out. We require for all solutions that they have such a 2pF -fold symmetry. Puzzle 2 to 4 are not difficult, and lead to other examples: a dodec- ahedron; a beach ball, also known as a hosohedron [Coxeter 1989]; and a torus, obtained by making a 6  6 checkerboard, followed by matching opposite sides. The next puzzles are more challenging.  ", 
        "id": 987, 
        "title": "Symmetric tiling of closed surfaces: visualization of regular maps."
    }, 
    {
        "abstract": "", 
        "id": 988, 
        "title": "Toward a perceptual space for gloss."
    }, 
    {
        "abstract": "We present a method for accurately tracking the moving surface of deformable materials in a manner that gracefully handles topological changes. We employ a Lagrangian surface tracking method, and we use a triangle mesh for our surface representation so that fine features can be retained. We make topological changes to the mesh by first identifying merging or splitting events at a particular grid resolution, and then locally creating new pieces of the mesh in the affected cells using a standard isosurface creation method. We stitch the new, topologically simplified portion of the mesh to the rest of the mesh at the cell boundaries. Our method detects and treats topological events with an emphasis on the preservation of detailed features, while simultaneously simplifying those portions of the material that are not visible. Our surface tracker is not tied to a particular method for simulating deformable materials. In particular, we show results from two significantly different simulators: a Lagrangian FEM simulator with tetrahedral elements, and an Eulerian grid-based fluid simulator. Although our surface tracking method is generic, it is particularly well-suited for simulations that exhibit fine surface details and numerous topological events. Highlights of our results include merging of viscoplastic materials with complex geometry, a taffy-pulling animation with many fold and merge events, and stretching and slicing of stiff plastic material. ", 
        "id": 989, 
        "title": "Deforming meshes that split and merge."
    }, 
    {
        "abstract": "", 
        "id": 990, 
        "title": "Patch-based image vectorization with automatic curvilinear feature alignment."
    }, 
    {
        "abstract": "", 
        "id": 991, 
        "title": "Image-based street-side city modeling."
    }, 
    {
        "abstract": "", 
        "id": 992, 
        "title": "Improving Chen and Han's algorithm on the discrete geodesic problem."
    }, 
    {
        "abstract": "", 
        "id": 993, 
        "title": "Feature-aligned shape texturing."
    }, 
    {
        "abstract": "", 
        "id": 994, 
        "title": "Efficient affinity-based edit propagation using K-D tree."
    }, 
    {
        "abstract": "Complex mesh models of man-made objects often consist of multiple components connected by various types of joints. We propose a joint-aware deformation framework that supports the direct manipulation of an arbitrary mix of rigid and deformable components. First we apply slippable motion analysis to automatically detect multiple types of joint constraints that are implicit in model geometry. For single-component geometry or models with disconnected components, we support user-defined virtual joints. Then we integrate manipulation handle constraints, multiple components, joint constraints, joint limits, and deformation energies into a single volumetric-cell-based space deformation problem. An iterative, parallelized Gauss-Newton solver is used to solve the resulting nonlinear optimization. Interactive deformable manipulation is demonstrated on a variety of geometric models while automatically respecting their multi-component nature and the natural behavior of their joints. ", 
        "id": 995, 
        "title": "Joint-aware manipulation of deformable models."
    }, 
    {
        "abstract": "", 
        "id": 996, 
        "title": "Partial intrinsic reflectional symmetry of 3D shapes."
    }, 
    {
        "abstract": "", 
        "id": 997, 
        "title": "Amortized supersampling."
    }, 
    {
        "abstract": "", 
        "id": 998, 
        "title": "Hair meshes."
    }, 
    {
        "abstract": "", 
        "id": 999, 
        "title": "Relief analysis and extraction."
    }, 
    {
        "abstract": "Fluid sounds, such as splashing and pouring, are ubiquitous and familiar but we lack physically based algorithms to synthesize them in computer animation or interactive virtual environments. We propose a practical method for automatic procedural synthesis of synchronized harmonic bubble-based sounds from 3D fluid animations. To avoid audio-rate time-stepping of compressible fluids, we acoustically augment existing incompressible fluid solvers with particle-based models for bubble creation, vibration, advection, and radiation. Sound radiation from harmonic fluid vibrations is modeled using a time-varying linear superposition of bubble oscillators. We weight each oscillator by its bubble-to-ear acoustic transfer function, which is modeled as a discrete Green's function of the Helmholtz equation. To solve potentially millions of 3D Helmholtz problems, we propose a fast dual-domain multipole boundary-integral solver, with cost linear in the complexity of the fluid domain's boundary. Enhancements are proposed for robust evaluation, noise elimination, acceleration, and parallelization. Examples are provided for water drops, pouring, babbling, and splashing phenomena, often with thousands of acoustic bubbles, and hundreds of thousands of transfer function solves. ", 
        "id": 1000, 
        "title": "Harmonic fluids."
    }, 
    {
        "abstract": "", 
        "id": 1001, 
        "title": "RenderAnts: interactive Reyes rendering on GPUs."
    }, 
    {
        "abstract": "", 
        "id": 1002, 
        "title": "A practical approach for photometric acquisition of hair color."
    }, 
    {
        "abstract": "Although there has been much interest in computational photography within the research and photography communities, progress has been hampered by the lack of a portable, programmable camera with sufficient image quality and computing power. To address this problem, we have designed and implemented an open architecture and API for such cameras: the Frankencamera. It consists of a base hardware specification, a software stack based on Linux, and an API for C++. Our architecture permits control and synchronization of the sensor and image processing pipeline at the microsecond time scale, as well as the ability to incorporate and synchronize external hardware like lenses and flashes. This paper specifies our architecture and API, and it describes two reference implementations we have built. Using these implementations we demonstrate six computational photography applications: HDR viewfinding and capture, low-light viewfinding and capture, automated acquisition of extended dynamic range panoramas, foveal imaging, IMU-based hand shake detection, and rephotography. Our goal is to standardize the architecture and distribute Frankencameras to researchers and students, as a step towards creating a community of photographerprogrammers who develop algorithms, applications, and hardware for computational cameras. ", 
        "id": 1003, 
        "title": "The Frankencamera: an experimental platform for computational photography."
    }, 
    {
        "abstract": "We present a technique for learning clothing models that enables the simultaneous animation of thousands of detailed garments in real-time. This surprisingly simple conditional model learns and preserves the key dynamic properties of a cloth motion along with folding details. Our approach requires no a priori physical model, but rather treats training data as a \"black box.\" We show that the models learned with our method are stable over large time-steps and can approximately resolve cloth-body collisions. We also show that within a class of methods, no simpler model covers the full range of cloth dynamics captured by ours. Our method bridges the current gap between skinning and physical simulation, combining benefits of speed from the former with dynamic effects from the latter. We demonstrate our approach on a variety of apparel worn by male and female human characters performing a varied set of motions typically used in video games (e.g., walking, running, jumping, etc.). ", 
        "id": 1004, 
        "title": "Stable spaces for real-time clothing."
    }, 
    {
        "abstract": "We describe how to create relief surfaces whose diffuse reflection approximates given images under known directional illumination. This allows using any surface with a significant diffuse reflection component as an image display. We propose a discrete model for the area in the relief surface that corresponds to a pixel in the desired image. This model introduces the necessary degrees of freedom to overcome theoretical limitations in shape from shading and practical requirements such as stability of the image under changes in viewing condition and limited overall variation in depth. The discrete surface is determined using an iterative least squares optimization. We show several resulting relief surfaces conveying one image for varying lighting directions as well as two images for two specific lighting directions. ", 
        "id": 1005, 
        "title": "Reliefs as images."
    }, 
    {
        "abstract": "", 
        "id": 1006, 
        "title": "A framework for modeling 3D scenes using pose-free equations."
    }, 
    {
        "abstract": "We introduce a new method for simulating frictional contact between volumetric objects using interpenetration volume constraints. When applied to complex geometries, our formulation results in dramatically simpler systems of equations than those of traditional mesh contact models. Contact between highly detailed meshes can be simplified to a single unilateral constraint equation, or accurately processed at arbitrary geometry-independent resolution with simultaneous sticking and sliding across contact patches. We exploit fast GPU methods for computing layered depth images, which provides us with the intersection volumes and gradients necessary to formulate the contact equations as linear complementarity problems. Straightforward and popular numerical methods, such as projected Gauss-Seidel, can be used to solve the system. We demonstrate our method in a number of scenarios and present results involving both rigid and deformable objects at interactive rates. ", 
        "id": 1007, 
        "title": "Volume contact constraints at arbitrary resolution."
    }, 
    {
        "abstract": "", 
        "id": 1008, 
        "title": "l1-Sparse reconstruction of sharp point set surfaces."
    }, 
    {
        "abstract": "", 
        "id": 1009, 
        "title": "Video quality assessment for computer graphics applications."
    }, 
    {
        "abstract": "", 
        "id": 1010, 
        "title": "Computational rephotography."
    }, 
    {
        "abstract": "", 
        "id": 1011, 
        "title": "Accelerating spatially varying Gaussian filters."
    }, 
    {
        "abstract": "We present an algorithm designed for navigating around a performance that was filmed as a \"casual\" multi-view video collection: real-world footage captured on hand held cameras by a few audience members. The objective is to easily navigate in 3D, generating a video-based rendering (VBR) of a performance filmed with widely separated cameras. Casually filmed events are especially challenging because they yield footage with complicated backgrounds and camera motion. Such challenging conditions preclude the use of most algorithms that depend on correlation-based stereo or 3D shape-from-silhouettes. Our algorithm builds on the concepts developed for the exploration of photo-collections of empty scenes. Interactive performerspecific view-interpolation is now possible through innovations in interactive rendering and offline-matting relating to i) modeling the foreground subject as video-sprites on billboards, ii) modeling the background geometry with adaptive view-dependent textures, and iii) view interpolation that follows a performer. The billboards are embedded in a simple but realistic reconstruction of the environment. The reconstructed environment provides very effective visual cues for spatial navigation as the user transitions between viewpoints. The prototype is tested on footage from several challenging events, and demonstrates the editorial utility of the whole system and the particular value of our new inter-billboard optimization. ACM Reference Format Ballan, L., Brostow, G., Puwein, J., Pollefeys, M. 2010. Unstructured Video-Based Rendering: Interactive Exploration of Casually Captured Videos. ACM Trans. Graph. 29, 4, Article 87 (July 2010), 11 pages. DOI = 10.1145/1778765.1778824 http://doi.acm.org/10.1145/1778765.1778824. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org.  2010 ACM 0730-0301/2010/07-ART87 $10.00 DOI 10.1145/1778765.1778824 http://doi.acm.org/10.1145/1778765.1778824  ", 
        "id": 1012, 
        "title": "Unstructured video-based rendering: interactive exploration of casually captured videos."
    }, 
    {
        "abstract": "", 
        "id": 1013, 
        "title": "A hierarchical volumetric shadow algorithm for single scattering."
    }, 
    {
        "abstract": "We show how to greatly accelerate self-collision detection (SCD) for reduced deformable models. Given a triangle mesh and a set of deformation modes, our method precomputes Subspace SelfCollision Culling (SSCC) certificates which, if satisfied, prove the absence of self-collisions for large parts of the model. At runtime, bounding volume hierarchies augmented with our certificates can aggressively cull overlap tests and reduce hierarchy updates. Our method supports both discrete and continuous SCD, can handle complex geometry, and makes no assumptions about geometric smoothness or normal bounds. It is particularly effective for simulations with modest subspace deformations, where it can often verify the absence of self-collisions in constant time. Our certificates enable low amortized costs, in time and across many objects in multibody dynamics simulations. Finally, SSCC is effective enough to support self-collision tests at audio rates, which we demonstrate by producing the first sound simulations of clattering objects. ", 
        "id": 1014, 
        "title": "Subspace self-collision culling."
    }, 
    {
        "abstract": "We present a novel approach for summarizing video in the form of a multiscale image that is continuous in both the spatial domain and across the scale dimension: There are no hard borders between discrete moments in time, and a user can zoom smoothly into the image to reveal additional temporal details. We call these artifacts tapestries because their continuous nature is akin to medieval tapestries and other narrative depictions predating the advent of motion pictures. We propose a set of criteria for such a summarization, and a series of optimizations motivated by these criteria. These can be performed as an entirely offline computation to produce high quality renderings, or by adjusting some optimization parameters the later stages can be solved in real time, enabling an interactive interface for video navigation. Our video tapestries combine the best aspects of two common visualizations, providing the visual clarity of DVD chapter menus with the information density and multiple scales of a video editing timeline representation. In addition, they provide continuous transitions between zoom levels. In a user study, participants preferred both the aesthetics and efficiency of tapestries over other interfaces for visual browsing.", 
        "id": 1015, 
        "title": "Video tapestries with continuous temporal zoom."
    }, 
    {
        "abstract": " We present a multi-layered display that uses water drops as voxels. Water drops refract most incident light, making them excellent wide-angle lenses. Each 2D layer of our display can exhibit arbitrary visual content, creating a layered-depth (2.5D) display. Our system consists of a single projector-camera system and a set of linear drop generator manifolds that are tightly synchronized and controlled using a computer. Following the principles of fluid mechanics, we are able to accurately generate and control drops so that, at any time instant, no two drops occupy the same projector pixel's line-of-sight. This drop control is combined with an algorithm for space-time division of projector light rays. Our prototype system has up to four layers, with each layer consisting of an row of 50 drops that can be generated at up to 60 Hz. The effective resolution of the display is 50 projector vertical-resolution  number of layers. We show how this water drop display can be used for text, videos, and interactive games.  ", 
        "id": 1016, 
        "title": "A multi-layered display with water drops."
    }, 
    {
        "abstract": " This paper describes a passive stereo system for capturing the 3D geometry of a face in a single-shot under standard light sources. The system is low-cost and easy to deploy. Results are submillimeter accurate and commensurate with those from state-ofthe-art systems based on active lighting, and the models meet the quality requirements of a demanding domain like the movie industry. Recovered models are shown for captures from both high-end cameras in a studio setting and from a consumer binocular-stereo camera, demonstrating scalability across a spectrum of camera deployments, and showing the potential for 3D face modeling to move beyond the professional arena and into the emerging consumer market in stereoscopic photography. Our primary technical contribution is a modification of standard stereo refinement methods to capture pore-scale geometry, using a qualitative approach that produces visually realistic results. The second technical contribution is a calibration method suited to face capture systems. The systemic contribution includes multiple demonstrations of system robustness and quality. These include capture in a studio setup, capture off a consumer binocular-stereo camera, scanning of faces of varying gender and ethnicity and age, capture of highly-transient facial expression, and scanning a physical mask to provide ground-truth validation.  ", 
        "id": 1017, 
        "title": "High-quality single-shot capture of facial geometry."
    }, 
    {
        "abstract": "We present a continuum-based discrete model for thin threads of viscous fluid by drawing upon the Rayleigh analogy to elastic rods, demonstrating canonical coiling, folding, and breakup in dynamic simulations. Our derivation emphasizes space-time symmetry, which sheds light on the role of time-parallel transport in eliminatingwithout approximationall but an O(n) band of entries of the physical systems energy Hessian. The result is a fast, unified, implicit treatment of viscous threads and elastic rods that closely reproduces a variety of fascinating physical phenomena, including hysteretic transitions between coiling regimes, competition between surface tension and gravity, and the first numerical fluid-mechanical sewing machine. The novel implicit treatment also yields an order of magnitude speedup in our elastic rod dynamics.", 
        "id": 1018, 
        "title": "Discrete viscous threads."
    }, 
    {
        "abstract": "", 
        "id": 1019, 
        "title": "GradientShop: A gradient-domain optimization framework for image and video filtering."
    }, 
    {
        "abstract": "This paper introduces a data-driven process for designing and fabricating materials with desired deformation behavior. Our process starts with measuring deformation properties of base materials. For each base material we acquire a set of example deformations, and we represent the material as a non-linear stress-strain relationship in a finite-element model. We have validated our material measurement process by comparing simulations of arbitrary stacks of base materials with measured deformations of fabricated material stacks. After material measurement, our process continues with designing stacked layers of base materials. We introduce an optimization process that finds the best combination of stacked layers that meets a user's criteria specified by example deformations. Our algorithm employs a number of strategies to prune poor solutions from the combinatorial search space. We demonstrate the complete process by designing and fabricating objects with complex heterogeneous materials using modern multi-material 3D printers. ", 
        "id": 1020, 
        "title": "Design and fabrication of materials with desired deformation behavior."
    }, 
    {
        "abstract": "In this paper, we address the problem of inverse procedural modeling: Given a piece of exemplar 3D geometry, we would like to find a set of rules that describe objects that are similar to the exemplar. We consider local similarity, i.e., each local neighborhood of the newly created object must match some local neighborhood of the exemplar. We show that we can find explicit shape modification rules that guarantee strict local similarity by looking at the structure of the partial symmetries of the object. By cutting the object into pieces along curves within symmetric areas, we can build shape operations that maintain local similarity by construction. We systematically collect such editing operations and analyze their dependency to build a shape grammar. We discuss how to extract general rewriting systems, context free hierarchical rules, and grid-based rules. All of this information is derived directly from the model, without user interaction. The extracted rules are then used to implement tools for semi-automatic shape modeling by example, which are demonstrated on a number of different example data sets. Overall, our paper provides a concise theoretical and practical framework for inverse procedural modeling of 3D objects.", 
        "id": 1021, 
        "title": "A connection between partial symmetry and inverse procedural modeling."
    }, 
    {
        "abstract": "", 
        "id": 1022, 
        "title": "Parallel Poisson disk sampling with spectrum analysis on surfaces."
    }, 
    {
        "abstract": "We introduce a purely passive facial capture approach that uses only an array of video cameras, but requires no template facial geometry, no special makeup or markers, and no active lighting. We obtain initial geometry using multi-view stereo, and then use a novel approach for automatically tracking texture detail across the frames. As a result, we obtain a high-resolution sequence of compatibly triangulated and parameterized meshes. The resulting sequence can be rendered with dynamically captured textures, while also consistently applying texture changes such as virtual makeup.  ", 
        "id": 1023, 
        "title": "High resolution passive facial performance capture."
    }, 
    {
        "abstract": "We introduce an Eulerian liquid simulation framework based on the Voronoi diagram of a potentially unorganized collection of pressure samples. Constructing the simulation mesh in this way allows us to place samples anywhere in the computational domain; we exploit this by choosing samples that accurately capture the geometry and topology of the liquid surface. When combined with highresolution explicit surface tracking this allows us to simulate nearly arbitrarily thin features, while eliminating noise and other artifacts that arise when there is a resolution mismatch between the simulation and the surface--and allowing a precise inclusion of surface tension based directly on and at the same resolution as the surface mesh. In addition, we present a simplified Voronoi/Delaunay mesh velocity interpolation scheme, and a direct extension of embedded free surfaces and solid boundaries to Voronoi meshes. ", 
        "id": 1024, 
        "title": "Matching fluid simulation elements to surface geometry and topology."
    }, 
    {
        "abstract": " Painters and illustrators commonly sketch vanishing points and lines to guide the construction of perspective images. We present a tool that gives users the ability to manipulate perspective in photographs using image space controls similar to those used by artists. Our approach computes a 2D warp guided by constraints based on projective geometry. A user annotates an image by marking a number of image space constraints including planar regions of the scene, straight lines, and associated vanishing points. The user can then use the lines, vanishing points, and other point constraints as handles to control the warp. Our system optimizes the warp such that straight lines remain straight, planar regions transform according to a homography, and the entire mapping is as shape-preserving as possible. While the result of this warp is not necessarily an accurate perspective projection of the scene, it is often visually plausible. We demonstrate how this approach can be used to produce a variety of effects, such as changing the perspective composition of a scene, exploring artistic perspectives not realizable with a camera, and matching perspectives of objects from different images so that they appear consistent for compositing. ", 
        "id": 1025, 
        "title": "Image warps for artistic perspective manipulation."
    }, 
    {
        "abstract": "We advocate a simple geometric model for elasticity: distance between the differential of a deformation and the rotation group. It comes with rigorous differential geometric underpinnings, both smooth and discrete, and is computationally almost as simple and efficient as linear elasticity. Owing to its geometric non-linearity, though, it does not suffer from the usual linearization artifacts. A material model with standard elastic moduli (Lam parameters) falls out naturally, and a minimizer for static problems is easily augmented to construct a fully variational 2nd order time integrator. It has excellent conservation properties even for very coarse simulations, making it very robust. Our analysis was motivated by a number of heuristic, physics-like algorithms from geometry processing (editing, morphing, parameterization, and simulation). Starting with a continuous energy formulation and taking the underlying geometry into account, we simplify and accelerate these algorithms while avoiding common pitfalls. Through the connection with the Biot strain of mechanics, the intuition of previous work that these ideas are \"like\" elasticity is shown to be spot on.  ", 
        "id": 1026, 
        "title": "A simple geometric model for elastic deformations."
    }, 
    {
        "abstract": "", 
        "id": 1027, 
        "title": "Data-driven suggestions for creativity support in 3D modeling."
    }, 
    {
        "abstract": "Repeated elements are ubiquitous and abundant in both manmade and natural scenes. Editing such images while preserving the repetitions and their relations is nontrivial due to overlap, missing parts, deformation across instances, illumination variation, etc. Manually enforcing such relations is laborious and error-prone. We propose a novel framework where user scribbles are used to guide detection and extraction of such repeated elements. Our detection process, which is based on a novel boundary band method, robustly extracts the repetitions along with their deformations. The algorithm only considers the shape of the elements, and ignores similarity based on color, texture, etc. We then use topological sorting to establish a partial depth ordering of overlapping repeated instances. Missing parts on occluded instances are completed using information from other instances. The extracted repeated instances can then be seamlessly edited and manipulated for a variety of high level tasks that are otherwise difficult to perform. We demonstrate the versatility of our framework on a large set of inputs of varying complexity, showing applications to image rearrangement, edit transfer, deformation propagation, and instance replacement. ", 
        "id": 1028, 
        "title": "RepFinder: finding approximately repeated scene elements for image editing."
    }, 
    {
        "abstract": "Camouflage images contain one or more hidden figures that remain imperceptible or unnoticed for a while. In one possible explanation, the ability to delay the perception of the hidden figures is attributed to the theory that human perception works in two main phases: feature search and conjunction search. Effective camouflage images make feature based recognition difficult, and thus force the recognition process to employ conjunction search, which takes considerable effort and time. In this paper, we present a technique for creating camouflage images. To foil the feature search, we remove the original subtle texture details of the hidden figures and replace them by that of the surrounding apparent image. To leave an appropriate degree of clues for the conjunction search, we compute and assign new tones to regions in the embedded figures by performing an optimization between two conflicting terms, which we call immersion and standout, corresponding to hiding and leaving clues, respectively. We show a large number of camouflage images generated by our technique, with or without user guidance. We have tested the quality of the images in an extensive user study, showing a good control of the difficulty levels.", 
        "id": 1029, 
        "title": "Camouflage images."
    }, 
    {
        "abstract": "We present a control strategy for physically-simulated walking motions that generalizes well across gait parameters, motion styles, character proportions, and a variety of skills. The control is realtime, requires no character-specific or motion-specific tuning, is robust to disturbances, and is simple to compute. The method works by integrating tracking, using proportional-derivative control; foot placement, using an inverted pendulum model; and adjustments for gravity and velocity errors, using Jacobian transpose control. Highlevel gait parameters allow for forwards-and-backwards walking, various walking speeds, turns, walk-to-stop, idling, and stop-towalk behaviors. Character proportions and motion styles can be authored interactively, with edits resulting in the instant realization of a suitable controller. The control is further shown to generalize across a variety of walking-related skills, including picking up objects placed at any height, lifting and walking with heavy crates, pushing and pulling crates, stepping over obstacles, ducking under obstacles, and climbing steps. ", 
        "id": 1030, 
        "title": "Generalized biped walking control."
    }, 
    {
        "abstract": "This paper presents a system for generating dynamic narratives from videos. These narratives are characterized for being compact, coherent and interactive, as inspired by principles of sequential art. Narratives depict the motion of one or several actors over time. Creating compact narratives is challenging as it is desired to combine the video frames in a way that reuses redundant backgrounds and depicts the stages of a motion. In addition, previous approaches focus on the generation of static summaries and can afford expensive image composition techniques. A dynamic narrative, on the other hand, must be played and skimmed in real-time, which imposes certain cost limitations in the video processing. In this paper, we define a novel process to compose foreground and background regions of video frames in a single interactive image using a series of spatio-temporal masks. These masks are created to improve the output of automatic video processing techniques such as image stitching and foreground segmentation. Unlike hand-drawn narratives, often limited to static representations, the proposed system allows users to explore the narrative dynamically and produce different representations of motion. We have built an authoring system that incorporates these methods and demonstrated successful results on a number of video clips. The authoring system can be used to create interactive posters of video clips, browse video in a compact manner or highlight a motion sequence in a movie. ", 
        "id": 1031, 
        "title": "Dynamic video narratives."
    }, 
    {
        "abstract": "In recent years, several cameras have been introduced which extend depth of field (DOF) by producing a depth-invariant point spread function (PSF). These cameras extend DOF by deblurring a captured image with a single spatially-invariant PSF. For these cameras, the quality of recovered images depends both on the magnitude of the PSF spectrum (MTF) of the camera, and the similarity between PSFs at different depths. While researchers have compared the MTFs of different extended DOF cameras, relatively little attention has been paid to evaluating their depth invariances. In this paper, we compare the depth invariance of several cameras, and introduce a new camera that improves in this regard over existing designs, while still maintaining a good MTF. Our technique utilizes a novel optical element placed in the pupil plane of an imaging system. Whereas previous approaches use optical elements characterized by their amplitude or phase profile, our approach utilizes one whose behavior is characterized by its scattering properties. Such an element is commonly referred to as an optical diffuser, and thus we refer to our new approach as diffusion coding. We show that diffusion coding can be analyzed in a simple and intuitive way by modeling the effect of a diffuser as a kernel in light field space. We provide detailed analysis of diffusion coded cameras and show results from an implementation using a custom designed diffuser. ", 
        "id": 1032, 
        "title": "Diffusion coded photography for extended depth of field."
    }, 
    {
        "abstract": "", 
        "id": 1033, 
        "title": "Geodesic image and video editing."
    }, 
    {
        "abstract": "", 
        "id": 1034, 
        "title": "Combining global and local virtual lights for detailed glossy illumination."
    }, 
    {
        "abstract": "", 
        "id": 1035, 
        "title": "Stable inverse dynamic curves."
    }, 
    {
        "abstract": "Limited spatial resolution of current displays makes the depiction of very fine spatial details difficult. This work proposes a novel method applied to moving images that takes into account the human visual system and leads to an improved perception of such details. To this end, we display images rapidly varying over time along a given trajectory on a high refresh rate display. Due to the retinal integration time the information is fused and yields apparent super-resolution pixels on a conventional-resolution display. We discuss how to find optimal temporal pixel variations based on linear eye-movement and image content and extend our solution to arbitrary trajectories. This step involves an efficient method to predict and successfully treat potentially visible flickering. Finally, we evaluate the resolution enhancement in a perceptual study that shows that significant improvements can be achieved both for computer generated images and photographs. ", 
        "id": 1036, 
        "title": "Apparent display resolution enhancement for moving images."
    }, 
    {
        "abstract": "Many real world surfaces exhibit translucent appearance due to subsurface scattering. Although various methods exists to measure, edit and render subsurface scattering effects, no solution exists for manufacturing physical objects with desired translucent appearance. In this paper, we present a complete solution for fabricating a material volume with a desired surface BSSRDF. We stack layers from a fixed set of manufacturing materials whose thickness is varied spatially to reproduce the heterogeneity of the input BSSRDF. Given an input BSSRDF and the optical properties of the manufacturing materials, our system efficiently determines the optimal order and thickness of the layers. We demonstrate our approach by printing a variety of homogenous and heterogenous BSSRDFs using two hardware setups: a milling machine and a 3D printer. ", 
        "id": 1037, 
        "title": "Fabricating spatially-varying subsurface scattering."
    }, 
    {
        "abstract": "Manifold bootstrapping is a new method for data-driven modeling of real-world, spatially-varying reflectance, based on the idea that reflectance over a given material sample forms a low-dimensional manifold. It provides a high-resolution result in both the spatial and angular domains by decomposing reflectance measurement into two lower-dimensional phases. The first acquires representatives of high angular dimension but sampled sparsely over the surface, while the second acquires keys of low angular dimension but sampled densely over the surface. We develop a hand-held, high-speed BRDF capturing device for phase one measurements. A condenser-based optical setup collects a dense hemisphere of rays emanating from a single point on the target sample as it is manually scanned over it, yielding 10 BRDF point measurements per second. Lighting directions from 6 LEDs are applied at each measurement; these are amplified to a full 4D BRDF using the general (NDF-tabulated) microfacet model. The second phase captures N=20-200 images of the entire sample from a fixed view and lit by a varying area source. We show that the resulting N-dimensional keys capture much of the distance information in the original BRDF space, so that they effectively discriminate among representatives, though they lack sufficient angular detail to reconstruct the SVBRDF by themselves. At each surface position, a local linear combination of a small number of neighboring representatives is computed to match each key, yielding a highresolution SVBRDF. A quick capture session (10-20 minutes) on simple devices yields results showing sharp and anisotropic specularity and rich spatial detail. ACM Reference Format Dong, Y., Wang, J., Tong, X., Snyder, J., Lan, Y., Ben-Ezra, M., Guo, B. 2010. Manifold Bootstrapping for SVBRDF Capture. ACM Trans. Graph. 29, 4, Article 98 (July 2010), 10 pages. DOI = 10.1145/1778765.1778835 http://doi.acm.org/10.1145/1778765.1778835. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org.  2010 ACM 0730-0301/2010/07-ART98 $10.00 DOI 10.1145/1778765.1778835 http://doi.acm.org/10.1145/1778765.1778835  ", 
        "id": 1038, 
        "title": "Manifold bootstrapping for SVBRDF capture."
    }, 
    {
        "abstract": "The emergence of large-scale freeform shapes in architecture poses big challenges to the fabrication of such structures. A key problem is the approximation of the design surface by a union of patches, socalled panels, that can be manufactured with a selected technology at reasonable cost, while meeting the design intent and achieving the desired aesthetic quality of panel layout and surface smoothness. The production of curved panels is mostly based on molds. Since the cost of mold fabrication often dominates the panel cost, there is strong incentive to use the same mold for multiple panels. We cast the major practical requirements for architectural surface paneling, including mold reuse, into a global optimization framework that interleaves discrete and continuous optimization steps to minimize production cost while meeting user-specified quality constraints. The search space for optimization is mainly generated through controlled deviation from the design surface and tolerances on positional and normal continuity between neighboring panels. A novel 6-dimensional metric space allows us to quickly compute approximate inter-panel distances, which dramatically improves the performance of the optimization and enables the handling of complex arrangements with thousands of panels. The practical relevance of our system is demonstrated by paneling solutions for real, cutting-edge architectural freeform design projects. ", 
        "id": 1039, 
        "title": "Paneling architectural freeform surfaces."
    }, 
    {
        "abstract": "In many scenes with human characters, interacting groups are an important factor for maintaining a sense of realism. However, little is known about what makes these characters appear realistic. In this paper, we investigate human sensitivity to audio mismatches (i.e., when individuals' voices are not matched to their gestures) and visual desynchronization (i.e., when the body motions of the individuals in a group are mis-aligned in time) in virtual human conversers. Using motion capture data from a range of both polite conversations and arguments, we conduct a series of perceptual experiments and determine some factors that contribute to the plausibility of virtual conversing groups. We found that participants are more sensitive to visual desynchronization of body motions, than to mismatches between the characters' gestures and their voices. Furthermore, synthetic conversations can appear sufficiently realistic once there is an appropriate balance between talker and listener roles. This is regardless of body motion desynchronization or mismatched audio. ", 
        "id": 1040, 
        "title": "Seeing is believing: body motion dominates in multisensory conversations."
    }, 
    {
        "abstract": "", 
        "id": 1041, 
        "title": "Diffusion maps for edge-aware image editing."
    }, 
    {
        "abstract": " Current GPUs perform a significant amount of redundant shading when surfaces are tessellated into small triangles. We address this inefficiency by augmenting the GPU pipeline to gather and merge rasterized fragments from adjacent triangles in a mesh. This approach has minimal impact on output image quality, is amenable to implementation in fixed-function hardware, and, when rendering pixel-sized triangles, requires only a small amount of buffering to reduce overall pipeline shading work by a factor of eight. We find that a fragment-shading pipeline with this optimization is competitive with the REYES pipeline approach of shading at micropolygon vertices and, in cases of complex occlusion, can perform up to two times less shading work.  ", 
        "id": 1042, 
        "title": "Reducing shading on GPUs using quad-fragment merging."
    }, 
    {
        "abstract": "", 
        "id": 1043, 
        "title": "Edge-based image coarsening."
    }, 
    {
        "abstract": "", 
        "id": 1044, 
        "title": "Feature-preserving triangular geometry images for level-of-detail representation of static and skinned meshes."
    }, 
    {
        "abstract": " Achieving interactive performance in cloth animation has significant implications in computer games and other interactive graphics applications. Although much progress has been made, it is still much desired to have real-time high-quality results that well preserve dynamic folds and wrinkles. In this paper, we introduce a hybrid method for real-time cloth animation. It relies on datadriven models to capture the relationship between cloth deformations at two resolutions. Such data-driven models are responsible for transforming low-quality simulated deformations at the low resolution into high-resolution cloth deformations with dynamically introduced fine details. Our data-driven transformation is trained using rotation invariant quantities extracted from the cloth models, and is independent of the simulation technique chosen for the lower resolution model. We have also developed a fast collision detection and handling scheme based on dynamically transformed bounding volumes. All the components in our algorithm can be efficiently implemented on programmable graphics hardware to achieve an overall real-time performance on high-resolution cloth models. ", 
        "id": 1045, 
        "title": "A deformation transformer for real-time cloth animation."
    }, 
    {
        "abstract": "", 
        "id": 1046, 
        "title": "Context-based search for 3D models."
    }, 
    {
        "abstract": "This paper introduces a method for optimizing the tiles of a quadmesh. Given a quad-based surface, the goal is to generate a set of K quads whose instances can produce a tiled surface that approximates the input surface. A solution to the problem is a K-set tilable surface, which can lead to an effective cost reduction in the physical construction of the given surface. Rather than molding lots of different building blocks, a K-set tilable surface requires the construction of K prefabricated components only. To realize the K-set tilable surface, we use a cluster-optimize approach. First, we iteratively cluster and analyze: clusters of similar shapes are merged, while edge connections between the K quads on the target surface are analyzed to learn the induced flexibility of the K-set tilable surface. Then, we apply a non-linear optimization model with constraints that maintain the K quads connections and shapes, and show how quad-based surfaces are optimized into K-set tilable surfaces. Our algorithm is demonstrated on various surfaces, including some that mimic the exteriors of certain renowned building landmarks. ", 
        "id": 1047, 
        "title": "K-set tilable surfaces."
    }, 
    {
        "abstract": "", 
        "id": 1048, 
        "title": "Accurate multidimensional Poisson-disk sampling."
    }, 
    {
        "abstract": "", 
        "id": 1049, 
        "title": "Circularly polarized spherical illumination reflectometry."
    }, 
    {
        "abstract": "View interpolation and image-based rendering algorithms often produce visual artifacts in regions where the 3D scene geometry is erroneous, uncertain, or incomplete. We introduce ambient point clouds constructed from colored pixels with uncertain depth, which help reduce these artifacts while providing non-photorealistic background coloring and emphasizing reconstructed 3D geometry. Ambient point clouds are created by randomly sampling colored points along the viewing rays associated with uncertain pixels. Our realtime rendering system combines these with more traditional rigid 3D point clouds and colored surface meshes obtained using multiview stereo. Our resulting system can handle larger-range view transitions with fewer visible artifacts than previous approaches. ", 
        "id": 1050, 
        "title": "Ambient point clouds for view interpolation."
    }, 
    {
        "abstract": "", 
        "id": 1051, 
        "title": "Programmable rendering of line drawing from 3D scenes."
    }, 
    {
        "abstract": "", 
        "id": 1052, 
        "title": "Coded aperture projection."
    }, 
    {
        "abstract": "", 
        "id": 1053, 
        "title": "A progressive error estimation framework for photon density estimation."
    }, 
    {
        "abstract": "", 
        "id": 1054, 
        "title": "Extrusion and revolution mapping."
    }, 
    {
        "abstract": "", 
        "id": 1055, 
        "title": "Optimizing continuity in multiscale imagery."
    }, 
    {
        "abstract": "We investigate a complete pipeline for measuring, modeling, and fabricating objects with specified subsurface scattering behaviors. The process starts with measuring the scattering properties of a given set of base materials, determining their radial reflection and transmission profiles. We describe a mathematical model that predicts the profiles of different stackings of base materials, at arbitrary thicknesses. In an inverse process, we can then specify a desired reflection profile and compute a layered composite material that best approximates it. Our algorithm efficiently searches the space of possible combinations of base materials, pruning unsatisfactory states imposed by physical constraints. We validate our process by producing both homogeneous and heterogeneous composites fabricated using a multi-material 3D printer. We demonstrate reproductions that have scattering properties approximating complex materials. ", 
        "id": 1056, 
        "title": "Physical reproduction of materials with specified subsurface scattering."
    }, 
    {
        "abstract": "", 
        "id": 1057, 
        "title": "Using blur to affect perceived distance and size."
    }, 
    {
        "abstract": "", 
        "id": 1058, 
        "title": "Detail-preserving fully-Eulerian interface tracking framework."
    }, 
    {
        "abstract": "We present a method for parameterizing subdivision surfaces in an as-rigid-as-possible fashion. While much work has concentrated on parameterizing polygon meshes, little if any work has focused on subdivision surfaces despite their popularity. We show that polygon parameterization methods produce suboptimal results when applied to subdivision surfaces and describe how these methods may be modified to operate on subdivision surfaces. We also describe a method for creating extended charts to further reduce the distortion of the parameterization. Finally we demonstrate how to take advantage of the multi-resolution structure of subdivision surfaces to accelerate convergence of our optimization. ", 
        "id": 1059, 
        "title": "Parameterizing subdivision surfaces."
    }, 
    {
        "abstract": "This paper presents a new method for editing and retargeting motions that involve close interactions between body parts of single or multiple articulated characters, such as dancing, wrestling, and sword fighting, or between characters and a restricted environment, such as getting into a car. In such motions, the implicit spatial relationships between body parts/objects are important for capturing the scene semantics. We introduce a simple structure called an interaction mesh to represent such spatial relationships. By minimizing the local deformation of the interaction meshes of animation frames, such relationships are preserved during motion editing while reducing the number of inappropriate interpenetrations. The interaction mesh representation is general and applicable to various kinds of close interactions. It also works well for interactions involving contacts and tangles as well as those without any contacts. The method is computationally efficient, allowing real-time character control. We demonstrate its effectiveness and versatility in synthesizing a wide variety of motions with close interactions.", 
        "id": 1060, 
        "title": "Spatial relationship preserving character motion adaptation."
    }, 
    {
        "abstract": "We present a novel optical setup and processing pipeline for measuring the 3D geometry and spatially-varying surface reflectance of physical objects. Central to our design is a digital camera and a high frequency spatially-modulated light source aligned to share a common focal point and optical axis. Pairs of such devices allow capturing a sequence of images from which precise measurements of geometry and reflectance can be recovered. Our approach is enabled by two technical contributions: a new active multiview stereo algorithm and an analysis of light descattering that has important implications for image-based reflectometry. We show that the geometry measured by our scanner is accurate to within 50 microns at a resolution of roughly 200 microns and that the reflectance agrees with reference data to within 5.5%. Additionally, we present an image relighting application and show renderings that agree very well with reference images at light and view positions far from those that were initially measured. ", 
        "id": 1061, 
        "title": "A coaxial optical scanner for synchronous acquisition of 3D geometry and surface reflectance."
    }, 
    {
        "abstract": "", 
        "id": 1062, 
        "title": "Light reallocation for high contrast projection using an analog micromirror array."
    }, 
    {
        "abstract": "We present a micropolygon ray tracing algorithm that is capable of efficiently rendering high quality defocus and motion blur effects. A key component of our algorithm is a BVH (bounding volume hierarchy) based on 4D hyper-trapezoids that project into 3D OBBs (oriented bounding boxes) in spatial dimensions. This acceleration structure is able to provide tight bounding volumes for scene geometries, and is thus efficient in pruning intersection tests during ray traversal. More importantly, it can exploit the natural coherence on the time dimension in motion blurred scenes. The structure can be quickly constructed by utilizing the micropolygon grids generated during micropolygon tessellation. Ray tracing of defocused and motion blurred scenes is efficiently performed by traversing the structure. Both the BVH construction and ray traversal are easily implemented on GPUs and integrated into a GPU-based micropolygon renderer. In our experiments, our ray tracer performs up to an order of magnitude faster than the state-of-art rasterizers while consistently delivering an image quality equivalent to a maximumquality rasterizer. We also demonstrate that the ray tracing algorithm can be extended to handle a variety of effects, such as secondary ray effects and transparency. ", 
        "id": 1063, 
        "title": "Micropolygon ray tracing with defocus and motion blur."
    }, 
    {
        "abstract": "", 
        "id": 1064, 
        "title": "Piles of objects."
    }, 
    {
        "abstract": "In fluorescent materials, light from a certain band of incident wavelengths is reradiated at longer wavelengths, i.e., with a reduced per-photon energy. While fluorescent materials are common in everyday life, they have received little attention in computer graphics. Especially, no bidirectional reradiation measurements of fluorescent materials have been available so far. In this paper, we extend the well-known concept of the bidirectional reflectance distribution function (BRDF) to account for energy transfer between wavelengths, resulting in a Bispectral Bidirectional Reflectance and Reradiation Distribution Function (bispectral BRRDF). Using a bidirectional and bispectral measurement setup, we acquire reflectance and reradiation data of a variety of fluorescent materials, including vehicle paints, paper and fabric, and compare their renderings with RGB, RGBRGB, and spectral BRDFs. Our acquisition is guided by a principal component analysis on complete bispectral data taken under a sparse set of angles. We show that in order to faithfully reproduce the full bispectral information for all other angles, only a very small number of wavelength pairs needs to be measured at a high angular resolution. ", 
        "id": 1065, 
        "title": "Acquisition and analysis of bispectral bidirectional reflectance and reradiation distribution functions."
    }, 
    {
        "abstract": "We introduce layer operations for single-view 3D deformable object manipulation, in which the user can control the depth order of layered 3D objects resting on a flat ground with simple clicks and drags, as in 2D drawing systems. We present two interaction techniques based on this idea and describe their implementation. The first technique is explicit layer swap. The user clicks the target layer, and the system swaps the layer with the one directly underneath it. The second technique is layer-aware dragging. As the user drags the object, the system adjusts its depth automatically to pass over or under a colliding object in the screen space, according to user control. Although the user interface is 2.5D, all scene representations are true 3D, and thus the system naturally supports local layering, self-occlusions, and folds. Internally, the system dynamically computes the apparent layer structure in the current configuration and makes appropriate depth adjustments to obtain the desired results. We demonstrate the effectiveness of this approach in cloth and rope manipulation systems. ", 
        "id": 1066, 
        "title": "Apparent layer operations for the manipulation of deformable objects."
    }, 
    {
        "abstract": "", 
        "id": 1067, 
        "title": "MovieReshape: tracking and reshaping of humans in videos."
    }, 
    {
        "abstract": "The radiative transfer framework that underlies all current rendering of volumes is limited to scattering media whose properties are invariant to rotation. Many systems allow for \"anisotropic scattering,\" in the sense that scattered intensity depends on the scattering angle, but the standard equation assumes that the structure of the medium is isotropic. This limitation impedes physics-based rendering of volume models of cloth, hair, skin, and other important volumetric or translucent materials that do have anisotropic structure. This paper presents an end-to-end formulation of physics-based volume rendering of anisotropic scattering structures, allowing these materials to become full participants in global illumination simulations. We begin with a generalized radiative transfer equation, derived from scattering by oriented non-spherical particles. Within this framework, we propose a new volume scattering model analogous to the well-known family of microfacet surface reflection models; we derive an anisotropic diffusion approximation, including the weak form required for finite element solution and a way to compute the diffusion matrix from the parameters of the scattering model; and we also derive a new anisotropic dipole BSSRDF for anisotropic translucent materials. We demonstrate results from Monte Carlo, finite element, and dipole simulations. All these contributions are readily implemented in existing rendering systems for volumes and translucent materials, and they all reduce to the standard practice in the isotropic case. ACM Reference Format Jakob, W., Arbree, A., Moon, J., Bala, K., Marschner, S. 2010. A radiative transfer framework for rendering materials with anisotropic structure. ACM Trans. Graph. 29, 4, Article 53 (July 2010), 13 pages. DOI = 10.1145/1778765.1778790 http://doi.acm.org/10.1145/1778765.1778790. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for prot or direct commercial advantage and that copies show this notice on the rst page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specic permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org.  2010 ACM 0730-0301/2010/07-ART53 $10.00 DOI 10.1145/1778765.1778790 http://doi.acm.org/10.1145/1778765.1778790  ", 
        "id": 1068, 
        "title": "A radiative transfer framework for rendering materials with anisotropic structure."
    }, 
    {
        "abstract": "", 
        "id": 1069, 
        "title": "A practical appearance model for dynamic facial color."
    }, 
    {
        "abstract": "We present a deblurring algorithm that uses a hardware attachment coupled with a natural image prior to deblur images from consumer cameras. Our approach uses a combination of inexpensive gyroscopes and accelerometers in an energy optimization framework to estimate a blur function from the camera's acceleration and angular velocity during an exposure. We solve for the camera motion at a high sampling rate during an exposure and infer the latent image using a joint optimization. Our method is completely automatic, handles per-pixel, spatially-varying blur, and out-performs the current leading image-based methods. Our experiments show that it handles large kernels  up to at least 100 pixels, with a typical size of 30 pixels. We also present a method to perform \"ground-truth\" measurements of camera motion blur. We use this method to validate our hardware and deconvolution approach. To the best of our knowledge, this is the first work that uses 6 DOF inertial sensors for dense, per-pixel spatially-varying image deblurring and the first work to gather dense ground-truth measurements for camera-shake blur. ", 
        "id": 1070, 
        "title": "Image deblurring using inertial measurement sensors."
    }, 
    {
        "abstract": "", 
        "id": 1071, 
        "title": "Personal photo enhancement using example images."
    }, 
    {
        "abstract": "", 
        "id": 1072, 
        "title": "Morphable crowds."
    }, 
    {
        "abstract": "Yarn-based cloth simulation can improve visual quality but at high computational costs due to the reliance on numerous persistent yarn-yarn contacts to generate material behavior. Finding so many contacts in densely interlinked geometry is a pathological case for traditional collision detection, and the sheer number of contact interactions makes contact processing the simulation bottleneck. In this paper, we propose a method for approximating penalty-based contact forces in yarn-yarn collisions by computing the exact contact response at one time step, then using a rotated linear force model to approximate forces in nearby deformed configurations. Because contacts internal to the cloth exhibit good temporal coherence, sufficient accuracy can be obtained with infrequent updates to the approximation, which are done adaptively in space and time. Furthermore, by tracking contact models we reduce the time to detect new contacts. The end result is a 7to 9-fold speedup in contact processing and a 4to 5-fold overall speedup, enabling simulation of character-scale garments.", 
        "id": 1073, 
        "title": "Efficient yarn-based cloth with adaptive contact linearization."
    }, 
    {
        "abstract": "This paper presents a data-driven approach to simultaneous segmentation and labeling of parts in 3D meshes. An objective function is formulated as a Conditional Random Field model, with terms assessing the consistency of faces with labels, and terms between labels of neighboring faces. The objective function is learned from a collection of labeled training meshes. The algorithm uses hundreds of geometric and contextual label features and learns different types of segmentations for different tasks, without requiring manual parameter tuning. Our algorithm achieves a significant improvement in results over the state-of-the-art when evaluated on the Princeton Segmentation Benchmark, often producing segmentations and labelings comparable to those produced by humans.  tasks in geometric modeling, manufacturing, animation and texturing of 3D meshes rely on their segmentation into parts. Many of these problems further require labeled segmentations, where the parts are also recognized as instances of known part types. For most of these applications, the segmentation and labeling of the input shape is manually specified. For example, to synthesize texture for a humanoid mesh, one must identify which parts should have \"arm\" texture, which should have \"leg\" texture, and so on. Even tasks such as 3D shape matching or retrieval, which do not directly require labeled-segmentations, could benefit from knowledge of constituent parts and labels. However, there has been very little research in part labeling for 3D meshes, and 3D object segmentation likewise remains an open research problem [Chen et al. 2009].  ", 
        "id": 1074, 
        "title": "Learning 3D mesh segmentation and labeling."
    }, 
    {
        "abstract": "Local image histograms contain a great deal of information useful for applications in computer graphics, computer vision and computational photography. Making use of that information has been challenging because of the expense of computing histogram properties over large neighborhoods. Efficient algorithms exist for some specific computations like the bilateral filter, but not others. Here, we present an efficient and practical method for computing accurate derivatives and integrals of locally-weighted histograms over large neighborhoods. The method allows us to compute the location, height, width and integral of all local histogram modes at interactive rates. Among other things, it enables the first constanttime isotropic median filter, robust isotropic image morphology operators, an efficient \"dominant mode\" filter and a non-iterative alternative to the mean shift. In addition, we present a method to combat the over-sharpening that is typical of histogram-based edge-preserving smoothing. This post-processing step should make histogram-based filters not only fast and efficient, but also suitable for a variety of new applications. ", 
        "id": 1075, 
        "title": "Smoothed local histogram filters."
    }, 
    {
        "abstract": "", 
        "id": 1076, 
        "title": "Metric-aware processing of spherical imagery."
    }, 
    {
        "abstract": "", 
        "id": 1077, 
        "title": "Distributed gradient-domain processing of planar and spherical images."
    }, 
    {
        "abstract": "Material design is the process by which artists specify the reflectance properties of a surface, such as its diffuse color and specular roughness. We present a user study to evaluate the relative benefits of different material design interfaces, focusing on novice users since they stand to gain the most from intuitive interfaces. Specifically, we investigate the editing of the parameters of analytic bidirectional distribution functions (BRDFs) using three interface paradigms: physical sliders by which users set the parameters of analytic BRDF models, such as diffuse albedo and specular roughness; perceptual sliders by which users set perceptually-inspired parameters, such as diffuse luminance and gloss contrast; and image navigation by which material variations are displayed in arrays of image thumbnails and users make edits by selecting them. We investigate two design tasks: precise adjustment and artistic exploration. We collect objective and subjective data, finding that subjects can perform equally well with physical and perceptual sliders as long as the interface responds interactively. Image navigation performs worse than the other interfaces on precise adjustment tasks, but excels at aiding in artistic exploration. We find that given enough time, novices can perform relatively complex material editing tasks with little training, and most novices work similarly to one another. ", 
        "id": 1078, 
        "title": "Toward evaluating material design interface paradigms for novice users."
    }, 
    {
        "abstract": "", 
        "id": 1079, 
        "title": "Multi-phase fluid simulations using regional level sets."
    }, 
    {
        "abstract": "In this paper, we propose a simple and efficient framework for simulating dispersed bubble flow. Instead of modeling the complex hydrodynamics of numerous small bubbles explicitly, our method approximates the average motion of these bubbles using a continuum multiphase solver. Then, the subgrid interactions among bubbles are computed using our new stochastic solver. Using the proposed scheme, we can efficiently simulate complex scenes with millions of bubbles. ", 
        "id": 1080, 
        "title": "A practical simulation of dispersed bubble flow."
    }, 
    {
        "abstract": "", 
        "id": 1081, 
        "title": "Automatic generation of destination maps."
    }, 
    {
        "abstract": "Systems such as Google Street View and Bing Maps Streetside enable users to virtually visit cities by navigating between immersive 360panoramas, or bubbles. The discrete moves from bubble to bubble enabled in these systems do not provide a good visual sense of a larger aggregate such as a whole city block. Multi-perspective \"strip\" panoramas can provide a visual summary of a city street but lack the full realism of immersive panoramas. We present Street Slide, which combines the best aspects of the immersive nature of bubbles with the overview provided by multiperspective strip panoramas. We demonstrate a seamless transition between bubbles and multi-perspective panoramas. We also present a dynamic construction of the panoramas which overcomes many of the limitations of previous systems. As the user slides sideways, the multi-perspective panorama is constructed and rendered dynamically to simulate either a perspective or hyper-perspective view. This provides a strong sense of parallax, which adds to the immersion. We call this form of sliding sideways while looking at a street facade a street slide. Finally we integrate annotations and a mini-map within the user interface to provide geographic information as well additional affordances for navigation. We demonstrate our Street Slide system on a series of intersecting streets in an urban setting. We report the results of a user study, which shows that visual searching is greatly enhanced with the Street Slide interface over existing systems from Google and Bing. ", 
        "id": 1082, 
        "title": "Street slide: browsing street level imagery."
    }, 
    {
        "abstract": "Figure 1: Examples of inequivalent and equivalent VPL rendering. (a)-(b) are VPL renderings with 1k VPLs, and clamp levels C1 = 316 and C8 = 0.1, respectively, that are not equivalent (6) to the reference (d) because they have image artifacts (a) or different perceived material appearance (b). (c) VPL rendering produces an image that is visually equivalent () to the reference for 100k VPLs and clamp level C4 = 10, even though some reflections are lost where the Dragon is in contact with the pedestal and around its silhouette. Abstract Rendering applications in design, manufacturing, ecommerce and other fields are used to simulate the appearance of objects and scenes. Fidelity with respect to appearance is often critical, and calculating global illumination (GI) is an important contributor to image fidelity; but it is expensive to compute. GI approximation methods, such as virtual point light (VPL) algorithms, are efficient, but they can induce image artifacts and distortions of object appearance. In this paper we systematically study the perceptual effects on image quality and material appearance of global illumination approximations made by VPL algorithms. In a series of psy-chophysical experiments we investigate the relationships between rendering parameters, object properties and image fidelity in a VPL renderer. Using the results of these experiments we analyze how VPL counts and energy clamping levels affect the visibility of image artifacts and distortions of material appearance, and show how object geometry and material properties modulate these effects. We find the ranges of these parameters that produce VPL renderings that are visually equivalent to reference renderings. Further we identify classes of shapes and materials that cannot be accurately rendered using VPL methods with limited resources. Using these findings we propose simple heuristics to guide visually equivalent and efficient rendering, and present a method for correcting energy losses in VPL renderings. This work provides a strong perceptual foundation for a popular and efficient class of GI algorithms.", 
        "id": 1083, 
        "title": "Effects of global illumination approximations on material appearance."
    }, 
    {
        "abstract": "This paper addresses the problem of remapping the disparity range of stereoscopic images and video. Such operations are highly important for a variety of issues arising from the production, live broadcast, and consumption of 3D content. Our work is motivated by the observation that the displayed depth and the resulting 3D viewing experience are dictated by a complex combination of perceptual, technological, and artistic constraints. We first discuss the most important perceptual aspects of stereo vision and their implications for stereoscopic content creation. We then formalize these insights into a set of basic disparity mapping operators. These operators enable us to control and retarget the depth of a stereoscopic scene in a nonlinear and locally adaptive fashion. To implement our operators, we propose a new strategy based on stereoscopic warping of the input video streams. From a sparse set of stereo correspondences, our algorithm computes disparity and image-based saliency estimates, and uses them to compute a deformation of the input views so as to meet the target disparities. Our approach represents a practical solution for actual stereo production and display that does not require camera calibration, accurate dense depth maps, occlusion handling, or inpainting. We demonstrate the performance and versatility of our method using examples from live action postproduction, 3D display size adaptation, and live broadcast. An additional user study and ground truth comparison further provide evidence for the quality and practical relevance of the presented work. ", 
        "id": 1084, 
        "title": "Nonlinear disparity mapping for stereoscopic 3D."
    }, 
    {
        "abstract": "", 
        "id": 1085, 
        "title": "Content-adaptive parallax barriers: optimizing dual-layer 3D displays using low-rank light field factorization."
    }, 
    {
        "abstract": "This paper introduces an approach to control of physics-based characters based on high-level features of movement, such as centerof-mass, angular momentum, and end-effectors. Objective terms are used to control each feature, and are combined by a prioritization algorithm. We show how locomotion can be expressed in terms of a small number of features that control balance and endeffectors. This approach is used to build controllers for human balancing, standing jump, and walking. These controllers provide numerous benefits: human-like qualities such as arm-swing, heeloff, and hip-shoulder counter-rotation emerge automatically during walking; controllers are robust to changes in body parameters; control parameters and goals may be modified at run-time; control parameters apply to intuitive properties such as center-of-mass height; and controllers may be mapped onto entirely new bipeds with different topology and mass distribution, without modifications to the controller itself. No motion capture or off-line optimization process is used. ", 
        "id": 1086, 
        "title": "Feature-based locomotion controllers."
    }, 
    {
        "abstract": "", 
        "id": 1087, 
        "title": "Face poser: Interactive modeling of 3D facial expressions using facial priors."
    }, 
    {
        "abstract": "We present a novel rendering system for defocus blur and lens effects. It supports physically-based rendering and outperforms previous approaches by involving a novel GPU-based tracing method. Our solution achieves more precision than competing real-time solutions and our results are mostly indistinguishable from offline rendering. Our method is also more general and can integrate advanced simulations, such as simple geometric lens models enabling various lens aberration effects. These latter is crucial for realism, but are often employed in artistic contexts, too. We show that available artistic lenses can be simulated by our method. In this spirit, our work introduces an intuitive control over depth-of-field effects. The physical basis is crucial as a starting point to enable new artistic renderings based on a generalized focal surface to emphasize particular elements in the scene while retaining a realistic look. Our real-time solution provides realistic, as well as plausible expressive results. ", 
        "id": 1088, 
        "title": "Real-time lens blur effects and focus control."
    }, 
    {
        "abstract": "We present a dynamic controller to physically simulate underactuated three-dimensional full-body biped locomotion. Our datadriven controller takes motion capture reference data to reproduce realistic human locomotion through realtime physically based simulation. The key idea is modulating the reference trajectory continuously and seamlessly such that even a simple dynamic tracking controller can follow the reference trajectory while maintaining its balance. In our framework, biped control can be facilitated by a large array of existing data-driven animation techniques because our controller can take a stream of reference data generated on-thefly at runtime. We demonstrate the effectiveness of our approach through examples that allow bipeds to turn, spin, and walk while steering its direction interactively. ", 
        "id": 1089, 
        "title": "Data-driven biped control."
    }, 
    {
        "abstract": "We present a method for inferring the behavior styles of character controllers from a small set of examples. We show that a rich set of behavior variations can be captured by determining the appropriate reward function in the reinforcement learning framework, and show that the discovered reward function can be applied to different environments and scenarios. We also introduce a new algorithm to recover the unknown reward function that improves over the original apprenticeship learning algorithm. We show that the reward function representing a behavior style can be applied to a variety of different tasks, while still preserving the key features of the style present in the given examples. We describe an adaptive process where an author can, with just a few additional examples, refine the behavior so that it has better generalization properties. ", 
        "id": 1090, 
        "title": "Learning behavior styles with inverse reinforcement learning."
    }, 
    {
        "abstract": "", 
        "id": 1091, 
        "title": "Motion fields for interactive character locomotion."
    }, 
    {
        "abstract": "Textures are often reused on different surfaces in large virtual environments. This leads to unpleasing stretch and cropping of features when textures contain architectural elements. Existing retargeting methods could adapt each texture to the size of their support surface, but this would imply storing a different image for each and every surface, saturating memory. Our new texture synthesis approach casts synthesis as a shortest path problem in a graph describing the space of images that can be synthesized. Each path in the graph describes how to form a new image by cutting strips of the source image and reassembling them in a different order. Only the paths describing the result need to be stored in memory: synthesized textures are reconstructed at rendering time. The user can control repetition of features, and may specify positional constraints. We demonstrate our approach on a variety of textures, from facades for large city rendering to structured textures commonly used in video games. ", 
        "id": 1092, 
        "title": "By-example synthesis of architectural textures."
    }, 
    {
        "abstract": "Large scale fluid simulation can be difficult using existing techniques due to the high computational cost of using large grids. We present a novel technique for simulating detailed fluids quickly. Our technique coarsens the Eulerian fluid grid during the pressure solve, allowing for a fast implicit update but still maintaining the resolution obtained with a large grid. This allows our simulations to run at a fraction of the cost of existing techniques while still providing the fine scale structure and details obtained with a full projection. Our algorithm scales well to very large grids and large numbers of processors, allowing for high fidelity simulations that would otherwise be intractable.  noise (see [Stam and Fiume 1993; Lamorlette and Foster 2002; Rasmussen et al. 2003]) and curl noise (see [Bridson et al. 2007]) can be used to enhance the visual fidelity of fluid simulations by coupling the noise to the incompressible Navier-Stokes equations producing a more detailed flow. Alternatively, [Kim et al. 2008] and [Narain et al. 2008] determine where to add noise using information from the existing simulation and then add it as a postprocess which allows them to add noise where it is best suited. Other techniques such as [Schechter and Bridson 2008] both determine where to add noise and couple the noise to the Navier-Stokes equations. All of these techniques are successful at adding details but are nonphysical and can produce significantly less realistic results than simply simulating with a higher resolution grid.  ", 
        "id": 1093, 
        "title": "A novel algorithm for incompressible flow using only a coarse grid projection."
    }, 
    {
        "abstract": " We introduce gesture controllers, a method for animating the body language of avatars engaged in live spoken conversation. A gesture controller is an optimal-policy controller that schedules gesture animations in real time based on acoustic features in the user's speech. The controller consists of an inference layer, which infers a distribution over a set of hidden states from the speech signal, and a control layer, which selects the optimal motion based on the inferred state distribution. The inference layer, consisting of a specialized conditional random field, learns the hidden structure in body language style and associates it with acoustic features in speech. The control layer uses reinforcement learning to construct an optimal policy for selecting motion clips from a distribution over the learned hidden states. The modularity of the proposed method allows customization of a character's gesture repertoire, animation of non-human characters, and the use of additional inputs such as speech recognition or direct user control. ", 
        "id": 1094, 
        "title": "Gesture controllers."
    }, 
    {
        "abstract": " This paper introduces Lp-Centroidal Voronoi Tessellation (LpCVT), a generalization of CVT that minimizes a higher-order moment of the coordinates on the Voronoi cells. This generalization allows for aligning the axes of the Voronoi cells with a predefined background tensor field (anisotropy). Lp-CVT is computed by a quasi-Newton optimization framework, based on closed-form derivations of the objective function and its gradient. The derivations are given for both surface meshing ( is a triangulated mesh with per-facet anisotropy) and volume meshing ( is the interior of a closed triangulated mesh with a 3D anisotropy field). Applications to anisotropic, quad-dominant surface remeshing and to hexdominant volume meshing are presented. Unlike previous work, Lp-CVT captures sharp features and intersections without requiring any pre-tagging.  ", 
        "id": 1095, 
        "title": "Lp Centroidal Voronoi Tessellation and its applications."
    }, 
    {
        "abstract": "", 
        "id": 1096, 
        "title": "Analysis, reconstruction and manipulation using arterial snakes."
    }, 
    {
        "abstract": "We introduce the Symmetry Factored Embedding (SFE) and the Symmetry Factored Distance (SFD) as new tools to analyze and represent symmetries in a point set. The SFE provides new coordinates in which symmetry is \"factored out,\" and the SFD is the Euclidean distance in that space. These constructions characterize the space of symmetric correspondences between points  i.e., orbits. A key observation is that a set of points in the same orbit appears as a clique in a correspondence graph induced by pairwise similarities. As a result, the problem of finding approximate and partial symmetries in a point set reduces to the problem of measuring connectedness in the correspondence graph, a well-studied problem for which spectral methods provide a robust solution. We provide methods for computing the SFE and SFD for extrinsic global symmetries and then extend them to consider partial extrinsic and intrinsic cases. During experiments with difficult examples, we find that the proposed methods can characterize symmetries in inputs with noise, missing data, non-rigid deformations, and complex symmetries, without a priori knowledge of the symmetry group. As such, we believe that it provides a useful tool for automatic shape analysis in applications such as segmentation and stationary point detection.  ", 
        "id": 1097, 
        "title": "Symmetry factored embedding and distance."
    }, 
    {
        "abstract": "", 
        "id": 1098, 
        "title": "Biharmonic distance."
    }, 
    {
        "abstract": "Paper architectures are 3D paper buildings created by folding and cutting. The creation process of paper architecture is often laborintensive and highly skill-demanding, even with the aid of existing computer-aided design tools. We propose an automatic algorithm for generating paper architectures given a user-specified 3D model. The algorithm is grounded on geometric formulation of planar layout for paper architectures that can be popped-up in a rigid and stable manner, and sufficient conditions for a 3D surface to be poppedup from such a planar layout. Based on these conditions, our algorithm computes a class of paper architectures containing two sets of parallel patches that approximate the input geometry while guaranteed to be physically realizable. The method is demonstrated on a number of architectural examples, and physically engineered results are presented. ", 
        "id": 1099, 
        "title": "Popup: automatic paper architectures from 3D models."
    }, 
    {
        "abstract": "", 
        "id": 1100, 
        "title": "Real-time collision culling of a million bodies on graphics processing units."
    }, 
    {
        "abstract": "Human motions are the product of internal and external forces, but these forces are very difficult to measure in a general setting. Given a motion capture trajectory, we propose a method to reconstruct its open-loop control and the implicit contact forces. The method employs a strategy based on randomized sampling of the control within user-specified bounds, coupled with forward dynamics simulation. Sampling-based techniques are well suited to this task because of their lack of dependence on derivatives, which are difficult to estimate in contact-rich scenarios. They are also easy to parallelize, which we exploit in our implementation on a compute cluster. We demonstrate reconstruction of a diverse set of captured motions, including walking, running, and contact rich tasks such as rolls and kip-up jumps. We further show how the method can be applied to physically based motion transformation and retargeting, physically plausible motion variations, and referencetrajectory-free idling motions. Alongside the successes, we point out a number of limitations and directions for future work. ", 
        "id": 1101, 
        "title": "Sampling-based contact-rich motion control."
    }, 
    {
        "abstract": "", 
        "id": 1102, 
        "title": "Automatic reconstruction of tree skeletal structures from point clouds."
    }, 
    {
        "abstract": "We introduce a method for generating facial blendshape rigs from a set of example poses of a CG character. Our system transfers controller semantics and expression dynamics from a generic template to the target blendshape model, while solving for an optimal reproduction of the training poses. This enables a scalable design process, where the user can iteratively add more training poses to refine the blendshape expression space. However, plausible animations can be obtained even with a single training pose. We show how formulating the optimization in gradient space yields superior results as compared to a direct optimization on blendshape vertices. We provide examples for both hand-crafted characters and 3D scans of a real actor and demonstrate the performance of our system in the context of markerless art-directable facial tracking. ", 
        "id": 1103, 
        "title": "Example-based facial rigging."
    }, 
    {
        "abstract": "", 
        "id": 1104, 
        "title": "Anisotropic blue noise sampling."
    }, 
    {
        "abstract": "", 
        "id": 1105, 
        "title": "Editing operations for irregular vertices in triangle meshes."
    }, 
    {
        "abstract": "", 
        "id": 1106, 
        "title": "Stereoscopic 3D copy & paste."
    }, 
    {
        "abstract": "We develop an accurate, unified treatment of elastica. Following the method of resultant-based formulation to its logical extreme, we derive a higher-order integration rule, or elaston, measuring stretching, shearing, bending, and twisting along any axis. The theory and accompanying implementation do not distinguish between forms of different dimension (solids, shells, rods), nor between manifold regions and non-manifold junctions. Consequently, a single code accurately models a diverse range of elastoplastic behaviors, including buckling, writhing, cutting and merging. Emphasis on convergence to the continuum sets us apart from early unification efforts. ", 
        "id": 1107, 
        "title": "Unified simulation of elastic rods, shells, and solids."
    }, 
    {
        "abstract": "", 
        "id": 1108, 
        "title": "Computer-generated residential building layouts."
    }, 
    {
        "abstract": " This paper addresses the fundamental problem of computing stable medial representations of 3D shapes. We propose a spatially adaptive classification of geometric features that yields a robust algorithm for generating medial representations at different levels of abstraction. The recently introduced continuous scale axis transform serves as the mathematical foundation of our algorithm. We show how geometric and topological properties of the continuous setting carry over to discrete shape representations. Our method combines scaling operations of medial balls for geometric simplification with filtrations of the medial axis and provably good conversion steps to and from union of balls, to enable efficient processing of a wide variety shape representations including polygon meshes, 3D images, implicit surfaces, and point clouds. We demonstrate the robustness and versatility of our algorithm with an extensive validation on hundreds of shapes including complex geometries consisting of millions of triangles. ", 
        "id": 1109, 
        "title": "Discrete scale axis representations for 3D geometry."
    }, 
    {
        "abstract": "", 
        "id": 1110, 
        "title": "Interactive generation of human animation with deformable motion models."
    }, 
    {
        "abstract": "How things work visualizations use a variety of visual techniques to depict the operation of complex mechanical assemblies. We present an automated approach for generating such visualizations. Starting with a 3D CAD model of an assembly, we first infer the motions of individual parts and the interactions between parts based on their geometry and a few user specified constraints. We then use this information to generate visualizations that incorporate motion arrows, frame sequences and animation to convey the causal chain of motions and mechanical interactions between parts. We present results for a wide variety of assemblies. ", 
        "id": 1111, 
        "title": "Illustrating how mechanical assemblies work."
    }, 
    {
        "abstract": "", 
        "id": 1112, 
        "title": "Cache-oblivious ray reordering."
    }, 
    {
        "abstract": "This paper presents a physics-based locomotion controller based on online planning. At each time-step, a planner optimizes locomotion over multiple phases of gait. Stance dynamics are modeled using a simplified Spring-Load Inverted (SLIP) model, while flight dynamics are modeled using projectile motion equations. Full-body control at each instant is optimized to match the instantaneous plan values, while also maintaining balance. Different types of gaits, including walking, running, and jumping, emerge automatically, as do transitions between different gaits. The controllers can traverse challenging terrain and withstand large external disturbances, while following high-level user commands at interactive rates. ", 
        "id": 1113, 
        "title": "Robust physics-based locomotion using low-dimensional planning."
    }, 
    {
        "abstract": "", 
        "id": 1114, 
        "title": "Sounding liquids: Automatic sound synthesis from fluid simulation."
    }, 
    {
        "abstract": "", 
        "id": 1115, 
        "title": "Dinus: Double insertion, nonuniform, stationary subdivision surfaces."
    }, 
    {
        "abstract": "High-order and regularly sampled surface representations are more efficient and compact than general meshes and considerably simplify many geometric modeling and processing algorithms. A number of recent algorithms for conversion of arbitrary meshes to regularly sampled form (typically quadrangulation) aim to align the resulting mesh with feature lines of the geometry. While resulting in a substantial improvement in mesh quality, feature alignment makes it difficult to obtain coarse regular patch partitions of the mesh. In this paper, we propose an approach to constructing patch layouts consisting of small numbers of quadrilateral patches while maintaining good feature alignment. To achieve this, we use quadrilateral T-meshes, for which the intersection of two faces may not be the whole edge or vertex, but a part of an edge. T-meshes offer more flexibility for reduction of the number of patches and vertices in a base domain while maintaining alignment with geometric features. At the same time, T-meshes retain many desirable features of quadrangulations, allowing construction of high-order representations, easy packing of regularly sampled geometric data into textures, as well as supporting different types of discretizations for physical simulation.  2. Approximation: Each patch should approximate the original mesh well. 3. Mesh complexity: The domain mesh should have as few vertices as possible, while satisfying other constraints. 4. Orientation and Alignment: In areas with well-pronounced consistent curvature directions, patch parametric lines should follow the curvature; patch boundaries should be aligned with sharp features and smooth surface boundaries. Existing techniques offer a tradeoff between alignment with features and isometry and the number of patches in the domain mesh. Techniques allowing to keep the number of patches small have only restricted forms of alignment control, while many recent algorithms with good alignment control often yield a larger number of patches in the domain mesh.  ", 
        "id": 1116, 
        "title": "Feature-aligned T-meshes."
    }, 
    {
        "abstract": "We introduce an interactive tool which enables a user to quickly assemble an architectural model directly over a 3D point cloud acquired from large-scale scanning of an urban scene. The user loosely defines and manipulates simple building blocks, which we call SmartBoxes, over the point samples. These boxes quickly snap to their proper locations to conform to common architectural structures. The key idea is that the building blocks are smart in the sense that their locations and sizes are automatically adjusted on-the-fly to fit well to the point data, while at the same time respecting contextual relations with nearby similar blocks. SmartBoxes are assembled through a discrete optimization to balance between two snapping forces defined respectively by a data-fitting term and a contextual term, which together assist the user in reconstructing the architectural model from a sparse and noisy point cloud. We show that a combination of the users interactive guidance and high-level knowledge about the semantics of the underlying model, together with the snapping forces, allows the reconstruction of structures which are partially or even completely missing from the input.", 
        "id": 1117, 
        "title": "SmartBoxes for interactive urban reconstruction."
    }, 
    {
        "abstract": "", 
        "id": 1118, 
        "title": "Free-flowing granular materials with two-way solid coupling."
    }, 
    {
        "abstract": "Golaem S.A. Figure 1: Animations resulting from our simulations. Emergent self-organized patterns appear in real crowds of walkers. Our simulations display similar effects by proposing an optic flow-based approach for steering walkers inspired by cognitive science work on human locomotion. Compared to previous approaches, our model improves such an emergence as well as the global efficiency of walkers traffic. We thus enhance the overall believability of animations by avoiding improbable locking situations. Abstract In the everyday exercise of controlling their locomotion, humans rely on their optic flow of the perceived environment to achieve collision-free navigation. In crowds, in spite of the complexity of the environment made of numerous obstacles, humans demonstrate remarkable capacities in avoiding collisions. Cognitive science work on human locomotion states that relatively succinct information is extracted from the optic flow to achieve safe locomotion. In this paper, we explore a novel vision-based approach of collision avoidance between walkers that fits the requirements of interactive crowd simulation. By simulating humans based on cognitive science results, we detect future collisions as well as the level of danger from visual stimuli. The motor-response is twofold: a reorientation strategy prevents future collision, whereas a deceleration strategy prevents imminent collisions. Several examples of our simulation results show that the emergence of self-organized patterns of walkers is reinforced using our approach. The emergent phenomena are visually appealing. More importantly, they improve the overall efficiency of the walkers traffic and avoid improbable locking situations.", 
        "id": 1119, 
        "title": "A synthetic-vision based steering approach for crowd simulation."
    }, 
    {
        "abstract": "", 
        "id": 1120, 
        "title": "Optical computing for fast light transport analysis."
    }, 
    {
        "abstract": "", 
        "id": 1121, 
        "title": "Underwater cloth simulation with fractional derivatives."
    }, 
    {
        "abstract": "", 
        "id": 1122, 
        "title": "Spectral sampling of manifolds."
    }, 
    {
        "abstract": "We introduce an interactive, portable, and inexpensive solution for estimating refractive errors in the human eye. While expensive optical devices for automatic estimation of refractive correction exist, our goal is to greatly simplify the mechanism by putting the human subject in the loop. Our solution is based on a high-resolution programmable display and combines inexpensive optical elements, interactive GUI, and computational reconstruction. The key idea is to interface a lenticular view-dependent display with the human eye in close range - a few millimeters apart. Via this platform, we create a new range of interactivity that is extremely sensitive to parameters of the human eye, like refractive errors, focal range, focusing speed, lens opacity, etc. We propose several simple optical setups, verify their accuracy, precision, and validate them in a user study. ", 
        "id": 1123, 
        "title": "NETRA: interactive display for estimating refractive errors and focal range."
    }, 
    {
        "abstract": "We describe the architecture of a novel system for precomputing sparse directional occlusion caches. These caches are used for accelerating a fast cinematic lighting pipeline that works in the spherical harmonics domain. The system was used as a primary lighting technology in the movie Avatar, and is able to efficiently handle massive scenes of unprecedented complexity through the use of a flexible, stream-based geometry processing architecture, a novel out-of-core algorithm for creating efficient ray tracing acceleration structures, and a novel out-of-core GPU ray tracing algorithm for the computation of directional occlusion and spherical integrals at arbitrary points.", 
        "id": 1124, 
        "title": "PantaRay: fast ray-traced occlusion caching of massive scenes."
    }, 
    {
        "abstract": "The NVIDIA OptiXTM ray tracing engine is a programmable system designed for NVIDIA GPUs and other highly parallel architectures. The OptiX engine builds on the key observation that most ray tracing algorithms can be implemented using a small set of programmable operations. Consequently, the core of OptiX is a domain-specific just-in-time compiler that generates custom ray tracing kernels by combining user-supplied programs for ray generation, material shading, object intersection, and scene traversal. This enables the implementation of a highly diverse set of ray tracing-based algorithms and applications, including interactive rendering, offline rendering, collision detection systems, artificial intelligence queries, and scientific simulations such as sound propagation. OptiX achieves high performance through a compact object model and application of several ray tracing-specific compiler optimizations. For ease of use it exposes a single-ray programming model with full support for recursion and a dynamic dispatch mechanism similar to virtual function calls. ", 
        "id": 1125, 
        "title": "OptiX: a general purpose ray tracing engine."
    }, 
    {
        "abstract": "", 
        "id": 1126, 
        "title": "Topology- and error-driven extension of scalar functions from surfaces to volumes."
    }, 
    {
        "abstract": "Scenes lit with high dynamic range environment maps of real-world environments exhibit all the complex nuances of natural illumination. For applications that need lighting adjustments to the rendered images, editing environment maps directly is still cumbersome. First, designers have to determine which region in the environment map is responsible for the specific lighting feature (e.g. diffuse gradients, highlights and shadows) they desire to edit. Second, determining the parameters of image-editing operations needed to achieve specific changes to the selected lighting feature requires extensive trial-and-error. This paper presents envyLight, an interactive interface for editing natural illumination that combines an algorithm to select environment map regions, by sketching strokes on lighting features in the rendered image, with a small set of editing operations to quickly adjust the selected feature. The envyLight selection algorithm works well for indoor and outdoor lighting corresponding to rendered images where lighting features vary widely in number, size, contrast and edge blur. Furthermore, envyLight selection is general with respect to material type, from matte to sharp glossy, and the complexity of scenes' shapes. envyLight editing operations allow designers to quickly alter the position, contrast and edge blur of the selected lighting feature and can be keyframed to support animation. ", 
        "id": 1127, 
        "title": "envyLight: an interface for editing natural illumination."
    }, 
    {
        "abstract": "", 
        "id": 1128, 
        "title": "Scalable fluid simulation using anisotropic turbulence particles."
    }, 
    {
        "abstract": "Geodesic curves in surfaces are not only minimizers of distance, but they are also the curves of zero geodesic (sideways) curvature. It turns out that this property makes patterns of geodesics the basic geometric entity when dealing with the cladding of a freeform surface with wooden panels which do not bend sideways. Likewise a geodesic is the favored shape of timber support elements in freeform architecture, for reasons of manufacturing and statics. Both problem areas are fundamental in freeform architecture, but so far only experimental solutions have been available. This paper provides a systematic treatment and shows how to design geodesic patterns in different ways: The evolution of geodesic curves is good for local studies and simple patterns; the level set formulation can deal with the global layout of multiple patterns of geodesics; finally geodesic vector fields allow us to interactively model geodesic patterns and perform surface segmentation into panelizable parts. ", 
        "id": 1129, 
        "title": "Geodesic patterns."
    }, 
    {
        "abstract": "We present a method for real-time sound propagation that captures all wave effects, including diffraction and reverberation, for multiple moving sources and a moving listener in a complex, static 3D scene. It performs an offline numerical simulation over the scene and then applies a novel technique to extract and compactly encode the perceptually salient information in the resulting acoustic responses. Each response is automatically broken into two phases: early reflections (ER) and late reverberation (LR), via a threshold on the temporal density of arriving wavefronts. The LR is simulated and stored in the frequency domain, once per room in the scene. The ER accounts for more detailed spatial variation, by recording a set of peak delays/amplitudes in the time domain and a residual frequency response sampled in octave frequency bands, at each source/receiver point pair in a 5D grid. An efficient run-time uses this precomputed representation to perform binaural sound rendering based on frequency-domain convolution. Our system demonstrates realistic, wave-based acoustic effects in real time, including diffraction low-passing behind obstructions, sound focusing, hollow reverberation in empty rooms, sound diffusion in fully-furnished rooms, and realistic late reverberation. ", 
        "id": 1130, 
        "title": "Precomputed wave simulation for real-time sound propagation of dynamic sources in complex scenes."
    }, 
    {
        "abstract": "", 
        "id": 1131, 
        "title": "Geometry-aware direction field processing."
    }, 
    {
        "abstract": "", 
        "id": 1132, 
        "title": "Computational highlight holography."
    }, 
    {
        "abstract": "We present an algorithm for interactive hair rendering with both single and multiple scattering effects under complex environment lighting. The outgoing radiance due to single scattering is determined by the integral of the product of the environment lighting, the scattering function, and the transmittance that accounts for selfshadowing among hair fibers. We approximate the environment light by a set of spherical radial basis functions (SRBFs) and thus convert the outgoing radiance integral into the sum of radiance contributions of all SRBF lights. For each SRBF light, we factor out the effective transmittance to represent the radiance integral as the product of two terms: the transmittance and the convolution of the SRBF light and the scattering function. Observing that the convolution term is independent of the hair geometry, we precompute it for commonly-used scattering models, and reduce the run-time computation to table lookups. We further propose a technique, called the convolution optical depth map, to efficiently approximate the effective transmittance by filtering the optical depth maps generated at the center of the SRBF using a depth-dependent kernel. As for the multiple scattering computation, we handle SRBF lights by using similar factorization and precomputation schemes, and adopt sparse sampling and interpolation to speed up the computation. Compared to off-line algorithms, our algorithm can generate images of comparable quality, but at interactive frame rates. ", 
        "id": 1133, 
        "title": "Interactive hair rendering under environment lighting."
    }, 
    {
        "abstract": "", 
        "id": 1134, 
        "title": "Consistent normal interpolation."
    }, 
    {
        "abstract": "Example-based texture synthesis algorithms generate novel texture images from example data. A popular hierarchical pixel-based approach uses spatial jitter to introduce diversity, at the risk of breaking coarse structure beyond repair. We propose a multiscale descriptor that enables appearance-space jitter, which retains structure. This idea enables repurposing of existing texture synthesis implementations for a qualitatively different problem statement and class of inputs: generating hybrids of structured images. ", 
        "id": 1135, 
        "title": "Synthesizing structured image hybrids."
    }, 
    {
        "abstract": "We present an interactive system for the artistic control of visual phenomena visible on surfaces. Our method allows the user to intuitively reposition shadows, caustics, and indirect illumination using a simple click-and-drag user interface working directly on surfaces. In contrast to previous approaches, the positions of the lights or objects in the scene remain unchanged, enabling localized edits of individual shading components. Our method facilitates the editing by computing a mapping from one surface location to another. Based on this mapping, we can not only edit shadows, caustics, and indirect illumination but also other surface properties, such as color or texture, in a unified way. This is achieved using an intuitive userinterface that allows the user to specify position constraints with drag-and-drop or sketching operations directly on the surface. Our approach requires no explicit surface parametrization and handles scenes with arbitrary topology. We demonstrate the applicability of the approach to interactive editing of shadows, reflections, refractions, textures, caustics, and diffuse indirect light. The effectiveness of the system to achieve an artistic goal is evaluated by a user study. ", 
        "id": 1136, 
        "title": "Interactive on-surface signal deformation."
    }, 
    {
        "abstract": "We present a new sketch-based modeling approach in which models are interactively designed by drawing their 2D silhouettes from different views. The core idea of our paper is to limit the input to 2D silhouettes, removing the need to explicitly create or position 3D elements. Arbitrarily complex models can be constructed by assembling them out of parts defined by their silhouettes, which can be combined using CSG operations. We introduce a new simplified algorithm to compute CSG solids that leverages special properties of silhouette cylinders to convert the 3D CSG problem into one that can be handled entirely with 2D operations, making implementation simpler and more robust. We evaluate our approach by modeling a random sampling of man-made objects taken from the words in WordNet, and show that all of the tested man-made objects can be modeled quickly and easily using our approach. ", 
        "id": 1137, 
        "title": "3D modeling with silhouettes."
    }, 
    {
        "abstract": "We present a way to bring cartoon objects and characters into the third dimension, by giving them the ability to rotate and be viewed from any angle. We show how 2D vector art drawings of a cartoon from different views can be used to generate a novel structure, the 2.5D cartoon model, which can be used to simulate 3D rotations and generate plausible renderings of the cartoon from any view. 2.5D cartoon models are easier to create than a full 3D model, and retain the 2D nature of hand-drawn vector art, supporting a wide range of stylizations that need not correspond to any real 3D shape. ", 
        "id": 1138, 
        "title": "2.5D cartoon models."
    }, 
    {
        "abstract": "", 
        "id": 1139, 
        "title": "Animation wrinkling: augmenting coarse cloth simulations with realistic-looking wrinkles."
    }, 
    {
        "abstract": "", 
        "id": 1140, 
        "title": "A comparative study of image retargeting."
    }, 
    {
        "abstract": "Rendering hair in motion pictures is an important and challenging task. Despite much research on physically based hair rendering, it is currently difficult to benefit from this work because physically based shading models do not offer artist friendly controls. As a consequence much production work so far has used ad hoc shaders that are easier to control, but often lack the richness seen in real hair. We show that physically based shading models fail to provide intuitive artist controls and we introduce a novel approach for creating an art-directable hair shading model from existing physically based models. Through an informal user study we show that this system is easier to use compared to existing systems. Our shader has been integrated into the production pipeline at the Walt Disney Animation Studios and is being used in the production of the upcoming animated feature film Tangled. ", 
        "id": 1141, 
        "title": "An artist friendly hair shading system."
    }, 
    {
        "abstract": "Although animation is one of the most compelling aspects of computer graphics, the possibilities for depicting the movement that make dynamic scenes so exciting remain limited for both still images and animations. In our work, we experiment with motion depiction as a first-class entity within the rendering process. We extend the concept of a surface shader, which is evaluated on an infinitesimal portion of an object's surface at one instant in time, to that of a programmable motion effect, which is evaluated with global knowledge about all portions of an object's surface that pass in front of a pixel during an arbitrary long sequence of time. With this added information, our programmable motion effects can decide to color pixels long after (or long before) an object has passed in front of them. In order to compute the input required by the motion effects, we propose a 4D data structure that aggregates an object's movement into a single geometric representation by sampling an object's position at different time instances and connecting corresponding edges in two adjacent samples with a bilinear patch. We present example motion effects for various styles of speed lines, multiple stroboscopic images, temporal offsetting, and photorealistic and stylized blurring on both simple and production examples. ", 
        "id": 1142, 
        "title": "Programmable motion effects."
    }, 
    {
        "abstract": "Collision detection is a problem that has often been addressed efficiently with the use of hierarchical culling data structures. In the subproblem of self-collision detection for triangle meshes, however, such hierarchical data structures lose much of their power, because triangles adjacent to each other cannot be distinguished from actually colliding ones unless individually tested. Shape regularity of surface patches, described in terms of orientation and contour conditions, was proposed long ago as a culling criterion for hierarchical self-collision detection. However, to date, algorithms based on shape regularity had to trade conservativeness for efficiency, because there was no known algorithm for efficiently performing 2D contour self-intersection tests. In this paper, we introduce a star-contour criterion that is amenable to hierarchical computations. Together with a thorough analysis of the tree traversal process in hierarchical self-collision detection, it has led us to novel hierarchical data structures and algorithms for efficient yet conservative self-collision detection. We demonstrate the application of our algorithm to several example animations, and we show that it consistently outperforms other approaches. ", 
        "id": 1143, 
        "title": "Star-contours for efficient hierarchical self-collision detection."
    }, 
    {
        "abstract": "", 
        "id": 1144, 
        "title": "Fast parallel surface and solid voxelization on GPUs."
    }, 
    {
        "abstract": "", 
        "id": 1145, 
        "title": "Cone carving for surface reconstruction."
    }, 
    {
        "abstract": "We propose a technique that takes a triangulated surface as input and outputs a surface with the same topology but altered geometry such that each polygon falls into a set of discrete equivalence classes. We begin by describing an error function that measures how close the polygons are to satisfying this criteria. To optimize this error function, we first cluster triangles into discrete sets such that the assignment of sets minimizes our error. We then find canonical polygons for each set using nonlinear optimization. Next, we solve a Poisson equation to find positions of vertices such that the surface polygons match the canonical polygons as close as possible. We also describe how to incorporate a fairness criteria into the optimization to avoid oscillations of the surface. We iterate this entire process until we reach a user specified tolerance, possibly adding clusters during iteration to guarantee convergence. We have been able to successfully reduce the number of unique triangles to lie within a small percentage of the total number of triangles in the surface and demonstrate our technique on various examples. ", 
        "id": 1146, 
        "title": "Triangle surfaces with discrete equivalence classes."
    }, 
    {
        "abstract": "A new definition of immersion with respect to virtual environment (VE) systems has been proposed in earlier work, based on the concept of simulation. One system (A) is said to be more immersive than another (B) if A can be used to simulate an application as if it were running on B. Here we show how this concept can be used as the basis for a psychophysics of presence in VEs, the sensation of being in the place depicted by the virtual environment displays (Place Illusion, PI), and also the illusion that events occurring in the virtual environment are real (Plausibility Illusion, Psi). The new methodology involves matching experiments akin to those in color science. Twenty participants first experienced PI or Psi in the initial highest level immersive system, and then in 5 different trials chose transitions from lower to higher order systems and declared a match whenever they felt the same level of PI or Psi as they had in the initial system. In each transition they could change the type of illumination model used, or the field-of-view, or the display type (powerwall or HMD) or the extent of self-representation by an avatar. The results showed that the 10 participants instructed to choose transitions to attain a level of PI corresponding to that in the initial system tended to first choose a wide field-of-view and headmounted display, and then ensure that they had a virtual body that moved as they did. The other 10 in the Psi group concentrated far more on achieving a higher level of illumination realism, although having a virtual body representation was important for both groups. This methodology is offered as a way forward in the evaluation of the responses of people to immersive virtual environments, a unified theory and methodology for psychophysical measurement. ", 
        "id": 1147, 
        "title": "Simulating virtual environments within virtual environments as the basis for a psychophysics of presence."
    }, 
    {
        "abstract": "", 
        "id": 1148, 
        "title": "A PML-based nonreflective boundary for free surface fluid animation."
    }, 
    {
        "abstract": "", 
        "id": 1149, 
        "title": "Video-based reconstruction of animatable human characters."
    }, 
    {
        "abstract": "Traditional image compositing techniques, such as alpha matting and gradient domain compositing, are used to create composites that have plausible boundaries. But when applied to images taken from different sources or shot under different conditions, these techniques can produce unrealistic results. In this work, we present a framework that explicitly matches the visual appearance of images through a process we call image harmonization, before blending them. At the heart of this framework is a multi-scale technique that allows us to transfer the appearance of one image to another. We show that by carefully manipulating the scales of a pyramid decomposition of an image, we can match contrast, texture, noise, and blur, while avoiding image artifacts. The output composite can then be reconstructed from the modified pyramid coefficients while enforcing both alpha-based and seamless boundary constraints. We show how the proposed framework can be used to produce realistic composites with minimal user interaction in a number of different scenarios.", 
        "id": 1150, 
        "title": "Multi-scale image harmonization."
    }, 
    {
        "abstract": "We present an efficient technique to render single scattering in large scenes with reflective and refractive objects and homogeneous participating media. Efficiency is obtained by evaluating the final radiance along a viewing ray directly from the lighting rays passing near to it, and by rapidly identifying such lighting rays in the scene. To facilitate the search for nearby lighting rays, we convert lighting rays and viewing rays into 6D points and planes according to their Plucker coordinates and coefficients, respectively. In this 6D line space, the problem of closest lines search becomes one of closest points to a plane query, which we significantly accelerate using a spatial hierarchy of the 6D points. This approach to lighting ray gathering supports complex light paths with multiple reflections and refractions, and avoids the use of a volume representation, which is expensive for large-scale scenes. This method also utilizes far fewer lighting rays than the number of photons needed in traditional volumetric photon mapping, and does not discretize viewing rays into numerous steps for ray marching. With this approach, results similar to volumetric photon mapping are obtained efficiently in terms of both storage and computation. ", 
        "id": 1151, 
        "title": "Line space gathering for single scattering in large scenes."
    }, 
    {
        "abstract": "", 
        "id": 1152, 
        "title": "Axial-cones: modeling spherical catadioptric cameras for wide-angle light field rendering."
    }, 
    {
        "abstract": "", 
        "id": 1153, 
        "title": "Volumetric modeling with diffusion surfaces."
    }, 
    {
        "abstract": "We present an approach to simulate flows driven by surface tension based on triangle meshes. Our method consists of two simulation layers: the first layer is an Eulerian method for simulating surface tension forces that is free from typical strict time step constraints. The second simulation layer is a Lagrangian finite element method that simulates sub-grid scale wave details on the fluid surface. The surface wave simulation employs an unconditionally stable, symplectic time integration method that allows for a high ACM Reference Format Threy, N., Wojtan, C., Gross, M., Turk, G. 2010. A Multiscale Approach to Mesh-based Surface Tension Flows. ACM Trans. Graph. 29, 4, Article 48 (July 2010), 10 pages. DOI = 10.1145/1778765.1778785 http://doi.acm.org/10.1145/1778765.1778785. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org.  2010 ACM 0730-0301/2010/07-ART48 $10.00 DOI 10.1145/1778765.1778785 http://doi.acm.org/10.1145/1778765.1778785  propagation speed due to strong surface tension. Our approach can naturally separate the grid- and sub-grid scales based on a volumepreserving mean curvature flow. As our model for the sub-grid dynamics enforces a local conservation of mass, it leads to realistic pinch off and merging effects. In addition to this method for simulating dynamic surface tension effects, we also present an efficient non-oscillatory approximation for capturing damped surface tension behavior. These approaches allow us to efficiently simulate complex phenomena associated with strong surface tension, such as Rayleigh-Plateau instabilities and crown splashes, in a short amount of time. ", 
        "id": 1154, 
        "title": "A multiscale approach to mesh-based surface tension flows."
    }, 
    {
        "abstract": "", 
        "id": 1155, 
        "title": "Multi-feature matching of fresco fragments."
    }, 
    {
        "abstract": "Studying the behavior of the heat diffusion process on a manifold is emerging as an important tool for analyzing the geometry of the manifold. Unfortunately, the high complexity of the computation of the heat kernel  the key to the diffusion process - limits this type of analysis to 3D models of modest resolution. We show how to use the unique properties of the heat kernel of a discrete two dimensional manifold to overcome these limitations. Combining a multi-resolution approach with a novel approximation method for the heat kernel at short times results in an efficient and robust algorithm for computing the heat kernels of detailed models. We show experimentally that our method can achieve good approximations in a fraction of the time required by traditional algorithms. Finally, we demonstrate how these heat kernels can be used to improve a diffusion-based feature extraction algorithm. ", 
        "id": 1156, 
        "title": "A multi-resolution approach to heat kernels on discrete surfaces."
    }, 
    {
        "abstract": "", 
        "id": 1157, 
        "title": "Character animation in two-player adversarial games."
    }, 
    {
        "abstract": "We introduce methods for optimizing physics-based walking controllers for robustness to uncertainty. Many unknown factors, such as external forces, control torques, and user control inputs, cannot be known in advance and must be treated as uncertain. These variables are represented with probability distributions, and a return function scores the desirability of a single motion. Controller optimization entails maximizing the expected value of the return, which is computed by Monte Carlo methods. We demonstrate examples with different sources of uncertainty and task constraints. Optimizing control strategies under uncertainty increases robustness and produces natural variations in style. ", 
        "id": 1158, 
        "title": "Optimizing walking controllers for uncertain inputs and environments."
    }, 
    {
        "abstract": "This paper describes a method for animating the appearance of clothing, such as pants or a shirt, that fits closely to a figure's body. Compared to flowing cloth, such as loose dresses or capes, these types of garments involve nearly continuous collision contact and small wrinkles, that can be troublesome for traditional cloth simulation methods. Based on the observation that the wrinkles in closefitting clothing behave in a predominantly kinematic fashion, we have developed an example-based wrinkle synthesis technique. Our method drives wrinkle generation from the pose of the figure's kinematic skeleton. This approach allows high quality clothing wrinkles to be combined with a coarse cloth simulation that computes the global and dynamic aspects of the clothing motion. While the combined results do not exactly match a high-resolution reference simulation, they do capture many of the characteristic fine-scale features and wrinkles. Further, the combined system runs at interactive rates, making it suitable for applications where high-resolution offline simulations would not be a viable option. The wrinkle synthesis method uses a precomputed database built by simulating the high-resolution clothing as the articulated figure is moved over a range of poses. In principle, the space of poses is exponential in the total number of degrees of freedom; however clothing wrinkles are primarily affected by the nearest joints, allowing each joint to be processed independently. During synthesis, mesh interpolation is used to consider the influence of multiple joints, and combined with a coarse simulation to produce the final results at interactive rates. ", 
        "id": 1159, 
        "title": "Example-based wrinkle synthesis for clothing animation."
    }, 
    {
        "abstract": " ", 
        "id": 1160, 
        "title": "Motion-based video retargeting with optimized crop-and-warp."
    }, 
    {
        "abstract": "", 
        "id": 1161, 
        "title": "Multi-resolution isotropic strain limiting."
    }, 
    {
        "abstract": "", 
        "id": 1162, 
        "title": "Data-driven image color theme enhancement."
    }, 
    {
        "abstract": "In this paper, we introduce a compact random-access vector representation for solid textures made of intermixed regions with relatively smooth internal color variations. It is feature-preserving and resolution-independent. In this representation, a texture volume is divided into multiple regions. Region boundaries are implicitly defined using a signed distance function. Color variations within the regions are represented using compactly supported radial basis functions (RBFs). With a spatial indexing structure, such RBFs enable efficient color evaluation during real-time solid texture mapping. Effective techniques have been developed for generating such a vector representation from bitmap solid textures. Data structures and techniques have also been developed to compactly store region labels and distance values for efficient random access during boundary and color evaluation. ", 
        "id": 1163, 
        "title": "Vector solid textures."
    }, 
    {
        "abstract": "Conformal maps are considered very desirable for planar deformation applications, since they allow only local rotations and scale, avoiding shear and other visually disturbing distortions of local detail. Conformal maps are also orientation-preserving C diffeomorphisms, meaning they are extremely smooth and prevent unacceptable \"foldovers\" in the plane. Unfortunately, these maps are also notoriously difficult to control, so working with them in an interactive animation scenario to achieve specific effects is a significant challenge, sometimes even impossible. We describe a novel 2D shape deformation system which generates conformal maps, yet provides the user a large degree of control over the result. For example, it allows discontinuities at userspecified boundary points, so true \"bends\" can be introduced into the deformation. It also allows the prescription of angular constraints at corners of the target image. Combining these provides for a very effective user experience. At the heart of our method is a very natural differential shape representation for conformal maps, using so-called \"conformal factors\" and \"angular factors\", which allow more intuitive control compared to representation in the usual spatial domain. Beyond deforming a given shape into a new one at each key frame, our method also provides the ability to interpolate between shapes in a very natural way, such that also the intermediate deformations are conformal.  ACM Reference Format Weber, O., Gotsman, C. 2010. Controllable Conformal Maps for Shape Deformation and Interpolation. ACM Trans. Graph. 29, 4, Article 78 (July 2010), 11 pages. DOI = 10.1145/1778765.1778815 http://doi.acm.org/10.1145/1778765.1778815. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org.  2010 ACM 0730-0301/2010/07-ART78 $10.00 DOI 10.1145/1778765.1778815 http://doi.acm.org/10.1145/1778765.1778815  Our method is extremely efficient: it requires only the solution of a small dense linear system at preprocess time and a matrix-vector multiplication during runtime (which can be implemented on a modern GPU), thus the deformations, even on extremely large images, may be performed in real-time. ", 
        "id": 1164, 
        "title": "Controllable conformal maps for shape deformation and interpolation."
    }, 
    {
        "abstract": "Sampling is a core process for a variety of graphics applications. Among existing sampling methods, blue noise sampling remains popular thanks to its spatial uniformity and absence of aliasing artifacts. However, research so far has been mainly focused on blue noise sampling with a single class of samples. This could be insufficient for common natural as well as man-made phenomena requiring multiple classes of samples, such as object placement, imaging sensors, and stippling patterns. We extend blue noise sampling to multiple classes where each individual class as well as their unions exhibit blue noise characteristics. We propose two flavors of algorithms to generate such multiclass blue noise samples, one extended from traditional Poisson hard disk sampling for explicit control of sample spacing, and another based on our soft disk sampling for explicit control of sample count. Our algorithms support uniform and adaptive sampling, and are applicable to both discrete and continuous sample space in arbitrary dimensions. We study characteristics of samples generated by our methods, and demonstrate applications in object placement, sensor layout, and color stippling. ", 
        "id": 1165, 
        "title": "Multi-class blue noise sampling."
    }, 
    {
        "abstract": "This paper presents a video-based motion modeling technique for capturing physically realistic human motion from monocular video sequences. We formulate the video-based motion modeling process in an image-based keyframe animation framework. The system first computes camera parameters, human skeletal size, and a small number of 3D key poses from video and then uses 2D image measurements at intermediate frames to automatically calculate the \"in between\" poses. During reconstruction, we leverage Newtonian physics, contact constraints, and 2D image measurements to simultaneously reconstruct full-body poses, joint torques, and contact forces. We have demonstrated the power and effectiveness of our system by generating a wide variety of physically realistic human actions from uncalibrated monocular video sequences such as sports video footage. ", 
        "id": 1166, 
        "title": "VideoMocap: modeling physically realistic human motion from monocular video sequences."
    }, 
    {
        "abstract": " Simulating fluids based on vortex filaments is highly attractive for the creation of special effects because it gives artists full control over the simulation using familiar tools like curve editors or the scripted generation of new vortex filaments over time. Because filaments offer a very compact description of fluid flow, real time applications like games or virtual reality are also possible. We present a complete model that includes moving obstacles with vortex shedding, all represented as filaments. Due to variational reconnection the long-time behavior of our method is excellent: Energy and momentum stay constant within reasonable bounds and computational complexity does not increase over time.  ", 
        "id": 1167, 
        "title": "Filament-based smoke with vortex shedding and variational reconnection."
    }, 
    {
        "abstract": "We propose a finite element simulation method that addresses the full range of material behavior, from purely elastic to highly plastic, for physical domains that are substantially reshaped by plastic flow, fracture, or large elastic deformations. To mitigate artificial plasticity, we maintain a simulation mesh in both the current state and the rest shape, and store plastic offsets only to represent the nonembeddable portion of the plastic deformation. To maintain high element quality in a tetrahedral mesh undergoing gross changes, we use a dynamic meshing algorithm that attempts to replace as few tetrahedra as possible, and thereby limits the visual artifacts and artificial diffusion that would otherwise be introduced by repeatedly remeshing the domain from scratch. Our dynamic mesher also locally refines and coarsens a mesh, and even creates anisotropic tetrahedra, wherever a simulation requests it. We illustrate these features with animations of elastic and plastic behavior, extreme deformations, and fracture. ", 
        "id": 1168, 
        "title": "Dynamic local remeshing for elastoplastic simulation."
    }, 
    {
        "abstract": "", 
        "id": 1169, 
        "title": "Temporal upsampling of performance geometry using photometric alignment."
    }, 
    {
        "abstract": "We propose a mesh-based surface tracking method for fluid animation that both preserves fine surface details and robustly adjusts the topology of the surface in the presence of arbitrarily thin features like sheets and strands. We replace traditional re-sampling methods with a convex hull method for connecting surface features during topological changes. This technique permits arbitrarily thin fluid features with minimal re-sampling errors by reusing points from the original surface. We further reduce re-sampling artifacts with a subdivision-based mesh-stitching algorithm, and we use a higher order interpolating subdivision scheme to determine the location of any newly-created vertices. The resulting algorithm efficiently produces detailed fluid surfaces with arbitrarily thin features while maintaining a consistent topology with the underlying fluid simulation. ", 
        "id": 1170, 
        "title": "Physics-inspired topology changes for thin fluid features."
    }, 
    {
        "abstract": "", 
        "id": 1171, 
        "title": "Modeling and rendering of impossible figures."
    }, 
    {
        "abstract": "We describe a framework for the automatic synthesis of biped locomotion controllers that adapt to uneven terrain at run-time. The framework consists of two components: a per-footstep end-effector path planner and a per-timestep generalized-force solver. At the start of each footstep, the planner performs short-term planning in the space of end-effector trajectories. These trajectories adapt to the interactive task goals and the features of the surrounding uneven terrain at run-time. We solve for the parameters of the planner for different tasks in offline optimizations. Using the per-footstep plan, the generalized-force solver takes ground contacts into consideration and solves a quadratic program at each simulation timestep to obtain joint torques that drive the biped. We demonstrate the capabilities of the controllers in complex navigation tasks where they perform gradual or sharp turns and transition between moving forwards, backwards, and sideways on uneven terrain (including hurdles and stairs) according to the interactive task goals. We also show that the resulting controllers are capable of handling morphology changes to the character. ", 
        "id": 1172, 
        "title": "Terrain-adaptive bipedal locomotion control."
    }, 
    {
        "abstract": "", 
        "id": 1173, 
        "title": "Resizing by symmetry-summarization."
    }, 
    {
        "abstract": "", 
        "id": 1174, 
        "title": "Style-content separation by anisotropic part scales."
    }, 
    {
        "abstract": "The wide availability and popularity of text-based communication channels encourage the usage of ASCII art in representing images. Existing tone-based ASCII art generation methods lead to halftone-like results and require high text resolution for display, as higher text resolution offers more tone variety. This paper presents a novel method to generate structure-based ASCII art that is currently mostly created by hand. It approximates the major line structure of the reference image content with the shape of characters. Representing the unlimited image content with the extremely limited shapes and restrictive placement of characters makes this problem challenging. Most existing shape similarity metrics either fail to address the misalignment in real-world scenarios, or are unable to account for the differences in position, orientation and scaling. Our key contribution is a novel alignment-insensitive shape similarity (AISS) metric that tolerates misalignment of shapes while accounting for the differences in position, orientation and scaling. Together with the constrained deformation approach, we formulate the ASCII art generation as an optimization that minimizes shape dissimilarity and deformation. Convincing results and user study are shown to demonstrate its effectiveness. ", 
        "id": 1175, 
        "title": "Structure-based ASCII art."
    }, 
    {
        "abstract": "", 
        "id": 1176, 
        "title": "Fool me twice: Exploring and exploiting error tolerance in physics-based animation."
    }, 
    {
        "abstract": "Real-time adaptation of a motion capture sequence to virtual environments with physical perturbations requires robust control strategies. This paper describes an optimal feedback controller for motion tracking that allows for on-the-fly re-planning of long-term goals and adjustments in the final completion time. We first solve an offline optimal trajectory problem for an abstract dynamic model that captures the essential relation between contact forces and momenta. A feedback control policy is then derived and used to simulate the abstract model online. Simulation results become dynamic constraints for online reconstruction of full-body motion from a reference. We applied our controller to a wide range of motions including walking, long stepping, and a squat exercise. Results show that our controllers are robust to large perturbations and changes in the environment. ", 
        "id": 1177, 
        "title": "Optimal feedback control for character animation using an abstract model."
    }, 
    {
        "abstract": "", 
        "id": 1178, 
        "title": "Unbiased, adaptive stochastic sampling for rendering inhomogeneous participating media."
    }, 
    {
        "abstract": "", 
        "id": 1179, 
        "title": "Mesh colors."
    }, 
    {
        "abstract": "", 
        "id": 1180, 
        "title": "From image parsing to painterly rendering."
    }, 
    {
        "abstract": "This paper proposes a new method for remeshing a surface into anisotropically sized quads. The basic idea is to construct a special standing wave on the surface to generate the global quadrilateral structure. This wave based quadrangulation method is capable of controlling the quad size in two directions and precisely aligning the quads with feature lines. Similar to the previous methods, we augment the input surface with a vector field to guide the quad orientation. The anisotropic size control is achieved by using two size fields on the surface. In order to reduce singularity points, the size fields are optimized by a new curl minimization method. The experimental results show that the proposed method can successfully handle various quadrangulation requirements and complex shapes, which is difficult for the existing state-of-the-art methods. ", 
        "id": 1181, 
        "title": "A wave-based anisotropic quadrangulation method."
    }, 
    {
        "abstract": " We propose a physically based algorithm for synthesizing sounds synchronized with brittle fracture animations. Motivated by laboratory experiments, we approximate brittle fracture sounds using time-varying rigid-body sound models. We extend methods for fracturing rigid materials by proposing a fast quasistatic stress solver to resolve near-audio-rate fracture events, energy-based fracture pattern modeling and estimation of \"crack\"-related fracture impulses. Multipole radiation models provide scalable sound radiation for complex debris and level of detail control. To reduce soundmodel generation costs for complex fracture debris, we propose Precomputed Rigid-Body Soundbanks comprised of precomputed ellipsoidal sound proxies. Examples and experiments are presented that demonstrate plausible and affordable brittle fracture sounds.  ", 
        "id": 1182, 
        "title": "Rigid-body fracture sound with precomputed soundbanks."
    }, 
    {
        "abstract": "Recent advances in scanning technologies, in particular devices that extract depth through active sensing, allow fast scanning of urban scenes. Such rapid acquisition incurs imperfections: large regions remain missing, significant variation in sampling density is common, and the data is often corrupted with noise and outliers. However, buildings often exhibit large scale repetitions and selfsimilarities. Detecting, extracting, and utilizing such large scale repetitions provide powerful means to consolidate the imperfect data. Our key observation is that the same geometry, when scanned multiple times over reoccurrences of instances, allow application of a simple yet effective non-local filtering. The multiplicity of the geometry is fused together and projected to a base-geometry defined by clustering corresponding surfaces. Denoising is applied by separating the process into off-plane and in-plane phases. We show that the consolidation of the reoccurrences provides robust denoising and allow reliable completion of missing parts. We present evaluation results of the algorithm on several LiDAR scans of buildings of varying complexity and styles. ", 
        "id": 1183, 
        "title": "Non-local scan consolidation for 3D urban scenes."
    }, 
    {
        "abstract": "We present an easy-to-use image retouching technique for realistic reshaping of human bodies in a single image. A model-based approach is taken by integrating a 3D whole-body morphable model into the reshaping process to achieve globally consistent editing effects. A novel body-aware image warping approach is introduced to reliably transfer the reshaping effects from the model to the image, even under moderate fitting errors. Thanks to the parametric nature of the model, our technique parameterizes the degree of reshaping by a small set of semantic attributes, such as weight and height. It allows easy creation of desired reshaping effects by changing the full-body attributes, while producing visually pleasing results even for loosely-dressed humans in casual photographs with a variety of poses and shapes. ", 
        "id": 1184, 
        "title": "Parametric reshaping of human bodies in images."
    }, 
    {
        "abstract": "", 
        "id": 1185, 
        "title": "An efficient multigrid method for the simulation of high-resolution elastic solids."
    }, 
    {
        "abstract": " While the theory and applications of discrete Laplacians on triangulated surfaces are well developed, far less is known about the general polygonal case. We present here a principled approach for constructing geometric discrete Laplacians on surfaces with arbitrary polygonal faces, encompassing non-planar and non-convex polygons. Our construction is guided by closely mimicking structural properties of the smooth LaplaceBeltrami operator. Among other features, our construction leads to an extension of the widely employed cotan formula from triangles to polygons. Besides carefully laying out theoretical aspects, we demonstrate the versatility of our approach for a variety of geometry processing applications, embarking on situations that would have been more difficult to achieve based on geometric Laplacians for simplicial meshes or purely combinatorial Laplacians for general meshes. ", 
        "id": 1186, 
        "title": "Discrete Laplacians on general polygonal meshes."
    }, 
    {
        "abstract": "", 
        "id": 1187, 
        "title": "AppWarp: retargeting measured materials by appearance-space warping."
    }, 
    {
        "abstract": "", 
        "id": 1188, 
        "title": "Mixed-order compositing for 3D paintings."
    }, 
    {
        "abstract": "This paper shows a method to extend 3D nonlinear elasticity model reduction to open-loop multi-level reduced deformable structures. Given a volumetric mesh, we decompose the mesh into several subdomains, build a reduced deformable model for each domain, and connect the domains using inertia coupling. This makes model reduction deformable simulations much more versatile: localized deformations can be supported without prohibitive computational costs, parts can be re-used and precomputation times shortened. Our method does not use constraints, and can handle large domain rigid body motion in addition to large deformations, due to our derivation of the gradient and Hessian of the rotation matrix in polar decomposition. We show real-time examples with multi-level domain hierarchies and hundreds of reduced degrees of freedom. ", 
        "id": 1189, 
        "title": "Real-time large-deformation substructuring."
    }, 
    {
        "abstract": "", 
        "id": 1190, 
        "title": "Contributing vertices-based Minkowski sum of a nonconvex-convex pair of polyhedra."
    }, 
    {
        "abstract": " We present a new technique for passive and markerless facial performance capture based on anchor frames. Our method starts with high resolution per-frame geometry acquisition using state-of-theart stereo reconstruction, and proceeds to establish a single triangle mesh that is propagated through the entire performance. Leveraging the fact that facial performances often contain repetitive subsequences, we identify anchor frames as those which contain similar facial expressions to a manually chosen reference expression. Anchor frames are automatically computed over one or even multiple performances. We introduce a robust image-space tracking method that computes pixel matches directly from the reference frame to all anchor frames, and thereby to the remaining frames in the sequence via sequential matching. This allows us to propagate one reconstructed frame to an entire sequence in parallel, in contrast to previous sequential methods. Our anchored reconstruction approach also limits tracker drift and robustly handles occlusions and motion blur. The parallel tracking and mesh propagation offer low computation times. Our technique will even automatically match anchor frames across different sequences captured on different occasions, propagating a single mesh to all performances.  ", 
        "id": 1191, 
        "title": "High-quality passive facial performance capture using anchor frames."
    }, 
    {
        "abstract": "", 
        "id": 1192, 
        "title": "Online reconstruction of 3D objects from arbitrary cross-sections."
    }, 
    {
        "abstract": "", 
        "id": 1193, 
        "title": "A nonsmooth Newton solver for capturing exact Coulomb friction in fiber assemblies."
    }, 
    {
        "abstract": "", 
        "id": 1194, 
        "title": "A Framework for content-adaptive photo manipulation macros: Application to face, landscape, and global manipulations."
    }, 
    {
        "abstract": "", 
        "id": 1195, 
        "title": "Pattern-aware shape deformation using sliding dockers."
    }, 
    {
        "abstract": "", 
        "id": 1196, 
        "title": "Displacement interpolation using Lagrangian mass transport."
    }, 
    {
        "abstract": " The most important guiding principle in computational methods for freeform architecture is the balance between cost efficiency on the one hand, and adherence to the design intent on the other. Key issues are the simplicity of supporting and connecting elements as well as repetition of costly parts. This paper proposes so-called circular arc structures as a means to faithfully realize freeform designs without giving up smooth appearance. In contrast to non-smooth meshes with straight edges where geometric complexity is concentrated in the nodes, we stay with smooth surfaces and rather distribute complexity in a uniform way by allowing edges in the shape of circular arcs. We are able to achieve the simplest possible shape of nodes without interfering with known panel optimization algorithms. We study remarkable special cases of circular arc structures which possess simple supporting elements or repetitive edges, we present the first global approximation method for principal patches, and we show an extension to volumetric structures for truly threedimensional designs.  Figure 1: Architectural freeform designs based on circular arc structures exhibit smooth skin, congruent node elements, and simple shapes of beams. In special cases like for the cyclidic CAS shown here, they also admit offsets at constant distance.  ", 
        "id": 1197, 
        "title": "Circular arc structures."
    }, 
    {
        "abstract": "", 
        "id": 1198, 
        "title": "Image-guided weathering: A new approach applied to flow phenomena."
    }, 
    {
        "abstract": "", 
        "id": 1199, 
        "title": "Shape google: Geometric words and expressions for invariant shape retrieval."
    }, 
    {
        "abstract": "Changing the color of an object is a basic image editing operation, but a high quality result must also preserve natural shading. A common approach is to first compute reflectance and illumination intrinsic images. Reflectances can then be edited independently, and recomposed with the illumination. However, manipulating only the reflectance color does not account for diffuse interreflections, and can result in inconsistent shading in the edited image. We propose an approach for further decomposing illumination into direct lighting, and indirect diffuse illumination from each material. This decomposition allows us to change indirect illumination from an individual material independently, so it matches the modified reflectance color. To address the underconstrained problem of decomposing illumination into multiple components, we take advantage of its smooth nature, as well as user-provided constraints. We demonstrate our approach on a number of examples, where we consistently edit material colors and the associated interreflections. Links: DL PDF WEB ", 
        "id": 1200, 
        "title": "Illumination decomposition for material recoloring with consistent interreflections."
    }, 
    {
        "abstract": " We propose a practical method for synthesizing plausible fire sounds that are synchronized with physically based fire animations. To enable synthesis of combustion sounds without incurring the cost of time-stepping fluid simulations at audio rates, we decompose our synthesis procedure into two components. First, a lowfrequency flame sound is synthesized using a physically based combustion sound model driven with data from a visual flame simulation run at a relatively low temporal sampling rate. Second, we propose two bandwidth extension methods for synthesizing additional high-frequency flame sound content: (1) spectral bandwidth extension which synthesizes higher-frequency noise matching combustion sound spectra from theory and experiment; and (2) data-driven texture synthesis to synthesize high-frequency content based on input flame sound recordings. Various examples and comparisons are presented demonstrating plausible flame sounds, from small candle flames to large flame jets.  ", 
        "id": 1201, 
        "title": "Animating fire with sound."
    }, 
    {
        "abstract": "", 
        "id": 1202, 
        "title": "Fast oriented bounding box optimization on the rotation group "
    }, 
    {
        "abstract": "", 
        "id": 1203, 
        "title": "Global registration of dynamic range scans for articulated model reconstruction."
    }, 
    {
        "abstract": "Assembly-based modeling is a promising approach to broadening the accessibility of 3D modeling. In assembly-based modeling, new models are assembled from shape components extracted from a database. A key challenge in assembly-based modeling is the identification of relevant components to be presented to the user. In this paper, we introduce a probabilistic reasoning approach to this problem. Given a repository of shapes, our approach learns a probabilistic graphical model that encodes semantic and geometric relationships among shape components. The probabilistic model is used to present components that are semantically and stylistically compatible with the 3D model that is being assembled. Our experiments indicate that the probabilistic model increases the relevance of presented components. ", 
        "id": 1204, 
        "title": "Probabilistic reasoning for assembly-based 3D modeling."
    }, 
    {
        "abstract": "We present a new Eulerian fluid simulation method, which allows real-time simulations of large scale three dimensional liquids. Such scenarios have hitherto been restricted to the domain of off-line computation. To reduce computation time we use a hybrid grid representation composed of regular cubic cells on top of a layer of tall cells. With this layout water above an arbitrary terrain can be represented without consuming an excessive amount of memory and compute power, while focusing effort on the area near the surface where it most matters. Additionally, we optimized the grid representation for a GPU implementation of the fluid solver. To further accelerate the simulation, we introduce a specialized multigrid algorithm for solving the Poisson equation and propose solver modifications to keep the simulation stable for large time steps. We demonstrate the efficiency of our approach in several real-world scenarios, all running above 30 frames per second on a modern GPU. Some scenes include additional features such as two-way rigid body coupling as well as particle representations of sub-grid detail. ", 
        "id": 1205, 
        "title": "Real-time Eulerian water simulation using a restricted tall cell grid."
    }, 
    {
        "abstract": "Revision control is a vital component of digital project management and has been widely deployed for text files. Binary files, on the other hand, have received relatively less attention. This can be inconvenient for graphics applications that use a significant amount of binary data, such as images, videos, meshes, and animations. Existing strategies such as storing whole files for individual revisions or simple binary deltas could consume significant storage and obscure vital semantic information. We present a nonlinear revision control system for images, designed with the common digital editing and sketching workflows in mind. We use DAG (directed acyclic graph) as the core structure, with DAG nodes representing editing operations and DAG edges the corresponding spatial, temporal and semantic relationships. We visualize our DAG in RevG (revision graph), which provides not only as a meaningful display of the revision history but also an intuitive interface for common revision control operations such as review, replay, diff, addition, branching, merging, and conflict resolving. Beyond revision control, our system also facilitates artistic creation processes in common image editing and digital painting workflows. We have built a prototype system upon GIMP, an open source image editor, and demonstrate its effectiveness through formative user study and comparisons with alternative revision control systems. ", 
        "id": 1206, 
        "title": "Nonlinear revision control for images."
    }, 
    {
        "abstract": "", 
        "id": 1207, 
        "title": "Semantic colorization with internet images."
    }, 
    {
        "abstract": "We present a general framework for performing geometry filtering through the solution of a screened Poisson equation. We show that this framework can be efficiently adapted to a changing Riemannian metric to support curvature-aware filtering and describe a parallel and streaming multigrid implementation for solving the system. We demonstrate the practicality of our approach by developing an interactive system for mesh editing that allows for exploration of a large family of curvature-guided, anisotropic filters. ", 
        "id": 1208, 
        "title": "Interactive and anisotropic geometry processing using the screened Poisson equation."
    }, 
    {
        "abstract": "We develop an integrated set of gaits and skills for a physics-based simulation of a quadruped. The motion repertoire for our simulated dog includes walk, trot, pace, canter, transverse gallop, rotary gallop, leaps capable of jumping on-and-off platforms and over obstacles, sitting, lying down, standing up, and getting up from a fall. The controllers use a representation based on gait graphs, a dual leg frame model, a flexible spine model, and the extensive use of internal virtual forces applied via the Jacobian transpose. Optimizations are applied to these control abstractions in order to achieve robust gaits and leaps with desired motion styles. The resulting gaits are evaluated for robustness with respect to push disturbances and the traversal of variable terrain. The simulated motions are also compared to motion data captured from a filmed dog. ", 
        "id": 1209, 
        "title": "Locomotion skills for simulated quadrupeds."
    }, 
    {
        "abstract": "We introduce a new method for computing conformal transformations of triangle meshes in 3. Conformal maps are desirable in digital geometry processing because they do not exhibit shear, and therefore preserve texture fidelity as well as the quality of the mesh itself. Traditional discretizations consider maps into the complex plane, which are useful only for problems such as surface parameterization and planar shape deformation where the target surface is flat. We instead consider maps into the quaternions , which allows us to work directly with surfaces sitting in 3. In particular, we introduce a quaternionic Dirac operator and use it to develop a novel integrability condition on conformal deformations. Our discretization of this condition results in a sparse linear system that is simple to build and can be used to efficiently edit surfaces by manipulating curvature and boundary data, as demonstrated via several mesh processing applications. ", 
        "id": 1210, 
        "title": "Spin transformations of discrete surfaces."
    }, 
    {
        "abstract": "", 
        "id": 1211, 
        "title": "Video face replacement."
    }, 
    {
        "abstract": "", 
        "id": 1212, 
        "title": "A hybrid iterative solver for robustly capturing coulomb friction in hair dynamics."
    }, 
    {
        "abstract": "The construction of polygonal meshes remains a complex task in Computer Graphics, taking tens of thousands of individual operations over several hours of modeling time. The complexity of modeling in terms of number of operations and time makes it difficult for artists to understand all details of how meshes are constructed. We present MeshFlow, an interactive system for visualizing mesh construction sequences. MeshFlow hierarchically clusters mesh editing operations to provide viewers with an overview of the model construction while still allowing them to view more details on demand. We base our clustering on an analysis of the frequency of repeated operations and implement it using substituting regular expressions. By filtering operations based on either their type or which vertices they affect, MeshFlow also ensures that viewers can interactively focus on the relevant parts of the modeling process. Automatically generated graphical annotations visualize the clustered operations. We have tested MeshFlow by visualizing five mesh sequences each taking a few hours to model, and we found it to work well for all. We have also evaluated MeshFlow with a case study using modeling students. We conclude that our system provides useful visualizations that are found to be more helpful than video or document-form instructions in understanding mesh construction. ", 
        "id": 1213, 
        "title": "MeshFlow: interactive visualization of mesh construction sequences."
    }, 
    {
        "abstract": " Links: DL PDF WEB  We present a new BSSRDF for rendering images of translucent materials. Previous diffusion BSSRDFs are limited by the accuracy of classical diffusion theory. We introduce a modified diffusion theory that is more accurate for highly absorbing materials and near the point of illumination. The new diffusion solution accurately decouples single and multiple scattering. We then derive a novel, analytic, extended-source solution to the multilayer searchlight problem by quantizing the diffusion Green's function. This allows the application of the diffusion multipole model to material layers several orders of magnitude thinner than previously possible and creates accurate results under high-frequency illumination. Quantized diffusion provides both a new physical foundation and a variable-accuracy construction method for sum-of-Gaussians BSSRDFs, which have many useful properties for efficient rendering and appearance capture. Our BSSRDF maps directly to previous real-time rendering algorithms. For film production rendering, we propose several improvements to previous hierarchical point cloud algorithms by introducing a new radial-binning data structure and a doubly-adaptive traversal strategy. ", 
        "id": 1214, 
        "title": "A quantized-diffusion model for rendering translucent materials."
    }, 
    {
        "abstract": "Binocular disparity is an important cue for the human visual system to recognize spatial layout, both in reality and simulated virtual worlds. This paper introduces a perceptual model of disparity for computer graphics that is used to define a metric to compare a stereo image to an alternative stereo image and to estimate the magnitude of the perceived disparity change. Our model can be used to assess the effect of disparity to control the level of undesirable distortions or enhancements (introduced on purpose). A number of psycho-visual experiments are conducted to quantify the mutual effect of disparity magnitude and frequency to derive the model. Besides difference prediction, other applications include compression, and re-targeting. We also present novel applications in form of hybrid stereo images and backward-compatible stereo. The latter minimizes disparity in order to convey a stereo impression if special equipment is used but produces images that appear almost ordinary to the naked eye. The validity of our model and difference metric is again confirmed in a study. ", 
        "id": 1215, 
        "title": "A perceptual model for disparity."
    }, 
    {
        "abstract": "", 
        "id": 1216, 
        "title": "Razor: An architecture for dynamic multiresolution ray tracing."
    }, 
    {
        "abstract": "", 
        "id": 1217, 
        "title": "AppGen: interactive material modeling from a single image."
    }, 
    {
        "abstract": "We solve the problem of generating a uniform Poisson-disk sampling that is both maximal and unbiased over bounded non-convex domains. To our knowledge this is the first provably correct algorithm with time and space dependent only on the number of points produced. Our method has two phases, both based on classical dartthrowing. The first phase uses a background grid of square cells to rapidly create an unbiased, near-maximal covering of the domain. The second phase completes the maximal covering by calculating the connected components of the remaining uncovered voids, and by using their geometry to efficiently place unbiased samples that cover them. The second phase converges quickly, overcoming a common difficulty in dart-throwing methods. The deterministic memory is O(n) and the expected running time is O(n log n), where n is the output size, the number of points in the final sample. Our serial implementation verifies that the log n dependence is minor, and nearly O(n) performance for both time and memory is achieved in practice. We also present a parallel implementation on GPUs to demonstrate the parallel-friendly nature of our method, which achieves 2.4 the performance of our serial version. ", 
        "id": 1218, 
        "title": "Efficient maximal poisson-disk sampling."
    }, 
    {
        "abstract": "", 
        "id": 1219, 
        "title": "Practical filtering for efficient ray-traced directional occlusion."
    }, 
    {
        "abstract": "", 
        "id": 1220, 
        "title": "Frequency analysis and sheared filtering for shadow light fields of complex occluders."
    }, 
    {
        "abstract": "", 
        "id": 1221, 
        "title": "Convolution pyramids."
    }, 
    {
        "abstract": "This paper presents a method for reducing undesirable tonal fluctuations in video: minute changes in tonal characteristics, such as exposure, color temperature, brightness and contrast in a sequence of frames, which are easily noticeable when the sequence is viewed. These fluctuations are typically caused by the camera's automatic adjustment of its tonal settings while shooting. Our approach operates on a continuous video shot by first designating one or more frames as anchors. We then tonally align a sequence of frames with each anchor: for each frame, we compute an adjustment map that indicates how each of its pixels should be modified in order to appear as if it was captured with the tonal settings of the anchor. The adjustment map is efficiently updated between successive frames by taking advantage of temporal video coherence and the global nature of the tonal fluctuations. Once a sequence has been aligned, it is possible to generate smooth tonal transitions between anchors, and also further control its tonal characteristics in a consistent and principled manner, which is difficult to do without incurring strong artifacts when operating on unstable sequences. We demonstrate the utility of our method using a number of clips captured with a variety of video cameras, and believe that it is well-suited for integration into today's non-linear video editing tools. ", 
        "id": 1222, 
        "title": "Tonal stabilization of video."
    }, 
    {
        "abstract": "Stochastic point distributions with blue-noise spectrum are used extensively in computer graphics for various applications such as avoiding aliasing artifacts in ray tracing, halftoning, stippling, etc. In this paper we present a new approach for generating point sets with high-quality blue noise properties that formulates the problem using a statistical mechanics interacting particle model. Points distributions are generated by sampling this model. This new formulation of the problem unifies randomness with the requirement for equidistant point spacing, responsible for the enhanced blue noise spectral properties. We derive a highly efficient multi-scale sampling scheme for drawing random point distributions from this model. The new scheme avoids the critical slowing down phenomena that plagues this type of models. This derivation is accompanied by a model-specific analysis. Altogether, our approach generates high-quality point distributions, supports spatially-varying spatial point density, and runs in time that is linear in the number of points generated.", 
        "id": 1223, 
        "title": "Blue-noise point sampling using kernel density model."
    }, 
    {
        "abstract": "A new method to simulate deformable objects with heterogeneous material properties and complex geometries is presented. Given a volumetric map of the material properties and an arbitrary number of control nodes, a distribution of the nodes is computed automatically, as well as the associated shape functions. Reference frames attached to the nodes are used to apply skeleton subspace deformation across the volume of the objects. A continuum mechanics formulation is derived from the displacements and the material properties. We introduce novel material-aware shape functions in place of the traditional radial basis functions used in meshless frameworks. In contrast with previous approaches, these allow coarse deformation functions to efficiently resolve non-uniform stiffnesses. Complex models can thus be simulated at high frame rates using a small number of control nodes. ", 
        "id": 1224, 
        "title": "Sparse meshless models of complex deformable solids."
    }, 
    {
        "abstract": "", 
        "id": 1225, 
        "title": "Freeform vector graphics with controlled thin-plate splines."
    }, 
    {
        "abstract": "Modeling virtual environments is a time consuming and expensive task that is becoming increasingly popular for both professional and casual artists. The model density and complexity of the scenes representing these virtual environments is rising rapidly. This trend suggests that data-mining a 3D scene corpus could be a very powerful tool enabling more efficient scene design. In this paper, we show how to represent scenes as graphs that encode models and their semantic relationships. We then define a kernel between these relationship graphs that compares common virtual substructures in two graphs and captures the similarity between their corresponding scenes. We apply this framework to several scene modeling problems, such as finding similar scenes, relevance feedback, and context-based model search. We show that incorporating structural relationships allows our method to provide a more relevant set of results when compared against previous approaches to model context search. ", 
        "id": 1226, 
        "title": "Characterizing structural relationships in scenes using graph kernels."
    }, 
    {
        "abstract": "", 
        "id": 1227, 
        "title": "Candid portrait selection from video."
    }, 
    {
        "abstract": "In creating complex real-time shaders, programmers should be able to decompose code into independent, localized modules of their choosing. Current real-time shading languages, however, enforce a fixed decomposition into per-pipeline-stage procedures. Program concerns at other scales  including those that cross-cut multiple pipeline stages  cannot be expressed as reusable modules. We present a shading language, Spark, and its implementation for modern graphics hardware that improves support for separation of concerns into modules. A Spark shader class can encapsulate code that maps to more than one pipeline stage, and can be extended and composed using object-oriented inheritance. In our tests, shaders written in Spark achieve performance within 2% of HLSL. ", 
        "id": 1228, 
        "title": "Spark: modular, composable shaders for graphics hardware."
    }, 
    {
        "abstract": "", 
        "id": 1229, 
        "title": "Image and video upscaling from local self-examples."
    }, 
    {
        "abstract": "", 
        "id": 1230, 
        "title": "Fusion of depth maps with multiple scales."
    }, 
    {
        "abstract": "", 
        "id": 1231, 
        "title": "Animated construction of line drawings."
    }, 
    {
        "abstract": "", 
        "id": 1232, 
        "title": "Toric degenerations of B\u00e9zier patches."
    }, 
    {
        "abstract": "", 
        "id": 1233, 
        "title": "Coherent parallel hashing."
    }, 
    {
        "abstract": "We present a new approach for performing high-quality edgepreserving filtering of images and videos in real time. Our solution is based on a transform that defines an isometry between curves on the 2D image manifold in 5D and the real line. This transform preserves the geodesic distance between points on these curves, adaptively warping the input signal so that 1D edge-preserving filtering can be efficiently performed in linear time. We demonstrate three realizations of 1D edge-preserving filters, show how to produce high-quality 2D edge-preserving filters by iterating 1D-filtering operations, and empirically analyze the convergence of this process. Our approach has several desirable features: the use of 1D operations leads to considerable speedups over existing techniques and potential memory savings; its computational cost is not affected by the choice of the filter parameters; and it is the first edge-preserving filter to work on color images at arbitrary scales in real time, without resorting to subsampling or quantization. We demonstrate the versatility of our domain transform and edge-preserving filters on several real-time image and video processing tasks including edgepreserving filtering, depth-of-field effects, stylization, recoloring, colorization, detail enhancement, and tone mapping. ", 
        "id": 1234, 
        "title": "Domain transform for edge-aware image and video processing."
    }, 
    {
        "abstract": "", 
        "id": 1235, 
        "title": "Multiview face capture using polarized spherical gradient illumination."
    }, 
    {
        "abstract": "", 
        "id": 1236, 
        "title": "Frame-based elastic models."
    }, 
    {
        "abstract": "We present a novel visibility algorithm for rendering motion blur with per-pixel anti-aliasing. Our algorithm uses a number of line samples over a rectangular group of pixels, and together with the time dimension, a two-dimensional spatio-temporal visibility problem needs to be solved per line sample. In a coarse culling step, our algorithm first uses a bounding volume hierarchy to rapidly remove geometry that does not overlap with the current line sample. For the remaining triangles, we approximate each triangles depth function, along the line and along the time dimension, with a number of patch triangles. We resolve for the final color using an analytical visibility algorithm with depth sorting, simple occlusion culling, and clipping. Shading is decoupled from visibility, and we use a shading cache for efficient reuse of shaded values. In our results, we show practically noise-free renderings of motion blur with high-quality spatial anti-aliasing and with competitive rendering times. We also demonstrate that our algorithm, with some adjustments, can be used to accurately compute motion blurred ambient occlusion.", 
        "id": 1237, 
        "title": "High-quality spatio-temporal rendering using semi-analytical visibility."
    }, 
    {
        "abstract": "We propose LR (Laced Ring)--a simple data structure for representing the connectivity of manifold triangle meshes. LR provides the option to store on average either 1.08 references per triangle or 26.2 bits per triangle. Its construction, from an input mesh that supports constant-time adjacency queries, has linear space and time complexity, and involves ordering most vertices along a nearlyHamiltonian cycle. LR is best suited for applications that process meshes with fixed connectivity, as any changes to the connectivity require the data structure to be rebuilt. We provide an implementation of the set of standard random-access, constant-time operators for traversing a mesh, and show that LR often saves both space and traversal time over competing representations. ", 
        "id": 1238, 
        "title": "LR: compact connectivity representation for triangle meshes."
    }, 
    {
        "abstract": "", 
        "id": 1239, 
        "title": "Robust adaptive photon tracing using photon path visibility."
    }, 
    {
        "abstract": "This paper presents a new efficient method for recovering reliable local sets of dense correspondences between two images with some shared content. Our method is designed for pairs of images depicting similar regions acquired by different cameras and lenses, under non-rigid transformations, under different lighting, and over different backgrounds. We utilize a new coarse-to-fine scheme in which nearest-neighbor field computations using Generalized PatchMatch [Barnes et al. 2010] are interleaved with fitting a global non-linear parametric color model and aggregating consistent matching regions using locally adaptive constraints. Compared to previous correspondence approaches, our method combines the best of two worlds: It is dense, like optical flow and stereo reconstruction methods, and it is also robust to geometric and photometric variations, like sparse feature matching. We demonstrate the usefulness of our method using three applications for automatic example-based photograph enhancement: adjusting the tonal characteristics of a source image to match a reference, transferring a known mask to a new image, and kernel estimation for image deblurring. ", 
        "id": 1240, 
        "title": "Non-rigid dense correspondence with applications for image enhancement."
    }, 
    {
        "abstract": "", 
        "id": 1241, 
        "title": "Interference-aware geometric modeling."
    }, 
    {
        "abstract": "Stereoscopic 3D has gained significant importance in the entertainment industry. However, production of high quality stereoscopic content is still a challenging art that requires mastering the complex interplay of human perception, 3D display properties, and artistic intent. In this paper, we present a computational stereo camera system that closes the control loop from capture and analysis to automatic adjustment of physical parameters. Intuitive interaction metaphors are developed that replace cumbersome handling of rig parameters using a touch screen interface with 3D visualization. Our system is designed to make stereoscopic 3D production as easy, intuitive, flexible, and reliable as possible. Captured signals are processed and analyzed in real-time on a stream processor. Stereoscopy and user settings define programmable control functionali-ties, which are executed in real-time on a control processor. Computational power and flexibility is enabled by a dedicated software and hardware architecture. We show that even traditionally difficult shots can be easily captured using our system.", 
        "id": 1242, 
        "title": "Computational stereo camera system with programmable control loop."
    }, 
    {
        "abstract": "", 
        "id": 1243, 
        "title": "Interactive surface modeling using modal analysis."
    }, 
    {
        "abstract": "", 
        "id": 1244, 
        "title": "Computing and fabricating multilayer models."
    }, 
    {
        "abstract": "", 
        "id": 1245, 
        "title": "A shading reuse method for efficient micropolygon ray tracing."
    }, 
    {
        "abstract": "", 
        "id": 1246, 
        "title": "A rendering framework for multiscale views of 3D models."
    }, 
    {
        "abstract": "This paper introduces a new approach for acquiring high-fidelity 3D facial performances with realistic dynamic wrinkles and finescale facial details. Our approach leverages state-of-the-art motion capture technology and advanced 3D scanning technology for facial performance acquisition. We start the process by recording 3D facial performances of an actor using a marker-based motion capture system and perform facial analysis on the captured data, thereby determining a minimal set of face scans required for accurate facial reconstruction. We introduce a two-step registration process to efficiently build dense consistent surface correspondences across all the face scans. We reconstruct high-fidelity 3D facial performances by combining motion capture data with the minimal set of face scans in the blendshape interpolation framework. We have evaluated the performance of our system on both real and synthetic data. Our results show that the system can capture facial performances that match both the spatial resolution of static face scans and the acquisition speed of motion capture systems. ", 
        "id": 1247, 
        "title": "Leveraging motion capture and 3D scanning for high-fidelity facial performance acquisition."
    }, 
    {
        "abstract": "", 
        "id": 1248, 
        "title": "Joint shape segmentation with linear programming."
    }, 
    {
        "abstract": "", 
        "id": 1249, 
        "title": "Boundary aligned smooth 3D cross-frame field."
    }, 
    {
        "abstract": "", 
        "id": 1250, 
        "title": "Arcimboldo-like collage using internet images."
    }, 
    {
        "abstract": "Lens flare is caused by light passing through a photographic lens system in an unintended way. Often considered a degrading artifact, it has become a crucial component for realistic imagery and an artistic means that can even lead to an increased perceived brightness. So far, only costly offline processes allowed for convincing simulations of the complex light interactions. In this paper, we present a novel method to interactively compute physically-plausible flare renderings for photographic lenses. The underlying model covers many components that are important for realism, such as imperfections, chromatic and geometric lens aberrations, and antireflective lens coatings. Various acceleration strategies allow for a perfor-mance/quality tradeoff, making our technique applicable both in real-time applications and in high-quality production rendering. We further outline artistic extensions to our system. ", 
        "id": 1251, 
        "title": "Physically-based real-time lens flare rendering."
    }, 
    {
        "abstract": "", 
        "id": 1252, 
        "title": "The area perspective transform: A homogeneous transform for efficient in-volume queries."
    }, 
    {
        "abstract": "Object deformation with linear blending dominates practical use as the fastest approach for transforming raster images, vector graphics, geometric models and animated characters. Unfortunately, linear blending schemes for skeletons or cages are not always easy to use because they may require manual weight painting or modeling closed polyhedral envelopes around objects. Our goal is to make the design and control of deformations simpler by allowing the user to work freely with the most convenient combination of handle types. We develop linear blending weights that produce smooth and intuitive deformations for points, bones and cages of arbitrary topology. Our weights, called bounded biharmonic weights, minimize the Laplacian energy subject to bound constraints. Doing so spreads the influences of the controls in a shape-aware and localized manner, even for objects with complex and concave boundaries. The variational weight optimization also makes it possible to customize the weights so that they preserve the shape of specified essential object features. We demonstrate successful use of our blending weights for real-time deformation of 2D and 3D shapes. ", 
        "id": 1253, 
        "title": "Bounded biharmonic weights for real-time deformation."
    }, 
    {
        "abstract": "", 
        "id": 1254, 
        "title": "Stretchable and Twistable Bones for Skeletal Shape Deformation."
    }, 
    {
        "abstract": "", 
        "id": 1255, 
        "title": "Modal-space control for articulated characters."
    }, 
    {
        "abstract": "", 
        "id": 1256, 
        "title": "Controlling physics-based characters using soft contacts."
    }, 
    {
        "abstract": "", 
        "id": 1257, 
        "title": "A comprehensive theory of volumetric radiance estimation using photon points and beams."
    }, 
    {
        "abstract": "", 
        "id": 1258, 
        "title": "Progressive photon beams."
    }, 
    {
        "abstract": "We describe a system for capturing microscopic surface geometry. The system extends the retrographic sensor [Johnson and Adelson 2009] to the microscopic domain, demonstrating spatial resolution as small as 2 microns. In contrast to existing microgeometry capture techniques, the system is not affected by the optical characteristics of the surface being measured--it captures the same geometry whether the object is matte, glossy, or transparent. In addition, the hardware design allows for a variety of form factors, including a hand-held device that can be used to capture high-resolution surface geometry in the field. We achieve these results with a combination of improved sensor materials, illumination design, and reconstruction algorithm, as compared to the original sensor of Johnson and Adelson [2009]. ", 
        "id": 1259, 
        "title": "Microgeometry capture using an elastomeric sensor."
    }, 
    {
        "abstract": "", 
        "id": 1260, 
        "title": "Rendering synthetic objects into legacy photographs."
    }, 
    {
        "abstract": "A wide variety of non-photorealistic rendering techniques make use of random variation in the placement or appearance of primitives. In order to avoid the \"shower-door\" effect, this random variation should move with the objects in the scene. Here we present coherent noise tailored to this purpose. We compute the coherent noise with a specialized filter that uses the depth and velocity fields of a source sequence. The computation is fast and suitable for interactive applications like games. ", 
        "id": 1261, 
        "title": "Coherent noise for non-photorealistic rendering."
    }, 
    {
        "abstract": "We propose a method for learning linear upsampling operators for physically-based cloth simulation, allowing us to enrich coarse meshes with mid-scale details in minimal time and memory budgets, as required in computer games. In contrast to classical subdivision schemes, our operators adapt to a specific context (e.g. a flag flapping in the wind or a skirt worn by a character), which allows them to achieve higher detail. Our method starts by pre-computing a pair of coarse and fine training simulations aligned with tracking constraints using harmonic test functions. Next, we train the upsampling operators with a new regularization method that enables us to learn mid-scale details without overfitting. We demonstrate generalizability to unseen conditions such as different wind velocities or novel character motions. Finally, we discuss how to re-introduce high frequency details not explainable by the coarse mesh alone using oscillatory modes. ", 
        "id": 1262, 
        "title": "Physics-inspired upsampling for cloth simulation in games."
    }, 
    {
        "abstract": "", 
        "id": 1263, 
        "title": "Interactive architectural modeling with procedural extrusions."
    }, 
    {
        "abstract": "We present an approach for generating face animations from large image collections of the same person. Such collections, which we call photobios, sample the appearance of a person over changes in pose, facial expression, hairstyle, age, and other variations. By optimizing the order in which images are displayed and crossdissolving between them, we control the motion through face space and create compelling animations (e.g., render a smooth transition from frowning to smiling). Used in this context, the cross dissolve produces a very strong motion effect; a key contribution of the paper is to explain this effect and analyze its operating range. The approach operates by creating a graph with faces as nodes, and similarities as edges, and solving for walks and shortest paths on this graph. The processing pipeline involves face detection, locating fiducials (eyes/nose/mouth), solving for pose, warping to frontal views, and image comparison based on Local Binary Patterns. We demonstrate results on a variety of datasets including time-lapse photography, personal photo collections, and images of celebrities downloaded from the Internet. Our approach is the basis for the Face Movies feature in Google's Picasa. ", 
        "id": 1264, 
        "title": "Exploring photobios."
    }, 
    {
        "abstract": "", 
        "id": 1265, 
        "title": "Multi-perspective stereoscopy from light fields."
    }, 
    {
        "abstract": "", 
        "id": 1266, 
        "title": "Highlighted depth-of-field photography: Shining light on focus."
    }, 
    {
        "abstract": "This paper describes a fully automatic pipeline for finding an intrinsic map between two non-isometric, genus zero surfaces. Our approach is based on the observation that efficient methods exist to search for nearly isometric maps (e.g., Mobius Voting or Heat Kernel Maps), but no single solution found with these methods provides low-distortion everywhere for pairs of surfaces differing by large deformations. To address this problem, we suggest using a weighted combination of these maps to produce a \"blended map.\" This approach enables algorithms that leverage efficient search procedures, yet can provide the flexibility to handle large deformations. The main challenges of this approach lie in finding a set of candidate maps {mi} and their associated blending weights {bi(p)} for every point p on the surface. We address these challenges specifically for conformal maps by making the following contributions. First, we provide a way to blend maps, defining the image of p as the weighted geodesic centroid of mi(p). Second, we provide a definition for smooth blending weights at every point p that are proportional to the area preservation of mi at p. Third, we solve a global optimization problem that selects candidate maps based both on their area preservation and consistency with other selected maps. During experiments with these methods, we find that our algorithm produces blended maps that align semantic features better than alternative approaches over a variety of data sets. ", 
        "id": 1267, 
        "title": "Blended intrinsic maps."
    }, 
    {
        "abstract": "", 
        "id": 1268, 
        "title": "Coons BVH for freeform geometric models."
    }, 
    {
        "abstract": "", 
        "id": 1269, 
        "title": "Fast simulation of skeleton-driven deformable body characters."
    }, 
    {
        "abstract": "", 
        "id": 1270, 
        "title": "Edge-aware color appearance."
    }, 
    {
        "abstract": "In this paper we present a perceptually based algorithm for modeling the color shift that occurs for human viewers in low-light scenes. Known as the Purkinje effect, this color shift occurs as the eye transitions from photopic, cone-mediated vision in well-lit scenes to scotopic, rod-mediated vision in dark scenes. At intermediate light levels vision is mesopic with both the rods and cones active. Although the rods have a spectral response distinct from the cones, they still share the same neural pathways. As light levels decrease and the rods become increasingly active they cause a perceived shift in color. We model this process so that we can compute perceived colors for mesopic and scotopic scenes from spectral image data. We also describe how the effect can be approximated from standard high dynamic range RGB images. Once we have determined rod and cone responses, we map them to RGB values that can be displayed on a standard monitor to elicit the intended color perception when viewed photopically. Our method focuses on computing the color shift associated with low-light conditions and leverages current HDR techniques to control the images dynamic range. We include results generated from both spectral and RGB input images.", 
        "id": 1271, 
        "title": "Perceptually based tone mapping for low-light conditions."
    }, 
    {
        "abstract": "", 
        "id": 1272, 
        "title": "Progressive photon mapping: A probabilistic approach."
    }, 
    {
        "abstract": "We describe a novel algorithm for extracting a resolutionindependent vector representation from pixel art images, which enables magnifying the results by an arbitrary amount without image degradation. Our algorithm resolves pixel-scale features in the input and converts them into regions with smoothly varying shading that are crisply separated by piecewise-smooth contour curves. In the original image, pixels are represented on a square pixel lattice, where diagonal neighbors are only connected through a single point. This causes thin features to become visually disconnected under magnification by conventional means, and creates ambiguities in the connectedness and separation of diagonal neighbors. The key to our algorithm is in resolving these ambiguities. This enables us to reshape the pixel cells so that neighboring pixels belonging to the same feature are connected through edges, thereby preserving the feature connectivity under magnification. We reduce pixel aliasing artifacts and improve smoothness by fitting spline curves to contours in the image and optimizing their control points. ", 
        "id": 1273, 
        "title": "Depixelizing pixel art."
    }, 
    {
        "abstract": "", 
        "id": 1274, 
        "title": "Multigrid and multilevel preconditioners for computational photography."
    }, 
    {
        "abstract": "", 
        "id": 1275, 
        "title": "C1x6: a stereoscopic six-user display for co-located collaboration in shared virtual environments."
    }, 
    {
        "abstract": "", 
        "id": 1276, 
        "title": "Imperceptible relaxation of collision avoidance constraints in virtual crowds."
    }, 
    {
        "abstract": "Solid noise is a fundamental tool in computer graphics. Surprisingly, no existing noise function supports both high-quality antialiasing and continuity across sharp edges. In this paper we show that a slicing approach is required to preserve continuity across sharp edges, and we present a new noise function that supports anisotropic filtering of sliced solid noise. This is made possible by individually filtering the slices of Gabor kernels, which requires the proper treatment of phase. This in turn leads to the introduction of the phase-augmented Gabor kernel and random-phase Gabor noise, our new noise function. We demonstrate that our new noise function supports both high-quality anti-aliasing and continuity across sharp edges, as well as anisotropy. ", 
        "id": 1277, 
        "title": "Filtering solid Gabor noise."
    }, 
    {
        "abstract": "We present a novel method for increasing the efficiency of stochastic rasterization of motion and defocus blur. Contrary to earlier approaches, our method is efficient even with the low sampling densities commonly encountered in realtime rendering, while allowing the use of arbitrary sampling patterns for maximal image quality. Our clipless dual-space formulation avoids problems with triangles that cross the camera plane during the shutter interval. The method is also simple to plug into existing rendering systems. ", 
        "id": 1278, 
        "title": "Clipless dual-space bounds for faster stochastic rasterization."
    }, 
    {
        "abstract": "", 
        "id": 1279, 
        "title": "Polarization fields: dynamic light field display using multi-layer LCDs."
    }, 
    {
        "abstract": "Although there is an abundance of 3D models available, most of them exist only in virtual simulation and are not immediately usable as physical objects in the real world. We solve the problem of taking as input a 3D model of a man-made object, and automatically generating the parts and connectors needed to build the corresponding physical object. We focus on furniture models, and we define formal grammars for IKEA cabinets and tables. We perform lexical analysis to identify the primitive parts of the 3D model. Structural analysis then gives structural information to these parts, and generates the connectors (i.e. nails, screws) needed to attach the parts together. We demonstrate our approach with arbitrary 3D models of cabinets and tables available online. ", 
        "id": 1280, 
        "title": "Converting 3D furniture models to fabricatable parts and connectors."
    }, 
    {
        "abstract": "Figure 1: Results of the user study: (top) Freehand drawings of objects without using ShadowDraw, (bottom) freehand drawings of objects using ShadowDraw. Notice the improved spacing and proportions while maintaining the subjects own unique styles. Abstract We present ShadowDraw, a system for guiding the freeform drawing of objects. As the user draws, ShadowDraw dynamically updates a shadow image underlying the users strokes. The shadows are suggestive of object contours that guide the user as they continue drawing. This paradigm is similar to tracing, with two major differences. First, we do not provide a single image from which the user can trace; rather ShadowDraw automatically blends relevant images from a large database to construct the shadows. Second, the system dynamically adapts to the users drawings in real-time and produces suggestions accordingly. ShadowDraw works by efficiently matching local edge patches between the query, constructed from the current drawing, and a database of images. A hashing technique enforces both local and global similarity and provides sufficient speed for interactive feedback. Shadows are created by aggregating the edge maps from the best database matches, spatially weighted by their match scores. We test our approach with human subjects and show comparisons between the drawings that were produced with and without the system. The results show that our system produces more realistically proportioned line drawings.", 
        "id": 1281, 
        "title": "ShadowDraw: real-time user guidance for freehand drawing."
    }, 
    {
        "abstract": "Traditionally, effects that require evaluating multidimensional integrals for each pixel, such as motion blur, depth of field, and soft shadows, suffer from noise due to the variance of the highdimensional integrand. In this paper, we describe a general reconstruction technique that exploits the anisotropy in the temporal light field and permits efficient reuse of samples between pixels, multiplying the effective sampling rate by a large factor. We show that our technique can be applied in situations that are challenging or impossible for previous anisotropic reconstruction methods, and that it can yield good results with very sparse inputs. We demonstrate our method for simultaneous motion blur, depth of field, and soft shadows. ", 
        "id": 1282, 
        "title": "Temporal light field reconstruction for rendering distribution effects."
    }, 
    {
        "abstract": "", 
        "id": 1283, 
        "title": "Material matting."
    }, 
    {
        "abstract": "", 
        "id": 1284, 
        "title": "Space-time planning with parameterized locomotion controllers."
    }, 
    {
        "abstract": "Simulating viscoelastic solids undergoing large, nonlinear deformations in close contact is challenging. In addition to inter-object contact, methods relying on Lagrangian discretizations must handle degenerate cases by explicitly remeshing or resampling the object. Eulerian methods, which discretize space itself, provide an interesting alternative due to the fixed nature of the discretization. In this paper we present a new Eulerian method for viscoelastic materials that features a collision detection and resolution scheme which does not require explicit surface tracking to achieve accurate collision response. Time-stepping with contact is performed by the efficient solution of large sparse quadratic programs; this avoids constraint sticking and other difficulties. Simulation and collision processing can share the same uniform grid, making the algorithm easy to parallelize. We demonstrate an implementation of all the steps of the algorithm on the GPU. The method is effective for simulation of complicated contact scenarios involving multiple highly deformable objects, and can directly simulate volumetric models obtained from medical imaging techniques such as CT and MRI. ", 
        "id": 1285, 
        "title": "Eulerian solid simulation with contact."
    }, 
    {
        "abstract": "", 
        "id": 1286, 
        "title": "Modeling and generating moving trees from video."
    }, 
    {
        "abstract": "Pop-up books are a fascinating form of paper art with intriguing geometric properties. In this paper, we present a systematic study of a simple but common class of pop-ups consisting of patches falling into four parallel groups, which we call v-style pop-ups. We give sufficient conditions for a v-style paper structure to be pop-uppable. That is, it can be closed flat while maintaining the rigidity of the patches, the closing and opening do not need extra force besides holding two patches and are free of intersections, and the closed paper is contained within the page border. These conditions allow us to identify novel mechanisms for making pop-ups. Based on the theory and mechanisms, we developed an interactive tool for designing v-style pop-ups and an automated construction algorithm from a given geometry, both of which guaranteeing the popuppability of the results. ", 
        "id": 1287, 
        "title": "A geometric study of v-style pop-ups: theories and algorithms."
    }, 
    {
        "abstract": "", 
        "id": 1288, 
        "title": "Structure-preserving retargeting of irregular 3D architecture."
    }, 
    {
        "abstract": "", 
        "id": 1289, 
        "title": "Subspace video stabilization."
    }, 
    {
        "abstract": "", 
        "id": 1290, 
        "title": "General planar quadrilateral mesh design using conjugate direction field."
    }, 
    {
        "abstract": "We present a lobe-based tree representation for modeling trees. The new representation is based on the observation that the tree's foliage details can be abstracted into canonical geometry structures, termed lobe-textures. We introduce techniques to (i) approximate the geometry of given tree data and encode it into a lobe-based representation, (ii) decode the representation and synthesize a fully detailed tree model that visually resembles the input. The encoded tree serves as a light intermediate representation, which facilitates efficient storage and transmission of massive amounts of trees, e.g., from a server to clients for interactive applications in urban environments. The method is evaluated by both reconstructing laser scanned trees (given as point sets) as well as re-representing existing tree models (given as polygons). ", 
        "id": 1291, 
        "title": "Texture-lobes for tree modelling."
    }, 
    {
        "abstract": "Given a noisy and incomplete point set, we introduce a method that simultaneously recovers a set of locally fitted primitives along with their global mutual relations. We operate under the assumption that the data corresponds to a man-made engineering object consisting of basic primitives, possibly repeated and globally aligned under common relations. We introduce an algorithm to directly couple the local and global aspects of the problem. The local fit of the model is determined by how well the inferred model agrees to the observed data, while the global relations are iteratively learned and enforced through a constrained optimization. Starting with a set of initial RANSAC based locally fitted primitives, relations across the primitives such as orientation, placement, and equality are progressively learned and conformed to. In each stage, a set of feasible relations are extracted among the candidate relations, and then aligned to, while best fitting to the input data. The global coupling corrects the primitives obtained in the local RANSAC stage, and brings them to precise global alignment. We test the robustness of our algorithm on a range of synthesized and scanned data, with varying amounts of noise, outliers, and non-uniform sampling, and validate the results against ground truth, where available.", 
        "id": 1292, 
        "title": "GlobFit: consistently fitting primitives by discovering global relations."
    }, 
    {
        "abstract": "", 
        "id": 1293, 
        "title": "Modular Radiance Transfer."
    }, 
    {
        "abstract": " Links: DL PDF VIDEO  We present an algorithm for creating digital micrography images, or micrograms, a special type of calligrams created from minuscule text. These attractive text-art works successfully combine beautiful images with readable meaningful text. Traditional micrograms are created by highly skilled artists and involve a huge amount of tedious manual work. We aim to simplify this process by providing a computerized digital micrography design tool. The main challenge in creating digital micrograms is designing textual layouts that simultaneously convey the input image, are readable and appealing. To generate such layout we use the streamlines of singularity free, low curvature, smooth vector fields, especially designed for our needs. The vector fields are computed using a new approach which controls field properties via a priori boundary condition design that balances the different requirements we aim to satisfy. The optimal boundary conditions are computed using a graph-cut approach balancing local and global design considerations. The generated layouts are further processed to obtain the final micrograms. Our method automatically generates engaging, readable micrograms starting from a vector image and an input text while providing a variety of optional high-level controls to the user. ", 
        "id": 1294, 
        "title": "Digital micrography."
    }, 
    {
        "abstract": "Visual metrics can play an important role in the evaluation of novel lighting, rendering, and imaging algorithms. Unfortunately, current metrics only work well for narrow intensity ranges, and do not correlate well with experimental data outside these ranges. To address these issues, we propose a visual metric for predicting visibility (discrimination) and quality (mean-opinion-score). The metric is based on a new visual model for all luminance conditions, which has been derived from new contrast sensitivity measurements. The model is calibrated and validated against several contrast discrimination data sets, and image quality databases (LIVE and TID2008). The visibility metric is shown to provide much improved predictions as compared to the original HDR-VDP and VDP metrics, especially for low luminance conditions. The image quality predictions are comparable to or better than for the MS-SSIM, which is considered one of the most successful quality metrics. The code of the proposed metric is available on-line.", 
        "id": 1295, 
        "title": "HDR-VDP-2: a calibrated visual metric for visibility and quality predictions in all luminance conditions."
    }, 
    {
        "abstract": "We propose an example-based approach for simulating complex elastic material behavior. Supplied with a few poses that characterize a given object, our system starts by constructing a space of prefered deformations by means of interpolation. During simulation, this example manifold then acts as an additional elastic attractor that guides the object towards its space of prefered shapes. Added on top of existing solid simulation codes, this example potential effectively allows us to implement inhomogeneous and anisotropic materials in a direct and intuitive way. Due to its example-based interface, our method promotes an art-directed approach to solid simulation, which we exemplify on a set of practical examples. ", 
        "id": 1296, 
        "title": "Example-based elastic materials."
    }, 
    {
        "abstract": "A variety of phenomena can be characterized by repetitive small scale elements within a large scale domain. Examples include a stack of fresh produce, a plate of spaghetti, or a mosaic pattern. Although certain results can be produced via manual placement or procedural/physical simulation, these methods can be labor intensive, difficult to control, or limited to specific phenomena. We present discrete element textures, a data-driven method for synthesizing repetitive elements according to a small input exemplar and a large output domain. Our method preserves both individual element properties and their aggregate distributions. It is also general and applicable to a variety of phenomena, including different dimensionalities, different element properties and distributions, and different effects including both artistic and physically realistic ones. We represent each element by one or multiple samples whose positions encode relevant element attributes including position, size, shape, and orientation. We propose a sample-based neighborhood similarity metric and an energy optimization solver to synthesize desired outputs that observe not only input exemplars and output domains but also optional constraints such as physics, orientation fields, and boundary conditions. As a further benefit, our method can also be applied for editing existing element distributions. ", 
        "id": 1297, 
        "title": "Discrete element textures."
    }, 
    {
        "abstract": "We present a new algorithm for near-interactive simulation of skeleton driven, high resolution elasticity models. Our methodology is used for soft tissue deformation in character animation. The algorithm is based on a novel discretization of corotational elasticity over a hexahedral lattice. Within this framework we enforce positive definiteness of the stiffness matrix to allow efficient quasistatics and dynamics. In addition, we present a multigrid method that converges with very high efficiency. Our design targets performance through parallelism using a fully vectorized and branch-free SVD algorithm as well as a stable one-point quadrature scheme. Since body collisions, self collisions and soft-constraints are necessary for real-world examples, we present a simple framework for enforcing them. The whole approach is demonstrated in an end-toend production-level character skinning system. ", 
        "id": 1298, 
        "title": "Efficient elasticity for character skinning with contact and collisions."
    }, 
    {
        "abstract": "", 
        "id": 1299, 
        "title": "Slices: a shape-proxy based on planar sections."
    }, 
    {
        "abstract": "We present an interactive furniture layout system that assists users by suggesting furniture arrangements that are based on interior design guidelines. Our system incorporates the layout guidelines as terms in a density function and generates layout suggestions by rapidly sampling the density function using a hardware-accelerated Monte Carlo sampler. Our results demonstrate that the suggestion generation functionality measurably increases the quality of furniture arrangements produced by participants with no prior training in interior design. ", 
        "id": 1300, 
        "title": "Interactive furniture layout using interior design guidelines."
    }, 
    {
        "abstract": "", 
        "id": 1301, 
        "title": "Naive ray-tracing: A divide-and-conquer approach."
    }, 
    {
        "abstract": "", 
        "id": 1302, 
        "title": "Composite control of physically simulated characters."
    }, 
    {
        "abstract": "We introduce Hodge-optimized triangulations (HOT), a family of well-shaped primal-dual pairs of complexes designed for fast and accurate computations in computer graphics. Previous work most commonly employs barycentric or circumcentric duals; while barycentric duals guarantee that the dual of each simplex lies within the simplex, circumcentric duals are often preferred due to the induced orthogonality between primal and dual complexes. We instead promote the use of weighted duals (\"power diagrams\"). They allow greater flexibility in the location of dual vertices while keeping primal-dual orthogonality, thus providing a valuable extension to the usual choices of dual by only adding one additional scalar per primal vertex. Furthermore, we introduce a family of functionals on pairs of complexes that we derive from bounds on the errors induced by diagonal Hodge stars, commonly used in discrete computations. The minimizers of these functionals, called HOT meshes, are shown to be generalizations of Centroidal Voronoi Tesselations and Optimal Delaunay Triangulations, and to provide increased accuracy and flexibility for a variety of computational purposes. ", 
        "id": 1303, 
        "title": "HOT: Hodge-optimized triangulations."
    }, 
    {
        "abstract": "We propose a new fast and robust method to simulate various types of solid including rigid, plastic and soft bodies as well as one, two and three dimensional structures such as ropes, cloth and volumetric objects. The underlying idea is to use oriented particles that store rotation and spin, along with the usual linear attributes, i.e. position and velocity. This additional information adds substantially to traditional particle methods. First, particles can be represented by anisotropic shapes such as ellipsoids, which approximate surfaces more accurately than spheres. Second, shape matching becomes robust for sparse structures such as chains of particles or even single particles because the undefined degrees of freedom are captured in the rotational states of the particles. Third, the full transformation stored in the particles, including translation and rotation, can be used for robust skinning of graphical meshes and for transforming plastic deformations back into the rest state. ", 
        "id": 1304, 
        "title": "Solid simulation with oriented particles."
    }, 
    {
        "abstract": "", 
        "id": 1305, 
        "title": "T&I engine: traversal and intersection engine for hardware accelerated ray tracing."
    }, 
    {
        "abstract": "", 
        "id": 1306, 
        "title": "Single view reflectance capture using multiplexed scattering and time-of-flight imaging."
    }, 
    {
        "abstract": "", 
        "id": 1307, 
        "title": "Conjoining Gestalt rules for abstraction of architectural drawings."
    }, 
    {
        "abstract": "", 
        "id": 1308, 
        "title": "GPU-efficient recursive filtering and summed-area tables."
    }, 
    {
        "abstract": "Art direction of high resolution naturalistic liquid simulations is notoriously hard, due to both the chaotic nature of the physics and the computational resources required. Resimulating a scene at higher resolution often produces very different results, and is too expensive to allow many design cycles. We present a method of constraining or guiding a high resolution liquid simulation to stay close to a finalized low resolution version (either simulated or directly animated), restricting the solve to a thin outer shell of liquid around a guide shape. Our method is generally faster than an unconstrained simulation and can be integrated with a standard fluid simulator. We demonstrate several applications, with both simulated and handanimated inputs. ", 
        "id": 1309, 
        "title": "Guide shapes for high resolution naturalistic liquid simulation."
    }, 
    {
        "abstract": "We present a method for generating art-directable volumetric effects, ranging from physically-accurate to non-physical results. Our system mimics the way experienced artists think about volumetric effects by using an intuitive lighting primitive, and decoupling the modeling and shading of this primitive. To accomplish this, we generalize the physically-based photon beams method to allow arbitrarily programmable simulation and shading phases. This provides an intuitive design space for artists to rapidly explore a wide range of physically-based as well as plausible, but exaggerated, volumetric effects. We integrate our approach into a real-world production pipeline and couple our volumetric effects to surface shading. ", 
        "id": 1310, 
        "title": "A programmable system for artistic volumetric lighting."
    }, 
    {
        "abstract": "This paper studies color compatibility theories using large datasets, and develops new tools for choosing colors. There are three parts to this work. First, using on-line datasets, we test new and existing theories of human color preferences. For example, we test whether certain hues or hue templates may be preferred by viewers. Second, we learn quantitative models that score the quality of a five-color set of colors, called a color theme. Such models can be used to rate the quality of a new color theme. Third, we demonstrate simple prototypes that apply a learned model to tasks in color design, including improving existing themes and extracting themes from images. Links: DL PDF WEB DATA CODE ", 
        "id": 1311, 
        "title": "Color compatibility from large datasets."
    }, 
    {
        "abstract": "", 
        "id": 1312, 
        "title": "OSCAM - optimized stereoscopic camera control for interactive 3D."
    }, 
    {
        "abstract": "", 
        "id": 1313, 
        "title": "LightSlice: matrix slice sampling for the many-lights problem."
    }, 
    {
        "abstract": "As large public repositories of 3D shapes continue to grow, the amount of shape variability in such collections also increases, both in terms of the number of different classes of shapes, as well as the geometric variability of shapes within each class. While this gives users more choice for shape selection, it can be difficult to explore large collections and understand the range of variations amongst the shapes. Exploration is particularly challenging for public shape repositories, which are often only loosely tagged and contain neither point-based nor part-based correspondences. In this paper, we present a method for discovering and exploring continuous variability in a collection of 3D shapes without correspondences. Our method is based on a novel navigation interface that allows users to explore a collection of related shapes by deforming a base template shape through a set of intuitive deformation controls. We also help the user to select the most meaningful deformations using a novel technique for learning shape variability in terms of deformations of the template. Our technique assumes that the set of shapes lies near a low-dimensional manifold in a certain descriptor space, which allows us to avoid establishing correspondences between shapes, while being rotation and scaling invariant. We present results on several shape collections taken directly from public repositories. ", 
        "id": 1314, 
        "title": "Exploration of continuous variability in collections of 3D shapes."
    }, 
    {
        "abstract": "", 
        "id": 1315, 
        "title": "Insitu: sketching architectural designs in context."
    }, 
    {
        "abstract": "We introduce an interactive method to assess cataracts in the human eye by crafting an optical solution that measures the perceptual impact of forward scattering on the foveal region. Current solutions rely on highly-trained clinicians to check the back scattering in the crystallin lens and test their predictions on visual acuity tests. Close-range parallax barriers create collimated beams of light to scan through sub-apertures, scattering light as it strikes a cataract. User feedback generates maps for opacity, attenuation, contrast and sub-aperture point-spread functions. The goal is to allow a general audience to operate a portable high-contrast light-field display to gain a meaningful understanding of their own visual conditions. User evaluations and validation with modified camera optics are performed. Compiled data is used to reconstruct the individual's cataract-affected view, offering a novel approach for capturing information for screening, diagnostic, and clinical analysis. ", 
        "id": 1316, 
        "title": "CATRA: interactive measuring and modeling of cataracts."
    }, 
    {
        "abstract": "(a) input HDR image tone-mapped with a simple gamma curve (details are compressed) (b) our pyramid-based tone mapping, set to preserve details without increasing them (c) our pyramid-based tone mapping, set to strongly enhance the contrast of details Figure 1: We demonstrate edge-aware image filters based on the direct manipulation of Laplacian pyramids. Our approach produces high-quality results, without degrading edges or introducing halos, even at extreme settings. Our approach builds upon standard image pyramids and enables a broad range of effects via simple point-wise nonlinearities (shown in corners). For an example image (a), we show results of tone mapping using our method, creating a natural rendition (b) and a more exaggerated look that enhances details as well (c). Laplacian pyramids have previously been considered unsuitable for such tasks, but our approach shows otherwise. Abstract The Laplacian pyramid is ubiquitous for decomposing images into multiple scales and is widely used for image analysis. However, because it is constructed with spatially invariant Gaussian kernels, the Laplacian pyramid is widely believed as being unable to represent edges well and as being ill-suited for edge-aware operations such as edge-preserving smoothing and tone mapping. To tackle these tasks, a wealth of alternative techniques and representations have been proposed, e.g., anisotropic diffusion, neighborhood filtering, and specialized wavelet bases. While these methods have demonstrated successful results, they come at the price of additional complexity, often accompanied by higher computational cost or the need to post-process the generated results. In this paper, we show state-of-the-art edge-aware processing using standard Laplacian pyramids. We characterize edges with a simple threshold on pixel values that allows us to differentiate large-scale edges from small-scale details. Building upon this result, we propose a set of image filters to achieve edge-preserving smoothing, detail enhancement, tone mapping, and inverse tone mapping. The advantage of our approach is its simplicity and flexibility, relying only on simple point-wise nonlinearities and small Gaussian convolutions; no optimization or post-processing is required. As we demonstrate, our method produces consistently high-quality results, without degrading edges or introducing halos.", 
        "id": 1317, 
        "title": "Local Laplacian filters: edge-aware image processing with a Laplacian pyramid."
    }, 
    {
        "abstract": "", 
        "id": 1318, 
        "title": "Connectivity editing for quadrilateral meshes."
    }, 
    {
        "abstract": "", 
        "id": 1319, 
        "title": "Global parametrization of range image sets."
    }, 
    {
        "abstract": "", 
        "id": 1320, 
        "title": "Decoupled sampling for graphics pipelines."
    }, 
    {
        "abstract": "We present a simple, fast solution for reflectance acquisition using tools that fit into a pocket. Our method captures video of a flat target surface from a fixed video camera lit by a hand-held, moving, linear light source. After processing, we obtain an SVBRDF. We introduce a BRDF chart, analogous to a color \"checker\" chart, which arranges a set of known-BRDF reference tiles over a small card. A sequence of light responses from the chart tiles as well as from points on the target is captured and matched to reconstruct the target's appearance. We develop a new algorithm for BRDF reconstruction which works directly on these LDR responses, without knowing the light or camera position, or acquiring HDR lighting. It compensates for spatial variation caused by the local (finite distance) camera and light position by warping responses over time to align them to a specular reference. After alignment, we find an optimal linear combination of the Lambertian and purely specular reference responses to match each target point's response. The same weights are then applied to the corresponding (known) reference BRDFs to reconstruct the target point's BRDF. We extend the basic algorithm to also recover varying surface normals by adding two spherical caps for diffuse and specular references to the BRDF chart. We demonstrate convincing results obtained after less than 30 seconds of data capture, using commercial mobile phone cameras in a casual environment. ", 
        "id": 1321, 
        "title": "Pocket reflectometry."
    }, 
    {
        "abstract": "", 
        "id": 1322, 
        "title": "Steady affine motions and morphs."
    }, 
    {
        "abstract": "", 
        "id": 1323, 
        "title": "Adaptive sampling and reconstruction using greedy error minimization."
    }, 
    {
        "abstract": "", 
        "id": 1324, 
        "title": "Practical spectral characterization of trichromatic cameras."
    }, 
    {
        "abstract": "We present a camera with switchable primaries using shiftable layers of color filter arrays (CFAs). By layering a pair of CMY CFAs in this novel manner we can switch between multiple sets of color primaries (namely RGB, CMY and RGBCY) in the same camera. In contrast to fixed color primaries (e.g. RGB or CMY), which cannot provide optimal image quality for all scene conditions, our camera with switchable primaries provides optimal color fidelity and signal to noise ratio for multiple scene conditions. Next, we show that the same concept can be used to layer two RGB CFAs to design a camera with switchable low dynamic range (LDR) and high dynamic range (HDR) modes. Further, we show that such layering can be generalized as a constrained satisfaction problem (CSP) allowing to constrain a large number of parameters (e.g. different operational modes, amount and direction of the shifts, place- e-mail: bsajadi@uci.edu e-mail: majumder@ics.uci.edu e-mail: kazuhiro.hiwada@toshiba.co.jp e-mail: atsuto.maki@crl.toshiba.co.uk e-mail: raskar@media.mit.edu ACM Reference Format Sajadi, B., Majumder, A., Hiwada, K., Maki, A., Raskar, R. 2011. Switchable Primaries Using Shiftable Layers of Color Filter Arrays. ACM Trans. Graph. 30, 4, Article 65 (July 2011), 10 pages. DOI = 10.1145/1964921.1964960 http://doi.acm.org/10.1145/1964921.1964960. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org.  2011 ACM 0730-0301/2011/07-ART65 $10.00 DOI 10.1145/1964921.1964960 http://doi.acm.org/10.1145/1964921.1964960  ment of the primaries in the CFA) to provide an optimal solution. We investigate practical design options for shiftable layering of the CFAs. We demonstrate these by building prototype cameras for both switchable primaries and switchable LDR/HDR modes. To the best of our knowledge, we present, for the first time, the concept of shiftable layers of CFAs that provides a new degree of freedom in photography where multiple operational modes are available to the user in a single camera for optimizing the picture quality based on the nature of the scene geometry, color and illumination. ", 
        "id": 1325, 
        "title": "Switchable primaries using shiftable layers of color filter arrays."
    }, 
    {
        "abstract": "We present a technique to generalize the 2D painting metaphor to 3D that allows the artist to treat the full 3D space as a canvas. Strokes painted in the 2D viewport window must be embedded in 3D space in a way that gives creative freedom to the artist while maintaining an acceptable level of controllability. We address this challenge by proposing a canvas concept defined implicitly by a 3D scalar field. The artist shapes the implicit canvas by creating approximate 3D proxy geometry. An optimization procedure is then used to embed painted strokes in space by satisfying different objective criteria defined on the scalar field. This functionality allows us to implement tools for painting along level set surfaces or across different level sets. Our method gives the power of fine-tuning the implicit canvas to the artist using a unified painting/sculpting metaphor. A sculpting tool can be used to paint into the implicit canvas. Rather than adding color, this tool creates a local change in the scalar field that results in outward or inward protrusions along the field's gradient direction. We address a visibility ambiguity inherent in 3D stroke rendering with a depth offsetting method that is well suited for hardware acceleration. We demonstrate results with a number of 3D paintings that exhibit effects difficult to realize with existing systems. ", 
        "id": 1326, 
        "title": "OverCoat: an implicit canvas for 3D painting."
    }, 
    {
        "abstract": "", 
        "id": 1327, 
        "title": "Perceptual models of viewpoint preference."
    }, 
    {
        "abstract": "", 
        "id": 1328, 
        "title": "Compression and direct manipulation of complex blendshape models."
    }, 
    {
        "abstract": "", 
        "id": 1329, 
        "title": "Artist friendly facial animation retargeting."
    }, 
    {
        "abstract": "", 
        "id": 1330, 
        "title": "Interactive hybrid simulation of large-scale traffic."
    }, 
    {
        "abstract": "", 
        "id": 1331, 
        "title": "Adaptive partitioning of urban facades."
    }, 
    {
        "abstract": "Motion capture technology generally requires that recordings be performed in a laboratory or closed stage setting with controlled lighting. This restriction precludes the capture of motions that require an outdoor setting or the traversal of large areas. In this paper, we present the theory and practice of using body-mounted cameras to reconstruct the motion of a subject. Outward-looking cameras are attached to the limbs of the subject, and the joint angles and root pose are estimated through non-linear optimization. The optimization objective function incorporates terms for image matching error and temporal continuity of motion. Structure-from-motion is used to estimate the skeleton structure and to provide initialization for the non-linear optimization procedure. Global motion is estimated and drift is controlled by matching the captured set of videos to reference imagery. We show results in settings where capture would be difficult or impossible with traditional motion capture systems, including walking outside and swinging on monkey bars. The quality of the motion reconstruction is evaluated by comparing our results against motion capture data produced by a commercially available optical system. ", 
        "id": 1332, 
        "title": "Motion capture from body-mounted cameras."
    }, 
    {
        "abstract": "", 
        "id": 1333, 
        "title": "Data-driven visual similarity for cross-domain image matching."
    }, 
    {
        "abstract": "", 
        "id": 1334, 
        "title": "Unsupervised co-segmentation of a set of shapes via descriptor-space spectral clustering."
    }, 
    {
        "abstract": "", 
        "id": 1335, 
        "title": "An efficient alias-free shadow algorithm for opaque and transparent objects using per-triangle shadow volumes."
    }, 
    {
        "abstract": "", 
        "id": 1336, 
        "title": "Genetic programming for shader simplification."
    }, 
    {
        "abstract": "We propose a two-scale method for particle-based fluids that allocates computing resources to regions of the fluid where complex flow behavior emerges. Our method uses a low- and a highresolution simulation that run at the same time. While in the coarse simulation the whole fluid is represented by large particles, the fine level simulates only a subset of the fluid with small particles. The subset can be arbitrarily defined and also dynamically change over time to capture complex flows and small-scale surface details. The low- and high-resolution simulations are coupled by including feedback forces and defining appropriate boundary conditions. Our method offers the benefit that particles are of the same size within each simulation level. This avoids particle splitting and merging processes, and allows the simulation of very large resolution differences without any stability problems. The model is easy to implement, and we show how it can be integrated into a standard SPH simulation as well as into the incompressible PCISPH solver. Compared to the single-resolution simulation, our method produces similar surface details while improving the efficiency linearly to the achieved reduction rate of the particle number. ", 
        "id": 1337, 
        "title": "Two-scale particle simulation."
    }, 
    {
        "abstract": "", 
        "id": 1338, 
        "title": "On the velocity of an implicit surface."
    }, 
    {
        "abstract": "", 
        "id": 1339, 
        "title": "Realistic perspective projections for virtual objects and environments."
    }, 
    {
        "abstract": "A significant challenge in applications of computer animation is the simulation of ropes, cables, and other highly constrained strandlike physical curves. Such scenarios occur frequently, for instance, when a strand wraps around rigid bodies or passes through narrow sheaths. Purely Lagrangian methods designed for less constrained applications such as hair simulation suffer from difficulties in these important cases. To overcome this, we introduce a new framework that combines Lagrangian and Eulerian approaches. The two key contributions are the reduced node, whose degrees of freedom precisely match the constraint, and the Eulerian node, which allows constraint handling that is independent of the initial discretization of the strand. The resulting system generates robust, efficient, and accurate simulations of massively constrained systems of rigid bodies and strands. ", 
        "id": 1340, 
        "title": "Large-scale dynamic simulation of highly constrained strands."
    }, 
    {
        "abstract": "", 
        "id": 1341, 
        "title": "Interactive editing of massive imagery made simple: Turning Atlanta into Atlantis."
    }, 
    {
        "abstract": "", 
        "id": 1342, 
        "title": "Metropolis procedural modeling."
    }, 
    {
        "abstract": "", 
        "id": 1343, 
        "title": "VolCCD: Fast continuous collision culling between deforming volume meshes."
    }, 
    {
        "abstract": "We present a general approach to creating realistic swimming behavior for a given articulated creature body. The two main components of our method are creature/fluid simulation and the optimization of the creature motion parameters. We simulate two-way coupling between the fluid and the articulated body by solving a linear system that matches acceleration at fluid/solid boundaries and that also enforces fluid incompressibility. The swimming motion of a given creature is described as a set of periodic functions, one for each joint degree of freedom. We optimize over the space of these functions in order to find a motion that causes the creature to swim straight and stay within a given energy budget. Our creatures can perform path following by first training appropriate turning maneuvers through offline optimization and then selecting between these motions to track the given path. We present results for a clownfish, an eel, a sea turtle, a manta ray and a frog, and in each case the resulting motion is a good match to the real-world animals. We also demonstrate a plausible swimming gait for a fictional creature that has no real-world counterpart. ", 
        "id": 1344, 
        "title": "Articulated swimming creatures."
    }, 
    {
        "abstract": "", 
        "id": 1345, 
        "title": "Simple quad domains for field aligned mesh parametrization."
    }, 
    {
        "abstract": "", 
        "id": 1346, 
        "title": "Motion reconstruction using sparse accelerometer data."
    }, 
    {
        "abstract": "Linear models, particularly those based on principal component analysis (PCA), have been used successfully on a broad range of human face-related applications. Although PCA models achieve high compression, they have not been widely used for animation in a production environment because their bases lack a semantic interpretation. Their parameters are not an intuitive set for animators to work with. In this paper we present a linear face modelling approach that generalises to unseen data better than the traditional holistic approach while also allowing click-and-drag interaction for animation. Our model is composed of a collection of PCA sub-models that are independently trained but share boundaries. Boundary consistency and user-given constraints are enforced in a soft least mean squares sense to give flexibility to the model while maintaining coherence. Our results show that the region-based model generalises better than its holistic counterpart when describing previously unseen motion capture data from multiple subjects. The decomposition of the face into several regions, which we determine automatically from training data, gives the user localised manipulation control. This feature allows to use the model for face posing and animation in an intuitive style. ", 
        "id": 1347, 
        "title": "Interactive region-based linear 3D face models."
    }, 
    {
        "abstract": "Although High Dynamic Range (HDR) imaging has been the subject of significant research over the past fifteen years, the goal of acquiring cinema-quality HDR images of fast-moving scenes using available components has not yet been achieved. In this work, we present an optical architecture for HDR imaging that allows simultaneous capture of high, medium, and low-exposure images on three sensors at high fidelity with efficient use of the available light. We also present an HDR merging algorithm to complement this architecture, which avoids undesired artifacts when there is a large exposure difference between the images. We implemented a prototype high-definition HDR-video system and we present still frames from the acquired HDR video, tonemapped with various techniques. ", 
        "id": 1348, 
        "title": "A versatile HDR video production system."
    }, 
    {
        "abstract": "We present a novel interactive tool for garment design that enables, for the first time, interactive bidirectional editing between 2D patterns and 3D high-fidelity simulated draped forms. This provides a continuous, interactive, and natural design modality in which 2D and 3D representations are simultaneously visible and seamlessly maintain correspondence. Artists can now interactively edit 2D pattern designs and immediately obtain stable accurate feedback online, thus enabling rapid prototyping and an intuitive understanding of complex drape form. ", 
        "id": 1349, 
        "title": "Sensitive couture for interactive garment modeling and editing."
    }, 
    {
        "abstract": "Yu-Shuen Wang1,2 Jen-Hung Hsiao2 Olga Sorkine3,4 Tong-Yee Lee2 1National Chiao Tung University 2National Cheng Kung University 3New York University 4ETH Zurich original video cube deformed video cube original frames deformed frames Figure 1: We introduce a scalable content-aware video retargeting method. Here, we render pairs of original and deformed motion trajectories in red and blue. Making the relative transformation of such pathlines consistent ensures temporal coherence of the resized video. Abstract The key to high-quality video resizing is preserving the shape and motion of visually salient objects while remaining temporally-coherent. These spatial and temporal requirements are difficult to reconcile, typically leading existing video retargeting methods to sacrifice one of them and causing distortion or waving artifacts. Recent work enforces temporal coherence of content-aware video warping by solving a global optimization problem over the entire video cube. This significantly improves the results but does not scale well with the resolution and length of the input video and quickly becomes intractable. We propose a new method that solves the scalability problem without compromising the resizing quality. Our method factors the problem into spatial and time/motion components: we first resize each frame independently to preserve the shape of salient regions, and then we optimize their motion using a reduced model for each pathline of the optical flow. This factorization decomposes the optimization of the video cube into sets of subproblems whose size is proportional to a single frames resolution and which can be solved in parallel. We also show how to incorporate cropping into our optimization, which is useful for scenes with numerous salient objects where warping alone would degenerate to linear scaling. Our results match the quality of state-of-the-art retargeting methods while dramatically reducing the computation time and memory consumption, making content-aware video resiz-ing scalable and practical.", 
        "id": 1350, 
        "title": "Scalable and coherent video resizing with per-frame optimization."
    }, 
    {
        "abstract": "Cloth often has complicated nonlinear, anisotropic elastic behavior due to its woven pattern and fiber properties. However, most current cloth simulation techniques simply use linear and isotropic elastic models with manually selected stiffness parameters. Such simple simulations do not allow differentiating the behavior of distinct cloth materials such as silk or denim, and they cannot model most materials with fidelity to their real-world counterparts. In this paper, we present a data-driven technique to more realistically animate cloth. We propose a piecewise linear elastic model that is a good approximation to nonlinear, anisotropic stretching and bending behaviors of various materials. We develop new measurement techniques for studying the elastic deformations for both stretching and bending in real cloth samples. Our setup is easy and inexpensive to construct, and the parameters of our model can be fit to observed data with a well-posed optimization procedure. We have measured a database of ten different cloth materials, each of which exhibits distinctive elastic behaviors. These measurements can be used in most cloth simulation systems to create natural and realistic clothing wrinkles and shapes, for a range of different materials.", 
        "id": 1351, 
        "title": "Data-driven elastic models for cloth: modeling and measurement."
    }, 
    {
        "abstract": "", 
        "id": 1352, 
        "title": "Estimating dual-scale properties of glossy surfaces from step-edge lighting."
    }, 
    {
        "abstract": "Color and tone adjustments are among the most frequent image enhancement operations. We define a color and tone style as a set of explicit or implicit rules governing color and tone adjustments. Our goal in this paper is to learn implicit color and tone adjustment rules from examples. That is, given a set of examples, each of which is a pair of corresponding images before and after adjustments, we would like to discover the underlying mathematical relationships optimally connecting the color and tone of corresponding pixels in all image pairs. We formally define tone and color adjustment rules as mappings, and propose to approximate complicated spatially varying nonlinear mappings in a piecewise manner. The reason behind this is that a very complicated mapping can still be locally approximated with a low-order polynomial model. Parameters within such low-order models are trained using data extracted from example image pairs. We successfully apply our framework in two scenarios, low-quality photo enhancement by transferring the style of a high-end camera, and photo enhancement using styles learned from photographers and designers. ", 
        "id": 1353, 
        "title": "Example-based image color and tone style enhancement."
    }, 
    {
        "abstract": "", 
        "id": 1354, 
        "title": "Multiscale vector volumes."
    }, 
    {
        "abstract": "", 
        "id": 1355, 
        "title": "Physically valid statistical models for human motion generation."
    }, 
    {
        "abstract": "This paper presents a system for performance-based character animation that enables any user to control the facial expressions of a digital avatar in realtime. The user is recorded in a natural environment using a non-intrusive, commercially available 3D sensor. The simplicity of this acquisition device comes at the cost of high noise levels in the acquired data. To effectively map low-quality 2D images and 3D depth maps to realistic facial expressions, we introduce a novel face tracking algorithm that combines geometry and texture registration with pre-recorded animation priors in a single optimization. Formulated as a maximum a posteriori estimation in a reduced parameter space, our method implicitly exploits temporal coherence to stabilize the tracking. We demonstrate that compelling 3D facial dynamics can be reconstructed in realtime without the use of face markers, intrusive lighting, or complex scanning hardware. This makes our system easy to deploy and facilitates a range of new applications, e.g. in digital gameplay or social interactions. ", 
        "id": 1356, 
        "title": "Realtime performance-based facial animation."
    }, 
    {
        "abstract": " Li-Yi Wei Microsoft Research  Rui Wang University of Massachusetts Amherst  Sampling is a core component for many graphics applications including rendering, imaging, animation, and geometry processing. The efficacy of these applications often crucially depends upon the distribution quality of the underlying samples. While uniform sampling can be analyzed by using existing spatial and spectral methods, these cannot be easily extended to general non-uniform settings, such as adaptive, anisotropic, or non-Euclidean domains. We present new methods for analyzing non-uniform sample distributions. Our key insight is that standard Fourier analysis, which depends on samples' spatial locations, can be reformulated into an equivalent form that depends only on the distribution of their location differentials. We call this differential domain analysis. The main benefit of this reformulation is that it bridges the fundamental connection between the samples' spatial statistics and their spectral properties. In addition, it allows us to generalize our method with different computation kernels and differential measurements. Using this analysis, we can quantitatively measure the spatial and spectral properties of various non-uniform sample distributions, including adaptive, anisotropic, and non-Euclidean domains.  3 2.5 2 1.5 1 0.5 0 10 20 30 40 50 60 70 80 90 frequency  uniform  3 2.5 2 1.5 1 0.5 0 0  0.02 0.04 0.06 0.08 0.1 0.12 0.14 |d|  ", 
        "id": 1357, 
        "title": "Differential domain analysis for non-uniform sampling."
    }, 
    {
        "abstract": "We develop tomographic techniques for image synthesis on displays composed of compact volumes of light-attenuating material. Such volumetric attenuators recreate a 4D light field or highcontrast 2D image when illuminated by a uniform backlight. Since arbitrary oblique views may be inconsistent with any single attenuator, iterative tomographic reconstruction minimizes the difference between the emitted and target light fields, subject to physical constraints on attenuation. As multi-layer generalizations of conventional parallax barriers, such displays are shown, both by theory and experiment, to exceed the performance of existing dual-layer architectures. For 3D display, spatial resolution, depth of field, and brightness are increased, compared to parallax barriers. For a plane at a fixed depth, our optimization also allows optimal construction of high dynamic range displays, confirming existing heuristics and providing the first extension to multiple, disjoint layers. We conclude by demonstrating the benefits and limitations of attenuationbased light field displays using an inexpensive fabrication method: separating multiple printed transparencies with acrylic sheets. ", 
        "id": 1358, 
        "title": "Layered 3D: tomographic image synthesis for attenuation-based light field and high dynamic range displays."
    }, 
    {
        "abstract": "", 
        "id": 1359, 
        "title": "Physically-based interactive bi-scale material design."
    }, 
    {
        "abstract": "A 3D burr puzzle is a 3D model that consists of interlocking pieces with a single-key property. That is, when the puzzle is assembled, all the pieces are notched except one single key component which remains mobile. The intriguing property of the assembled burr puzzle is that it is stable, perfectly interlocked, without glue or screws, etc. Moreover, a burr puzzle consisting of a small number of pieces is still rather difficult to solve since the assembly must follow certain orders while the combinatorial complexity of the puzzle's piece arrangements is extremely high. In this paper, we generalize the 6-piece orthogonal burr puzzle (a knot) to design and model burr puzzles from 3D models. Given a 3D input model, we first interactively embed a network of knots into the 3D shape. Our method automatically optimizes and arranges the orientation of each knot, and modifies pieces of adjacent knots with an appropriate connection type. Then, following the geometry of the embedded pieces, the entire 3D model is partitioned by splitting the solid while respecting the assembly motion of embedded pieces. The main technical challenge is to enforce the single-key property and ensure the assembly/disassembly remains feasible, as the puzzle pieces in a network of knots are highly interlocked. Lastly, we also present an automated approach to generate the visualizations of the puzzle assembly process. ", 
        "id": 1360, 
        "title": "Making burr puzzles from 3D models."
    }, 
    {
        "abstract": "We present a method to synthesize plausible video sequences of humans according to user-defined body motions and viewpoints. We first capture a small database of multi-view video sequences of an actor performing various basic motions. This database needs to be captured only once and serves as the input to our synthesis algorithm. We then apply a marker-less model-based performance capture approach to the entire database to obtain pose and geometry of the actor in each database frame. To create novel video sequences of the actor from the database, a user animates a 3D human skeleton with novel motion and viewpoints. Our technique then synthesizes a realistic video sequence of the actor performing the specified motion based only on the initial database. The first key component of our approach is a new efficient retrieval strategy to find appropriate spatio-temporally coherent database frames from which to synthesize target video frames. The second key component is a warping-based texture synthesis approach that uses the retrieved most-similar database frames to synthesize spatio-temporally coherent target video frames. For instance, this enables us to easily create video sequences of actors performing dangerous stunts without them being placed in harms way. We show through a variety of result videos and a user study that we can synthesize realistic videos of people, even if the target motions and camera views are different from the database content.", 
        "id": 1361, 
        "title": "Video-based characters: creating new human performances from a multi-view video database."
    }, 
    {
        "abstract": "", 
        "id": 1362, 
        "title": "Image smoothing via "
    }, 
    {
        "abstract": "", 
        "id": 1363, 
        "title": "Interactive hair rendering and appearance editing under environment lighting."
    }, 
    {
        "abstract": "We introduce an algorithm for 3D object modeling where the user draws creative inspiration from an object captured in a single photograph. Our method leverages the rich source of photographs for creative 3D modeling. However, with only a photo as a guide, creating a 3D model from scratch is a daunting task. We support the modeling process by utilizing an available set of 3D candidate models. Specifically, the user creates a digital 3D model as a geometric variation from a 3D candidate. Our modeling technique consists of two major steps. The first step is a user-guided image-space object segmentation to reveal the structure of the photographed object. The core step is the second one, in which a 3D candidate is automatically deformed to fit the photographed target under the guidance of silhouette correspondence. The set of candidate models have been pre-analyzed to possess useful high-level structural information, which is heavily utilized in both steps to compensate for the ill-posedness of the analysis and modeling problems based only on content in a single image. Equally important, the structural information is preserved by the geometric variation so that the final product is coherent with its inherited structural information readily usable for subsequent model refinement or processing. Links: DL PDF WEB VIDEO ", 
        "id": 1364, 
        "title": "Photo-inspired model-driven 3D object modeling."
    }, 
    {
        "abstract": "", 
        "id": 1365, 
        "title": "Antialiasing recovery."
    }, 
    {
        "abstract": "", 
        "id": 1366, 
        "title": "Image-based bidirectional scene reprojection."
    }, 
    {
        "abstract": "We address the problem of correcting an undesirable expression on a face photo by transferring local facial components, such as a smiling mouth, from another face photo of the same person which has the desired expression. Direct copying and blending using existing compositing tools results in semantically unnatural composites, since expression is a global effect and the local component in one expression is often incompatible with the shape and other components of the face in another expression. To solve this problem we present Expression Flow, a 2D flow field which can warp the target face globally in a natural way, so that the warped face is compatible with the new facial component to be copied over. To do this, starting with the two input face photos, we jointly construct a pair of 3D face shapes with the same identity but different expressions. The expression flow is computed by projecting the difference between the two 3D shapes back to 2D. It describes how to warp the target face photo to match the expression of the reference photo. User studies suggest that our system is able to generate face composites with much higher fidelity than existing methods. ", 
        "id": 1367, 
        "title": "Expression flow for 3D-aware face component transfer."
    }, 
    {
        "abstract": "", 
        "id": 1368, 
        "title": "Shape space exploration of constrained meshes."
    }, 
    {
        "abstract": "", 
        "id": 1369, 
        "title": "Matting and compositing of transparent and refractive objects."
    }, 
    {
        "abstract": "", 
        "id": 1370, 
        "title": "Pattern-guided smoke animation with lagrangian coherent structure."
    }, 
    {
        "abstract": "We present a system that automatically synthesizes indoor scenes realistically populated by a variety of furniture objects. Given examples of sensibly furnished indoor scenes, our system extracts, in advance, hierarchical and spatial relationships for various furniture objects, encoding them into priors associated with ergonomic factors, such as visibility and accessibility, which are assembled into a cost function whose optimization yields realistic furniture arrangements. To deal with the prohibitively large search space, the cost function is optimized by simulated annealing using a MetropolisHastings state search step. We demonstrate that our system can synthesize multiple realistic furniture arrangements and, through a perceptual study, investigate whether there is a significant difference in the perceived functionality of the automatically synthesized results relative to furniture arrangements produced by human designers. ", 
        "id": 1371, 
        "title": "Make it home: automatic optimization of furniture arrangement."
    }, 
    {
        "abstract": "", 
        "id": 1372, 
        "title": "An efficient scheme for curve and surface construction based on a set of interpolatory basis functions."
    }, 
    {
        "abstract": "The appearance of complex, thick materials like textiles is determined by their 3D structure, and they are incompletely described by surface reflection models alone. While volume scattering can produce highly realistic images of such materials, creating the required volume density models is difficult. Procedural approaches require significant programmer effort and intuition to design specialpurpose algorithms for each material. Further, the resulting models lack the visual complexity of real materials with their naturallyarising irregularities. This paper proposes a new approach to acquiring volume models, based on density data from X-ray computed tomography (CT) scans and appearance data from photographs under uncontrolled illumination. To model a material, a CT scan is made, resulting in a scalar density volume. This 3D data is processed to extract orientation information and remove noise. The resulting density and orientation fields are used in an appearance matching procedure to define scattering properties in the volume that, when rendered, produce images with texture statistics that match the photographs. As our results show, this approach can easily produce volume appearance models with extreme detail, and at larger scales the distinctive textures and highlights of a range of very different fabrics like satin and velvet emerge automatically--all based simply on having accurate mesoscale geometry. ", 
        "id": 1373, 
        "title": "Building volumetric appearance models of fabric using micro CT imaging."
    }, 
    {
        "abstract": "Contact sound models based on linear modal analysis are commonly used with rigid body dynamics. Unfortunately, treating vibrating objects as \"rigid\" during collision and contact processing fundamentally limits the range of sounds that can be computed, and contact solvers for rigid body animation can be ill-suited for modal contact sound synthesis, producing various sound artifacts. In this paper, we resolve modal vibrations in both collision and frictional contact processing stages, thereby enabling non-rigid sound phenomena such as micro-collisions, vibrational energy exchange, and chattering. We propose a frictional multibody contact formulation and modified Staggered Projections solver which is well-suited to sound rendering and avoids noise artifacts associated with spatial and temporal contact-force fluctuations which plague prior methods. To enable practical animation and sound synthesis of numerous bodies with many coupled modes, we propose a novel asynchronous integrator with model-level adaptivity built into the frictional contact solver. Vibrational contact damping is modeled to approximate contact-dependent sound dissipation. Results are provided that demonstrate high-quality contact resolution with sound. ", 
        "id": 1374, 
        "title": "Toward high-quality modal contact sound."
    }, 
    {
        "abstract": "", 
        "id": 1375, 
        "title": "Sketch-based Dynamic Illustration of Fluid Systems."
    }, 
    {
        "abstract": "", 
        "id": 1376, 
        "title": "Multi-scale partial intrinsic symmetry detection."
    }, 
    {
        "abstract": "", 
        "id": 1377, 
        "title": "Field-guided registration for feature-conforming shape composition."
    }, 
    {
        "abstract": "", 
        "id": 1378, 
        "title": "Speculative parallel asynchronous contact mechanics."
    }, 
    {
        "abstract": "", 
        "id": 1379, 
        "title": "Bilinear spatiotemporal basis models."
    }, 
    {
        "abstract": "We propose a momentum-conserving two-way coupling method of SPH fluids and arbitrary rigid objects based on hydrodynamic forces. Our approach samples the surface of rigid bodies with boundary particles that interact with the fluid, preventing deficiency issues and both spatial and temporal discontinuities. The problem of inhomogeneous boundary sampling is addressed by considering the relative contribution of a boundary particle to a physical quantity. This facilitates not only the initialization process but also allows the simulation of multiple dynamic objects. Thin structures consisting of only one layer or one line of boundary particles, and also non-manifold geometries can be handled without any additional treatment. We have integrated our approach into WCSPH and PCISPH, and demonstrate its stability and flexibility with several scenarios including multiphase flow. ", 
        "id": 1380, 
        "title": "Versatile rigid-fluid coupling for incompressible SPH."
    }, 
    {
        "abstract": "", 
        "id": 1381, 
        "title": "Fast high-resolution appearance editing using superimposed projections."
    }, 
    {
        "abstract": "We present a practical data-driven method for automatically synthesizing plausible soundtracks for physics-based cloth animations running at graphics rates. Given a cloth animation, we analyze the deformations and use motion events to drive crumpling and friction sound models estimated from cloth measurements. We synthesize a low-quality sound signal, which is then used as a target signal for a concatenative sound synthesis (CSS) process. CSS selects a sequence of microsound units, very short segments, from a database of recorded cloth sounds, which best match the synthesized target sound in a low-dimensional feature-space after applying a hand-tuned warping function. The selected microsound units are concatenated together to produce the final cloth sound with minimal filtering. Our approach avoids expensive physics-based synthesis of cloth sound, instead relying on cloth recordings and our motion-driven CSS approach for realism. We demonstrate its effectiveness on a variety of cloth animations involving various materials and character motions, including first-person virtual clothing with binaural sound.", 
        "id": 1382, 
        "title": "Motion-driven concatenative synthesis of cloth sounds."
    }, 
    {
        "abstract": "", 
        "id": 1383, 
        "title": "Interactive sound propagation using compact acoustic transfer operators."
    }, 
    {
        "abstract": "Articulated deformable characters are widespread in computer animation. Unfortunately, we lack methods for their automatic fabrication using modern additive manufacturing (AM) technologies. We propose a method that takes a skinned mesh as input, then estimates a fabricatable single-material model that approximates the 3D kinematics of the corresponding virtual articulated character in a piecewise linear manner. We first extract a set of potential joint locations. From this set, together with optional, user-specified range constraints, we then estimate mechanical friction joints that satisfy inter-joint non-penetration and other fabrication constraints. To avoid brittle joint designs, we place joint centers on an approximate medial axis representation of the input geometry, and maximize each joint's minimal cross-sectional area. We provide several demonstrations, manufactured as single, assembled pieces using 3D printers. ", 
        "id": 1384, 
        "title": "Fabricating articulated characters from skinned meshes."
    }, 
    {
        "abstract": "We present a semi-automated technique for selectively deanimating video to remove the large-scale motions of one or more objects so that other motions are easier to see. The user draws strokes to indicate the regions of the video that should be immobilized, and our algorithm warps the video to remove the large-scale motion of these regions while leaving finer-scale, relative motions intact. However, such warps may introduce unnatural motions in previously motionless areas, such as background regions. We therefore use a graph-cut-based optimization to composite the warped video regions with still frames from the input video; we also optionally loop the output in a seamless manner. Our technique enables a number of applications such as clearer motion visualization, simpler creation of artistic cinemagraphs (photos that include looping motions in some regions), and new ways to edit appearance and complicated motion paths in video by manipulating a de-animated representation. We demonstrate the success of our technique with a number of motion visualizations, cinemagraphs and video editing examples created from a variety of short input videos, as well as visual and numerical comparison to previous techniques. ACM Reference Format Bai, J., Agarwala, A., Agrawala, M., Ramamoorthi, R. 2012. Selectively De-Animating Video. ACM Trans. Graph. 31 4, Article 66 (July 2012), 10 pages. DOI = 10.1145/2185520.2185562 http://doi.acm.org/10.1145/2185520.2185562. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org.  2012 ACM 0730-0301/2012/08-ART66 $15.00 DOI 10.1145/2185520.2185562 http://doi.acm.org/10.1145/2185520.2185562  Links: DL PDF WEB VIDEO ", 
        "id": 1385, 
        "title": "Selectively de-animating video."
    }, 
    {
        "abstract": "", 
        "id": 1386, 
        "title": "Synthesis of concurrent object manipulation tasks."
    }, 
    {
        "abstract": "We present an interactive animation editor for complex deformable object animations. Given an existing animation, the artist directly manipulates the deformable body at any time frame, and the surrounding animation immediately adjusts in response. The automatic adjustments are designed to respect physics, preserve detail in both the input motion and geometry, respect prescribed bilateral contact constraints, and controllably and smoothly decay in spacetime. While the utility of interactive editing for rigid body and articulated figure animations is widely recognized, a corresponding approach to deformable bodies has not been technically feasible before. We achieve interactive rates by combining spacetime model reduction, rotation-strain coordinate warping, linearized elasticity, and direct manipulation. This direct editing tool can serve the final stages of animation production, which often call for detailed, direct adjustments that are otherwise tedious to realize by re-simulation or frame-by-frame editing. ", 
        "id": 1387, 
        "title": "Interactive editing of deformable simulations."
    }, 
    {
        "abstract": "", 
        "id": 1388, 
        "title": "High-quality curve rendering using line sampled visibility."
    }, 
    {
        "abstract": "We present the first reduced-dimensional technique to simulate the dynamics of thin sheets of viscous incompressible liquid in three dimensions. Beginning from a discrete Lagrangian model for elastic thin shells, we apply the Stokes-Rayleigh analogy to derive a simple yet consistent model for viscous forces. We incorporate nonlinear surface tension forces with a formulation based on minimizing discrete surface area, and preserve the quality of triangular mesh elements through local remeshing operations. Simultaneously, we track and evolve the thickness of each triangle to exactly conserve liquid volume. This approach enables the simulation of extremely thin sheets of viscous liquids, which are difficult to animate with existing volumetric approaches. We demonstrate our method with examples of several characteristic viscous sheet behaviors, including stretching, buckling, sagging, and wrinkling. ", 
        "id": 1389, 
        "title": "Discrete viscous sheets."
    }, 
    {
        "abstract": "REVEL is an augmented reality (AR) tactile technology that allows for change to the tactile feeling of real objects by augmenting them with virtual tactile textures using a device worn by the user. Unlike previous attempts to enhance AR environments with haptics, we neither physically actuate objects or use any force- or tactile-feedback devices, nor require users to wear tactile gloves or other apparatus on their hands. Instead, we employ the principle of reverse electrovibration where we inject a weak electrical signal anywhere on the user body creating an oscillating electrical field around the user's fingers. When sliding his or her fingers on a surface of the object, the user perceives highly distinctive tactile textures augmenting the physical object. By tracking the objects and location of the touch, we associate dynamic tactile sensations to the interaction context. REVEL is built upon our previous work on designing electrovibration-based tactile feedback for touch surfaces [Bau, et al. 2010]. In this paper we expand tactile interfaces based on electrovibration beyond touch surfaces and bring them into the real world. We demonstrate a broad range of application scenarios where our technology can be used to enhance AR interaction with dynamic and unobtrusive tactile feedback. ", 
        "id": 1390, 
        "title": "REVEL: tactile feedback technology for augmented reality."
    }, 
    {
        "abstract": " ", 
        "id": 1391, 
        "title": "Coupled 3D reconstruction of sparse facial hair and skin."
    }, 
    {
        "abstract": "", 
        "id": 1392, 
        "title": "Resolution enhancement by vibrating displays."
    }, 
    {
        "abstract": "We present a set of tools designed to help editors place cuts and create transitions in interview video. To help place cuts, our interface links a text transcript of the video to the corresponding locations in the raw footage. It also visualizes the suitability of cut locations by analyzing the audio/visual features of the raw footage to find frames where the speaker is relatively quiet and still. With these tools editors can directly highlight segments of text, check if the endpoints are suitable cut locations and if so, simply delete the text to make the edit. For each cut our system generates visible (e.g. jump-cut, fade, etc.) and seamless, hidden transitions.We present a hierarchical, graph-based algorithm for efficiently generating hidden transitions that considers visual features specific to interview footage. We also describe a new data-driven technique for setting the timing of the hidden transition. Finally, our tools offer a one click method for seamlessly removing 'ums' and repeated words as well as inserting natural-looking pauses to emphasize semantic content. We apply our tools to edit a variety of interviews and also show how they can be used to quickly compose multiple takes of an actor narrating a story. ", 
        "id": 1393, 
        "title": "Tools for placing cuts and transitions in interview video."
    }, 
    {
        "abstract": "", 
        "id": 1394, 
        "title": "Design-driven quadrangulation of closed 3D curves."
    }, 
    {
        "abstract": "We propose a complete process for designing, simulating, and fabricating synthetic skin for an animatronics character that mimics the face of a given subject and its expressions. The process starts with measuring the elastic properties of a material used to manufacture synthetic soft tissue. Given these measurements we use physicsbased simulation to predict the behavior of a face when it is driven by the underlying robotic actuation. Next, we capture 3D facial expressions for a given target subject. As the key component of our process, we present a novel optimization scheme that determines the shape of the synthetic skin as well as the actuation parameters that provide the best match to the target expressions. We demonstrate this computational skin design by physically cloning a real human face onto an animatronics figure. ", 
        "id": 1395, 
        "title": "Physical face cloning."
    }, 
    {
        "abstract": "We present a method for recovering a temporally coherent, deforming triangle mesh with arbitrarily changing topology from an incoherent sequence of static closed surfaces. We solve this problem using the surface geometry alone, without any prior information like surface templates or velocity fields. Our system combines a proven strategy for triangle mesh improvement, a robust multi-resolution non-rigid registration routine, and a reliable technique for changing surface mesh topology. We also introduce a novel topological constraint enforcement algorithm to ensure that the output and input always have similar topology. We apply our technique to a series of diverse input data from video reconstructions, physics simulations, and artistic morphs. The structured output of our algorithm allows us to efficiently track information like colors and displacement maps, recover velocity information, and solve PDEs on the mesh as a post process. ", 
        "id": 1396, 
        "title": "Tracking surfaces with evolving topology."
    }, 
    {
        "abstract": "We present an approach to high-level shape editing that adapts the structure of the shape while maintaining its global characteristics. Our main contribution is a new algebraic model of shape structure that characterizes shapes in terms of linked translational patterns. The space of shapes that conform to this characterization is parameterized by a small set of numerical parameters bounded by a set of linear constraints. This convex space permits a direct exploration of variations of the input shape. We use this representation to develop a robust interactive system that allows shapes to be intuitively manipulated through sparse constraints. ", 
        "id": 1397, 
        "title": "An algebraic model for parameterized shape editing."
    }, 
    {
        "abstract": "", 
        "id": 1398, 
        "title": "RigMesh: automatic rigging for part-based shape modeling and deformation."
    }, 
    {
        "abstract": "", 
        "id": 1399, 
        "title": "User-guided white balance for mixed lighting conditions."
    }, 
    {
        "abstract": "", 
        "id": 1400, 
        "title": "MultiFLIP for energetic two-phase fluid simulation."
    }, 
    {
        "abstract": "", 
        "id": 1401, 
        "title": "A vectorial solver for free-form vector gradients."
    }, 
    {
        "abstract": "Continuous collision detection (CCD) between deforming triangle mesh elements in 3D is a critical tool for many applications. The standard method involving a cubic polynomial solver is vulnerable to rounding error, requiring the use of ad hoc tolerances, and nevertheless is particularly fragile in (near-)planar cases. Even with per-simulation tuning, it may still cause problems by missing collisions or erroneously flagging non-collisions. We present a geometrically exact alternative guaranteed to produce the correct Boolean result (significant collision or not) as if calculated with exact arithmetic, even in degenerate scenarios. Our critical insight is that only the parity of the number of collisions is needed for robust simulation, and this parity can be calculated with simpler non-constructive predicates. In essence we analyze the roots of the nonlinear system of equations defining CCD through careful consideration of the boundary of the parameter domain. The use of new conservative culling and interval filters allows typical simulations to run as fast as with the non-robust version, but without need for tuning or worries about failure cases even in geometrically degenerate scenarios. We demonstrate the effectiveness of geometrically exact detection with a novel adaptive cloth simulation, the first to guarantee to remain intersection-free despite frequent curvature-driven remeshing. ", 
        "id": 1402, 
        "title": "Efficient geometrically exact continuous collision detection."
    }, 
    {
        "abstract": "We present a fully automatic method for design-preserving transfer of garments between characters with different body shapes. For real-life garments, such transfer is performed through a knowledge intensive and time consuming process, known as pattern grading. Our first contribution is to reformulate the criteria used in professional pattern-grading as a set of geometric requirements, respectively expressing shape or design preservation, proportionality, and fit. We then propose a fully automatic garment transfer algorithm which satisfies all of these criteria while ensuring the physical plausibility of the result. Specifically, we formulate garment transfer as a constrained optimization problem and solve it efficiently through iterative quadratic minimization. As demonstrated by our results, our method is able to automatically generate design-preserving versions of existing garments for target characters whose proportions and body shape significantly differ from those of the source. The method correctly handles the transfer of multiple layers of garment. Lastly, when source 2D patterns are available, we output graded patterns suitable for manufacturing the transferred garments. Our fully automatic design-preserving transfer method leads to significant time savings for both computer artists and fashion designers. ", 
        "id": 1403, 
        "title": "Design preserving garment transfer."
    }, 
    {
        "abstract": "Bubbles and foams are important features of liquid surface phenomena, but they are difficult to animate due to their thin films and complex interactions in the real world. In particular, small bubbles (having diameter <1cm) in a dense foam are highly affected by surface tension, so their shapes are much less deformable compared with larger bubbles. Under this small bubble assumption, we propose a more accurate and efficient particle-based algorithm to simulate bubble dynamics and interactions. The key component of this algorithm is an approximation of foam geometry, by treating bubble particles as the sites of a weighted Voronoi diagram. The connectivity information provided by the Voronoi diagram allows us to accurately model various interaction effects among bubbles. Using Voronoi cells and weights, we can also explicitly address the volume loss issue in foam simulation, which is a common problem in previous approaches. Under this framework, we present a set of bubble interaction forces to handle miscellaneous foam behaviors, including foam structure under Plateau's laws, clusters formed by liquid surface bubbles, bubble-liquid and bubble-solid coupling, bursting and coalescing. Our experiment shows that this method can be straightforwardly incorporated into existing liquid simulators, and it can efficiently generate realistic foam animations, some of which have never been produced in graphics before. ", 
        "id": 1404, 
        "title": "Animating bubble interactions in a liquid foam."
    }, 
    {
        "abstract": "", 
        "id": 1405, 
        "title": "New measurements reveal weaknesses of image quality metrics in evaluating graphics artifacts."
    }, 
    {
        "abstract": "", 
        "id": 1406, 
        "title": "3D-printing of non-assembly, articulated models."
    }, 
    {
        "abstract": "We present a theoretical framework and practical method for the automatic construction of simple, all-quadrilateral patch layouts on manifold surfaces. The resulting layouts are coarse, surface-embedded cell complexes well adapted to the geometric structure, hence they are ideally suited as domains and base complexes for surface parameterization, spline fitting, or subdivision surfaces and can be used to generate quad meshes with a high-level patch structure that are advantageous in many application scenarios. Our approach is based on the careful construction of the layout graphs combinatorial dual. In contrast to the primal this dual perspective provides direct control over the globally interdependent structural constraints inherent to quad layouts. The dual layout is built from curvature-guided, crossing loops on the surface. A novel method to construct these efficiently in a geometryand structure-aware manner constitutes the core of our approach.", 
        "id": 1407, 
        "title": "Dual loops meshing: quality quad layouts on manifolds."
    }, 
    {
        "abstract": "", 
        "id": 1408, 
        "title": "Automatic stylistic manga layout."
    }, 
    {
        "abstract": " We introduce an efficient method for synthesizing acceleration noise  sound produced when an object experiences abrupt rigidbody acceleration due to collisions or other contact events. We approach this in two main steps. First, we estimate continuous contact force profiles from rigid-body impulses using a simple model based on Hertz contact theory. Next, we compute solutions to the acoustic wave equation due to short acceleration pulses in each rigid-body degree of freedom. We introduce an efficient representation for these solutions  Precomputed Acceleration Noise  which allows us to accurately estimate sound due to arbitrary rigid-body accelerations. We find that the addition of acceleration noise significantly complements the standard modal sound algorithm, especially for small objects.  ", 
        "id": 1409, 
        "title": "Precomputed acceleration noise for improved rigid-body sound."
    }, 
    {
        "abstract": "Human hair is known to be very difficult to model or reconstruct. In this paper, we focus on applications related to portrait manipulation and take an application-driven approach to hair modeling. To enable an average user to achieve interesting portrait manipulation results, we develop a single-view hair modeling technique with modest user interaction to meet the unique requirements set by portrait manipulation. Our method relies on heuristics to generate a plausible high-resolution strand-based 3D hair model. This is made possible by an effective high-precision 2D strand tracing algorithm, which explicitly models uncertainty and local layering during tracing. The depth of the traced strands is solved through an optimization, which simultaneously considers depth constraints, layering constraints as well as regularization terms. Our single-view hair modeling enables a number of interesting applications that were previously challenging, including transferring the hairstyle of one subject to another in a potentially different pose, rendering the original portrait in a novel view and image-space hair editing.", 
        "id": 1410, 
        "title": "Single-view hair modeling for portrait manipulation."
    }, 
    {
        "abstract": "", 
        "id": 1411, 
        "title": "Depth-presorted triangle lists."
    }, 
    {
        "abstract": "This paper investigates \"Schelling points\" on 3D meshes, feature points selected by people in a pure coordination game due to their salience. To collect data for this investigation, we designed an online experiment that asked people to select points on 3D surfaces that they expect will be selected by other people. We then analyzed properties of the selected points, finding that: 1) Schelling point sets are usually highly symmetric, and 2) local curvature properties (e.g., Gauss curvature) are most helpful for identifying obvious Schelling points (tips of protrusions), but 3) global properties (e.g., segment centeredness, proximity to a symmetry axis, etc.) are required to explain more subtle features. Based on these observations, we use regression analysis to combine multiple properties into an analytical model that predicts where Schelling points are likely to be on new meshes. We find that this model benefits from a variety of surface properties, particularly when training data comes from examples in the same object class. ", 
        "id": 1412, 
        "title": "Schelling points on 3D surface meshes."
    }, 
    {
        "abstract": "", 
        "id": 1413, 
        "title": "Manifold preserving edit propagation."
    }, 
    {
        "abstract": "Videos captured by hand-held cameras often contain significant camera shake, causing many frames to be blurry. Restoring shaky videos not only requires smoothing the camera motion and stabilizing the content, but also demands removing blur from video frames. However, video blur is hard to remove using existing single or multiple image deblurring techniques, as the blur kernel is both spatially and temporally varying. This paper presents a video deblurring method that can effectively restore sharp frames from blurry ones caused by camera shake. Our method is built upon the observation that due to the nature of camera shake, not all video frames are equally blurry. The same object may appear sharp on some frames while blurry on others. Our method detects sharp regions in the video, and uses them to restore blurry regions of the same content in nearby frames. Our method also ensures that the deblurred frames are both spatially and temporally coherent using patch-based synthesis. Experimental results show that our method can effectively remove complex video blur under the presence of moving objects and other outliers, which cannot be achieved using previous deconvolution-based approaches. ", 
        "id": 1414, 
        "title": "Video deblurring for hand-held cameras using patch-based synthesis."
    }, 
    {
        "abstract": "We present a method for controlling the motions of active deformable characters. As an underlying principle, we require that all motions be driven by internal deformations. We achieve this by dynamically adapting rest shapes in order to induce deformations that, together with environment interactions, result in purposeful and physically-plausible motions. Rest shape adaptation is a powerful concept and we show that by restricting shapes to suitable subspaces, it is possible to explicitly control the motion styles of deformable characters. Our formulation is general and can be combined with arbitrary elastic models and locomotion controllers. We demonstrate the efficiency of our method by animating curve, shell, and solid-based characters whose motion repertoires range from simple hopping to complex walking behaviors. ", 
        "id": 1415, 
        "title": "Deformable objects alive!"
    }, 
    {
        "abstract": "", 
        "id": 1416, 
        "title": "Reflectance model for diffraction."
    }, 
    {
        "abstract": "Current methods for combining two different images produce visible artifacts when the sources have very different textures and structures. We present a new method for synthesizing a transition region between two source images, such that inconsistent color, texture, and structural properties all change gradually from one source to the other. We call this process image melding. Our method builds upon a patch-based optimization foundation with three key generalizations: First, we enrich the patch search space with additional geometric and photometric transformations. Second, we integrate image gradients into the patch representation and replace the usual color averaging with a screened Poisson equation solver. And third, we propose a new energy based on mixed L2/L0 norms for colors and gradients that produces a gradual transition between sources without sacrificing texture sharpness. Together, all three generalizations enable patch-based solutions to a broad class of image melding problems involving inconsistent sources: object cloning, stitching challenging panoramas, hole filling from multiple photos, and image harmonization. In several cases, our unified method outperforms previous state-of-the-art methods specifically designed for those applications.", 
        "id": 1417, 
        "title": "Image melding: combining inconsistent images using patch-based synthesis."
    }, 
    {
        "abstract": "", 
        "id": 1418, 
        "title": "A luminance-contrast-aware disparity model and applications."
    }, 
    {
        "abstract": "", 
        "id": 1419, 
        "title": "An inverse problem approach for automatically adjusting the parameters for rendering clouds using photographs."
    }, 
    {
        "abstract": "Given a large repository of geotagged imagery, we seek to automatically find visual elements, e.g. windows, balconies, and street signs, that are most distinctive for a certain geo-spatial area, for example the city of Paris. This is a tremendously difficult task as the visual features distinguishing architectural elements of different places can be very subtle. In addition, we face a hard search problem: given all possible patches in all images, which of them are both frequently occurring and geographically informative? To address these issues, we propose to use a discriminative clustering approach able to take into account the weak geographic supervision. We show that geographically representative image elements can be discovered automatically from Google Street View imagery in a discriminative manner. We demonstrate that these elements are visually interpretable and perceptually geo-informative. The discovered visual elements can also support a variety of computational geography tasks, such as mapping architectural correspondences and influences within and across cities, finding representative elements at different geo-spatial scales, and geographically-informed image retrieval.", 
        "id": 1420, 
        "title": "What makes Paris look like Paris?"
    }, 
    {
        "abstract": "We present a solution for viewing high dynamic range (HDR) images with spatially-varying distributions of glossy materials printed on reflective media. Our method exploits appearance variations of the glossy materials in the angular domain to display the input HDR image at different exposures. As viewers change the print orientation or lighting directions, the print gradually varies its appearance to display the image content from the darkest to the brightest levels. Our solution is based on a commercially available printing system and is fully automatic. Given the input HDR image and the BRDFs of a set of available inks, our method computes the optimal exposures of the HDR image for all viewing conditions and the optimal ink combinations for all pixels by minimizing the difference of their appearances under all viewing conditions. We demonstrate the effectiveness of our method with print samples generated from different inputs and visualized under different viewing and lighting conditions. ", 
        "id": 1421, 
        "title": "Printing spatially-varying reflectance for reproducing HDR images."
    }, 
    {
        "abstract": "Humans have used sketching to depict our visual world since prehistoric times. Even today, sketching is possibly the only rendering technique readily available to all humans. This paper is the first large scale exploration of human sketches. We analyze the distribution of non-expert sketches of everyday objects such as `teapot' or `car'. We ask humans to sketch objects of a given category and gather 20,000 unique sketches evenly distributed over 250 object categories. With this dataset we perform a perceptual study and find that humans can correctly identify the object category of a sketch 73% of the time. We compare human performance against computational recognition methods. We develop a bag-of-features sketch representation and use multi-class support vector machines, trained on our sketch dataset, to classify sketches. The resulting recognition method is able to identify unknown sketches with 56% accuracy (chance is 0.4%). Based on the computational model, we demonstrate an interactive sketch recognition system. We release the complete crowd-sourced dataset of sketches to the community. ", 
        "id": 1422, 
        "title": "How do humans sketch objects?"
    }, 
    {
        "abstract": "We develop a system for 3D object retrieval based on sketched feature lines as input. For objective evaluation, we collect a large number of query sketches from human users that are related to an existing data base of objects. The sketches turn out to be generally quite abstract with large local and global deviations from the original shape. Based on this observation, we decide to use a bagof-features approach over computer generated line drawings of the objects. We develop a targeted feature transform based on Gabor filters for this system. We can show objectively that this transform is better suited than other approaches from the literature developed for similar tasks. Moreover, we demonstrate how to optimize the parameters of our, as well as other approaches, based on the gathered sketches. In the resulting comparison, our approach is significantly better than any other system described so far. ", 
        "id": 1423, 
        "title": "Sketch-based shape retrieval."
    }, 
    {
        "abstract": "Divided differences play a fundamental role in the construction of univariate B-splines over irregular knot sequences. Unfortunately, generalizations of divided differences to irregular knot geometries on two-dimensional domains are quite limited. As a result, most spline constructions for such domains typically focus on regular (or semi-regular) knot geometries. In the planar harmonic case, we show that the discrete Laplacian plays a role similar to that of the divided differences and can be used to define well-behaved harmonic B-splines. In our main contribution, we then construct an analogous discrete bi-Laplacian for both planar and curved domains and show that its corresponding biharmonic B-splines are also well-behaved. Finally, we derive a fully irregular, discrete refinement scheme for these splines that generalizes knot insertion for univariate B-splines. ", 
        "id": 1424, 
        "title": "Discrete bi-Laplacians and biharmonic b-splines."
    }, 
    {
        "abstract": "", 
        "id": 1425, 
        "title": "Example-based synthesis of 3D object arrangements."
    }, 
    {
        "abstract": "Procedural noise is a fundamental tool in Computer Graphics. However, designing noise patterns is hard. In this paper, we present Gabor noise by example, a method to estimate the parameters of bandwidth-quantized Gabor noise, a procedural noise function that can generate noise with an arbitrary power spectrum, from exemplar Gaussian textures, a class of textures that is completely characterized by their power spectrum. More specifically, we introduce (i) bandwidth-quantized Gabor noise, a generalization of Gabor noise to arbitrary power spectra that enables robust parameter estimation and efficient procedural evaluation; (ii) a robust parameter estimation technique for quantized-bandwidth Gabor noise, that automatically decomposes the noisy power spectrum estimate of an exemplar into a sparse sum of Gaussians using non-negative basis pursuit denoising; and (iii) an efficient procedural evaluation scheme for bandwidth-quantized Gabor noise, that uses multi-grid evaluation and importance sampling of the kernel parameters. Gabor noise by example preserves the traditional advantages of procedural noise, including a compact representation and a fast on-the-fly evaluation, and is mathematically well-founded.", 
        "id": 1426, 
        "title": "Gabor noise by example."
    }, 
    {
        "abstract": "We present a technique for performing high-dimensional filtering of images and videos in real time. Our approach produces high-quality results and accelerates filtering by computing the filter's response at a reduced set of sampling points, and using these for interpolation at all N input pixels. We show that for a proper choice of these sampling points, the total cost of the filtering operation is linear both in N and in the dimension d of the space in which the filter operates. As such, ours is the first high-dimensional filter with such a complexity. We present formal derivations for the equations that define our filter, as well as for an algorithm to compute the sampling points. This provides a sound theoretical justification for our method and for its properties. The resulting filter is quite flexible, being capable of producing responses that approximate either standard Gaussian, bilateral, or non-local-means filters. Such flexibility also allows us to demonstrate the first hybrid Euclidean-geodesic filter that runs in a single pass. Our filter is faster and requires less memory than previous approaches, being able to process a 10Megapixel full-color image at 50 fps on modern GPUs. We illustrate the effectiveness of our approach by performing a variety of tasks ranging from edge-aware color filtering in 5-D, noise reduction (using up to 147 dimensions), single-pass hybrid Euclideangeodesic filtering, and detail enhancement, among others. ", 
        "id": 1427, 
        "title": "Adaptive manifolds for real-time high-dimensional filtering."
    }, 
    {
        "abstract": "", 
        "id": 1428, 
        "title": "Light transport simulation with vertex connection and merging."
    }, 
    {
        "abstract": "", 
        "id": 1429, 
        "title": "Micro perceptual human computation for visual tasks."
    }, 
    {
        "abstract": "", 
        "id": 1430, 
        "title": "Blue noise through optimal transport."
    }, 
    {
        "abstract": "", 
        "id": 1431, 
        "title": "Large-scale fluid simulation using velocity-vorticity domain decomposition."
    }, 
    {
        "abstract": "", 
        "id": 1432, 
        "title": "Video stabilization using epipolar geometry."
    }, 
    {
        "abstract": "We present a novel approach for highly detailed 3D imaging of turbulent fluid mixing behaviors. The method is based on visible light computed tomography, and is made possible by a new stochastic tomographic reconstruction algorithm based on random walks. We show that this new stochastic algorithm is competitive with specialized tomography solvers such as SART, but can also easily include arbitrary convex regularizers that make it possible to obtain highquality reconstructions with a very small number of views. Finally, we demonstrate that the same stochastic tomography approach can also be used to directly re-render arbitrary 2D projections without the need to ever store a 3D volume grid. ", 
        "id": 1433, 
        "title": "Stochastic tomography and its applications in 3D imaging of mixing fluids."
    }, 
    {
        "abstract": "We describe a complete system for animating realistic clothing on synthetic bodies of any shape and pose without manual intervention. The key component of the method is a model of clothing called DRAPE (DRessing Any PErson) that is learned from a physics-based simulation of clothing on bodies of different shapes and poses. The DRAPE model has the desirable property of \"factoring\" clothing deformations due to body shape from those due to pose variation. This factorization provides an approximation to the physical clothing deformation and greatly simplifies clothing synthesis. Given a parameterized model of the human body with known shape and pose parameters, we describe an algorithm that dresses the body with a garment that is customized to fit and possesses realistic wrinkles. DRAPE can be used to dress static bodies or animated sequences with a learned model of the cloth dynamics. Since the method is fully automated, it is appropriate for dressing large numbers of virtual characters of varying shape. The method is significantly more efficient than physical simulation. ", 
        "id": 1434, 
        "title": "DRAPE: DRessing Any PErson."
    }, 
    {
        "abstract": "", 
        "id": 1435, 
        "title": "Foveated 3D graphics."
    }, 
    {
        "abstract": "", 
        "id": 1436, 
        "title": "A statistical similarity measure for aggregate crowd dynamics."
    }, 
    {
        "abstract": "", 
        "id": 1437, 
        "title": "A path space extension for robust light transport simulation."
    }, 
    {
        "abstract": "", 
        "id": 1438, 
        "title": "Sparse PDF maps for non-linear multi-resolution image operations."
    }, 
    {
        "abstract": "We present a method that brings the benefits of physics-based simulations to traditional animation pipelines. We formulate the equations of motions in the subspace of deformations defined by an animator's rig. Our framework fits seamlessly into the workflow typically employed by artists, as our output consists of animation curves that are identical in nature to the result of manual keyframing. Artists can therefore explore the full spectrum between handcrafted animation and unrestricted physical simulation. To enhance the artist's control, we provide a method that transforms stiffness values defined on rig parameters to a non-homogeneous distribution of material parameters for the underlying FEM model. In addition, we use automatically extracted high-level rig parameters to intuitively edit the results of our simulations, and also to speed up computation. To demonstrate the effectiveness of our method, we create compelling results by adding rich physical motions to coarse input animations. In the absence of artist input, we create realistic passive motion directly in rig space. ", 
        "id": 1439, 
        "title": "Rig-space physics."
    }, 
    {
        "abstract": "", 
        "id": 1440, 
        "title": "Falling and landing motion control for character animation."
    }, 
    {
        "abstract": "", 
        "id": 1441, 
        "title": "Updated sparse cholesky factors for corotational elastodynamics."
    }, 
    {
        "abstract": "", 
        "id": 1442, 
        "title": "Staggered meshless solid-fluid coupling."
    }, 
    {
        "abstract": "", 
        "id": 1443, 
        "title": "Lighting hair from the inside: a thermal approach to hair reconstruction."
    }, 
    {
        "abstract": "Creating motions of objects or characters that are physically plausible and follow an animator's intent is a key task in computer animation. The spacetime constraints paradigm is a valuable approach to this problem, but it suffers from high computational costs. Based on spacetime constraints, we propose a framework for controlling the motion of deformable objects that offers interactive response times. This is achieved by a model reduction of the underlying variational problem, which combines dimension reduction, multipoint linearization, and decoupling of ODEs. After a preprocess, the cost for creating or editing a motion is reduced to solving a number of one-dimensional spacetime problems, whose solutions are the wiggly splines introduced by Kass and Anderson [2008]. We achieve interactive response times through a new fast and robust numerical scheme for solving the one-dimensional problems that is based on a closed-form representation of the wiggly splines. ", 
        "id": 1444, 
        "title": "Interactive spacetime control of deformable objects."
    }, 
    {
        "abstract": "We present a physically-based analytical model of the daytime sky. Based on the results of a first-principles brute force simulation of radiative transfer in the atmosphere, we use the same general approach of fitting basis function coefficients to radiance data as the Perez and Preetham models do. However, we make several modifications to this process, which together significantly improve the rendition of sunsets and high atmospheric turbidity setups  known weak points of the Preetham model. Additionally, our model accounts for ground albedo, and handles each spectral component independently. The latter property makes it easily extensible to the near ultraviolet range of the spectrum, so that the daylight appearance of surfaces that include optical brighteners can be properly predicted. Due to its similar mathematical properties, the new model can be used as a drop-in replacement of the Preetham model. ", 
        "id": 1445, 
        "title": "An analytic model for full spectral sky-dome radiance."
    }, 
    {
        "abstract": "With recent advances in real-time graphics technology, more realistic, believable and appealing virtual characters are needed than ever before. Both player-controlled avatars and non-player characters are now starting to interact with the environment, other virtual humans and crowds. However, simulating physical contacts between characters and matching appropriate reactions to specific actions is a highly complex problem, and timing errors, force mismatches and angular distortions are common. To investigate the effect of such anomalies on the perceived realism of two-character interactions, we captured a motion corpus of pushing animations and corresponding reactions and then conducted a series of perceptual experiments. We found that participants could easily distinguish between five different interaction forces, even when only one of the characters was visible. Furthermore, they were sensitive to all three types of anomalous interactions: timing errors of over 150ms were acceptable less than 50% of the time, with early or late reactions being equally perceptible; participants could perceive force mismatches, though over-reactions were more acceptable than under-reactions; finally, angular distortions when a character reacts to a pushing force reduce the acceptability of the interactions, but there is some evidence for a preference of expansion away from the pushing character's body. Our results provide insights to aid in designing motion capture sessions, motion editing strategies and balancing animation budgets. ", 
        "id": 1446, 
        "title": "Push it real: perceiving causality in virtual interactions."
    }, 
    {
        "abstract": "", 
        "id": 1447, 
        "title": "Automated constraint placement to maintain pile shape."
    }, 
    {
        "abstract": "", 
        "id": 1448, 
        "title": "Correcting for optical aberrations using multilayer displays."
    }, 
    {
        "abstract": "", 
        "id": 1449, 
        "title": "An optimization approach for extracting and encoding consistent maps in a shape collection."
    }, 
    {
        "abstract": "We introduce the interactive system \"Beady\" to assist the design and construction of customized 3D beadwork. The user first creates a polygonal mesh model called the design model that represents the overall structure of the beadwork. Each edge of the mesh model corresponds to a bead in the beadwork. We provide two methods to create the design model. One is interactive modeling from scratch. The user defines the mesh topology with gestural interaction and the system continuously adjusts edge lengths by considering the physical constraints among neighboring beads. The other is automatic conversion that takes an existing polygonal model as input and generates a near-hexagonal mesh model with a near-uniform edge length as output. The system then converts the design model into a beadwork model with the appropriate wiring. Computation of an appropriate wiring path requires careful consideration, and we present an algorithm based on face stripification of the mesh. The system also provides a visual step-by-step guide to assist the manual beadwork construction process. We show several beadwork designs constructed by the authors and by test users using the system.  ", 
        "id": 1450, 
        "title": "Beady: interactive beadwork design and construction."
    }, 
    {
        "abstract": "", 
        "id": 1451, 
        "title": "Specular reflection from woven cloth."
    }, 
    {
        "abstract": "", 
        "id": 1452, 
        "title": "Interactive bi-scale editing of highly glossy materials."
    }, 
    {
        "abstract": "Skinning transformations are a popular way to articulate shapes and characters. However, traditional animation interfaces require all of the skinning transformations to be specified explicitly, typically using a control structure (a rig). We propose a system where the user specifies only a subset of the degrees of freedom and the rest are automatically inferred using nonlinear, rigidity energies. By utilizing a low-order model and reformulating our energy functions accordingly, our algorithm runs orders of magnitude faster than previous methods without compromising quality. In addition to the immediate boosts in performance for existing modeling and real time animation tools, our approach also opens the door to new modes of control: disconnected skeletons combined with shape-aware inverse kinematics. With automatically generated skinning weights, our method can also be used for fast variational shape modeling.", 
        "id": 1453, 
        "title": "Fast automatic skinning transformations."
    }, 
    {
        "abstract": "", 
        "id": 1454, 
        "title": "Three-dimensional proxies for hand-drawn characters."
    }, 
    {
        "abstract": "", 
        "id": 1455, 
        "title": "Material memex: automatic material suggestions for 3D objects."
    }, 
    {
        "abstract": "It is a long-standing problem in unbiased Monte Carlo methods for rendering that certain difficult types of light transport paths, particularly those involving viewing and illumination along paths containing specular or glossy surfaces, cause unusably slow convergence. In this paper we introduce Manifold Exploration, a new way of handling specular paths in rendering. It is based on the idea that sets of paths contributing to the image naturally form manifolds in path space, which can be explored locally by a simple equationsolving iteration. This paper shows how to formulate and solve the required equations using only geometric information that is already generally available in ray tracing systems, and how to use this method in in two different Markov Chain Monte Carlo frameworks to accurately compute illumination from general families of paths. The resulting rendering algorithms handle specular, near-specular, glossy, and diffuse surface interactions as well as isotropic or highly anisotropic volume scattering interactions, all using the same fundamental algorithm. An implementation is demonstrated on a range of challenging scenes and evaluated against previous methods. ", 
        "id": 1456, 
        "title": "Manifold exploration: a Markov Chain Monte Carlo technique for rendering scenes with difficult specular transport."
    }, 
    {
        "abstract": "", 
        "id": 1457, 
        "title": "Theory, analysis and applications of 2D global illumination."
    }, 
    {
        "abstract": "", 
        "id": 1458, 
        "title": "PolyDepth: Real-time penetration depth computation using iterative contact-space projection."
    }, 
    {
        "abstract": "", 
        "id": 1459, 
        "title": "Data-driven finger motion synthesis for gesturing characters."
    }, 
    {
        "abstract": "We present an approach to synthesizing shapes from complex domains, by identifying new plausible combinations of components from existing shapes. Our primary contribution is a new generative model of component-based shape structure. The model represents probabilistic relationships between properties of shape components, and relates them to learned underlying causes of structural variability within the domain. These causes are treated as latent variables, leading to a compact representation that can be effectively learned without supervision from a set of compatibly segmented shapes. We evaluate the model on a number of shape datasets with complex structural variability and demonstrate its application to amplification of shape databases and to interactive shape synthesis. ", 
        "id": 1460, 
        "title": "A probabilistic model for component-based shape synthesis."
    }, 
    {
        "abstract": "", 
        "id": 1461, 
        "title": "Learning hatching for pen-and-ink illustration of surfaces."
    }, 
    {
        "abstract": "", 
        "id": 1462, 
        "title": "Elasticity-inspired deformers for character articulation."
    }, 
    {
        "abstract": "", 
        "id": 1463, 
        "title": "GPU-accelerated path rendering."
    }, 
    {
        "abstract": "", 
        "id": 1464, 
        "title": "Symmetry-guided texture synthesis and manipulation."
    }, 
    {
        "abstract": " Large collections of 3D models from the same object class (e.g., chairs, cars, animals) are now commonly available via many public repositories, but exploring the range of shape variations across such collections remains a challenging task. In this work, we present a new exploration interface that allows users to browse collections based on similarities and differences between shapes in userspecified regions of interest (ROIs). To support this interactive system, we introduce a novel analysis method for computing similarity relationships between points on 3D shapes across a collection. We encode the inherent ambiguity in these relationships using fuzzy point correspondences and propose a robust and efficient computational framework that estimates fuzzy correspondences using only a sparse set of pairwise model alignments. We evaluate our analysis method on a range of correspondence benchmarks and report substantial improvements in both speed and accuracy over existing alternatives. In addition, we demonstrate how fuzzy correspondences enable key features in our exploration tool, such as automated view alignment, ROI-based similarity search, and faceted browsing. ", 
        "id": 1465, 
        "title": "Exploring collections of 3D models using fuzzy correspondences."
    }, 
    {
        "abstract": "", 
        "id": 1466, 
        "title": "Acquiring 3D indoor environments with variability and repetition."
    }, 
    {
        "abstract": "Sophisticated methods for true spectral rendering have been developed in computer graphics to produce highly accurate images. In addition to traditional applications in visualizing appearance, such methods have potential applications in many areas of scientific study. In particular, we are motivated by the application of studying avian vision and appearance. An obstacle to using graphics in this application is the lack of reliable input data. We introduce an end-toend measurement system for capturing spectral data on 3D objects. We present the modification of a recently developed hyperspectral imager to make it suitable for acquiring such data in a wide spectral range at high spectral and spatial resolution. We capture four megapixel images, with data at each pixel from the near-ultraviolet (359 nm) to near-infrared (1,003 nm) at 12 nm spectral resolution. We fully characterize the imaging system, and document its accuracy. This imager is integrated into a 3D scanning system to enable the measurement of the diffuse spectral reflectance and fluorescence of specimens. We demonstrate the use of this measurement system in the study of the interplay between the visual capabilities and appearance of birds. We show further the use of the system in gaining insight into artifacts from geology and cultural heritage. Links: DL PDF ACM Reference Format Kim, M., Harvey, T., Kittle, D., Rushmeier, H., Dorsey, J., Prum, R., Brady, D. 2012. 3D Imaging Spectroscopy for Measuring 3D Hyperspectral Patterns on Solid Objects. ACM Trans. Graph. 31 4, Article 38 (July 2012), 11 pages. DOI = 10.1145/2185520.2185534 http://doi.acm.org/10.1145/2185520.2185534. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org.  2012 ACM 0730-0301/2012/08-ART38 $15.00 DOI 10.1145/2185520.2185534 http://doi.acm.org/10.1145/2185520.2185534  ", 
        "id": 1467, 
        "title": "3D imaging spectroscopy for measuring hyperspectral patterns on solid objects."
    }, 
    {
        "abstract": "", 
        "id": 1468, 
        "title": "Quality prediction for image completion."
    }, 
    {
        "abstract": "", 
        "id": 1469, 
        "title": "Digital reconstruction of halftoned color comics."
    }, 
    {
        "abstract": "", 
        "id": 1470, 
        "title": "Gaze correction for home video conferencing."
    }, 
    {
        "abstract": "", 
        "id": 1471, 
        "title": "Coherent intrinsic images from photo collections."
    }, 
    {
        "abstract": "We present an efficient and simple method for introducing temporal consistency to a large class of optimization driven image-based computer graphics problems. Our method extends recent work in edge-aware filtering, approximating costly global regularization with a fast iterative joint filtering operation. Using this representation, we can achieve tremendous efficiency gains both in terms of memory requirements and running time. This enables us to process entire shots at once, taking advantage of supporting information that exists across far away frames, something that is difficult with existing approaches due to the computational burden of video data. Our method is able to filter along motion paths using an iterative approach that simultaneously uses and estimates per-pixel optical flow vectors. We demonstrate its utility by creating temporally consistent results for a number of applications including optical flow, disparity estimation, colorization, scribble propagation, sparse data up-sampling, and visual saliency computation. ", 
        "id": 1472, 
        "title": "Practical temporal consistency for image-based graphics applications."
    }, 
    {
        "abstract": "", 
        "id": 1473, 
        "title": "Smooth skinning decomposition with rigid bones."
    }, 
    {
        "abstract": "Stochastic techniques for rendering indirect illumination suffer from noise due to the variance in the integrand. In this paper, we describe a general reconstruction technique that exploits anisotropy in the light field and permits efficient reuse of input samples between pixels or world-space locations, multiplying the effective sampling rate by a large factor. Our technique introduces visibility-aware anisotropic reconstruction to indirect illumination, ambient occlusion and glossy reflections. It operates on point samples without knowledge of the scene, and can thus be seen as an advanced image filter. Our results show dramatic improvement in image quality while using very sparse input samplings. ", 
        "id": 1474, 
        "title": "Reconstructing the indirect light field for global illumination."
    }, 
    {
        "abstract": "Interactive, task-guided character controllers must be agile and responsive to user input, while retaining the flexibility to be readily authored and modified by the designer. Central to a method's ease of use is its capacity to synthesize character motion for novel situations without requiring excessive data or programming effort. In this work, we present a technique that animates characters performing user-specified tasks by using a probabilistic motion model, which is trained on a small number of artist-provided animation clips. The method uses a low-dimensional space learned from the example motions to continuously control the character's pose to accomplish the desired task. By controlling the character through a reduced space, our method can discover new transitions, tractably precompute a control policy, and avoid low quality poses. ", 
        "id": 1475, 
        "title": "Continuous character control with low-dimensional embeddings."
    }, 
    {
        "abstract": "", 
        "id": 1476, 
        "title": "Stackabilization."
    }, 
    {
        "abstract": "", 
        "id": 1477, 
        "title": "Temporally coherent completion of dynamic shapes."
    }, 
    {
        "abstract": "", 
        "id": 1478, 
        "title": "All-hex meshing using singularity-restricted field."
    }, 
    {
        "abstract": "The problem of mapping triangular meshes into the plane is fundamental in geometric modeling, where planar deformations and surface parameterizations are two prominent examples. Current methods for triangular mesh mappings cannot, in general, control the worst case distortion of all triangles nor guarantee injectivity. This paper introduces a constructive definition of generic convex spaces of piecewise linear mappings with guarantees on the maximal conformal distortion, as-well as local and global injectivity of their maps. It is shown how common geometric processing objective functionals can be restricted to these new spaces, rather than to the entire space of piecewise linear mappings, to provide a bounded distortion version of popular algorithms. ", 
        "id": 1479, 
        "title": "Bounded distortion mapping spaces for triangular meshes."
    }, 
    {
        "abstract": "", 
        "id": 1480, 
        "title": "Simple formulas for quasiconformal plane deformations."
    }, 
    {
        "abstract": "", 
        "id": 1481, 
        "title": "Terrain runner: control, parameterization, composition, and planning for highly dynamic motions."
    }, 
    {
        "abstract": "", 
        "id": 1482, 
        "title": "SURE-based optimization for adaptive sampling and reconstruction."
    }, 
    {
        "abstract": "", 
        "id": 1483, 
        "title": "BRDF models for accurate and efficient rendering of glossy surfaces."
    }, 
    {
        "abstract": "", 
        "id": 1484, 
        "title": "Chopper: partitioning models into 3D-printable parts."
    }, 
    {
        "abstract": "", 
        "id": 1485, 
        "title": "Perspective-aware warping for seamless stereoscopic image cloning."
    }, 
    {
        "abstract": "Digital painters commonly use a tablet and stylus to drive software like Adobe Photoshop. A high quality stylus with 6 degrees of freedom (DOFs: 2D position, pressure, 2D tilt, and 1D rotation) coupled to a virtual brush simulation engine allows skilled users to produce expressive strokes in their own style. However, such devices are difficult for novices to control, and many people draw with less expensive (lower DOF) input devices. This paper presents a data-driven approach for synthesizing the 6D hand gesture data for users of low-quality input devices. Offline, we collect a library of strokes with 6D data created by trained artists. Online, given a query stroke as a series of 2D positions, we synthesize the 4D hand pose data at each sample based on samples from the library that locally match the query. This framework optionally can also modify the stroke trajectory to match characteristic shapes in the style of the library. Our algorithm outputs a 6D trajectory that can be fed into any virtual brush stroke engine to make expressive strokes for novices or users of limited hardware. ", 
        "id": 1486, 
        "title": "HelpingHand: example-based stroke stylization."
    }, 
    {
        "abstract": "", 
        "id": 1487, 
        "title": "Printing reflectance functions."
    }, 
    {
        "abstract": "The realistic depiction of lifelike virtual humans has been the goal of many movie makers in the last decade. Recently, films such as Tron: Legacy and The Curious Case of Benjamin Button have produced highly realistic characters. In the real-time domain, there is also a need to deliver realistic virtual characters, with the increase in popularity of interactive drama video games (such as L.A. NoireTM or Heavy RainTM). There have been mixed reactions from audiences to lifelike characters used in movies and games, with some saying that the increased realism highlights subtle imperfections, which can be disturbing. Some developers opt for a stylized rendering (such as cartoon-shading) to avoid a negative reaction [Thompson 2004]. In this paper, we investigate some of the consequences of choosing realistic or stylized rendering in order to provide guidelines for developers for creating appealing virtual characters. We conducted a series of psychophysical experiments to determine whether render style affects how virtual humans are perceived. Motion capture with synchronized eye-tracked data was used throughout to animate custom-made virtual model replicas of the captured actors. ", 
        "id": 1488, 
        "title": "Render me real?: investigating the effect of render style on the perception of animated virtual humans."
    }, 
    {
        "abstract": "", 
        "id": 1489, 
        "title": "Keynote: Jane McGonigal."
    }, 
    {
        "abstract": "", 
        "id": 1490, 
        "title": "Axis-aligned filtering for interactive sampled soft shadows."
    }, 
    {
        "abstract": "", 
        "id": 1491, 
        "title": "Motion graphs++: a compact generative model for semantic motion analysis and synthesis."
    }, 
    {
        "abstract": "", 
        "id": 1492, 
        "title": "Topology-adaptive interface tracking using the deformable simplicial complex."
    }, 
    {
        "abstract": "We present a motion synthesis framework capable of producing a wide variety of important human behaviors that have rarely been studied, including getting up from the ground, crawling, climbing, moving heavy objects, acrobatics (hand-stands in particular), and various cooperative actions involving two characters and their manipulation of the environment. Our framework is not specific to humans, but applies to characters of arbitrary morphology and limb configuration. The approach is fully automatic and does not require domain knowledge specific to each behavior. It also does not require pre-existing examples or motion capture data. At the core of our framework is the contact-invariant optimization (CIO) method we introduce here. It enables simultaneous optimization of contact and behavior. This is done by augmenting the search space with scalar variables that indicate whether a potential contact should be active in a given phase of the movement. These auxiliary variables affect not only the cost function but also the dynamics (by enabling and disabling contact forces), and are optimized together with the movement trajectory. Additional innovations include a continuation scheme allowing helper forces at the potential contacts rather than the torso, as well as a feature-based model of physics which is particularly well-suited to the CIO framework. We expect that CIO can also be used with a full physics model, but leave that extension for future work. ", 
        "id": 1493, 
        "title": "Discovery of complex behaviors through contact-invariant optimization."
    }, 
    {
        "abstract": "Global parametrization of surfaces requires singularities (cones) to keep distortion minimal. We describe a method for finding cone locations and angles and an algorithm for global parametrization which aim to produce seamless parametrizations with low metric distortion. The idea of the method is to evolve the metric of the surface, starting with the original metric so that a growing fraction of the area of the surface is constrained to have zero Gaussian curvature; the curvature becomes gradually concentrated at a small set of vertices which become cones. We demonstrate that the resulting parametrizations have significantly lower metric distortion compared to previously proposed methods. ", 
        "id": 1494, 
        "title": "Global parametrization by incremental flattening."
    }, 
    {
        "abstract": "", 
        "id": 1495, 
        "title": "A "
    }, 
    {
        "abstract": "", 
        "id": 1496, 
        "title": "Adaptive anisotropic remeshing for cloth simulation."
    }, 
    {
        "abstract": "", 
        "id": 1497, 
        "title": "Feature-adaptive GPU rendering of Catmull-Clark subdivision surfaces."
    }, 
    {
        "abstract": "", 
        "id": 1498, 
        "title": "Enabling warping on stereoscopic images."
    }, 
    {
        "abstract": "We present an efficient many-light algorithm for simulating indirect illumination in, and from, participating media. Instead of creating discrete virtual point lights (VPLs) at vertices of random-walk paths, we present a continuous generalization that places virtual ray lights (VRLs) along each path segment in the medium. Furthermore, instead of evaluating the lighting independently at discrete points in the medium, we calculate the contribution of each VRL to entire camera rays through the medium using an efficient Monte Carlo product sampling technique. We prove that by spreading the energy of virtual lights along both light and camera rays, the singularities that typically plague VPL methods are significantly diminished. This greatly reduces the need to clamp energy contributions in the medium, leading to robust and unbiased volumetric lighting not possible with current many-light techniques. Furthermore, by acting as a form of final gather, we obtain higher-quality multiple-scattering than existing density estimation techniques like progressive photon beams. ", 
        "id": 1499, 
        "title": "Virtual ray lights for rendering scenes with participating media."
    }, 
    {
        "abstract": "", 
        "id": 1500, 
        "title": "Sparse zonal harmonic factorization for efficient SH rotation."
    }, 
    {
        "abstract": "", 
        "id": 1501, 
        "title": "Exposing photo manipulation with inconsistent reflections."
    }, 
    {
        "abstract": "We present primal-dual coding, a photography technique that enables direct fine-grain control over which light paths contribute to a photo. We achieve this by projecting a sequence of patterns onto the scene while the sensor is exposed to light. At the same time, a second sequence of patterns, derived from the first and applied in lockstep, modulates the light received at individual sensor pixels. We show that photography in this regime is equivalent to a matrix probing operation in which the elements of the scene's transport matrix are individually re-scaled and then mapped to the photo. This makes it possible to directly acquire photos in which specific light transport paths have been blocked, attenuated or enhanced. We show captured photos for several scenes with challenging light transport effects, including specular inter-reflections, caustics, diffuse inter-reflections and volumetric scattering. A key feature of primal-dual coding is that it operates almost exclusively in the optical domain: our results consist of directly-acquired, unprocessed RAW photos or differences between them. ", 
        "id": 1502, 
        "title": "Primal-dual coding to probe light transport."
    }, 
    {
        "abstract": "We present a novel representation of maps between pairs of shapes that allows for efficient inference and manipulation. Key to our approach is a generalization of the notion of map that puts in correspondence real-valued functions rather than points on the shapes. By choosing a multi-scale basis for the function space on each shape, such as the eigenfunctions of its Laplace-Beltrami operator, we obtain a representation of a map that is very compact, yet fully suitable for global inference. Perhaps more remarkably, most natural constraints on a map, such as descriptor preservation, landmark correspondences, part preservation and operator commutativity become linear in this formulation. Moreover, the representation naturally supports certain algebraic operations such as map sum, difference and composition, and enables a number of applications, such as function or annotation transfer without establishing pointto-point correspondences. We exploit these properties to devise an efficient shape matching method, at the core of which is a single linear solve. The new method achieves state-of-the-art results on an isometric shape matching benchmark. We also show how this representation can be used to improve the quality of maps produced by existing shape matching methods, and illustrate its usefulness in segmentation transfer and joint analysis of shape collections. ", 
        "id": 1503, 
        "title": "Functional maps: a flexible representation of maps between shapes."
    }, 
    {
        "abstract": "", 
        "id": 1504, 
        "title": "Analysis and synthesis of point distributions based on pair correlation."
    }, 
    {
        "abstract": "We introduce tailored displays that enhance visual acuity by decomposing virtual objects and placing the resulting anisotropic pieces into the subject's focal range. The goal is to free the viewer from needing wearable optical corrections when looking at displays. Our tailoring process uses aberration and scattering maps to account for refractive errors and cataracts. It splits an object's light field into multiple instances that are each in-focus for a given eye subaperture. Their integration onto the retina leads to a quality improvement of perceived images when observing the display with naked eyes. The use of multiple depths to render each point of focus on the retina creates multi-focus, multi-depth displays. User evaluations and validation with modified camera optics are performed. We propose tailored displays for daily tasks where using eyeglasses are unfeasible or inconvenient (e.g., on head-mounted displays, ereaders, as well as for games); when a multi-focus function is required but undoable (e.g., driving for farsighted individuals, checking a portable device while doing physical activities); or for correcting the visual distortions produced by high-order aberrations that eyeglasses are not able to. ", 
        "id": 1505, 
        "title": "Tailored displays to compensate for visual aberrations."
    }, 
    {
        "abstract": "We present a new method for modeling discrete constant mean curvature (CMC) surfaces, which arise frequently in nature and are highly demanded in architecture and other engineering applications. Our method is based on a novel use of the CVT (centroidal Voronoi tessellation) optimization framework. We devise a CVTCMC energy function defined as a combination of an extended CVT energy and a volume functional. We show that minimizing the CVT-CMC energy is asymptotically equivalent to minimizing mesh surface area with a fixed volume, thus defining a discrete CMC surface. The CVT term in the energy function ensures high mesh quality throughout the evolution of a CMC surface in an interactive design process for form finding. Our method is capable of modeling CMC surfaces with fixed or free boundaries and is robust with respect to input mesh quality and topology changes. Experiments show that the new method generates discrete CMC surfaces of improved mesh quality over existing methods. ", 
        "id": 1506, 
        "title": "Robust modeling of constant mean curvature surfaces."
    }, 
    {
        "abstract": "Direction fields, line fields and cross fields are used in a variety of computer graphics applications ranging from non-photorealistic rendering to remeshing. In many cases, it is desirable that fields adhere to symmetry, which is predominant in natural as well as manmade shapes. We present an algorithm for designing smooth Nsymmetry fields on surfaces respecting generalized symmetries of the shape, while maintaining alignment with local features. Our formulation for constructing symmetry fields is based on global symmetries, which are given as input to the algorithm, with no isometry assumptions. We explore in detail the properties of generalized symmetries (reflections in particular), and we also develop an algorithm for the robust computation of such symmetry maps, based on a small number of correspondences, for surfaces of genus zero. ", 
        "id": 1507, 
        "title": "Fields on symmetric surfaces."
    }, 
    {
        "abstract": "", 
        "id": 1508, 
        "title": "The magic lens: refractive steganography."
    }, 
    {
        "abstract": "", 
        "id": 1509, 
        "title": "Simulation of complex nonlinear elastic bodies using lattice deformers."
    }, 
    {
        "abstract": "Buoyant turbulent smoke plumes with a sharp smoke-air interface, such as volcanic plumes, are notoriously hard to simulate. The surface clearly shows small-scale turbulent structures which are costly to resolve. In addition, the turbulence onset is directly visible at the interface, and is not captured by commonly used turbulence models. We present a novel approach that employs a triangle mesh as a high-resolution surface representation combined with a coarse Eulerian solver. On the mesh, we solve the interfacial vortex sheet equations, which allows us to accurately simulate buoyancy induced turbulence. For complex boundary conditions we propose an orthogonal turbulence model that handles vortices caused by obstacle interaction. In addition, we demonstrate a re-sampling scheme to remove surfaces that are hidden inside the bulk volume. In this way we are able to achieve highly detailed simulations of turbulent plumes efficiently.", 
        "id": 1510, 
        "title": "Lagrangian vortex sheets for animating fluids."
    }, 
    {
        "abstract": "", 
        "id": 1511, 
        "title": "Capturing and animating the morphogenesis of polygonal tree models."
    }, 
    {
        "abstract": "We present a dynamic tree modeling and representation technique that allows complex tree models to interact with their environment. Our method uses changes in the light distribution and proximity to solid obstacles and other trees as approximations of biologically motivated transformations on a skeletal representation of the tree's main branches and its procedurally generated foliage. Parts of the tree are transformed only when required, thus our approach is much faster than common algorithms such as Open L-Systems or space colonization methods. Input is a skeleton-based tree geometry that can be computed from common tree production systems or from reconstructed laser scanning models. Our approach enables content creators to directly interact with trees and to create visually convincing ecosystems interactively. We present different interaction types and evaluate our method by comparing our transformations to biologically based growth simulation techniques. ", 
        "id": 1512, 
        "title": "Plastic trees: interactive self-adapting botanical tree models."
    }, 
    {
        "abstract": "Using existing programming tools, writing high-performance image processing code requires sacrificing readability, portability, and modularity. We argue that this is a consequence of conflating what computations define the algorithm, with decisions about storage and the order of computation. We refer to these latter two concerns as the schedule, including choices of tiling, fusion, recomputation vs. storage, vectorization, and parallelism. We propose a representation for feed-forward imaging pipelines that separates the algorithm from its schedule, enabling highperformance without sacrificing code clarity. This decoupling simplifies the algorithm specification: images and intermediate buffers become functions over an infinite integer domain, with no explicit storage or boundary conditions. Imaging pipelines are compositions of functions. Programmers separately specify scheduling strategies for the various functions composing the algorithm, which allows them to efficiently explore different optimizations without changing the algorithmic code. We demonstrate the power of this representation by expressing a range of recent image processing applications in an embedded domain specific language called Halide, and compiling them for ARM, x86, and GPUs. Our compiler targets SIMD units, multiple cores, and complex memory hierarchies. We demonstrate that it can handle algorithms such as a camera raw pipeline, the bilateral grid, fast local Laplacian filtering, and image segmentation. The algorithms expressed in our language are both shorter and faster than state-of-the-art implementations. ", 
        "id": 1513, 
        "title": "Decoupling algorithms from schedules for easy optimization of image processing pipelines."
    }, 
    {
        "abstract": "", 
        "id": 1514, 
        "title": "A theory of monte carlo visibility sampling."
    }, 
    {
        "abstract": "", 
        "id": 1515, 
        "title": "Calibrated image appearance reproduction."
    }, 
    {
        "abstract": "", 
        "id": 1516, 
        "title": "Sculpting by numbers."
    }, 
    {
        "abstract": "Many kinds of digital fabrication are accomplished by precisely moving a tool along a digitally-specified path. This precise motion is typically accomplished fully automatically using a computer-controlled multi-axis stage. With that approach, one can only create objects smaller than the positioning stage, and large stages can be quite expensive. We propose a new approach to precise positioning of a tool that combines manual and automatic positioning: in our approach, the user coarsely positions a frame containing the tool in an approximation of the desired path, while the device tracks the frames location and adjusts the position of the tool within the frame to correct the users positioning error in real time. Because the automatic positioning need only cover the range of the humans positioning error, this frame can be small and inexpensive, and because the human has unlimited range, such a frame can be used to precisely position tools over an unlimited range.", 
        "id": 1517, 
        "title": "Position-correcting tools for 2D digital fabrication."
    }, 
    {
        "abstract": "", 
        "id": 1518, 
        "title": "Adaptive rendering with non-local means filtering."
    }, 
    {
        "abstract": "", 
        "id": 1519, 
        "title": "Physically-based simulation of rainbows."
    }, 
    {
        "abstract": " Digital projection technology has improved significantly in recent years. But, the relationship of cost with respect to available resolution in projectors is still super-linear. In this paper, we present a method that uses projector light modulator panels (e.g. LCD or DMD panels) of resolution n  n to create a perceptually close match to a target higher resolution cn  cn image, where c is a small integer greater than 1. This is achieved by enhancing the resolution using smaller pixels at specific regions of interest like edges.  A target high resolution image (cn  cn) is first decomposed into (a) a high resolution (cn  cn) but sparse edge image, and (b) a complementary lower resolution (n  n) non-edge image. These images are then projected in a time sequential manner at a high frame rate to create an edge-enhanced image  an image where the pixel density is not uniform but changes spatially. In 3D ready projectors with readily available refresh rate of 120Hz, such a temporal multiplexing is imperceptible to the user and the edge-enhanced image is perceptually almost identical to the target high resolution image.  To create the higher resolution edge image, we introduce the con-  cept of optical pixel sharing. This reduces the projected pixel size  by  a  factor  of  1 c2  while increasing  the  pixel  density  by  c2  at  the  e-mail: bsajadi@uci.edu e-mail:gopi@ics.uci.edu e-mail: majumder@ics.uci.edu  ACM Reference Format Sajadi, B., Gopi, M., Majumder, A. 2012. Edge-Guided Resolution Enhancement in Projectors via Optical Pixel Sharing. ACM Trans. Graph. 31 4, Article 79 (July 2012), 11 pages. DOI = 10.1145/2185520.2185575 http://doi.acm.org/10.1145/2185520.2185575. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org.  2012 ACM 0730-0301/2012/08-ART79 $15.00 DOI 10.1145/2185520.2185575 http://doi.acm.org/10.1145/2185520.2185575  edges enabling true higher resolution edges. Due to the sparsity of the edge pixels in an image we are able to choose a sufficiently large subset of these to be displayed at the higher resolution using perceptual parameters. We present a statistical analysis quantifying the expected number of pixels that will be reproduced at the higher resolution and verify it for different types of images. ", 
        "id": 1520, 
        "title": "Edge-guided resolution enhancement in projectors via optical pixel sharing."
    }, 
    {
        "abstract": "We propose a new ghost fluid approach for free surface and solid boundary conditions in Smoothed Particle Hydrodynamics (SPH) liquid simulations. Prior methods either suffer from a spurious numerical surface tension artifact or drift away from the mass conservation constraint, and do not capture realistic cohesion of liquid to solids. Our Ghost SPH scheme resolves this with a new particle sampling algorithm to create a narrow layer of ghost particles in the surrounding air and solid, with careful extrapolation and treatment of fluid variables to reflect the boundary conditions. We also provide a new, simpler form of artificial viscosity based on XSPH. Examples demonstrate how the new approach captures real liquid behaviour previously unattainable by SPH with very little extra cost. ", 
        "id": 1521, 
        "title": "Ghost SPH for animating water."
    }, 
    {
        "abstract": "", 
        "id": 1522, 
        "title": "Practical Hessian-based error control for irradiance caching."
    }, 
    {
        "abstract": "", 
        "id": 1523, 
        "title": "On filtering the noise from the random parameters in Monte Carlo rendering."
    }, 
    {
        "abstract": "", 
        "id": 1524, 
        "title": "Robust patch-based hdr reconstruction of dynamic scenes."
    }, 
    {
        "abstract": "", 
        "id": 1525, 
        "title": "Spacetime expression cloning for blendshapes."
    }, 
    {
        "abstract": "We facilitate the creation of 3D-looking shaded production drawings from concept sketches. The key to our approach is a class of commonly used construction curves known as cross-sections, that function as an aid to both sketch creation and viewer understanding of the depicted 3D shape. In particular, intersections of these curves, or cross-hairs, convey valuable 3D information, that viewers compose into a mental model of the overall sketch. We use the artist-drawn cross-sections to automatically infer the 3D normals across the sketch, enabling 3D-like rendering. The technical contribution of our work is twofold. First, we distill artistic guidelines for drawing cross-sections and insights from perception literature to introduce an explicit mathematical formulation of the relationships between cross-section curves and the geometry they aim to convey. We then use these relationships to develop an algorithm for estimating a normal field from cross-section curve networks and other curves present in concept sketches. We validate our formulation and algorithm through a user study and a ground truth normal comparison. As demonstrated by the examples throughout the paper, these contributions enable us to shade a wide range of concept sketches with a variety of rendering styles. ", 
        "id": 1526, 
        "title": "CrossShade: shading concept sketches using cross-section curves."
    }, 
    {
        "abstract": "", 
        "id": 1527, 
        "title": "An interactive approach to semantic modeling of indoor scenes with an RGBD camera."
    }, 
    {
        "abstract": "", 
        "id": 1528, 
        "title": "Structure recovery by part assembly."
    }, 
    {
        "abstract": "We present a system for image-based modeling and rendering of real-world scenes containing reflective and glossy surfaces. Previous approaches to image-based rendering assume that the scene can be approximated by 3D proxies that enable view interpolation using traditional back-to-front or z-buffer compositing. In this work, we show how these can be generalized to multiple layers that are combined in an additive fashion to model the reflection and transmission of light that occurs at specular surfaces such as glass and glossy materials. To simplify the analysis and rendering stages, we model the world using piecewise-planar layers combined using both additive and opaque mixing of light. We also introduce novel techniques for estimating multiple depths in the scene and separating the reflection and transmission components into different layers. We then use our system to model and render a variety of real-world scenes with reflections. ", 
        "id": 1529, 
        "title": "Image-based rendering for scenes with reflections."
    }, 
    {
        "abstract": " Before  Pre-impact Post-impact  After  Resolving simultaneous impacts is an open and significant problem in collision response modeling. Existing algorithms in this domain fail to fulfill at least one of five physical desiderata. To address this we present a simple generalized impact model motivated by both the successes and pitfalls of two popular approaches: pair-wise propagation and linear complementarity models. Our algorithm is the first to satisfy all identified desiderata, including simultaneously guaranteeing symmetry preservation, kinetic energy conservation, and allowing break-away. Furthermore, we address the associated problem of inelastic collapse, proposing a complementary generalized restitution model that eliminates this source of nontermination. We then consider the application of our models to the synchronous time-integration of large-scale assemblies of impacting rigid bodies. To enable such simulations we formulate a consistent frictional impact model that continues to satisfy the desiderata. Finally, we validate our proposed algorithm by correctly capturing the observed characteristics of physical experiments including the phenomenon of extended patterns in vertically oscillated granular materials. ", 
        "id": 1530, 
        "title": "Reflections on simultaneous impact."
    }, 
    {
        "abstract": "", 
        "id": 1531, 
        "title": "Recursive interlocking puzzles."
    }, 
    {
        "abstract": "The use of 3D printing has rapidly expanded in the past couple of years. It is now possible to produce 3D-printed objects with exceptionally high fidelity and precision. However, although the quality of 3D printing has improved, both the time to print and the material costs have remained high. Moreover, there is no guarantee that a printed model is structurally sound. The printed product often does not survive cleaning, transportation, or handling, or it may even collapse under its own weight. We present a system that addresses this issue by providing automatic detection and correction of the problematic cases. The structural problems are detected by combining a lightweight structural analysis solver with 3D medial axis approximations. After areas with high structural stress are found, the model is corrected by combining three approaches: hollowing, thickening, and strut insertion. Both detection and correction steps are repeated until the problems have been eliminated. Our process is designed to create a model that is visually similar to the original model but possessing greater structural integrity. ", 
        "id": 1532, 
        "title": "Stress relief: improving structural strength of 3D printable objects."
    }, 
    {
        "abstract": "", 
        "id": 1533, 
        "title": "Softshell: dynamic scheduling on GPUs."
    }, 
    {
        "abstract": "A fundamental step in stitching several pictures to form a larger mosaic is the computation of boundary seams that minimize the visual artifacts in the transition between images. Current seam computation algorithms use optimization methods that may be slow, sequential, memory intensive, and prone to finding suboptimal solutions related to local minima of the chosen energy function. Moreover, even when these techniques perform well, their solution may not be perceptually ideal (or even good). Such an inflexible approach does not allow the possibility of user-based improvement. This paper introduces the Panorama Weaving technique for seam creation and editing in an image mosaic. First, Panorama Weaving provides a procedure to create boundaries for panoramas that is fast, has low memory requirements and is easy to parallelize. This technique often produces seams with lower energy than the competing global technique. Second, it provides the first interactive technique for the exploration of the seam solution space. This powerful editing capability allows the user to automatically extract energy minimizing seams given a sparse set of constraints. With a variety of empirical results, we show how Panorama Weaving allows the computation and editing of a wide range of digital panoramas including unstructured configurations. Links: DL PDF e-mail: {bsumma, pascucci}@sci.utah.edu url: http://www.visuspano.com e-mail: tierny@telecom-paristech.fr  ", 
        "id": 1534, 
        "title": "Panorama weaving: fast and flexible seam processing."
    }, 
    {
        "abstract": "We introduce a vector representation called diffusion curve textures for mapping diffusion curve images (DCI) onto arbitrary surfaces. In contrast to the original implicit representation of DCIs [Orzan et al. 2008], where determining a single texture value requires iterative computation of the entire DCI via the Poisson equation, diffusion curve textures provide an explicit representation from which the texture value at any point can be solved directly, while preserving the compactness and resolution independence of diffusion curves. This is achieved through a formulation of the DCI diffusion process in terms of Green's functions. This formulation furthermore allows the texture value of any rectangular region (e.g. pixel area) to be solved in closed form, which facilitates anti-aliasing. We develop a GPU algorithm that renders anti-aliased diffusion curve textures in real time, and demonstrate the effectiveness of this method through high quality renderings with detailed control curves and color variations. ", 
        "id": 1535, 
        "title": "Diffusion curve textures for resolution independent texture mapping."
    }, 
    {
        "abstract": "We present a simple algorithm to compute continuous penalty forces to determine collision response between rigid and de-formable models bounded by triangle meshes. Our algorithm computes a well-behaved solution in contrast to the traditional stability and robustness problems of penalty methods, induced by force discontinuities. We trace contact features along their deforming trajectories and accumulate penalty forces along the penetration time intervals between the overlapping feature pairs. Moreover, we present a closed-form expression to compute the continuous and smooth collision response. Our method has very small additional overhead compared to previous penalty methods, and can significantly improve the stability and robustness. We highlight its benefits on several benchmarks. ", 
        "id": 1536, 
        "title": "Continuous penalty forces."
    }, 
    {
        "abstract": "We present a physically-based system to simulate and control the locomotion of soft body characters without skeletons. We use the finite element method to simulate the deformation of the soft body, and we instrument a character with muscle fibers to allow it to actively control its shape. To perform locomotion, we use a variety of intuitive controls such as moving a point on the character, specifying the center of mass or the angular momentum, and maintaining balance. These controllers yield an objective function that is passed to our optimization solver, which handles convex quadratic program with linear complementarity constraints. This solver determines the new muscle fiber lengths, and moreover it determines whether each point of contact should remain static, slide, or lift away from the floor. Our system can automatically find an appropriate combination of muscle contractions that enables a soft character to fulfill various locomotion tasks, including walking, jumping, crawling, rolling and balancing. ", 
        "id": 1537, 
        "title": "Soft body locomotion."
    }, 
    {
        "abstract": "Human stereo perception of glossy materials is substantially different from the perception of diffuse surfaces: A single point on a diffuse object appears the same for both eyes, whereas it appears different to both eyes on a specular object. As highlights are blurry reflections of light sources they have depth themselves, which is different from the depth of the reflecting surface. We call this difference in depth impression the \"highlight disparity\". Due to artistic motivation, for technical reasons, or because of incomplete data, highlights often have to be depicted on-surface, without any disparity. However, it has been shown that a lack of disparity decreases the perceived glossiness and authenticity of a material. To remedy this contradiction, our work introduces a technique for depiction of glossy materials, which improves over simple on-surface highlights, and avoids the problems of physical highlights. Our technique is computationally simple, can be easily integrated in an existing (GPU) shading system, and allows for local and interactive artistic control.  for solid diffuse surfaces, it no longer holds for view-dependent shading. Highlights, which are blurry images of the light sources, have their own depth, different from the surface on which they are visible (Fig. 2), and they are potential source of excessive disparities. Additionally, depending on the geometry of the reflecting surface, highlights can change shape, disappear, produce vertical disparities or result in different specular flow in both eyes. One solution to this problem is to assume a common (cyclopean) eye position when shading the surface. Doing so, we avoid conflicts, however highlights seem to be painted onto the surface. This is a significant shortcoming, as it is known, that highlight disparity is a strong factor for the perception of gloss [Blake and Blthoff 1990; Hurlbert et al. 1991; Sakano and Ando 2010] and material authenticity [Wendt et al. 2008]. Nevertheless on-surface highlights are quite common, presumably for three main reasons: Because artists consider them to be more pleasant to watch; because of performance (e. g., in games that can not afford to shade twice [Sousa et al. 2012]); and because the necessary information is missing (e. g., in 2D-to-3D conversion).  Links: DL PDF WEB VIDEO DATA  ", 
        "id": 1538, 
        "title": "Highlight microdisparity for improved gloss depiction."
    }, 
    {
        "abstract": "", 
        "id": 1539, 
        "title": "Animation cartography - intrinsic reconstruction of shape and motion."
    }, 
    {
        "abstract": "The abundance of mobile devices and digital cameras with video capture makes it easy to obtain large collections of video clips that contain the same location, environment, or event. However, such an unstructured collection is difficult to comprehend and explore. We propose a system that analyzes collections of unstructured but related video data to create a Videoscape: a data structure that enables interactive exploration of video collections by visually navigating  spatially and/or temporally  between different clips. We automatically identify transition opportunities, or portals. From these portals, we construct the Videoscape, a graph whose edges are video clips and whose nodes are portals between clips. Now structured, the videos can be interactively explored by walking the graph or by geographic map. Given this system, we gauge preference for different video transition styles in a user study, and generate heuristics that automatically choose an appropriate transition style. We evaluate our system using three further user studies, which allows us to conclude that Videoscapes provides significant benefits over related methods. Our system leads to previously unseen ways of interactive spatio-temporal exploration of casually captured videos, and we demonstrate this on several video collections.", 
        "id": 1540, 
        "title": "Videoscapes: exploring sparse, unstructured video collections."
    }, 
    {
        "abstract": "We present a parallel iterative rigid body solver that avoids common artifacts at low iteration counts. In large or real-time simulations, iteration is often terminated before convergence to maximize scene size. If the distribution of the resulting residual energy varies too much from frame to frame, then bodies close to rest can visibly jitter. Projected Gauss-Seidel (PGS) distributes the residual according to the order in which contacts are processed, and preserving the order in parallel implementations is very challenging. In contrast, Jacobi-based methods provide order independence, but have slower convergence. We accelerate projected Jacobi by dividing each body mass term in the effective mass by the number of contacts acting on the body, but use the full mass to apply impulses. We further accelerate the method by solving contacts in blocks, providing wallclock performance competitive with PGS while avoiding visible artifacts. We prove convergence to the solution of the underlying linear com-plementarity problem and present results for our GPU implementation, which can simulate a pile of 5000 objects with no visible jittering at over 60 FPS.", 
        "id": 1541, 
        "title": "Mass splitting for jitter-free parallel rigid body simulation."
    }, 
    {
        "abstract": "", 
        "id": 1542, 
        "title": "K-clustered tensor approximation: A sparse multilinear model for real-time rendering."
    }, 
    {
        "abstract": "Geometric modeling and the physical validity of shapes are traditionally considered independently. This makes creating aesthetically pleasing yet physically valid models challenging. We propose an interactive design framework for efficient and intuitive exploration of geometrically and physically valid shapes. During any geometric editing operation, the proposed system continuously visualizes the valid range of the parameter being edited. When one or more constraints are violated after an operation, the system generates multiple suggestions involving both discrete and continuous changes to restore validity. Each suggestion also comes with an editing mode that simultaneously adjusts multiple parameters in a coordinated way to maintain validity. Thus, while the user focuses on the aesthetic aspects of the design, our computational design framework helps to achieve physical realizability by providing active guidance to the user. We demonstrate our framework on plankbased furniture design with nail-joint and frictional constraints. We use our system to design a range of examples, conduct a user study, and also fabricate a physical prototype to test the validity and usefulness of the system. ", 
        "id": 1543, 
        "title": "Guided exploration of physically valid shapes for furniture design."
    }, 
    {
        "abstract": "", 
        "id": 1544, 
        "title": "Lightweight binocular facial performance capture under uncontrolled lighting."
    }, 
    {
        "abstract": "", 
        "id": 1545, 
        "title": "Inverse design of urban procedural models."
    }, 
    {
        "abstract": "We present a novel method for producing convincing pictures of shaded objects based entirely on 2D image operations. This approach, which we call image-based shading design, offers direct artistic control in the picture plane by deforming image primitives so that they appear to conform to specific 3D shapes. Using a differential analysis of reflected radiance, we identify the two types of surface flows involved in the depiction of shaded objects, which are consistent with recent perceptual studies. We then introduce two novel deformation operators that closely mimic surface flows while providing direct artistic controls in real-time. ", 
        "id": 1546, 
        "title": "Surface flows for image-based shading design."
    }, 
    {
        "abstract": "Marker-less motion capture is a challenging problem, particularly when only monocular video is available. We estimate human motion from monocular video by recovering three-dimensional controllers capable of implicitly simulating the observed human behavior and replaying this behavior in other environments and under physical perturbations. Our approach employs a state-space biped controller with a balance feedback mechanism that encodes control as a sequence of simple control tasks. Transitions among these tasks are triggered on time and on proprioceptive events (e.g., contact). Inference takes the form of optimal control where we optimize a high-dimensional vector of control parameters and the structure of the controller based on an objective function that compares the resulting simulated motion with input observations. We illustrate our approach by automatically estimating controllers for a variety of motions directly from monocular video. We show that the estimation of controller structure through incremental optimization and refinement leads to controllers that are more stable and that better approximate the reference motion. We demonstrate our approach by capturing sequences of walking, jumping, and gymnastics. ", 
        "id": 1547, 
        "title": "Video-based 3D motion capture through biped control."
    }, 
    {
        "abstract": "Self-supporting masonry is one of the most ancient and elegant techniques for building curved shapes. Because of the very geometric nature of their failure, analyzing and modeling such strutures is more a geometry processing problem than one of classical continuum mechanics. This paper uses the thrust network method of analysis and presents an iterative nonlinear optimization algorithm for efficiently approximating freeform shapes by self-supporting ones. The rich geometry of thrust networks leads us to close connections between diverse topics in discrete differential geometry, such as a finite-element discretization of the Airy stress potential, perfect graph Laplacians, and computing admissible loads via curvatures of polyhedral surfaces. This geometric viewpoint allows us, in particular, to remesh self-supporting shapes by self-supporting quad meshes with planar faces, and leads to another application of the theory: steel/glass constructions with low moments in nodes. ", 
        "id": 1548, 
        "title": "Design of self-supporting surfaces."
    }, 
    {
        "abstract": "Scenes modeling the real-world combine a wide variety of phenomena including glossy materials, detailed heterogeneous anisotropic media, subsurface scattering, and complex illumination. Predictive rendering of such scenes is difficult; unbiased algorithms are typically too slow or too noisy. Virtual point light (VPL) based algorithms produce low noise results across a wide range of performance/accuracy tradeoffs, from interactive rendering to high quality offline rendering, but their bias means that locally important illumination features may be missing. We introduce a bidirectional formulation and a set of weighting strategies to significantly reduce the bias in VPL-based rendering algorithms. Our approach, bidirectional lightcuts, maintains the scalability and low noise global illumination advantages of prior VPL-based work, while significantly extending their generality to support a wider range of important materials and visual cues. We demonstrate scalable, efficient, and low noise rendering of scenes with highly complex materials including gloss, BSSRDFs, and anisotropic volumetric models. ", 
        "id": 1549, 
        "title": "Bidirectional lightcuts."
    }, 
    {
        "abstract": "", 
        "id": 1550, 
        "title": "Active co-analysis of a set of shapes."
    }, 
    {
        "abstract": "A method for image-based contact detection and modeling, with guaranteed precision on the intersection volume, is presented. Unlike previous image-based methods, our method optimizes a nonuniform ray sampling resolution and allows precise control of the volume error. By cumulatively projecting all mesh edges into a generalized 2D texture, we construct a novel data structure, the Error Bound Polynomial Image (EBPI), which allows efficient computation of the maximum volume error as a function of ray density. Based on a precision criterion, EBPI pixels are subdivided or clustered. The rays are then cast in the projection direction according to the non-uniform resolution. The EBPI data, combined with ray-surface intersection points and normals, is also used to detect transient edges at surface intersections. This allows us to model intersection volumes at arbitrary resolution, while avoiding the geometric computation of mesh intersections. Moreover, the ray casting acceleration data structures can be reused for the generation of high quality images. ", 
        "id": 1551, 
        "title": "Adaptive image-based intersection volume."
    }, 
    {
        "abstract": "", 
        "id": 1552, 
        "title": "High-quality image deblurring with panchromatic pixels."
    }, 
    {
        "abstract": "We present a technique for automatically synthesizing walking and running controllers for physically-simulated 3D humanoid characters. The sagittal hip, knee, and ankle degrees-of-freedom are actuated using a set of eight Hill-type musculotendon models in each leg, with biologically-motivated control laws. The parameters of these control laws are set by an optimization procedure that satisfies a number of locomotion task terms while minimizing a biological model of metabolic energy expenditure. We show that the use of biologically-based actuators and objectives measurably increases the realism of gaits generated by locomotion controllers that operate without the use of motion capture data, and that metabolic energy expenditure provides a simple and unifying measurement of effort that can be used for both walking and running control optimization. ", 
        "id": 1553, 
        "title": "Optimizing locomotion controllers using biologically-based actuators and objectives."
    }, 
    {
        "abstract": "We show that the motion of rigid bodies under water can be realistically simulated by replacing the usual inertia tensor and scalar mass by the so-called Kirchhoff tensor. This allows us to model fluid-body interaction without simulating the surrounding fluid at all. We explain some of the phenomena that arise and compare our results against real experiments. It turns out that many real scenarios (sinking bodies, balloons) can be matched using a single, hand-tuned scaling parameter. We describe how to integrate our method into an existing physics engine, which makes underwater rigid body dynamics run in real time. ", 
        "id": 1554, 
        "title": "Underwater rigid body dynamics."
    }, 
    {
        "abstract": "", 
        "id": 1555, 
        "title": "Accurate realtime full-body motion capture using a single depth camera."
    }, 
    {
        "abstract": "We introduce tensor displays: a family of compressive light field displays comprising all architectures employing a stack of timemultiplexed, light-attenuating layers illuminated by uniform or directional backlighting (i.e., any low-resolution light field emitter). We show that the light field emitted by an N -layer, M -frame tensor display can be represented by an N th-order, rank-M tensor. Using this representation we introduce a unified optimization framework, based on nonnegative tensor factorization (NTF), encompassing all tensor display architectures. This framework is the first to allow joint multilayer, multiframe light field decompositions, significantly reducing artifacts observed with prior multilayer-only and multiframe-only decompositions; it is also the first optimization method for designs combining multiple layers with directional backlighting. We verify the benefits and limitations of tensor displays by constructing a prototype using modified LCD panels and a custom integral imaging backlight. Our efficient, GPU-based NTF implementation enables interactive applications. Through simulations and experiments we show that tensor displays reveal practical architectures with greater depths of field, wider fields of view, and thinner form factors, compared to prior automultiscopic displays. ", 
        "id": 1556, 
        "title": "Tensor displays: compressive light field synthesis using multilayer displays with directional backlighting."
    }, 
    {
        "abstract": "", 
        "id": 1557, 
        "title": "Structural optimization of 3D masonry buildings."
    }, 
    {
        "abstract": "", 
        "id": 1558, 
        "title": "Fluid simulation using Laplacian eigenfunctions."
    }, 
    {
        "abstract": "Our goal is to reveal temporal variations in videos that are difficult or impossible to see with the naked eye and display them in an indicative manner. Our method, which we call Eulerian Video Magnification, takes a standard video sequence as input, and applies spatial decomposition, followed by temporal filtering to the frames. The resulting signal is then amplified to reveal hidden information. Using our method, we are able to visualize the flow of blood as it fills the face and also to amplify and reveal small motions. Our technique can run in real time to show phenomena occurring at the temporal frequencies selected by the user. ", 
        "id": 1559, 
        "title": "Eulerian video magnification for revealing subtle changes in the world."
    }, 
    {
        "abstract": "Compositing is one of the most commonly performed operations in computer graphics. A realistic composite requires adjusting the appearance of the foreground and background so that they appear compatible; unfortunately, this task is challenging and poorly understood. We use statistical and visual perception experiments to study the realism of image composites. First, we evaluate a number of standard 2D image statistical measures, and identify those that are most significant in determining the realism of a composite. Then, we perform a human subjects experiment to determine how the changes in these key statistics influence human judgements of composite realism. Finally, we describe a data-driven algorithm that automatically adjusts these statistical measures in a foreground to make it more compatible with its background in a composite. We show a number of compositing results, and evaluate the performance of both our algorithm and previous work with a human subjects study. ", 
        "id": 1560, 
        "title": "Understanding and improving the realism of image composites."
    }, 
    {
        "abstract": "", 
        "id": 1561, 
        "title": "Lazy selection: a scribble-based tool for smart shape elements selection."
    }, 
    {
        "abstract": "", 
        "id": 1562, 
        "title": "Structure extraction from texture via relative total variation."
    }, 
    {
        "abstract": "We introduce set evolution as a means for creative 3D shape modeling, where an initial population of 3D models is evolved to produce generations of novel shapes. Part of the evolving set is presented to a user as a shape gallery to offer modeling suggestions. User preferences define the fitness for the evolution so that over time, the shape population will mainly consist of individuals with good fitness. However, to inspire the user's creativity, we must also keep the evolving set diverse. Hence the evolution is \"fit and diverse\", drawing motivation from evolution theory. We introduce a novel part crossover operator which works at the finer-level part structures of the shapes, leading to significant variations and thus increased diversity in the evolved shape structures. Diversity is also achieved by explicitly compromising the fitness scores on a portion of the evolving population. We demonstrate the effectiveness of set evolution on man-made shapes. We show that selecting only models with high fitness leads to an elite population with low diversity. By keeping the population fit and diverse, the evolution can generate inspiring, and sometimes unexpected, shapes. Links: DL PDF WEB VIDEO DATA ", 
        "id": 1563, 
        "title": "Fit and diverse: set evolution for inspiring 3D shape galleries."
    }, 
    {
        "abstract": " Links: DL PDF  By extending from monocular displays to binocular displays, one additional image domain is introduced. Existing binocular display systems only utilize this additional image domain for stereopsis. Our human vision is not only able to fuse two displaced images, but also two images with difference in detail, contrast and luminance, up to a certain limit. This phenomenon is known as binocular single vision. Humans can perceive more visual content via binocular fusion than just a linear blending of two views. In this paper, we make a first attempt in computer graphics to utilize this human vision phenomenon, and propose a binocular tone mapping framework. The proposed framework generates a binocular low-dynamic range (LDR) image pair that preserves more human-perceivable visual content than a single LDR image using the additional image domain. Given a tone-mapped LDR image (left, without loss of generality), our framework optimally synthesizes its counterpart (right) in the image pair from the same source HDR image. The two LDR images are different, so that they can aggregately present more human-perceivable visual richness than a single arbitrary LDR image, without triggering visual discomfort. To achieve this goal, a novel binocular viewing comfort predictor (BVCP) is also proposed to prevent such visual discomfort. The design of BVCP is based on the findings in vision science. Through our user studies, we demonstrate the increase of human-perceivable visual richness and the effectiveness of the proposed BVCP in conservatively predicting the visual discomfort threshold of human observers. ", 
        "id": 1564, 
        "title": "Binocular tone mapping."
    }, 
    {
        "abstract": "We present a novel Markov chain Monte Carlo (MCMC) algorithm that generates samples from transdimensional distributions encoding complex constraints. We use factor graphs, a type of graphical model, to encode constraints as factors. Our proposed MCMC method, called locally annealed reversible jump MCMC, exploits knowledge of how dimension changes affect the structure of the factor graph. We employ a sequence of annealed distributions during the sampling process, allowing us to explore the state space across different dimensionalities more freely. This approach is motivated by the application of layout synthesis where relationships between objects are characterized as constraints. In particular, our method addresses the challenge of synthesizing open world layouts where the number of objects are not fixed and optimal configurations for different numbers of objects may be drastically different. We demonstrate the applicability of our approach on two open world layout synthesis problems: coffee shops and golf courses. ", 
        "id": 1565, 
        "title": "Synthesizing open worlds with constraints using locally annealed reversible jump MCMC."
    }, 
    {
        "abstract": "Capturing human activities that involve both gross full-body motion and detailed hand manipulation of objects is challenging for standard motion capture systems. We introduce a new method for creating natural scenes with such human activities. The input to our method includes motions of the full-body and the objects acquired simultaneously by a standard motion capture system. Our method then automatically synthesizes detailed and physically plausible hand manipulation that can seamlessly integrate with the input motions. Instead of producing one \"optimal\" solution, our method presents a set of motions that exploit a wide variety of manipulation strategies. We propose a randomized sampling algorithm to search for as many as possible visually diverse solutions within the computational time budget. Our results highlight complex strategies human hands employ effortlessly and unconsciously, such as static, sliding, rolling, as well as finger gaits with discrete relocation of contact points. ", 
        "id": 1566, 
        "title": "Synthesis of detailed hand manipulations using contact sampling."
    }, 
    {
        "abstract": "We present a novel framework for animating human characters performing fast visually guided tasks, such as catching a ball. The main idea is to consider the coordinated dynamics of sensing and movement. Based on experimental evidence about such behaviors, we propose a generative model that constructs interception behavior online, using discrete submovements directed by uncertain visual estimates of target movement. An important aspect of this framework is that eye movements are included as well, and play a central role in coordinating movements of the head, hand, and body. We show that this framework efficiently generates plausible movements and generalizes well to novel scenarios. ", 
        "id": 1567, 
        "title": "Eyecatch: simulating visuomotor coordination for object interception."
    }, 
    {
        "abstract": " Implicit functions have a wide range of applications in entertainment, engineering and medical imaging. A standard two-phase implicit function only represents the interior and exterior of a single object. To facilitate solid modeling of heterogeneous objects with multiple internal regions, object-space multiphase implicit functions are much desired. Multiphase implicit functions have much potential in modeling natural organisms, heterogeneous mechanical parts and anatomical atlases. In this paper, we introduce a novel class of object-space multiphase implicit functions that are capable of accurately and compactly representing objects with multiple internal regions. Our proposed multiphase implicit functions facilitate true object-space geometric modeling of heterogeneous objects with non-manifold features. We present multiple methods to create object-space multiphase implicit functions from existing data, including meshes and segmented medical images. Our algorithms are inspired by machine learning algorithms for training multicategory max-margin classifiers. Comparisons demonstrate that our method achieves an error rate one order of magnitude smaller than alternative techniques.  (a)  ", 
        "id": 1568, 
        "title": "Object-space multiphase implicit functions."
    }, 
    {
        "abstract": "", 
        "id": 1569, 
        "title": "Transfusive image manipulation."
    }, 
    {
        "abstract": "Recent yarn-based simulation techniques permit realistic and efficient dynamic simulation of knitted clothing, but producing the required yarn-level models remains a challenge. The lack of practical modeling techniques significantly limits the diversity and complexity of knitted garments that can be simulated. We propose a new modeling technique that builds yarn-level models of complex knitted garments for virtual characters. We start with a polygonal model that represents the large-scale surface of the knitted cloth. Using this mesh as an input, our interactive modeling tool produces a finer mesh representing the layout of stitches in the garment, which we call the stitch mesh. By manipulating this mesh and assigning stitch types to its faces, the user can replicate a variety of complicated knitting patterns. The curve model representing the yarn is generated from the stitch mesh, then the final shape is computed by a yarn-level physical simulation that locally relaxes the yarn into realistic shape while preserving global shape of the garment and avoiding \"yarn pull-through,\" thereby producing valid yarn geometry suitable for dynamic simulation. Using our system, we can efficiently create yarn-level models of knitted clothing with a rich variety of patterns that would be completely impractical to model using traditional techniques. We show a variety of example knitting patterns and full-scale garments produced using our system. ", 
        "id": 1570, 
        "title": "Stitch meshes for modeling knitted clothing with yarn-level detail."
    }, 
    {
        "abstract": "", 
        "id": 1571, 
        "title": "Co-abstraction of shape collections."
    }, 
    {
        "abstract": "", 
        "id": 1572, 
        "title": "DressUp!: outfit synthesis through automatic optimization."
    }, 
    {
        "abstract": "", 
        "id": 1573, 
        "title": "Variational mesh decomposition."
    }, 
    {
        "abstract": " Links: DL PDF WEB  Woven fabrics have a wide range of appearance determined by their small-scale 3D structure. Accurately modeling this structural detail can produce highly realistic renderings of fabrics and is critical for predictive rendering of fabric appearance. But building these yarnlevel volumetric models is challenging. Procedural techniques are manually intensive, and fail to capture the naturally arising irregularities which contribute significantly to the overall appearance of cloth. Techniques that acquire the detailed 3D structure of real fabric samples are constrained only to model the scanned samples and cannot represent different fabric designs. This paper presents a new approach to creating volumetric models of woven cloth, which starts with user-specified fabric designs and produces models that correctly capture the yarn-level structural details of cloth. We create a small database of volumetric exemplars by scanning fabric samples with simple weave structures. To build an output model, our method synthesizes a new volume by copying data from the exemplars at each yarn crossing to match a weave pattern that specifies the desired output structure. Our results demonstrate that our approach generalizes well to complex designs and can produce highly realistic results at both large and small scales. ", 
        "id": 1574, 
        "title": "Structure-aware synthesis for predictive woven fabric appearance."
    }, 
    {
        "abstract": "Images are static and lack important depth information about the underlying 3D scenes. We introduce interactive images in the context of man-made environments wherein objects are simple and regular, share various non-local relations (e.g., coplanarity, parallelism, etc.), and are often repeated. Our interactive framework creates partial scene reconstructions based on cuboid-proxies with minimal user interaction. It subsequently allows a range of intuitive image edits mimicking real-world behavior, which are otherwise difficult to achieve. Effectively, the user simply provides high-level semantic hints, while our system ensures plausible operations by conforming to the extracted non-local relations. We demonstrate our system on a range of real-world images and validate the plausibility of the results using a user study. ", 
        "id": 1575, 
        "title": "Interactive images: cuboid proxies for smart image manipulation."
    }, 
    {
        "abstract": "In this paper, we accelerate self-collision detection (SCD) for a deforming triangle mesh by exploiting the idea that a mesh cannot self collide unless it deforms enough. Unlike prior work on subspace self-collision culling which is restricted to low-rank deformation subspaces, our energy-based approach supports arbitrary mesh deformations while still being fast. Given a bounding volume hierarchy (BVH) for a triangle mesh, we precompute Energy-based SelfCollision Culling (ESCC) certificates on bounding-volume-related sub-meshes which indicate the amount of deformation energy required for it to self collide. After updating energy values at runtime, many bounding-volume self-collision queries can be culled using the ESCC certificates. We propose an affine-frame Laplacian-based energy definition which sports a highly optimized certificate preprocess, and fast runtime energy evaluation. The latter is performed hierarchically to amortize Laplacian energy and affine-frame estimation computations. ESCC supports both discrete and continuous SCD with detailed and nonsmooth geometry. We observe significant culling on many examples, with SCD speed-ups up to 26. Links: DL PDF WEB ", 
        "id": 1576, 
        "title": "Energy-based self-collision culling for arbitrary mesh deformations."
    }, 
    {
        "abstract": "", 
        "id": 1577, 
        "title": "Discontinuity-aware video object cutout."
    }, 
    {
        "abstract": " Fourier spectrum Spatial samples  Point samples with different spectral noise properties (often defined using color names such as white, blue, green, and red) are important for many science and engineering disciplines including computer graphics. While existing techniques can easily produce white and blue noise samples, relatively little is known for generating other noise patterns. In particular, no single algorithm is available to generate different noise patterns according to user-defined spectra. In this paper, we describe an algorithm for generating point samples that match a user-defined Fourier spectrum function. Such a spectrum function can be either obtained from a known sampling method, or completely constructed by the user. Our key idea is to convert the Fourier spectrum function into a differential distribution function that describes the samples' local spatial statistics; we then use a gradient descent solver to iteratively compute a sample set that matches the target differential distribution function. Our algorithm can be easily modified to achieve adaptive sampling, and we provide a GPU-based implementation. Finally, we present a variety of different sample patterns obtained using our algorithm, and demonstrate suitable applications.  Initial  n-th Iteration  Final  Figure 1: Given the sample count and a target Fourier spectrum (a SIGGRAPH logo in this example), our algorithm produces a set of point samples (upper right) that matches the target spectrum. The computation starts from random initial samples, and iteratively updates points using a gradient descent solver. More examples can be found in Figure 2.  ", 
        "id": 1578, 
        "title": "Point sampling with general noise spectrum."
    }, 
    {
        "abstract": "", 
        "id": 1579, 
        "title": "Motion-guided mechanical toy modeling."
    }, 
    {
        "abstract": " We introduce L1-medial skeleton as a curve skeleton representation for 3D point cloud data. The L1-median is well-known as a robust global center of an arbitrary set of points. We make the key observation that adapting L1-medians locally to a point set representing a 3D shape gives rise to a one-dimensional structure, which can be seen as a localized center of the shape. The primary advantage of our approach is that it does not place strong requirements on the quality of the input point cloud nor on the geometry or topology of the captured shape. We develop a L1-medial skeleton construction algorithm, which can be directly applied to an unoriented raw point scan with significant noise, outliers, and large areas of missing data. We demonstrate L1-medial skeletons extracted from raw scans of a variety of shapes, including those modeling high-genus 3D objects, plant-like structures, and curve networks.  ", 
        "id": 1580, 
        "title": "L1-medial skeleton of point cloud."
    }, 
    {
        "abstract": "", 
        "id": 1581, 
        "title": "Edge-aware point set resampling."
    }, 
    {
        "abstract": "", 
        "id": 1582, 
        "title": "\"Mind the gap\": tele-registration for structure-driven image completion."
    }, 
    {
        "abstract": "", 
        "id": 1583, 
        "title": "Sparse localized deformation components."
    }, 
    {
        "abstract": " We introduce an efficient algorithm for producing provably injective mappings of tetrahedral meshes with strict bounds on their tetrahedra aspect-ratio distortion. The algorithm takes as input a simplicial map (e.g., produced by some common deformation or volumetric parameterization technique) and projects it on the space of injective and boundeddistortion simplicial maps. Namely, finds a similar map that is both bijective and bounded-distortion. As far as we are aware, this is the first algorithm to produce injective or bounded-distortion simplicial maps of tetrahedral meshes. The construction of the algorithm was made possible due to a novel closed-form solution to the problem of finding the closest orientation-preserving bounded-distortion matrix to an arbitrary matrix in three (and higher) dimensions. The algorithm is shown to have quadratic convergence, usually not requiring more than a handful of iterations to converge. Furthermore, it is readily generalized to simplicial maps of any dimension, including mixed dimensions. Finally, it can deal with different distortion spaces, such as bounded isometric distortion. During experiments we found the algorithm useful for producing bijective and bounded-distortion volume parameterizations and deformations of tetrahedral meshes, and improving tetrahedral meshes , increasing the tetrahedra quality produced by state-of-the-art techniques. ", 
        "id": 1584, 
        "title": "Injective and bounded distortion mappings in 3D."
    }, 
    {
        "abstract": "Capture Setup Photograph, novel viewpoint Rendering, novel viewpoint Figure 1: Left: our measurement setup consists of a screen and a camera. Middle: a photograph of a material sample, taken under a novel viewpoint and illumination not used in the capture. Right: our rendering with matching lighting and viewing conditions. Abstract Spatially-varying reflectance and small geometric variations play a vital role in the appearance of real-world surfaces. Consequently, robust, automatic capture of such models is highly desirable; however, current systems require either specialized hardware, long capture times, user intervention, or rely heavily on heuristics. We describe an acquisition setup that utilizes only portable commodity hardware (an LCD display, an SLR camera) and contains no moving parts. In particular, a laptop screen can be used for illumination. Our setup, aided by a carefully constructed image formation model, automatically produces realistic spatially-varying reflectance parameters over a wide range of materials from diffuse to almost mirror-like specular surfaces, while requiring relatively few photographs. We believe our system is the first to offer such generality, while requiring only standard office equipment and no user intervention or parameter tuning. Our results exhibit a good qualitative match to photographs taken under novel viewing and lighting conditions for a range of materials.", 
        "id": 1585, 
        "title": "Practical SVBRDF capture in the frequency domain."
    }, 
    {
        "abstract": "", 
        "id": 1586, 
        "title": "Versatile surface tension and adhesion for SPH fluids."
    }, 
    {
        "abstract": "", 
        "id": 1587, 
        "title": "Anatomy transfer."
    }, 
    {
        "abstract": " Links: DL PDF  We introduce a new method for efficiently simulating liquid with extreme amounts of spatial adaptivity. Our method combines several key components to drastically speed up the simulation of largescale fluid phenomena: We leverage an alternative Eulerian tetrahedral mesh discretization to significantly reduce the complexity of the pressure solve while increasing the robustness with respect to element quality and removing the possibility of locking. Next, we enable subtle free-surface phenomena by deriving novel second-order boundary conditions consistent with our discretization. We couple this discretization with a spatially adaptive Fluid-Implicit Particle (FLIP) method, enabling efficient, robust, minimally-dissipative simulations that can undergo sharp changes in spatial resolution while minimizing artifacts. Along the way, we provide a new method for generating a smooth and detailed surface from a set of particles with variable sizes. Finally, we explore several new sizing functions for determining spatially adaptive simulation resolutions, and we show how to couple them to our simulator. We combine each of these elements to produce a simulation algorithm that is capable of creating animations at high maximum resolutions while avoiding common pitfalls like inaccurate boundary conditions and inefficient computation.  ", 
        "id": 1588, 
        "title": "Highly adaptive liquid simulations on tetrahedral meshes."
    }, 
    {
        "abstract": "", 
        "id": 1589, 
        "title": "O-snap: Optimization-based snapping for modeling architecture."
    }, 
    {
        "abstract": "", 
        "id": 1590, 
        "title": "WYSIWYG computational photography via viewfinder editing."
    }, 
    {
        "abstract": "", 
        "id": 1591, 
        "title": "Near-invariant blur for depth and 2D motion via time-varying light field analysis."
    }, 
    {
        "abstract": "", 
        "id": 1592, 
        "title": "Procedural facade variations from a single layout."
    }, 
    {
        "abstract": "Good building layouts are required to conform to regulatory guidelines, while meeting certain quality measures. While different methods can sample the space of such good layouts, there exists little support for a user to understand and systematically explore the samples. Starting from a discrete set of good layouts, we analytically characterize the local shape space of good layouts around each initial layout, compactly encode these spaces, and link them to support transitions across the different local spaces. We represent such transitions in the form of a portal graph. The user can then use the portal graph, along with the family of local shape spaces, to globally and locally explore the space of good building layouts. We use our framework on a variety of different test scenarios to showcase an intuitive design, navigation, and exploration interface. ", 
        "id": 1593, 
        "title": "Generating and exploring good building layouts."
    }, 
    {
        "abstract": "Edge aliasing continues to be one of the most prominent problems in real-time graphics, e.g., in games. We present a novel algorithm that uses shared memory between the GPU and the CPU so that these two units can work in concert to solve the edge aliasing problem rapidly. Our system renders the scene as usual on the GPU with one sample per pixel. At the same time, our novel edge aliasing algorithm is executed asynchronously on the CPU. First, a sparse set of important pixels is created. This set may include pixels with geometric silhouette edges, discontinuities in the frame buffer, and pixels/polygons under user-guided artistic control. After that, the CPU runs our sparse rasterizer and fragment shader, which is parallel and SIMD:ified, and directly accesses shared resources (e.g., render targets created by the GPU). Our system can render a scene with shadow mapping with adaptive anti-aliasing with 16 samples per important pixel faster than the GPU with 8 samples per pixel using multi-sampling anti-aliasing. Since our system consists of an extensive code base, it will be released to the public for exploration and usage. ", 
        "id": 1594, 
        "title": "A4: asynchronous adaptive anti-aliasing using shared memory."
    }, 
    {
        "abstract": "", 
        "id": 1595, 
        "title": "Authoring and animating painterly characters."
    }, 
    {
        "abstract": "", 
        "id": 1596, 
        "title": "5D Covariance tracing for efficient defocus and motion blur."
    }, 
    {
        "abstract": "The appearance of surfaces in real-world scenes is determined by the materials, textures, and context in which the surfaces appear. However, the datasets we have for visualizing and modeling rich surface appearance in context, in applications such as home remodeling, are quite limited. To help address this need, we present OpenSurfaces, a rich, labeled database consisting of thousands of examples of surfaces segmented from consumer photographs of interiors, and annotated with material parameters (reflectance, material names), texture information (surface normals, rectified textures), and contextual information (scene category, and object names). Retrieving usable surface information from uncalibrated Internet photo collections is challenging. We use human annotations and present a new methodology for segmenting and annotating materials in Internet photo collections suitable for crowdsourcing (e.g., through Amazon's Mechanical Turk). Because of the noise and variability inherent in Internet photos and novice annotators, designing this annotation engine was a key challenge; we present a multi-stage set of annotation tasks with quality checks and validation. We demonstrate the use of this database in proof-of-concept applications including surface retexturing and material and image browsing, and discuss future uses. OpenSurfaces is a public resource available at http://opensurfaces.cs.cornell.edu/. ", 
        "id": 1597, 
        "title": "OpenSurfaces: a richly annotated catalog of surface appearance."
    }, 
    {
        "abstract": "Skilled artists, using traditional media or modern computer painting tools, can create a variety of expressive styles that are very appealing in still images, but have been unsuitable for animation. The key difficulty is that existing techniques lack adequate temporal coherence to animate these styles effectively. Here we augment the range of practical animation styles by extending the guided texture synthesis method of Image Analogies [Hertzmann et al. 2001] to create temporally coherent animation sequences. To make the method art directable, we allow artists to paint portions of keyframes that are used as constraints. The in-betweens calculated by our method maintain stylistic continuity and yet change no more than necessary over time.", 
        "id": 1598, 
        "title": "Stylizing animation by example."
    }, 
    {
        "abstract": "", 
        "id": 1599, 
        "title": "A benchmark for surface reconstruction."
    }, 
    {
        "abstract": "We use a data-driven approach to study both style and abstraction in sketching of a human face. We gather and analyze data from a number of artists as they sketch a human face from a reference photograph. To achieve different levels of abstraction in the sketches, decreasing time limits were imposed  from four and a half minutes to fifteen seconds. We analyzed the data at two levels: strokes and geometric shape. In each, we create a model that captures both the style of the different artists and the process of abstraction. These models are then used for a portrait sketch synthesis application. Starting from a novel face photograph, we can synthesize a sketch in the various artistic styles and in different levels of abstraction. Links: DL PDF WEB ", 
        "id": 1600, 
        "title": "Style and abstraction in portrait sketching."
    }, 
    {
        "abstract": "", 
        "id": 1601, 
        "title": "Augmenting physical avatars using projector-based illumination."
    }, 
    {
        "abstract": "This paper presents a method for computing topology changes for triangle meshes in an interactive geometric modeling environment. Most triangle meshes in practice do not exhibit desirable geometric properties, so we develop a solution that is independent of standard assumptions and robust to geometric errors. Specifically, we provide the first method for topology change applicable to arbitrary non-solid, non-manifold, non-closed, self-intersecting surfaces. We prove that this new method for topology change produces the expected conventional results when applied to solid (closed, manifold, non-self-intersecting) surfaces--that is, we prove a backwardscompatibility property relative to prior work. Beyond solid surfaces, we present empirical evidence that our method remains tolerant to a variety of surface aberrations through the incorporation of a novel error correction scheme. Finally, we demonstrate how topology change applied to non-solid objects enables wholly new and useful behaviors. ", 
        "id": 1602, 
        "title": "Putting holes in holey geometry: topology change for arbitrary surfaces."
    }, 
    {
        "abstract": "We present techniques for automatically parsing existing sewing patterns and converting them into 3D garment models. Our parser takes a sewing pattern in PDF format as input and starts by extracting the set of panels and styling elements (e.g. darts, pleats and hemlines) contained in the pattern. It then applies a combination of machine learning and integer programming to infer how the panels must be stitched together to form the garment. Our system includes an interactive garment simulator that takes the parsed result and generates the corresponding 3D model. Our fully automatic approach correctly parses 68% of the sewing patterns in our collection. Most of the remaining patterns contain only a few errors that can be quickly corrected within the garment simulator. Finally we present two applications that take advantage of our collection of parsed sewing patterns. Our garment hybrids application lets users smoothly interpolate multiple garments in the 2D space of patterns. Our sketch-based search application allows users to navigate the pattern collection by drawing the shape of panels. ", 
        "id": 1603, 
        "title": "Parsing sewing patterns into 3D garments."
    }, 
    {
        "abstract": " 1 Detailed surface tracking  Our work concerns the combination of an Eulerian liquid simulation with a high-resolution surface tracker (e.g. the level set method or a Lagrangian triangle mesh). The naive application of a high-resolution surface tracker to a low-resolution velocity field can produce many visually disturbing physical and topological artifacts that limit their use in practice. We address these problems by defining an error function which compares the current state of the surface tracker to the set of physically valid surface states. By reducing this error with a gradient descent technique, we introduce a novel physics-based surface fairing method. Similarly, by treating this error function as a potential energy, we derive a new surface correction force that mimics the vortex sheet equations. We demonstrate our results with both level set and mesh-based surface trackers. ", 
        "id": 1604, 
        "title": "Liquid surface tracking with error compensation."
    }, 
    {
        "abstract": "Quadrilateral remeshing approaches based on global parametrization enable many desirable mesh properties. Two of the most important ones are (1) high regularity due to explicit control over irregular vertices and (2) smooth distribution of distortion achieved by convex variational formulations. Apart from these strengths, state-of-the-art techniques suffer from limited reliability on realworld input data, i.e. the determined map might have degeneracies like (local) non-injectivities and consequently often cannot be used directly to generate a quadrilateral mesh. In this paper we propose a novel convex Mixed-Integer Quadratic Programming (MIQP) formulation which ensures by construction that the resulting map is within the class of so called Integer-Grid Maps that are guaranteed to imply a quad mesh. In order to overcome the NP-hardness of MIQP and to be able to remesh typical input geometries in acceptable time we propose two additional problem specific optimizations: a complexity reduction algorithm and singularity separating conditions. While the former decouples the dimension of the MIQP search space from the input complexity of the triangle mesh and thus is able to dramatically speed up the computation without inducing inaccuracies, the latter improves the continuous relaxation, which is crucial for the success of modern MIQP optimizers. Our experiments show that the reliability of the resulting algorithm does not only annihilate the main drawback of parametrization based quad-remeshing but moreover enables the global search for high-quality coarse quad layouts - a difficult task solely tackled by greedy methodologies before. ", 
        "id": 1605, 
        "title": "Integer-grid maps for reliable quad meshing."
    }, 
    {
        "abstract": "In most professional cinema productions, the color palette of the movie is painstakingly adjusted by a team of skilled colorists  through a process referred to as color grading  to achieve a certain visual look. The time and expertise required to grade a video makes it difficult for amateurs to manipulate the colors of their own video clips. In this work, we present a method that allows a user to transfer the color palette of a model video clip to their own video sequence. We estimate a per-frame color transform that maps the color distributions in the input video sequence to that of the model video clip. Applying this transformation naively leads to artifacts such as bleeding and flickering. Instead, we propose a novel differentialgeometry-based scheme that interpolates these transformations in a manner that minimizes their curvature, similarly to curvature flows. In addition, we automatically determine a set of keyframes that best represent this interpolated transformation curve, and can be used subsequently, to manually refine the color grade. We show how our method can successfully transfer color palettes between videos for a range of visual styles and a number of input video clips. ", 
        "id": 1606, 
        "title": "Example-based video color grading."
    }, 
    {
        "abstract": "We present a new algorithm for realtime face tracking on commodity RGB-D sensing devices. Our method requires no user-specific training or calibration, or any other form of manual assistance, thus enabling a range of new applications in performance-based facial animation and virtual interaction at the consumer level. The key novelty of our approach is an optimization algorithm that jointly solves for a detailed 3D expression model of the user and the corresponding dynamic tracking parameters. Realtime performance and robust computations are facilitated by a novel subspace parameterization of the dynamic facial expression space. We provide a detailed evaluation that shows that our approach significantly simplifies the performance capture workflow, while achieving accurate facial tracking for realtime applications. ", 
        "id": 1607, 
        "title": "Online modeling for realtime facial animation."
    }, 
    {
        "abstract": "", 
        "id": 1608, 
        "title": "Gloss perception in painterly and cartoon rendering."
    }, 
    {
        "abstract": " Links: DL PDF  Good lighting is crucial in photography and can make the difference between a great picture and a discarded image. Traditionally, professional photographers work in a studio with many light sources carefully set up, with the goal of getting a near-final image at exposure time, with post-processing mostly focusing on aspects orthogonal to lighting. Recently, a new workflow has emerged for architectural and commercial photography, where photographers capture several photos from a fixed viewpoint with a moving light source. The objective is not to produce the final result immediately, but rather to capture useful data that are later processed, often significantly, in photo editing software to create the final well-lit image. This new workflow is flexible, requires less manual setup, and works well for time-constrained shots. But dealing with several tens of unorganized layers is painstaking, requiring hours to days of manual effort, as well as advanced photo editing skills. Our objective in this paper is to make the compositing step easier. We describe a set of optimizations to assemble the input images to create a few basis lights that correspond to common goals pursued by photographers, e.g., accentuating edges and curved regions. We also introduce modifiers that capture standard photographic tasks, e.g., to alter the lights to soften highlights and shadows, akin to umbrellas and soft boxes. Our experiments with novice and professional users show that our approach allows them to quickly create satisfying results, whereas working with unorganized images requires considerably more time. Casual users particularly benefit from our approach since coping with a large number of layers is daunting for them and requires significant experience. ", 
        "id": 1609, 
        "title": "User-assisted image compositing for photographic lighting."
    }, 
    {
        "abstract": "Flora is an element in many computer-generated scenes. But trees, bushes and plants have complex geometry and appearance, and are difficult to model manually. One way to address this is to capture models directly from the real world. Existing techniques have focused on extracting macro structure such as the branching structure of trees, or the structure of broad-leaved plants with a relatively small number of surfaces. This paper presents a finer scale technique to demonstrate for the first time the processing of densely leaved foliage - computation of 3D structure, plus extraction of statistics for leaf shape and the configuration of neighboring leaves. Our method starts with a mesh of a single exemplar leaf of the target foliage. Using a small number of images, point cloud data is obtained from multi-view stereo, and the exemplar leaf mesh is fitted non-rigidly to the point cloud over several iterations. In addition, our method learns a statistical model of leaf shape and appearance during the reconstruction phase, and a model of the transformations between neighboring leaves. This information is useful in two ways - to augment and increase leaf density in reconstructions of captured foliage, and to synthesize new foliage that conforms to a user-specified layout and density. The result of our technique is a dense set of captured leaves with realistic appearance, and a method for leaf synthesis. Our approach excels at reconstructing plants and bushes that are primarily defined by dense leaves and is demonstrated with multiple examples. ", 
        "id": 1610, 
        "title": "Image-based reconstruction and synthesis of dense foliage."
    }, 
    {
        "abstract": "The fractures of thin plates often exhibit complex physical behaviors in the real world. In particular, fractures caused by tearing are different from fractures caused by in-plane motions. In this paper, we study how to make thin-plate fracture animations more realistic from three perspectives. We propose a stress relaxation method, which is applied to avoid shattering artifacts after generating each fracture cut. We formulate a fracture-aware remeshing scheme based on constrained Delaunay triangulation, to adaptively provide more fracture details. Finally, we use our multi-layered model to simulate complex fracture behaviors across thin layers. Our experiment shows that the system can efficiently and realistically simulate the fractures of multi-layered thin plates. ", 
        "id": 1611, 
        "title": "Adaptive fracture simulation of multi-layered thin plates."
    }, 
    {
        "abstract": "We present a real-time performance-driven facial animation system based on 3D shape regression. In this system, the 3D positions of facial landmark points are inferred by a regressor from 2D video frames of an ordinary web camera. From these 3D points, the pose and expressions of the face are recovered by fitting a user-specific blendshape model to them. The main technical contribution of this work is the 3D regression algorithm that learns an accurate, userspecific face alignment model from an easily acquired set of training data, generated from images of the user performing a sequence of predefined facial poses and expressions. Experiments show that our system can accurately recover 3D face shapes even for fast motions, non-frontal faces, and exaggerated expressions. In addition, some capacity to handle partial occlusions and changing lighting conditions is demonstrated. ", 
        "id": 1612, 
        "title": "3D shape regression for real-time facial animation."
    }, 
    {
        "abstract": "Thin elastic filaments in real world such as vine tendrils, hair ringlets or curled ribbons often depict a very smooth, curved shape that low-order rod models -- e.g., segment-based rods -- fail to reproduce accurately and compactly. In this paper, we push forward the investigation of high-order models for thin, inextensible elastic rods by building the dynamics of a G2-continuous piecewise 3D clothoid: a smooth space curve with piecewise affine curvature. With the aim of precisely integrating the rod kinematic problem, for which no closed-form solution exists, we introduce a dedicated integration scheme based on power series expansions. It turns out that our algorithm reaches machine precision orders of magnitude faster compared to classical numerical integrators. This property, nicely preserved under simple algebraic and differential operations, allows us to compute all spatial terms of the rod kinematics and dynamics in both an efficient and accurate way. Combined with a semi-implicit time-stepping scheme, our method leads to the efficient and robust simulation of arbitrary curly filaments that exhibit rich, visually pleasing configurations and motion. Our approach was successfully applied to generate various scenarios such as the unwinding of a curled ribbon as well as the aesthetic animation of spiral-like hair or the fascinating growth of twining plants. ", 
        "id": 1613, 
        "title": "Super space clothoids."
    }, 
    {
        "abstract": "", 
        "id": 1614, 
        "title": "Designing and fabricating mechanical automata from mocap sequences."
    }, 
    {
        "abstract": "This paper presents a single-view hair modeling technique for generating visually and physically plausible 3D hair models with modest user interaction. By solving an unambiguous 3D vector field explicitly from the image and adopting an iterative hair generation algorithm, we can create hair models that not only visually match the original input very well but also possess physical plausibility (e.g., having strand roots fixed on the scalp and preserving the length and continuity of real strands in the image as much as possible). The latter property enables us to manipulate hair in many new ways that were previously very difficult with a single image, such as dynamic simulation or interactive hair shape editing. We further extend the modeling approach to handle simple video input, and generate dynamic 3D hair models. This allows users to manipulate hair in a video or transfer styles from images to videos. ", 
        "id": 1615, 
        "title": "Dynamic hair manipulation in images and videos."
    }, 
    {
        "abstract": "", 
        "id": 1616, 
        "title": "Depth synthesis and local warps for plausible image-based navigation."
    }, 
    {
        "abstract": "We address the fundamental challenge of scalability for real-time volumetric surface reconstruction methods. We design a memory efficient, hierarchical data structure for commodity graphics hardware, which supports live reconstruction of large-scale scenes with fine geometric details. Our sparse data structure fuses overlapping depth maps from a moving depth camera into a single volumetric representation, from which detailed surface models are extracted. Our hierarchy losslessly streams data bidirectionally between GPU and host, allowing for unbounded reconstructions. Our pipeline, comprised of depth map post-processing, camera pose estimation, volumetric fusion, surface extraction, and streaming, runs entirely in real-time. We experimentally demonstrate that a shallow hierarchy with relatively large branching factors yields the best memory/speed tradeoff, consuming an order of magnitude less memory than a regular grid. We compare an implementation of our data structure to existing methods and demonstrate higher-quality reconstructions on a variety of large-scale scenes, all captured in real-time.", 
        "id": 1617, 
        "title": "Scalable real-time volumetric surface reconstruction."
    }, 
    {
        "abstract": "Real-world cloth exhibits complex behaviors when it contacts deformable bodies. In this paper, we study how to improve the simulation of cloth-body interactions from three perspectives: collision, friction, and air pressure. We propose an efficient and robust algorithm to detect the collisions between cloth and deformable bodies, using the surface traversal technique. We develop a friction measurement device and we use it to capture frictional data from real-world experiments. The derived friction model can realistically handle complex friction properties of cloth, including anisotropy and nonlinearity. To produce pressure effects caused by the air between cloth and deformable bodies, we define an air mass field on the cloth layer and we use real-world air permeability data to animate it over time. Our results demonstrate the efficiency and accuracy of our system in simulating objects with a three-layer structure (i.e., a cloth layer, an air layer, and an inner body layer), such as pillows, comforters, down jackets, and stuffed toys. ", 
        "id": 1618, 
        "title": "Modeling friction and air effects between cloth and deformable bodies."
    }, 
    {
        "abstract": "", 
        "id": 1619, 
        "title": "Bilateral blue noise sampling."
    }, 
    {
        "abstract": "Figure 1: 3D-printed objects with various effects designed using our reducer-tuner model. Our generalized approach to fabrication enables an easy and intuitive design of objects with different material properties. On the left: a miniature of Earth with a prescribed deformation behavior. On the right: an optimized surface producing a caustic image under proper illumination as well as casting a shadow of a previously designed shape. Insets visualize an input to our system. Abstract Multi-material 3D printing allows objects to be composed of complex, heterogenous arrangements of materials. It is often more natural to define a functional goal than to define the material composition of an object. Translating these functional requirements to fabri-cable 3D prints is still an open research problem. Recently, several specific instances of this problem have been explored (e.g., appearance or elastic deformation), but they exist as isolated, monolithic algorithms. In this paper, we propose an abstraction mechanism that simplifies the design, development, implementation, and reuse of these algorithms. Our solution relies on two new data structures: a reducer tree that efficiently parameterizes the space of material assignments and a tuner network that describes the optimization process used to compute material arrangement. We provide an application programming interface for specifying the desired object and for defining parameters for the reducer tree and tuner network. We illustrate the utility of our framework by implementing several fabrication algorithms as well as demonstrating the manufactured results.", 
        "id": 1620, 
        "title": "Spec2Fab: a reducer-tuner model for translating specifications to 3D prints."
    }, 
    {
        "abstract": "Planar shape interpolation is widely used in computer graphics applications. Despite a wealth of interpolation methods, there is currently no approach that produces shapes with a bounded amount of distortion with respect to the input. As a result, existing interpolation methods may produce shapes that are significantly different than the input and can suffer from fold-overs and other visual artifacts, making them less useful in many practical scenarios. We introduce a novel shape interpolation scheme designed specifically to produce results with a bounded amount of conformal (angular) distortion. Our method is based on an elegant continuous mathematical formulation and provides several appealing properties such as existence and uniqueness of the solution as well as smoothness in space and time domains. We further present a discretization and an efficient practical algorithm to compute the interpolant and demonstrate its usability and good convergence behavior on a wide variety of input shapes. The method is simple to implement and understand. We compare our method to state-of-the-art interpolation methods and demonstrate its superiority in various cases. ", 
        "id": 1621, 
        "title": "Planar shape interpolation with bounded distortion."
    }, 
    {
        "abstract": "", 
        "id": 1622, 
        "title": "3-Sweep: extracting editable objects from a single photo."
    }, 
    {
        "abstract": "", 
        "id": 1623, 
        "title": "Halftone QR codes."
    }, 
    {
        "abstract": "Stochastic sampling in time and over the lens is essential to produce photo-realistic images, and it has the potential to revolutionize real-time graphics. In this paper, we take an architectural view of the problem and propose a novel hardware architecture for efficient shading in the context of stochastic rendering. We replace previous caching mechanisms by a sorting step to extract coherence, thereby ensuring that only non-occluded samples are shaded. The memory bandwidth is kept at a minimum by operating on tiles and using new buffer compression methods. Our architecture has several unique benefits not traditionally associated with deferred shading. First, shading is performed in primitive order, which enables late shading of vertex attributes and avoids the need to generate a G-buffer of pre-interpolated vertex attributes. Second, we support state changes, e.g., change of shaders and resources in the deferred shading pass, avoiding the need for a single uber-shader. We perform an extensive architectural simulation to quantify the benefits of our algorithm on real workloads.", 
        "id": 1624, 
        "title": "A sort-based deferred shading architecture for decoupled sampling."
    }, 
    {
        "abstract": "", 
        "id": 1625, 
        "title": "Simulating liquids and solid-liquid interactions with lagrangian meshes."
    }, 
    {
        "abstract": " ", 
        "id": 1626, 
        "title": "Computational design of mechanical characters."
    }, 
    {
        "abstract": "We present a formulation of Willmore flow for triangulated surfaces that permits extraordinarily large time steps and naturally preserves the quality of the input mesh. The main insight is that Willmore flow becomes remarkably stable when expressed in curvature space  we develop the precise conditions under which curvature is allowed to evolve. The practical outcome is a highly efficient algorithm that naturally preserves texture and does not require remeshing during the flow. We apply this algorithm to surface fairing, geometric modeling, and construction of constant mean curvature (CMC) surfaces. We also present a new algorithm for length-preserving flow on planar curves, which provides a valuable analogy for the surface case. ", 
        "id": 1627, 
        "title": "Robust fairing via conformal curvature flow."
    }, 
    {
        "abstract": "", 
        "id": 1628, 
        "title": "Geodesics in heat: A new approach to computing distance based on heat flow."
    }, 
    {
        "abstract": "", 
        "id": 1629, 
        "title": "A unified interpolatory subdivision scheme for quadrilateral meshes."
    }, 
    {
        "abstract": "This paper presents MeshGit, a practical algorithm for diffing and merging polygonal meshes typically used in subdivision modeling workflows. Inspired by version control for text editing, we introduce the mesh edit distance as a measure of the dissimilarity between meshes. This distance is defined as the minimum cost of matching the vertices and faces of one mesh to those of another. We propose an iterative greedy algorithm to approximate the mesh edit distance, which scales well with model complexity, providing a practical solution to our problem. We translate the mesh correspondence into a set of mesh editing operations that transforms the first mesh into the second. The editing operations can be displayed directly to provide a meaningful visual difference between meshes. For merging, we compute the difference between two versions and their common ancestor, as sets of editing operations. We robustly detect conflicting operations, automatically apply non-conflicting edits, and allow the user to choose how to merge the conflicting edits. We evaluate MeshGit by diffing and merging a variety of meshes and find it to work well for all.", 
        "id": 1630, 
        "title": "MeshGit: diffing and merging meshes for polygonal modeling."
    }, 
    {
        "abstract": "", 
        "id": 1631, 
        "title": "Inverse dynamic hair modeling with frictional contact."
    }, 
    {
        "abstract": "A special family of non-trivial loops on a surface called handle and tunnel loops associates closely to geometric features of \"handles\" and \"tunnels\" respectively in a 3D model. The identification of these handle and tunnel loops can benefit a broad range of applications from topology simplification / repair, and surface parameterization, to feature and shape recognition. Many of the existing efficient algorithms for computing non-trivial loops cannot be used to compute these special type of loops. The two algorithms known for computing handle and tunnel loops provably have a serious drawback that they both require a tessellation of the interior and exterior spaces bounded by the surface. Computing such a tessellation of three dimensional space around the surface is a non-trivial task and can be quite expensive. Furthermore, such a tessellation may need to refine the surface mesh, thus causing the undesirable side-effect of outputting the loops on an altered surface mesh. In this paper, we present an efficient algorithm to compute a basis for handle and tunnel loops without requiring any 3D tessellation. This saves time considerably for large meshes making the algorithm scalable while computing the loops on the original input mesh and not on some refined version of it. We use the concept of the Reeb graph which together with several key theoretical insights on linking number provide an initial set of loops that provably constitute a handle and a tunnel basis. We further develop a novel strategy to tighten these handle and tunnel basis loops to make them geometrically relevant. We demonstrate the efficiency and effectiveness of our algorithm as well as show its robustness against noise, and other anomalies in the input. ", 
        "id": 1632, 
        "title": "An efficient computation of handle and tunnel loops via Reeb graphs."
    }, 
    {
        "abstract": "", 
        "id": 1633, 
        "title": "Joint view expansion and filtering for automultiscopic 3D displays."
    }, 
    {
        "abstract": "Ray-tracing algorithms are known for producing highly realistic images, but at a significant computational cost. For this reason, a large body of research exists on various techniques for accelerating these costly algorithms. One approach to achieving superior performance which has received comparatively little attention is the design of specialised ray-tracing hardware. The research that does exist on this topic has consistently demonstrated that significant performance and efficiency gains can be achieved with dedicated microarchitectures. However, previous work on hardware ray-tracing has focused almost entirely on the traversal and intersection aspects of the pipeline. As a result, the critical aspect of the management and construction of acceleration data-structures remains largely absent from the hardware literature. We propose that a specialised microarchitecture for this purpose could achieve considerable performance and efficiency improvements over programmable platforms. To this end, we have developed the first dedicated microarchitecture for the construction of binned SAH BVHs. Cycle-accurate simulations show that our design achieves significant improvements in raw performance and in the bandwidth required for construction, as well as large efficiency gains in terms of performance per clock and die area compared to manycore implementations. We conclude that such a design would be useful in the context of a heterogeneous graphics processor, and may help future graphics processor designs to reduce predicted technology-imposed utilisation limits. ", 
        "id": 1634, 
        "title": "A hardware unit for fast SAH-optimised BVH construction."
    }, 
    {
        "abstract": "", 
        "id": 1635, 
        "title": "A metric of visual comfort for stereoscopic motion."
    }, 
    {
        "abstract": "", 
        "id": 1636, 
        "title": "Linear efficient antialiased displacement and reflectance mapping."
    }, 
    {
        "abstract": "", 
        "id": 1637, 
        "title": "QEx: robust quad mesh extraction."
    }, 
    {
        "abstract": "", 
        "id": 1638, 
        "title": "Eulerian-on-lagrangian simulation."
    }, 
    {
        "abstract": "", 
        "id": 1639, 
        "title": "*Cages: : A multilevel, multi-cage-based system for mesh deformation."
    }, 
    {
        "abstract": "", 
        "id": 1640, 
        "title": "Reconstructing detailed dynamic face geometry from monocular video."
    }, 
    {
        "abstract": "", 
        "id": 1641, 
        "title": "Flexible muscle-based locomotion for bipedal creatures."
    }, 
    {
        "abstract": "We present a framework that allows quick and intuitive modeling of terrains using concepts inspired by hydrology. The terrain is generated from a simple initial sketch, and its generation is controlled by a few parameters. Our terrain representation is both analytic and continuous and can be rendered by using varying levels of detail. The terrain data are stored in a novel data structure: a construction tree whose internal nodes define a combination of operations, and whose leaves represent terrain features. The framework uses rivers as modeling elements, and it first creates a hierarchical drainage network that is represented as a geometric graph over a given input domain. The network is then analyzed to construct watersheds and to characterize the different types and trajectories of rivers. The terrain is finally generated by combining procedural terrain and river patches with blending and carving operators. ", 
        "id": 1642, 
        "title": "Terrain generation using procedural models based on hydrology."
    }, 
    {
        "abstract": "", 
        "id": 1643, 
        "title": "Joint importance sampling of low-order volumetric scattering."
    }, 
    {
        "abstract": "", 
        "id": 1644, 
        "title": "Physics-based animation of large-scale splashing liquids."
    }, 
    {
        "abstract": "", 
        "id": 1645, 
        "title": "Understanding the role of phase function in translucent appearance."
    }, 
    {
        "abstract": "", 
        "id": 1646, 
        "title": "Inverse volume rendering with material dictionaries."
    }, 
    {
        "abstract": "We present a novel approach for the analysis and design of selfsupporting simplicial masonry structures. A finite-dimensional formulation of their compressive stress field is derived, offering a new interpretation of thrust networks through numerical homogenization theory. We further leverage geometric properties of the resulting force diagram to identify a set of reduced coordinates characterizing the equilibrium of simplicial masonry. We finally derive computational form-finding tools that improve over previous work in efficiency, accuracy, and scalability. ", 
        "id": 1647, 
        "title": "On the equilibrium of simplicial masonry structures."
    }, 
    {
        "abstract": "", 
        "id": 1648, 
        "title": "A gradient-based implicit blend."
    }, 
    {
        "abstract": "", 
        "id": 1649, 
        "title": "Automatic noise modeling for ghost-free HDR reconstruction."
    }, 
    {
        "abstract": "", 
        "id": 1650, 
        "title": "The line of action: an intuitive interface for expressive character posing."
    }, 
    {
        "abstract": "For the visualization of dense line fields, the careful selection of lines to be rendered is a vital aspect. In this paper, we present a global line selection approach that is based on an optimization process. Starting with an initial set of lines that covers the domain, all lines are rendered with a varying opacity, which is subject to the minimization of a bounded-variable least-squares problem. The optimization strives to keep a balance between information presentation and occlusion avoidance. This way, we obtain view-dependent opacities of the line segments, allowing a real-time free navigation while minimizing the danger of missing important structures in the visualization. We compare our technique with existing local and greedy approaches and apply it to data sets in flow visualization, medical imaging, physics, and computer graphics. ", 
        "id": 1651, 
        "title": "Opacity optimization for 3D line fields."
    }, 
    {
        "abstract": "With dozens or even hundreds of photos in today's digital photo albums, editing an entire album can be a daunting task. Existing automatic tools operate on individual photos without ensuring consistency of appearance between photographs that share content. In this paper, we present a new method for consistent editing of photo collections. Our method automatically enforces consistent appearance of images that share content without any user input. When the user does make changes to selected images, these changes automatically propagate to other images in the collection, while still maintaining as much consistency as possible. This makes it possible to interactively adjust an entire photo album in a consistent manner by manipulating only a few images. Our method operates by efficiently constructing a graph with edges linking photo pairs that share content. Consistent appearance of connected photos is achieved by globally optimizing a quadratic cost function over the entire graph, treating user-specified edits as constraints in the optimization. The optimization is fast enough to provide interactive visual feedback to the user. We demonstrate the usefulness of our approach using a number of personal and professional photo collections, as well as internet collections. ACM Reference Format HaCohen, Y., Shechtman, E., Goldman, D., Lischinski, D. 2013. Optimizing Color Consistency in Photo Collections. ACM Trans. Graph. 32, 4, Article 38 (July 2013), 9 pages. DOI = 10.1145/2461912.2461997 http://doi.acm.org/10.1145/2461912.2461997. Copyright Notice Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Copyright  ACM 0730-0301/13/07-ART38 $15.00. DOI: http://doi.acm.org/10.1145/2461912.2461997  ", 
        "id": 1652, 
        "title": "Optimizing color consistency in photo collections."
    }, 
    {
        "abstract": " Subspace techniques greatly reduce the cost of nonlinear simulation by approximating deformations with a small custom basis. In order to represent the deformations well (in terms of a global metric), the basis functions usually have global support, and cannot capture localized deformations. While reduced-space basis functions can be localized to some extent, capturing truly local deformations would still require a very large number of precomputed basis functions, significantly degrading both precomputation and online performance. We present an efficient approach to handling local deformations that cannot be predicted, most commonly arising from contact and collisions, by augmenting the subspace basis with custom functions derived from analytic solutions to static loading problems. We also present a new cubature scheme designed to facilitate fast computation of the necessary runtime quantities while undergoing a changing basis. Our examples yield a two order of magnitude speedup over full-coordinate simulations, striking a desirable balance between runtime speeds and expressive ability. ", 
        "id": 1653, 
        "title": "Subspace integration with local deformations."
    }, 
    {
        "abstract": "", 
        "id": 1654, 
        "title": "Interactive albedo editing in path-traced volumetric materials."
    }, 
    {
        "abstract": "Stitched panoramic images mostly have irregular boundaries. Artists and common users generally prefer rectangular boundaries, which can be obtained through cropping or image completion techniques. In this paper, we present a content-aware warping algorithm that generates rectangular images from stitched panoramic images. Our algorithm consists of two steps. The first local step is meshfree and preliminarily warps the image into a rectangle. With a grid mesh placed on this rectangle, the second global step optimizes the mesh to preserve shapes and straight lines. In various experiments we demonstrate that the results of our approach are often visually plausible, and the introduced distortion is often unnoticeable. ", 
        "id": 1655, 
        "title": "Rectangling panoramic images via warping."
    }, 
    {
        "abstract": "", 
        "id": 1656, 
        "title": "Blue noise sampling with controlled aliasing."
    }, 
    {
        "abstract": "Transient imaging is an exciting a new imaging modality that can be used to understand light propagation in complex environments, and to capture and analyze scene properties such as the shape of hidden objects or the reflectance properties of surfaces. Unfortunately, research in transient imaging has so far been hindered by the high cost of the required instrumentation, as well as the fragility and difficulty to operate and calibrate devices such as femtosecond lasers and streak cameras. In this paper, we explore the use of photonic mixer devices (PMD), commonly used in inexpensive time-of-flight cameras, as alternative instrumentation for transient imaging. We obtain a sequence of differently modulated images with a PMD sensor, impose a model for local light/object interaction, and use an optimization procedure to infer transient images given the measurements and model. The resulting method produces transient images at a cost several orders of magnitude below existing methods, while simultaneously simplifying and speeding up the capture process. ", 
        "id": 1657, 
        "title": "Low-budget transient imaging using photonic mixer devices."
    }, 
    {
        "abstract": "", 
        "id": 1658, 
        "title": "High-quality computational imaging through simple lenses."
    }, 
    {
        "abstract": "Recent years have seen proposals for exciting new computational display technologies that are compressive in the sense that they generate high resolution images or light fields with relatively few display parameters. Image synthesis for these types of displays involves two major tasks: sampling and rendering high-dimensional target imagery, such as light fields or time-varying light fields, as well as optimizing the display parameters to provide a good approximation of the target content. In this paper, we introduce an adaptive optimization framework for compressive displays that generates high quality images and light fields using only a fraction of the total plenoptic samples. We demonstrate the framework for a large set of display technologies, including several types of auto-stereoscopic displays, high dynamic range displays, and high-resolution displays. We achieve significant performance gains, and in some cases are able to process data that would be infeasible with existing methods. ", 
        "id": 1659, 
        "title": "Adaptive image synthesis for compressive displays."
    }, 
    {
        "abstract": "We present an algorithm for denoising triangulated models based on L0 minimization. Our method maximizes the flat regions of the model and gradually removes noise while preserving sharp features. As part of this process, we build a discrete differential operator for arbitrary triangle meshes that is robust with respect to degenerate triangulations. We compare our method versus other anisotropic denoising algorithms and demonstrate that our method is more robust and produces good results even in the presence of high noise. ", 
        "id": 1660, 
        "title": "Mesh denoising via L0 minimization."
    }, 
    {
        "abstract": "", 
        "id": 1661, 
        "title": "Evaluating the distinctiveness and attractiveness of human motions on realistic virtual bodies."
    }, 
    {
        "abstract": "", 
        "id": 1662, 
        "title": "Fine-grained semi-supervised labeling of large shape collections."
    }, 
    {
        "abstract": "We present a method for organizing a heterogeneous collection of 3D shapes for overview and exploration. Instead of relying on quantitative distances, which may become unreliable between dissimilar shapes, we introduce a qualitative analysis which utilizes multiple distance measures but only in cases where the measures can be reliably compared. Our analysis is based on the notion of quartets, each defined by two pairs of shapes, where the shapes in each pair are close to each other, but far apart from the shapes in the other pair. Combining the information from many quartets computed across a shape collection using several distance measures, we create a hierarchical structure we call categorization tree of the shape collection. This tree satisfies the topological (qualitative) constraints imposed by the quartets creating an effective organization of the shapes. We present categorization trees computed on various collections of shapes and compare them to ground truth data from human categorization. We further introduce the concept of degree of separation chart for every shape in the collection and show the effectiveness of using it for interactive shapes exploration. ", 
        "id": 1663, 
        "title": "Qualitative organization of collections of shapes via quartet analysis."
    }, 
    {
        "abstract": "", 
        "id": 1664, 
        "title": "Inverse image editing: recovering a semantic editing history from a before-and-after image pair."
    }, 
    {
        "abstract": "", 
        "id": 1665, 
        "title": "PatchNet: a patch-based image representation for interactive library-driven image editing."
    }, 
    {
        "abstract": "", 
        "id": 1666, 
        "title": "Biharmonic diffusion curve images from boundary elements."
    }, 
    {
        "abstract": "Solid shapes in computer graphics are often represented with boundary descriptions, e.g. triangle meshes, but animation, physicallybased simulation, and geometry processing are more realistic and accurate when explicit volume representations are available. Tetrahedral meshes which exactly contain (interpolate) the input boundary description are desirable but difficult to construct for a large class of input meshes. Character meshes and CAD models are often composed of many connected components with numerous selfintersections, non-manifold pieces, and open boundaries, precluding existing meshing algorithms. We propose an automatic algorithm handling all of these issues, resulting in a compact discretization of the input's inner volume. We only require reasonably consistent orientation of the input triangle mesh. By generalizing the winding number for arbitrary triangle meshes, we define a function that is a perfect segmentation for watertight input and is well-behaved otherwise. This function guides a graphcut segmentation of a constrained Delaunay tessellation (CDT), providing a minimal description that meets the boundary exactly and may be fed as input to existing tools to achieve element quality. We highlight our robustness on a number of examples and show applications of solving PDEs, volumetric texturing and elastic simulation. ", 
        "id": 1667, 
        "title": "Robust inside-outside segmentation using generalized winding numbers."
    }, 
    {
        "abstract": "", 
        "id": 1668, 
        "title": "Data-driven control of flapping flight."
    }, 
    {
        "abstract": "", 
        "id": 1669, 
        "title": "Coded time of flight cameras: sparse deconvolution to address multipath interference and recover time profiles."
    }, 
    {
        "abstract": "We introduce an unsupervised co-hierarchical analysis of a set of shapes, aimed at discovering their hierarchical part structures and revealing relations between geometrically dissimilar yet functionally equivalent shape parts across the set. The core problem is that of representative co-selection. For each shape in the set, one representative hierarchy (tree) is selected from among many possible interpretations of the hierarchical structure of the shape. Collectively, the selected tree representatives maximize the within-cluster structural similarity among them. We develop an iterative algorithm for representative co-selection. At each step, a novel cluster-and-select scheme is applied to a set of candidate trees for all the shapes. The tree-to-tree distance for clustering caters to structural shape analysis by focusing on spatial arrangement of shape parts, rather than their geometric details. The final set of representative trees are unified to form a structural co-hierarchy. We demonstrate co-hierarchical analysis on families of man-made shapes exhibiting high degrees of geometric and finer-scale structural variabilities. ", 
        "id": 1670, 
        "title": "Co-hierarchical analysis of shape structures."
    }, 
    {
        "abstract": "", 
        "id": 1671, 
        "title": "Patch-based high dynamic range video."
    }, 
    {
        "abstract": "We show that a binary voxel grid can be represented orders of magnitude more efficiently than using a sparse voxel octree (SVO) by generalising the tree to a directed acyclic graph (DAG). While the SVO allows for efficient encoding of empty regions of space, the DAG additionally allows for efficient encoding of identical regions of space, as nodes are allowed to share pointers to identical subtrees. We present an efficient bottom-up algorithm that reduces an SVO to a minimal DAG, which can be applied even in cases where the complete SVO would not fit in memory. In all tested scenes, even the highly irregular ones, the number of nodes is reduced by one to three orders of magnitude. While the DAG requires more pointers per node, the memory cost for these is quickly amortized and the memory consumption of the DAG is considerably smaller, even when compared to an ideal SVO without pointers. Meanwhile, our sparse voxel DAG requires no decompression and can be traversed very efficiently. We demonstrate this by ray tracing hard and soft shadows, ambient occlusion, and primary rays in extremely high resolution DAGs at speeds that are on par with, or even faster than, state-of-the-art voxel and triangle GPU ray tracing.", 
        "id": 1672, 
        "title": "High resolution sparse voxel DAGs."
    }, 
    {
        "abstract": "", 
        "id": 1673, 
        "title": "Adaptive progressive photon mapping."
    }, 
    {
        "abstract": "", 
        "id": 1674, 
        "title": "Structure-preserving image smoothing via region covariances."
    }, 
    {
        "abstract": "", 
        "id": 1675, 
        "title": "Screened poisson surface reconstruction."
    }, 
    {
        "abstract": "", 
        "id": 1676, 
        "title": "Exposing photo manipulation with inconsistent shadows."
    }, 
    {
        "abstract": "We present a new subspace integration method that is capable of efficiently adding and subtracting dynamics from an existing highresolution fluid simulation. We show how to analyze the results of an existing high-resolution simulation, discover an efficient reduced approximation, and use it to quickly \"re-simulate\" novel variations of the original dynamics. Prior subspace methods have had difficulty re-simulating the original input dynamics because they lack efficient means of handling semi-Lagrangian advection methods. We show that multi-dimensional cubature schemes can be applied to this and other advection methods, such as MacCormack advection. The remaining pressure and diffusion stages can be written as a single matrix-vector multiply, so as with previous subspace methods, no matrix inversion is needed at runtime. We additionally propose a novel importance sampling-based fitting algorithm that asymptotically accelerates the precomputation stage, and show that the Iterated Orthogonal Projection method can be used to elegantly incorporate moving internal boundaries into a subspace simulation. In addition to efficiently producing variations of the original input, our method can produce novel, abstract fluid motions that we have not seen from any other solver.  ", 
        "id": 1677, 
        "title": "Subspace fluid re-simulation."
    }, 
    {
        "abstract": "The central argument against data-driven methods in computer graphics rests on the curse of dimensionality: it is intractable to precompute \"everything\" about a complex space. In this paper, we challenge that assumption by using several thousand CPU-hours to perform a massive exploration of the space of secondary clothing effects on a character animated through a large motion graph. Our system continually explores the phase space of cloth dynamics, incrementally constructing a secondary cloth motion graph that captures the dynamics of the system. We find that it is possible to sample the dynamical space to a low visual error tolerance and that secondary motion graphs containing tens of gigabytes of raw mesh data can be compressed down to only tens of megabytes. These results allow us to capture the effect of high-resolution, off-line cloth simulation for a rich space of character motion and deliver it efficiently as part of an interactive application. ", 
        "id": 1678, 
        "title": "Near-exhaustive precomputation of secondary cloth effects."
    }, 
    {
        "abstract": "This paper discusses stereoscopic 3D imaging based on line drawing of 3D shapes. We describe the major issues and challenges in generating stereoscopic 3D effects using lines only, with a couple of relatively simple approaches called each-eye-based and centereye-based. Each of these methods has its shortcomings, such as binocular rivalry and inaccurate lines. We explain why and how these problems occur, then describe the concept of stereo-coherent lines and an algorithm to extract them from 3D shapes. We also propose a simple method to stylize stereo lines that ensures the stereo coherence of stroke textures across binocular views. The proposed method provides viewers with unique visual experience of watching 2D drawings popping out of the screen like 3D. ", 
        "id": 1679, 
        "title": "Stereoscopic 3D line drawing."
    }, 
    {
        "abstract": "As large repositories of 3D shape collections continue to grow, understanding the data, especially encoding the inter-model similarity and their variations, is of central importance. For example, many data-driven approaches now rely on access to semantic segmentation information, accurate inter-model point-to-point correspondence, and deformation models that characterize the model collections. Existing approaches, however, are either supervised requiring manual labeling; or employ super-linear matching algorithms and thus are unsuited for analyzing large collections spanning many thousands of models. We propose an automatic algorithm that starts with an initial template model and then jointly optimizes for part segmentation, point-to-point surface correspondence, and a compact deformation model to best explain the input model collection. As output, the algorithm produces a set of probabilistic part-based templates that groups the original models into clusters of models capturing their styles and variations. We evaluate our algorithm on several standard datasets and demonstrate its scalability by analyzing much larger collections of up to thousands of shapes. ", 
        "id": 1680, 
        "title": "Learning part-based templates from large collections of 3D shapes."
    }, 
    {
        "abstract": "", 
        "id": 1681, 
        "title": "Spectral appearance changes induced by light exposure."
    }, 
    {
        "abstract": "", 
        "id": 1682, 
        "title": "Closest point turbulence for liquid surfaces."
    }, 
    {
        "abstract": "This paper describes a method for scene reconstruction of complex, detailed environments from 3D light fields. Densely sampled light fields in the order of 109 light rays allow us to capture the real world in unparalleled detail, but efficiently processing this amount of data to generate an equally detailed reconstruction represents a significant challenge to existing algorithms. We propose an algorithm that leverages coherence in massive light fields by breaking with a number of established practices in image-based reconstruction. Our algorithm first computes reliable depth estimates specifically around object boundaries instead of interior regions, by operating on individual light rays instead of image patches. More homogeneous interior regions are then processed in a fine-to-coarse procedure rather than the standard coarse-to-fine approaches. At no point in our method is any form of global optimization performed. This allows our algorithm to retain precise object contours while still ensuring smooth reconstructions in less detailed areas. While the core reconstruction method handles general unstructured input, we also introduce a sparse representation and a propagation scheme for reliable depth estimates which make our algorithm particularly effective for 3D input, enabling fast and memory efficient processing of \"Gigaray light fields\" on a standard GPU. We show dense 3D reconstructions of highly detailed scenes, enabling applications such as automatic segmentation and image-based rendering, and provide an extensive evaluation and comparison to existing image-based reconstruction techniques. ACM Reference Format Kim, C., Zimmer, H., Pritch, Y., Sorkine-Hornung, A., Gross, M. 2013. Scene Reconstruction from High Spatio-Angular Resolution Light Fields. ACM Trans. Graph. 32, 4, Article 73 (July 2013), 11 pages. DOI = 10.1145/2461912.2461926 http://doi.acm.org/10.1145/2461912.2461926. Copyright Notice Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Copyright  ACM 0730-0301/13/07-ART73 $15.00. DOI: http://doi.acm.org/10.1145/2461912.2461926  ", 
        "id": 1683, 
        "title": "Scene reconstruction from high spatio-angular resolution light fields."
    }, 
    {
        "abstract": "We present a method for constructing smooth n-direction fields (line fields, cross fields, etc.) on surfaces that is an order of magnitude faster than state-of-the-art methods, while still producing fields of equal or better quality. Fields produced by the method are globally optimal in the sense that they minimize a simple, well-defined quadratic smoothness energy over all possible configurations of singularities (number, location, and index). The method is fully automatic and can optionally produce fields aligned with a given guidance field such as principal curvature directions. Computationally the smoothest field is found via a sparse eigenvalue problem involving a matrix similar to the cotanLaplacian. When a guidance field is present, finding the optimal field amounts to solving a single linear system. ", 
        "id": 1684, 
        "title": "Globally optimal direction fields."
    }, 
    {
        "abstract": "", 
        "id": 1685, 
        "title": "Image-based rendering in the gradient domain."
    }, 
    {
        "abstract": "", 
        "id": 1686, 
        "title": "Content-adaptive image downscaling."
    }, 
    {
        "abstract": "We present a new multi-level preconditioning scheme for discrete Poisson equations that arise in various computer graphics applications such as colorization, edge-preserving decomposition for twodimensional images, and geodesic distances and diffusion on threedimensional meshes. Our approach interleaves the selection of fineand coarse-level variables with the removal of weak connections between potential fine-level variables (sparsification) and the compensation for these changes by strengthening nearby connections. By applying these operations before each elimination step and repeating the procedure recursively on the resulting smaller systems, we obtain a highly efficient multi-level preconditioning scheme with linear time and memory requirements. Our experiments demonstrate that our new scheme outperforms or is comparable with other state-of-the-art methods, both in terms of operation count and wallclock time. This speedup is achieved by the new method's ability to reduce the condition number of irregular Laplacian matrices as well as homogeneous systems. It can therefore be used for a wide variety of computational photography problems, as well as several 3D mesh processing tasks, without the need to carefully match the algorithm to the problem characteristics. ", 
        "id": 1687, 
        "title": "Efficient preconditioning of laplacian matrices for computer graphics."
    }, 
    {
        "abstract": "", 
        "id": 1688, 
        "title": "A compact random-access representation for urban modeling and rendering."
    }, 
    {
        "abstract": "", 
        "id": 1689, 
        "title": "Geometry and context for semantic correspondences and functionality recognition in man-made 3D shapes."
    }, 
    {
        "abstract": "Surfaces in the real world exhibit complex appearance due to spatial variations in both their reflectance and local shading frames (i.e. the local coordinate system defined by the normal and tangent direction). For opaque surfaces, existing fabrication solutions can reproduce well only the spatial variations of isotropic reflectance. In this paper, we present a system for fabricating surfaces with desired spatially-varying reflectance, including anisotropic ones, and local shading frames. We approximate each input reflectance, rotated by its local frame, as a small patch of oriented facets coated with isotropic glossy inks. By assigning different ink combinations to facets with different orientations, this bi-scale material can reproduce a wider variety of reflectance than the printer gamut, including anisotropic materials. By orienting the facets appropriately, we control the local shading frame. We propose an algorithm to automatically determine the optimal facets orientations and ink combinations that best approximate a given input appearance, while obeying manufacturing constraints on both geometry and ink gamut. We fabricate the resulting surface with commercially available hardware, a 3D printer to fabricate the facets and a flatbed UV printer to coat them with inks. We validate our method by fabricating a variety of isotropic and anisotropic materials with rich variations in normals and tangents.", 
        "id": 1690, 
        "title": "Bi-scale appearance fabrication."
    }, 
    {
        "abstract": "", 
        "id": 1691, 
        "title": "Near-eye light field displays."
    }, 
    {
        "abstract": "Weighted linear interpolation has been widely used in many skinning techniques including linear blend skinning, dual quaternion blend skinning, and cage based deformation. To speed up performance, these skinning models typically employ a sparseness constraint, in which each 3D model vertex has a small fixed number of non-zero weights. However, the sparseness constraint also imposes certain limitations to skinning models and their various applications. This paper introduces an efficient two-layer sparse compression technique to substantially reduce the computational cost of a dense-weight skinning model, with insignificant loss of its visual quality. It can directly work on dense skinning weights or use example-based skinning decomposition to further improve its accuracy. Experiments and comparisons demonstrate that the introduced sparse compression model can significantly outperform state of the art weight reduction algorithms, as well as skinning decomposition algorithms with a sparseness constraint.", 
        "id": 1692, 
        "title": "Two-layer sparse compression of dense-weight blend skinning."
    }, 
    {
        "abstract": "We introduce a novel Metropolis rendering algorithm that directly computes image gradients, and reconstructs the final image from the gradients by solving a Poisson equation. The reconstruction is aided by a low-fidelity approximation of the image computed during gradient sampling. As an extension of path-space Metropolis light transport, our algorithm is well suited for difficult transport scenarios. We demonstrate that our method outperforms the stateof-the-art in several well-known test scenes. Additionally, we analyze the spectral properties of gradient-domain sampling, and compare it to the traditional image-domain sampling. ", 
        "id": 1693, 
        "title": "Gradient-domain metropolis light transport."
    }, 
    {
        "abstract": "Recent attempts to fabricate surfaces with custom reflectance functions boast impressive angular resolution, yet their spatial resolution is limited. In this paper we present a method to construct spatially varying reflectance at a high resolution of up to 220dpi , orders of magnitude greater than previous attempts, albeit with a lower angular resolution. The resolution of previous approaches is limited by the machining, but more fundamentally, by the geometric optics model on which they are built. Beyond a certain scale geometric optics models break down and wave effects must be taken into account. We present an analysis of incoherent reflectance based on wave optics and gain important insights into reflectance design. We further suggest and demonstrate a practical method, which takes into account the limitations of existing micro-fabrication techniques such as photolithography to design and fabricate a range of reflection effects, based on wave interference. ", 
        "id": 1694, 
        "title": "Fabricating BRDFs at high spatial resolution using wave optics."
    }, 
    {
        "abstract": "Given a short video we create a representation that captures a spectrum of looping videos with varying levels of dynamism, ranging from a static image to a highly animated loop. In such a progressively dynamic video, scene liveliness can be adjusted interactively using a slider control. Applications include background images and slideshows, where the desired level of activity may depend on personal taste or mood. The representation also provides a segmentation of the scene into independently looping regions, enabling interactive local adjustment over dynamism. For a landscape scene, this control might correspond to selective animation and deanimation of grass motion, water ripples, and swaying trees. Converting arbitrary video to looping content is a challenging research problem. Unlike prior work, we explore an optimization in which each pixel automatically determines its own looping period. The resulting nested segmentation of static and dynamic scene regions forms an extremely compact representation. ", 
        "id": 1695, 
        "title": "Automated video looping with progressive dynamism."
    }, 
    {
        "abstract": "", 
        "id": 1696, 
        "title": "Analyzing growing plants from 4D point cloud data."
    }, 
    {
        "abstract": "We present a new method for interpolating both boundary values and gradients over a 2D polygonal domain. Despite various previous efforts, it remains challenging to define a closed-form inter-polant that produces natural-looking functions while allowing flexible control of boundary constraints. Our method builds on an existing transfinite interpolant over a continuous domain, which in turn extends the classical mean value interpolant. We re-derive the inter-polant from the mean value property of biharmonic functions, and prove that the interpolant indeed matches the gradient constraints when the boundary is piece-wise linear. We then give closed-form formula (as generalized barycentric coordinates) for boundary constraints represented as polynomials up to degree 3 (for values) and 1 (for normal derivatives) over each polygon edge. We demonstrate the flexibility and efficiency of our coordinates in two novel applications, smooth image deformation using curved cage networks and adaptive simplification of gradient meshes.", 
        "id": 1697, 
        "title": "Cubic mean value coordinates."
    }, 
    {
        "abstract": "We propose a new method for the large-scale collection and analysis of drawings by using a mobile game specifically designed to collect such data. Analyzing this crowdsourced drawing database, we build a spatially varying model of artistic consensus at the stroke level. We then present a surprisingly simple stroke-correction method which uses our artistic consensus model to improve strokes in realtime. Importantly, our auto-corrections run interactively and appear nearly invisible to the user while seamlessly preserving artistic intent. Closing the loop, the game itself serves as a platform for large-scale evaluation of the effectiveness of our stroke correction algorithm. ", 
        "id": 1698, 
        "title": "Real-time drawing assistance through crowdsourcing."
    }, 
    {
        "abstract": "We present a complete system to semantically decompose and reconstruct 3D models from point clouds. Different than previous urban modeling approaches, our system is designed for residential scenes, which consist of mainly low-rise buildings that do not exhibit the regularity and repetitiveness as high-rise buildings in downtown areas. Our system first automatically labels the input into distinctive categories using supervised learning techniques. Based on the semantic labels, objects in different categories are reconstructed with domain-specific knowledge. In particular, we present a novel building modeling scheme that aims to decompose and fit the building point cloud into basic blocks that are blockwise symmetric and convex. This building representation and its reconstruction algorithm are flexible, efficient, and robust to missing data. We demonstrate the effectiveness of our system on various datasets and compare our building modeling scheme with other state-of-the-art reconstruction algorithms to show its advantage in terms of both quality and speed. ", 
        "id": 1699, 
        "title": "Semantic decomposition and reconstruction of residential scenes from LiDAR data."
    }, 
    {
        "abstract": "We present a probabilistic factor graph model for automatically coloring 2D patterns. The model is trained on example patterns to statistically capture their stylistic properties. It incorporates terms for enforcing both color compatibility and spatial arrangements of colors that are consistent with the training examples. Using Markov Chain Monte Carlo, the model can be sampled to generate a diverse set of new colorings for a target pattern. This general probabilistic framework allows users to guide the generated suggestions via conditional inference or additional soft constraints. We demonstrate results on a variety of coloring tasks, and we evaluate the model through a perceptual study in which participants judged sampled colorings to be significantly preferable to other automatic baselines.", 
        "id": 1700, 
        "title": "Probabilistic color-by-numbers: suggesting pattern colorizations using factor graphs."
    }, 
    {
        "abstract": "We present a novel approach for simulating thin hyperelastic skin. Real human skin is only a few millimeters thick. It can stretch and slide over underlying body structures such as muscles, bones, and tendons, revealing rich details of a moving character. Simulating such skin is challenging because it is in close contact with the body and shares its geometry. Despite major advances in simulating elastodynamics of cloth and soft bodies for computer graphics, such methods are difficult to use for simulating thin skin due to the need to deal with non-conforming meshes, collision detection, and contact response. We propose a novel Eulerian representation of skin that avoids all the difficulties of constraining the skin to lie on the body surface by working directly on the surface itself. Skin is modeled as a 2D hyperelastic membrane with arbitrary topology, which makes it easy to cover an entire character or object. Unlike most Eulerian simulations, we do not require a regular grid and can use triangular meshes to model body and skin geometry. The method is easy to implement, and can use low resolution meshes to animate high-resolution details stored in texture-like maps. Skin movement is driven by the animation of body shape prescribed by an artist or by another simulation, and so it can be easily added as a post-processing stage to an existing animation pipeline. We provide several examples simulating human and animal skin, and skin-tight clothes. ", 
        "id": 1701, 
        "title": "Thin skin elastodynamics."
    }, 
    {
        "abstract": "", 
        "id": 1702, 
        "title": "Fast simulation of mass-spring systems."
    }, 
    {
        "abstract": "", 
        "id": 1703, 
        "title": "Stereoscopizing cel animations."
    }, 
    {
        "abstract": "Masonry structures must be compressively self-supporting; designing such surfaces forms an important topic in architecture as well as a challenging problem in geometric modeling. Under certain conditions, a surjective mapping exists between a power diagram, defined by a set of 2D vertices and associated weights, and the reciprocal diagram that characterizes the force diagram of a discrete self-supporting network. This observation lets us define a new and convenient parameterization for the space of self-supporting networks. Based on it and the discrete geometry of this design space, we present novel geometry processing methods including surface smoothing and remeshing which significantly reduce the magnitude of force densities and homogenize their distribution. ", 
        "id": 1704, 
        "title": "Computing self-supporting surfaces by regular triangulation."
    }, 
    {
        "abstract": "", 
        "id": 1705, 
        "title": "A no-reference metric for evaluating the quality of motion deblurring."
    }, 
    {
        "abstract": "We present a novel video stabilization method which models camera motion with a bundle of (multiple) camera paths. The proposed model is based on a mesh-based, spatially-variant motion representation and an adaptive, space-time path optimization. Our motion representation allows us to fundamentally handle parallax and rolling shutter effects while it does not require long feature trajectories or sparse 3D reconstruction. We introduce the `as-similaras-possible' idea to make motion estimation more robust. Our space-time path smoothing adaptively adjusts smoothness strength by considering discontinuities, cropping size and geometrical distortion in a unified optimization framework. The evaluation on a large variety of consumer videos demonstrates the merits of our method. ", 
        "id": 1706, 
        "title": "Bundled camera paths for video stabilization."
    }, 
    {
        "abstract": "", 
        "id": 1707, 
        "title": "Simulation and control of skeleton-driven soft body characters."
    }, 
    {
        "abstract": "", 
        "id": 1708, 
        "title": "PolyCut: monotone graph-cuts for PolyCube base-complex construction."
    }, 
    {
        "abstract": "", 
        "id": 1709, 
        "title": "3D self-portraits."
    }, 
    {
        "abstract": "We introduce a real-time and calibration-free facial performance capture framework based on a sensor with video and depth input. In this framework, we develop an adaptive PCA model using shape correctives that adjust on-the-fly to the actor's expressions through incremental PCA-based learning. Since the fitting of the adaptive model progressively improves during the performance, we do not require an extra capture or training session to build this model. As a result, the system is highly deployable and easy to use: it can faithfully track any individual, starting from just a single face scan of the subject in a neutral pose. Like many real-time methods, we use a linear subspace to cope with incomplete input data and fast motion. To boost the training of our tracking model with reliable samples, we use a well-trained 2D facial feature tracker on the input video and an efficient mesh deformation algorithm to snap the result of the previous step to high frequency details in visible depth map regions. We show that the combination of dense depth maps and texture features around eyes and lips is essential in capturing natural dialogues and nuanced actor-specific emotions. We demonstrate that using an adaptive PCA model not only improves the fitting accuracy for tracking but also increases the expressiveness of the retargeted character. ", 
        "id": 1710, 
        "title": "Realtime facial animation with on-the-fly correctives."
    }, 
    {
        "abstract": "Vector graphics represent images with compact, editable and scalable primitives. Skillful vector artists employ these primitives to produce vivid depictions of material appearance and lighting. However, such stylized imagery often requires building complex multilayered combinations of colored fills and gradient meshes. We facilitate this task by introducing vector shade trees that bring to vector graphics the flexibility of modular shading representations as known in the 3D rendering community. In contrast to traditional shade trees that combine pixel and vertex shaders, our shade nodes encapsulate the creation and blending of vector primitives that vector artists routinely use. We propose a set of basic shade nodes that we design to respect the traditional guidelines on material depiction described in drawing books and tutorials. We integrate our representation as an Adobe Illustrator plug-in that allows even inexperienced users to take a line drawing, apply a few clicks and obtain a fully colored illustration. More experienced artists can easily refine the illustration, adding more details and visual features, while using all the vector drawing tools they are already familiar with. We demonstrate the power of our representation by quickly generating illustrations of complex objects and materials. ", 
        "id": 1711, 
        "title": "Depicting stylized materials with vector shade trees."
    }, 
    {
        "abstract": "Conventional digital painting systems rely on procedural rules and physical simulation to render paint strokes. We present an interactive, data-driven painting system that uses scanned images of real natural media to synthesize both new strokes and complex stroke interactions, obviating the need for physical simulation. First, users capture images of real media, including examples of isolated strokes, pairs of overlapping strokes, and smudged strokes. Online, the user inputs a new stroke path, and our system synthesizes its 2D texture appearance with optional smearing or smudging when strokes overlap. We demonstrate high-fidelity paintings that closely resemble the captured media style, and also quantitatively evaluate our synthesis quality via user studies. ", 
        "id": 1712, 
        "title": "RealBrush: painting with examples of physical media."
    }, 
    {
        "abstract": "In this paper we propose a reinterpretation of the brush and the fill tools for digital image painting. The core idea is to provide an intuitive approach that allows users to paint in the visual style of arbitrary example images. Rather than a static library of colors, brushes, or fill patterns, we offer users entire images as their palette, from which they can select arbitrary contours or textures as their brush or fill tool in their own creations. Compared to previous example-based techniques related to the painting-by-numbers paradigm we propose a new strategy where users can generate salient texture boundaries by our randomized graph-traversal algorithm and apply a content-aware fill to transfer textures into the delimited regions. This workflow allows users of our system to intuitively create visually appealing images that better preserve the visual richness and fluidity of arbitrary example images. We demonstrate the potential of our approach in various applications including interactive image creation, editing and vector image stylization. ", 
        "id": 1713, 
        "title": "Painting by feature: texture boundaries for example-based image creation."
    }, 
    {
        "abstract": "Existing hair capture systems fail to produce strands that reflect the structures of real-world hairstyles. We introduce a system that reconstructs coherent and plausible wisps aware of the underlying hair structures from a set of still images without any special lighting. Our system first discovers locally coherent wisp structures in the reconstructed point cloud and the 3D orientation field, and then uses a novel graph data structure to reason about both the connectivity and directions of the local wisp structures in a global optimization. The wisps are then completed and used to synthesize hair strands which are robust against occlusion and missing data and plausible for animation and simulation. We show reconstruction results for a variety of complex hairstyles including curly, wispy, and messy hair. ", 
        "id": 1714, 
        "title": "Structure-aware hair capture."
    }, 
    {
        "abstract": " In fluid simulation, enforcing incompressibility is crucial for realism; it is also computationally expensive. Recent work has improved efficiency, but still requires time-steps that are impractical for real-time applications. In this work we present an iterative density solver integrated into the Position Based Dynamics framework (PBD). By formulating and solving a set of positional constraints that enforce constant density, our method allows similar incompressibility and convergence to modern smoothed particle hydrodynamic (SPH) solvers, but inherits the stability of the geometric, position based dynamics method, allowing large time steps suitable for real-time applications. We incorporate an artificial pressure term that improves particle distribution, creates surface tension, and lowers the neighborhood requirements of traditional SPH. Finally, we address the issue of energy loss by applying vorticity confinement as a velocity post process.  (a) Real-time rendered fluid surface using ellipsoid splatting  ", 
        "id": 1715, 
        "title": "Position based fluids."
    }, 
    {
        "abstract": "", 
        "id": 1716, 
        "title": "Focus 3D: Compressive accommodation display."
    }, 
    {
        "abstract": " We propose a non-permanent add-on that enables plenoptic imaging with standard cameras. Our design is based on a physical copying mechanism that multiplies a sensor image into a number of identical copies that still carry the plenoptic information of interest. Via different optical filters, we can then recover the desired information. A minor modification of the design also allows for aperture subsampling and, hence, light-field imaging. As the filters in our design are exchangeable, a reconfiguration for different imaging purposes is possible. We show in a prototype setup that high dynamic range, multispectral, polarization, and light-field imaging can be achieved with our design. ", 
        "id": 1717, 
        "title": "A reconfigurable camera add-on for high dynamic range, multispectral, polarization, and light-field imaging."
    }, 
    {
        "abstract": "We present a method to create high-quality sampling filters by combining a prescribed number of texels from several resolutions in a mipmap. Our technique provides fine control over the number of texels we read per texture sample so that we can scale quality to match a memory bandwidth budget. Our method also has a fixed cost regardless of the filter we approximate, which makes it feasible to approximate higher-quality filters such as a Lnczos 2 filter in real-time rendering. To find the best set of texels to represent a given sampling filter and what weights to assign those texels, we perform a cardinality-constrained least-squares optimization of the most likely candidate solutions and encode the results of the optimization in a small table that is easily stored on the GPU. We present results that show we accurately reproduce filters using few texel reads and that both quality and speed scale smoothly with available bandwidth. When using four or more texels per sample, our image quality exceeds that of trilinear interpolation.", 
        "id": 1718, 
        "title": "Cardinality-constrained texture filtering."
    }, 
    {
        "abstract": "Light field photography has gained a significant research interest in the last two decades; today, commercial light field cameras are widely available. Nevertheless, most existing acquisition approaches either multiplex a low-resolution light field into a single 2D sensor image or require multiple photographs to be taken for acquiring a high-resolution light field. We propose a compressive light field camera architecture that allows for higher-resolution light fields to be recovered than previously possible from a single image. The proposed architecture comprises three key components: light field atoms as a sparse representation of natural light fields, an optical design that allows for capturing optimized 2D light field projections, and robust sparse reconstruction methods to recover a 4D light field from a single coded 2D projection. In addition, we demonstrate a variety of other applications for light field atoms and sparse coding, including 4D light field compression and denoising. ", 
        "id": 1719, 
        "title": "Compressive light field photography using overcomplete dictionaries and optimized projections."
    }, 
    {
        "abstract": "Many natural phenomena consist of geometric elements with dynamic motions characterized by small scale repetitions over large scale structures, such as particles, herds, threads, and sheets. Due to their ubiquity, controlling the appearance and behavior of such phenomena is important for a variety of graphics applications. However, such control is often challenging; the repetitive elements are often too numerous for manual edit, while their overall structures are often too versatile for fully automatic computation. We propose a method that facilitates easy and intuitive controls at both scales: high-level structures through spatial-temporal output constraints (e.g. overall shape and motion of the output domain), and low-level details through small input exemplars (e.g. element arrangements and movements). These controls are suitable for manual specification, while the corresponding geometric and dynamic repetitions are suitable for automatic computation. Our system takes such user controls as inputs, and generates as outputs the corresponding repetitions satisfying the controls. Our method, which we call dynamic element textures, aims to produce such controllable repetitions through a combination of constrained optimization (satisfying controls) and data driven computation (synthesizing details). We use spatial-temporal samples as the core representation for dynamic geometric elements. We propose analysis algorithms for decomposing small scale repetitions from large scale themes, as well as synthesis algorithms for generating outputs satisfying user controls. Our method is general, producing a range of artistic effects that previously required disparate and specialized techniques. ", 
        "id": 1720, 
        "title": "Dynamic element textures."
    }, 
    {
        "abstract": "", 
        "id": 1721, 
        "title": "Wave-based sound propagation in large open scenes using an equivalent source formulation."
    }, 
    {
        "abstract": "We introduce an algorithm for interactive rendering of physicallybased global illumination, based on a novel frequency analysis of indirect lighting. Our method combines adaptive sampling by Monte Carlo ray or path tracing, using a standard GPU-accelerated raytracer, with real-time reconstruction of the resulting noisy images. Our theoretical analysis assumes diffuse indirect lighting, with general Lambertian and specular receivers. In practice, we demonstrate accurate interactive global illumination with diffuse and moderately glossy objects, at 1-3 fps. We show mathematically that indirect illumination is a structured signal in the Fourier domain, with inherent band-limiting due to the BRDF and geometry terms. We extend previous work on sheared and axis-aligned filtering for motion blur and shadows, to develop an image-space filtering method for interreflections. Our method enables 5-8 reduced sampling rates and wall clock times, and converges to ground truth as more samples are added. To develop our theory, we overcome important technical challenges--unlike previous work, there is no light source to serve as a band-limit in indirect lighting, and we also consider non-parallel geometry of receiver and reflecting surfaces, without first-order approximations. ACM Reference Format Mehta, S., Wang, B., Ramamoorthi, R., Durand, F. 2013. Axis-Aligned Filtering for Interactive PhysicallyBased Diffuse Indirect Lighting. ACM Trans. Graph. 32, 4, Article 96 (July 2013), 11 pages. DOI = 10.1145/2461912.2461947 http://doi.acm.org/10.1145/2461912.2461947. Copyright Notice Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. 2013 Copyright held by the Owner/Author. Publication rights licensed to ACM. 0730-0301/13/07-ART96 $15.00. DOI: http://dx.doi.org/10.1145/2461912.2461947  ", 
        "id": 1722, 
        "title": "Axis-aligned filtering for interactive physically-based diffuse indirect lighting."
    }, 
    {
        "abstract": "", 
        "id": 1723, 
        "title": "Modeling and estimation of internal friction in cloth."
    }, 
    {
        "abstract": "", 
        "id": 1724, 
        "title": "Animating human lower limbs using contact-invariant optimization."
    }, 
    {
        "abstract": "We propose a new fast, robust and controllable method to simulate the dynamic destruction of large and complex objects in real time. The common method for fracture simulation in computer games is to pre-fracture models and replace objects by their pre-computed parts at run-time. This popular method is computationally cheap but has the disadvantages that the fracture pattern does not align with the impact location and that the number of hierarchical fracture levels is fixed. Our method allows dynamic fracturing of large objects into an unlimited number of pieces fast enough to be used in computer games. We represent visual meshes by volumetric approximate convex decompositions (VACD) and apply user-defined fracture patterns dependent on the impact location. The method supports partial fracturing meaning that fracture patterns can be applied locally at multiple locations of an object. We propose new methods for computing a VACD, for approximate convex hull construction and for detecting islands in the convex decomposition after partial destruction in order to determine support structures.  Links: DL PDF ", 
        "id": 1725, 
        "title": "Real time dynamic fracture with volumetric approximate convex decompositions."
    }, 
    {
        "abstract": "", 
        "id": 1726, 
        "title": "VDB: High-resolution sparse volumes with dynamic topology."
    }, 
    {
        "abstract": "The quality of a global parametrization is determined by a number of factors, including amount of distortion, number of singularities (cones), and alignment with features and boundaries. Placement of cones plays a decisive role in determining the overall distortion of the parametrization; at the same time, feature and boundary alignment also affect the cone placement. A number of methods were proposed for automatic choice of cone positions, either based on singularities of cross-fields and emphasizing alignment, or based on distortion optimization. In this paper we describe a method for placing cones for seamless global parametrizations with alignment constraints. We use a close relation between variation-minimizing cross-fields and related 1forms and conformal maps, and demonstrate how it leads to a constrained optimization problem formulation. We show for boundaryaligned parametrizations metric distortion may be reduced by cone chains, sometimes to an arbitrarily small value, and the trade-off between the distortion and the number of cones can be controlled by a regularization term. Constrained parametrizations computed using our method have significantly lower distortion compared to the state-of-the art field-based method, yet maintain feature and boundary alignment. In the most extreme cases, parametrization collapse due to alignment constraints is eliminated. ", 
        "id": 1727, 
        "title": "Controlled-distortion constrained global parametrization."
    }, 
    {
        "abstract": "We present a technique for simulating plastic deformation in sheets of thin materials, such as crumpled paper, dented metal, and wrinkled cloth. Our simulation uses a framework of adaptive mesh refinement to dynamically align mesh edges with folds and creases. This framework allows efficient modeling of sharp features and avoids bend locking that would be otherwise caused by stiff in-plane behavior. By using an explicit plastic embedding space we prevent remeshing from causing shape diffusion. We include several examples demonstrating that the resulting method realistically simulates the behavior of thin sheets as they fold and crumple. ", 
        "id": 1728, 
        "title": "Folding and crumpling adaptive sheets."
    }, 
    {
        "abstract": "Physics based simulation of the dynamics of water spray - water droplets dispersed in air - is a means to increase the visual plausibility of computer graphics modeled phenomena such as waterfalls, water jets and stormy seas. Spray phenomena are frequently encountered by the visual effects industry and often challenge state of the art methods. Current spray simulation pipelines typically employ a combination of Lagrangian (particle) and Eulerian (volumetric) methods - the Eulerian methods being used for parts of the spray where individual droplets are not apparent. However, existing Eulerian methods in computer graphics are based on gas solvers that will for example exhibit hydrostatic equilibrium in certain scenarios where the air is expected to rise and the water droplets fall. To overcome this problem, we propose to simulate spray in the Eulerian domain as a two-way coupled two-continua of air and water phases co-existing at each point in space. The fundamental equations originate in applied physics and we present a number of contributions that make Eulerian two-continua spray simulation feasible for computer graphics applications. The contributions include a Poisson equation that fits into the operator splitting methodology as well as (semi-)implicit discretizations of droplet diffusion and the drag force with improved stability properties. As shown by several examples, our approach allows us to more faithfully capture the dynamics of spray than previous Eulerian methods. ", 
        "id": 1729, 
        "title": "A two-continua approach to Eulerian simulation of water spray."
    }, 
    {
        "abstract": "", 
        "id": 1730, 
        "title": "Synthesizing waves from animated height fields."
    }, 
    {
        "abstract": "", 
        "id": 1731, 
        "title": "Analytic displacement mapping using hardware tessellation."
    }, 
    {
        "abstract": "", 
        "id": 1732, 
        "title": "Real-time 3D reconstruction at scale using voxel hashing."
    }, 
    {
        "abstract": "", 
        "id": 1733, 
        "title": "Topology-driven vectorization of clean line drawings."
    }, 
    {
        "abstract": "", 
        "id": 1734, 
        "title": "Interactive localized liquid motion editing."
    }, 
    {
        "abstract": "We consider the problem of generalizing affine combinations in Euclidean spaces to triangle meshes: computing weighted averages of points on surfaces. We address both the forward problem, namely computing an average of given anchor points on the mesh with given weights, and the inverse problem, which is computing the weights given anchor points and a target point. Solving the forward problem on a mesh enables applications such as splines on surfaces, Laplacian smoothing and remeshing. Combining the forward and inverse problems allows us to define a correspondence mapping between two different meshes based on provided corresponding point pairs, enabling texture transfer, compatible remeshing, morphing and more. Our algorithm solves a single instance of a forward or an inverse problem in a few microseconds. We demonstrate that anchor points in the above applications can be added/removed and moved around on the meshes at interactive framerates, giving the user an immediate result as feedback. ", 
        "id": 1735, 
        "title": "Weighted averages on surfaces."
    }, 
    {
        "abstract": "We present a complete design pipeline that allows non-expert users to design and analyze masonry structures without any structural knowledge. We optimize the force layouts both geometrically and topologically, finding a self-supported structure that is as close as possible to a given target surface. The generated structures are tessellated into hexagonal blocks with a pattern that prevents sliding failure. The models can be used in physically plausible virtual environments or 3D printed and assembled without reinforcements. ", 
        "id": 1736, 
        "title": "Designing unreinforced masonry models."
    }, 
    {
        "abstract": "", 
        "id": 1737, 
        "title": "Efficient penetration depth approximation using active learning."
    }, 
    {
        "abstract": " ", 
        "id": 1738, 
        "title": "Fabricating translucent materials using continuous pigment mixtures."
    }, 
    {
        "abstract": "", 
        "id": 1739, 
        "title": "Instant convolution shadows for volumetric detail mapping."
    }, 
    {
        "abstract": "Imbalance suggests a feeling of dynamism and movement in static objects. It is therefore not surprising that many 3D models stand in impossibly balanced configurations. As long as the models remain in a computer this is of no consequence: the laws of physics do not apply. However, fabrication through 3D printing breaks the illusion: printed models topple instead of standing as initially intended. We propose to assist users in producing novel, properly balanced designs by interactively deforming an existing model. We formulate balance optimization as an energy minimization, improving stability by modifying the volume of the object, while preserving its surface details. This takes place during interactive editing: the user cooperates with our optimizer towards the end result. We demonstrate our method on a variety of models. With our technique, users can produce fabricated objects that stand in one or more surprising poses without requiring glue or heavy pedestals. ", 
        "id": 1740, 
        "title": "Make it stand: balancing shapes for 3D fabrication."
    }, 
    {
        "abstract": "", 
        "id": 1741, 
        "title": "Interactive by-example design of artistic packing layouts."
    }, 
    {
        "abstract": "We present a new technique for simulating high resolution surface wrinkling deformations of composite objects consisting of a soft interior and a harder skin. We combine high resolution thin shells with coarse finite element lattices and define frequency based constraints that allow the formation of wrinkles with properties matching those predicted by the physical parameters of the composite object. Our two-way coupled model produces the expected wrinkling behavior without the computational expense of a large number of volumetric elements to model deformations under the surface. We use C1 quadratic shape functions for the interior deformations, allowing very coarse resolutions to model the overall global deformation efficiently, while avoiding visual artifacts of wrinkling at discretization boundaries. We demonstrate that our model produces wrinkle wavelengths that match both theoretical predictions and high resolution volumetric simulations. We also show example applications in simulating wrinkles on passive objects, such as furniture, and for wrinkles on faces in character animation. ", 
        "id": 1742, 
        "title": "Embedded thin shells for wrinkle simulation."
    }, 
    {
        "abstract": "We present radiance regression functions for fast rendering of global illumination in scenes with dynamic local light sources. A radiance regression function (RRF) represents a non-linear mapping from local and contextual attributes of surface points, such as position, viewing direction, and lighting condition, to their indirect illumination values. The RRF is obtained from precomputed shading samples through regression analysis, which determines a function that best fits the shading data. For a given scene, the shading samples are precomputed by an offline renderer. The key idea behind our approach is to exploit the nonlinear coherence of the indirect illumination data to make the RRF both compact and fast to evaluate. We model the RRF as a multilayer acyclic feed-forward neural network, which provides a close functional approximation of the indirect illumination and can be efficiently evaluated at run time. To effectively model scenes with spatially variant material properties, we utilize an augmented set of attributes as input to the neural network RRF to reduce the amount of inference that the network needs to perform. To handle scenes with greater geometric complexity, we partition the input space of the RRF model and represent the subspaces with separate, smaller RRFs that can be evaluated more rapidly. As a result, the RRF model scales well to increasingly complex scene geometry and material variation. Because of its compactness and ease of evaluation, the RRF model enables real-time rendering with full global illumination effects, including changing caustics and multiple-bounce high-frequency glossy interreflections. ", 
        "id": 1743, 
        "title": "Global illumination with radiance regression functions."
    }, 
    {
        "abstract": "", 
        "id": 1744, 
        "title": "Example-guided physically based modal sound synthesis."
    }, 
    {
        "abstract": "", 
        "id": 1745, 
        "title": "3D Wikipedia: using online text to automatically label and navigate reconstructed geometry."
    }, 
    {
        "abstract": "We develop a novel formulation for the notion of shape differences, aimed at providing detailed information about the location and nature of the differences or distortions between the two shapes being compared. Our difference operator, derived from a shape map, is much more informative than just a scalar global shape similarity score, rendering it useful in a variety of applications where more refined shape comparisons are necessary. The approach is intrinsic and is based on a linear algebraic framework, allowing the use of many common linear algebra tools (e.g, SVD, PCA) for studying a matrix representation of the operator. Remarkably, the formulation allows us not only to localize shape differences on the shapes involved, but also to compare shape differences across pairs of shapes, and to analyze the variability in entire shape collections based on the differences between the shapes. Moreover, while we use a map or correspondence to define each shape difference, consistent correspondences between the shapes are not necessary for comparing shape differences, although they can be exploited if available. We give a number of applications of shape differences, including parameterizing the intrinsic variability in a shape collection, exploring shape collections using local variability at different scales, performing shape analogies, and aligning shape collections. ", 
        "id": 1746, 
        "title": "Map-based exploration of intrinsic shape differences and variability."
    }, 
    {
        "abstract": "", 
        "id": 1747, 
        "title": "A practical microcylinder appearance model for cloth rendering."
    }, 
    {
        "abstract": "", 
        "id": 1748, 
        "title": "3D+2DTV: 3D displays with no ghosting for viewers without glasses."
    }, 
    {
        "abstract": "Industry-quality content creation relies on tools for lighting artists to quickly prototype, iterate, and refine final renders. As industry-leading studios quickly adopt physically-based rendering (PBR) across their art generation pipelines, many existing tools have become unsuitable as they address only simple effects without considering underlying PBR concepts and constraints. We present a novel light transport manipulation technique that operates directly on path-space solutions of the rendering equation. We expose intuitive direct and indirect manipulation approaches to edit complex effects such as (multi-refracted) caustics, diffuse and glossy indirect bounces, and direct / indirect shadows. With our sketchand object-space selection, all built atop a parameterized regular expression engine, artists can search and isolate shading effects to inspect and edit. We classify and filter paths on the fly and visualize the selected transport phenomena. We survey artists who used our tool to manipulate complex phenomena on both static and animated scenes.", 
        "id": 1749, 
        "title": "Path-space manipulation of physically-based light transport."
    }, 
    {
        "abstract": "Concept sketches are popularly used by designers to convey pose and function of products. Understanding such sketches, however, requires special skills to form a mental 3D representation of the product geometry by linking parts across the different sketches and imagining the intermediate object configurations. Hence, the sketches can remain inaccessible to many, especially non-designers. We present a system to facilitate easy interpretation and exploration of concept sketches. Starting from crudely specified incomplete geometry, often inconsistent across the different views, we propose a globally-coupled analysis to extract part correspondence and inter-part junction information that best explain the different sketch views. The user can then interactively explore the abstracted object to gain better understanding of the product functions. Our key technical contribution is performing shape analysis without access to any coherent 3D geometric model by reasoning in the space of inter-part relations. We evaluate our system on various concept sketches obtained from popular product design books and websites. ", 
        "id": 1750, 
        "title": "Interpreting concept sketches."
    }, 
    {
        "abstract": "", 
        "id": 1751, 
        "title": "Data-driven hallucination of different times of day from a single outdoor photo."
    }, 
    {
        "abstract": "We present a method for fabrication-oriented design of actuated deformable characters that allows a user to automatically create physical replicas of digitally designed characters using rapid manufacturing technologies. Given a deformable character and a set of target poses as input, our method computes a small set of actuators along with their locations on the surface and optimizes the internal material distribution such that the resulting character exhibits the desired deformation behavior. We approach this problem with a dedicated algorithm that combines finite-element analysis, sparse regularization, and constrained optimization. We validate our pipeline on a set of two- and three-dimensional example characters and present results in simulation and physically-fabricated prototypes. ", 
        "id": 1752, 
        "title": "Computational design of actuated deformable characters."
    }, 
    {
        "abstract": "AIREAL is a novel haptic technology that delivers effective and expressive tactile sensations in free air, without requiring the user to wear a physical device. Combined with interactive computers graphics, AIREAL enables users to feel virtual 3D objects, experience free air textures and receive haptic feedback on gestures performed in free space. AIREAL relies on air vortex generation directed by an actuated flexible nozzle to provide effective tactile feedback with a 75 degrees field of view, and within an 8.5cm resolution at 1 meter. AIREAL is a scalable, inexpensive and practical free air haptic technology that can be used in a broad range of applications, including gaming, mobile applications, and gesture interaction among many others. This paper reports the details of the AIREAL design and control, experimental evaluations of the devices performance, as well as an exploration of the application space of free air haptic displays. Although we used vortices, we believe that the results reported are generalizable and will inform the design of haptic displays based on alternative principles of free air tactile actuation.", 
        "id": 1753, 
        "title": "AIREAL: interactive tactile experiences in free air."
    }, 
    {
        "abstract": "A reciprocal frame (RF) is a self-supported three-dimensional structure made up of three or more sloping rods, which form a closed circuit, namely an RF-unit. Large RF-structures built as complex grillages of one or a few similar RF-units have an intrinsic beauty derived from their inherent self-similar and highly symmetric patterns. Designing RF-structures that span over large domains is an intricate and complex task. In this paper, we present an interactive computational tool for designing RF-structures over a 3D guiding surface, focusing on the aesthetic aspect of the design. There are three key contributions in this work. First, we draw an analogy between RF-structures and plane tiling with regular polygons, and develop a computational scheme to generate coherent RF-tessellations from simple grammar rules. Second, we employ a conformal mapping to lift the 2D tessellation over a 3D guiding surface, allowing a real-time preview and efficient exploration of wide ranges of RF design parameters. Third, we devise an optimization method to guarantee the collinearity of contact joints along each rod, while preserving the geometric properties of the RF-structure. Our tool not only supports the design of wide variety of RF pattern classes and their variations, but also allows preview and refinement through interactive controls.", 
        "id": 1754, 
        "title": "Reciprocal frame structures made easy."
    }, 
    {
        "abstract": "", 
        "id": 1755, 
        "title": "Progressive photon relaxation."
    }, 
    {
        "abstract": "This paper extends Galerkin projection to a large class of nonpolynomial functions typically encountered in graphics. We demonstrate the broad applicability of our approach by applying it to two strikingly different problems: fluid simulation and radiosity rendering, both using deforming meshes. Standard Galerkin projection cannot efficiently approximate these phenomena. Our approach, by contrast, enables the compact representation and approximation of these complex non-polynomial systems, including quotients and roots of polynomials. We rely on representing each function to be model-reduced as a composition of tensor products, matrix inversions, and matrix roots. Once a function has been represented in this form, it can be easily model-reduced, and its reduced form can be evaluated with time and memory costs dependent only on the dimension of the reduced space. ", 
        "id": 1756, 
        "title": "Non-polynomial Galerkin projection on deforming meshes."
    }, 
    {
        "abstract": " Snow is a challenging natural phenomenon to visually simulate. While the graphics community has previously considered accumulation and rendering of snow, animation of snow dynamics has not been fully addressed. Additionally, existing techniques for solids and fluids have difficulty producing convincing snow results. Specifically, wet or dense snow that has both solid- and fluid-like properties is difficult to handle. Consequently, this paper presents a novel snow simulation method utilizing a usercontrollable elasto-plastic constitutive model integrated with a hybrid Eulerian/Lagrangian Material Point Method. The method is continuum based and its hybrid nature allows us to use a regular Cartesian grid to automate treatment of self-collision and fracture. It also naturally allows us to derive a grid-based semi-implicit integration scheme that has conditioning independent of the number of Lagrangian particles. We demonstrate the power of our method with a variety of snow phenomena including complex character interactions.  ", 
        "id": 1757, 
        "title": "A material point method for snow simulation."
    }, 
    {
        "abstract": "Each pixel in a photorealistic, computer generated picture is calculated by approximately integrating all the light arriving at the pixel, from the virtual scene. A common strategy to calculate these highdimensional integrals is to average the estimates at stochastically sampled locations. The strategy with which the sampled locations are chosen is of utmost importance in deciding the quality of the approximation, and hence rendered image. We derive connections between the spectral properties of stochastic sampling patterns and the first and second order statistics of estimates of integration using the samples. Our equations provide insight into the assessment of stochastic sampling strategies for integration. We show that the amplitude of the expected Fourier spectrum of sampling patterns is a useful indicator of the bias when used in numerical integration. We deduce that estimator variance is directly dependent on the variance of the sampling spectrum over multiple realizations of the sampling pattern. We then analyse Gaussian jittered sampling, a simple variant of jittered sampling, that allows a smooth trade-off of bias for variance in uniform (regular grid) sampling. We verify our predictions using spectral measurement, quantitative integration experiments and qualitative comparisons of rendered images. ", 
        "id": 1758, 
        "title": "Fourier analysis of stochastic sampling strategies for assessing bias and variance in integration."
    }, 
    {
        "abstract": "Line segment sampling has recently been adopted in many rendering algorithms for better handling of a wide range of effects such as motion blur, defocus blur and scattering media. A question naturally raised is how to generate line segment samples with good properties that can effectively reduce variance and aliasing artifacts observed in the rendering results. This paper studies this problem and presents a frequency analysis of line segment sampling. The analysis shows that the frequency content of a line segment sample is equivalent to the weighted frequency content of a point sample. The weight introduces anisotropy that smoothly changes among point samples, line segment samples and line samples according to the lengths of the samples. Line segment sampling thus makes it possible to achieve a balance between noise (point sampling) and aliasing (line sampling) under the same sampling rate. Based on the analysis, we propose a line segment sampling scheme to preserve blue-noise properties of samples which can significantly reduce noise and aliasing artifacts in reconstruction results. We demonstrate that our sampling scheme improves the quality of depth-of-field rendering, motion blur rendering, and temporal light field reconstruction.", 
        "id": 1759, 
        "title": "Line segment sampling with blue-noise properties."
    }, 
    {
        "abstract": "Figure 1: Results created by two professional artists using our novel sketch-based quad remeshing tool. The smooth subdivision surfaces defined by the coarse quad meshes demonstrate the suitability of our approach for practical production pipelines. Abstract Coarse quad meshes are the preferred representation for animating characters in movies and video games. In these scenarios, artists want explicit control over the edge flows and the singularities of the quad mesh. Despite the significant advances in recent years, existing automatic quad remeshing algorithms are not yet able to achieve the quality of manually created remeshings. We present an interactive system for manual quad remeshing that provides the user with a high degree of control while avoiding the tediousness involved in existing manual tools. With our sketch-based interface the user constructs a quad mesh by defining patches consisting of individual quads. The desired edge flow is intuitively specified by the sketched patch boundaries, and the mesh topology can be adjusted by varying the number of edge subdivisions at patch boundaries. Our system automatically inserts singularities inside patches if necessary, while providing the user with direct control of their topological and geometrical locations. We developed a set of novel user interfaces that assist the user in constructing a curve network representing such patch boundaries. The effectiveness of our system is demonstrated through a user evaluation with professional artists. Our system is also useful for editing automatically generated quad meshes.", 
        "id": 1760, 
        "title": "Sketch-based generation and editing of quad meshes."
    }, 
    {
        "abstract": "", 
        "id": 1761, 
        "title": "Sphere-Meshes: shape approximation using spherical quadric error metrics."
    }, 
    {
        "abstract": "Lenticular prints are a popular medium for producing automulti-scopic glasses-free 3D images. The light field emitted by such prints has a fixed spatial and angular resolution. We increase both perceived angular and spatial resolution by modifying the lenslet array to better match the content of a given light field. Our optimization algorithm analyzes the input light field and computes an optimal lenslet size, shape, and arrangement that best matches the input light field given a set of output parameters. The resulting emitted light field shows higher detail and smoother motion parallax compared to fixed-size lens arrays. We demonstrate our technique using rendered simulations and by 3D printing lens arrays, and we validate our approach in simulation with a user study.", 
        "id": 1762, 
        "title": "Content-adaptive lenticular prints."
    }, 
    {
        "abstract": "We present a novel technique for acquiring the geometry and spatially-varying reflectance properties of 3D objects by observing them under continuous spherical harmonic illumination conditions. The technique is general enough to characterize either entirely spec-ular or entirely diffuse materials, or any varying combination across the surface of the object. We employ a novel computational illumination setup consisting of a rotating arc of controllable LEDs which sweep out programmable spheres of incident illumination during 1-second exposures. We illuminate the object with a succession of spherical harmonic illumination conditions, as well as photographed environmental lighting for validation. From the response of the object to the harmonics, we can separate diffuse and specular reflections, estimate world-space diffuse and specular normals, and compute anisotropic roughness parameters for each view of the object. We then use the maps of both diffuse and specular reflectance to form correspondences in a multiview stereo algorithm, which allows even highly specular surfaces to be corresponded across views. The algorithm yields a complete 3D model and a set of merged reflectance maps. We use this technique to digitize the shape and reflectance of a variety of objects difficult to acquire with other techniques and present validation renderings which match well to photographs in similar lighting.", 
        "id": 1763, 
        "title": "Acquiring reflectance and shape from continuous spherical harmonic illumination."
    }, 
    {
        "abstract": "", 
        "id": 1764, 
        "title": "An efficient construction of reduced deformable objects."
    }, 
    {
        "abstract": "Geometric skinning techniques, such as smooth blending or dualquaternions, are very popular in the industry for their high performances, but fail to mimic realistic deformations. Other methods make use of physical simulation or control volume to better capture the skin behavior, yet they cannot deliver real-time feedback. In this paper, we present the first purely geometric method handling skin contact effects and muscular bulges in real-time. The insight is to exploit the advanced composition mechanism of volumetric, implicit representations for correcting the results of geometric skinning techniques. The mesh is first approximated by a set of implicit surfaces. At each animation step, these surfaces are combined in real-time and used to adjust the position of mesh vertices, starting from their smooth skinning position. This deformation step is done without any loss of detail and seamlessly handles contacts between skin parts. As it acts as a post-process, our method fits well into the standard animation pipeline. Moreover, it requires no intensive computation step such as collision detection, and therefore provides real-time performances. ", 
        "id": 1765, 
        "title": "Implicit skinning: real-time skin deformation with contact modeling."
    }, 
    {
        "abstract": "Image-based rendering (IBR) creates realistic images by enriching simple geometries with photographs, e.g., mapping the photograph of a building facade onto a plane. However, as soon as the viewer moves away from the correct viewpoint, the image in the retina becomes distorted, sometimes leading to gross misperceptions of the original geometry. Two hypotheses from vision science state how viewers perceive such image distortions, one claiming that they can compensate for them (and therefore perceive scene geometry reasonably correctly), and one claiming that they cannot compensate (and therefore can perceive rather significant distortions). We modified the latter hypothesis so that it extends to street-level IBR. We then conducted a rigorous experiment that measured the magnitude of perceptual distortions that occur with IBR for facade viewing. We also conducted a rating experiment that assessed the acceptability of the distortions. The results of the two experiments were consistent with one another. They showed that viewers' percepts are indeed distorted, but not as severely as predicted by the modified vision science hypothesis. From our experimental results, we develop a predictive model of distortion for street-level IBR, which we use to provide guidelines for acceptability of virtual views and for capture camera density. We perform a confirmatory study to validate our predictions, and illustrate their use with an application that guides users in IBR navigation to stay in regions where virtual views yield acceptable perceptual distortions. ", 
        "id": 1766, 
        "title": "Perception of perspective distortions in image-based rendering."
    }, 
    {
        "abstract": "", 
        "id": 1767, 
        "title": "On-the-fly multi-scale infinite texturing from example."
    }, 
    {
        "abstract": "We present femto-photography, a novel imaging technique to capture and visualize the propagation of light. With an effective exposure time of 1.85 picoseconds (ps) per frame, we reconstruct movies of ultrafast events at an equivalent resolution of about one half trillion frames per second. Because cameras with this shutter speed do not exist, we re-purpose modern imaging hardware to record an ensemble average of repeatable events that are synchronized to a streak sensor, in which the time of arrival of light from the scene is coded in one of the sensor's spatial dimensions. We introduce reconstruction methods that allow us to visualize the propagation of femtosecond light pulses through macroscopic scenes; at such fast resolution, we must consider the notion of time-unwarping between the camera's and the world's space-time coordinate systems to take into account effects associated with the finite speed of light. We apply our femto-photography technique to visualizations of very different scenes, which allow us to observe the rich dynamics of time-resolved light transport effects, including scattering, specular reflections, diffuse interreflections, diffraction, caustics, and subsurface scattering. Our work has potential applications in artistic, educational, and scientific visualizations; industrial imaging to analyze material properties; and medical imaging to reconstruct subsurface elements. In addition, our time-resolved technique may motivate new forms of computational photography. Currently at Morgridge Institute for Research, University of Wisconsin at Madison. Currently at Tsinghua University. Currently at College of Engineering, Pune.  ", 
        "id": 1768, 
        "title": "Femto-photography: capturing and visualizing the propagation of light."
    }, 
    {
        "abstract": "", 
        "id": 1769, 
        "title": "PiCam: an ultra-thin high performance monolithic camera array."
    }, 
    {
        "abstract": "3D printing hardware is rapidly scaling up to output continuous mixtures of multiple materials at increasing resolution over ever larger print volumes. This poses an enormous computational challenge: large high-resolution prints comprise trillions of voxels and petabytes of data and simply modeling and describing the input with spatially varying material mixtures at this scale is challenging. Existing 3D printing software is insufficient; in particular, most software is designed to support only a few million primitives, with discrete material choices per object. We present OpenFab, a programmable pipeline for synthesis of multi-material 3D printed objects that is inspired by RenderMan and modern GPU pipelines. The pipeline supports procedural evaluation of geometric detail and material composition, using shader-like fablets, allowing models to be specified easily and efficiently. We describe a streaming architecture for OpenFab; only a small fraction of the final volume is stored in memory and output is fed to the printer with little startup delay. We demonstrate it on a variety of multi-material objects.", 
        "id": 1770, 
        "title": "OpenFab: a programmable pipeline for multi-material fabrication."
    }, 
    {
        "abstract": "We introduce a technique to manipulate small movements in videos based on an analysis of motion in complex-valued image pyramids. Phase variations of the coefficients of a complex-valued steerable pyramid over time correspond to motion, and can be temporally processed and amplified to reveal imperceptible motions, or attenuated to remove distracting changes. This processing does not involve the computation of optical flow, and in comparison to the previous Eulerian Video Magnification method it supports larger amplification factors and is significantly less sensitive to noise. These improved capabilities broaden the set of applications for motion processing in videos. We demonstrate the advantages of this approach on synthetic and natural video sequences, and explore applications in scientific analysis, visualization and video enhancement. ", 
        "id": 1771, 
        "title": "Phase-based video motion processing."
    }, 
    {
        "abstract": "", 
        "id": 1772, 
        "title": "Projective analysis for 3D shape segmentation."
    }, 
    {
        "abstract": "", 
        "id": 1773, 
        "title": "GPU-based out-of-core many-lights rendering."
    }, 
    {
        "abstract": "This paper describes a new method for acquiring physically realistic hand manipulation data from multiple video streams. The key idea of our approach is to introduce a composite motion control to simultaneously model hand articulation, object movement, and subtle interaction between the hand and object. We formulate videobased hand manipulation capture in an optimization framework by maximizing the consistency between the simulated motion and the observed image data. We search an optimal motion control that drives the simulation to best match the observed image data. We demonstrate the effectiveness of our approach by capturing a wide range of high-fidelity dexterous manipulation data. We show the power of our recovered motion controllers by adapting the captured motion data to new objects with different properties. The system achieves superior performance against alternative methods such as marker-based motion capture and kinematic hand motion tracking. ", 
        "id": 1774, 
        "title": "Video-based hand manipulation capture through composite motion control."
    }, 
    {
        "abstract": "", 
        "id": 1775, 
        "title": "Harmonic parameterization by electrostatics."
    }, 
    {
        "abstract": "", 
        "id": 1776, 
        "title": "Cost-effective printing of 3D objects with skin-frame structures."
    }, 
    {
        "abstract": " `Virtualized traffic' reconstructs and displays continuous traffic flows from discrete spatio-temporal traffic sensor data or procedurally generated control input to enhance a sense of immersion in a dynamic virtual environment. In this paper, we introduce a fast technique to reconstruct traffic flows from in-road sensor measurements or procedurally generated data for interactive 3D visual applications. Our algorithm estimates the full state of the traffic flow from sparse sensor measurements (or procedural input) using a statistical inference method and a continuum traffic model. This estimated state then drives an agent-based traffic simulator to produce a 3D animation of vehicle traffic that statistically matches the original traffic conditions. Unlike existing traffic simulation and animation techniques, our method produces a full 3D rendering of individual vehicles as part of continuous traffic flows given discrete spatio-temporal sensor measurements. Instead of using a color map to indicate traffic conditions, users could visualize and fly over the reconstructed traffic in real time over a large digital cityscape.  ", 
        "id": 1777, 
        "title": "Flow reconstruction for data-driven traffic animation."
    }, 
    {
        "abstract": "We introduce InfraStructs, material-based tags that embed information inside digitally fabricated objects for imaging in the Terahertz region. Terahertz imaging can safely penetrate many common materials, opening up new possibilities for encoding hidden information as part of the fabrication process. We outline the design, fabrication, imaging, and data processing steps to fabricate information inside physical objects. Prototype tag designs are presented for location encoding, pose estimation, object identification, data storage, and authentication. We provide detailed analysis of the constraints and performance considerations for designing InfraStruct tags. Future application scenarios range from production line inventory, to customized game accessories, to mobile robotics.", 
        "id": 1778, 
        "title": "InfraStructs: fabricating information inside physical objects for imaging in the terahertz region."
    }, 
    {
        "abstract": "We present a novel radial-view-based culling method for continuous self-collision detection (CSCD) of skeletal models. Our method targets closed triangular meshes used to represent the surface of a model. It can be easily integrated with bounding volume hierarchies (BVHs) and used as the first stage for culling non-colliding triangle pairs. A mesh is decomposed into clusters with respect to a set of observer primitives (i.e., observer points and line segments) on the skeleton of the mesh so that each cluster is associated with an observer primitive. One BVH is then built for each cluster. At the runtime stage, a radial view test is performed from the observer primitive of each cluster to check its collision state. Every pair of clusters is also checked for collisions. We evaluated our method on various models and compared its performance with prior methods. Experimental results show that our method reduces the number of the bounding volume overlapping tests and the number of potentially colliding triangle pairs, thereby improving the overall process of CSCD.", 
        "id": 1779, 
        "title": "Radial view based culling for continuous self-collision detection of skeletal models."
    }, 
    {
        "abstract": "", 
        "id": 1780, 
        "title": "Inverse bi-scale material design."
    }, 
    {
        "abstract": "", 
        "id": 1781, 
        "title": "On-set performance capture of multiple actors with a stereo camera."
    }, 
    {
        "abstract": "This work presents Sketch2Scene, a framework that automatically turns a freehand sketch drawing inferring multiple scene objects to semantically valid, well arranged scenes of 3D models. Unlike the existing works on sketch-based search and composition of 3D models, which typically process individual sketched objects one by one, our technique performs co-retrieval and co-placement of 3D relevant models by jointly processing the sketched objects. This is enabled by summarizing functional and spatial relationships among models in a large collection of 3D scenes as structural groups. Our technique greatly reduces the amount of user intervention needed for sketch-based modeling of 3D scenes and fits well into the traditional production pipeline involving concept design followed by 3D modeling. A pilot study indicates that it is promising to use our technique as an alternative but more efficient tool of standard 3D modeling for 3D scene construction.  or models by properly recombining the existing models or their parts. Sketch-based user interface is commonly adopted for this task mainly due to its simplicity, intuitiveness, and ease of use [Eitz et al. 2012]. It has been shown that casually drawn sketches can be used as both shape queries for model retrieval and alignment cues for model placement, greatly simplifying the modeling process. The existing techniques for sketch-based search and composition of 3D models [Shin and Igarashi 2007; Lee and Funkhouser 2008; Xie et al. 2012] typically repeat the following process for individual desired models: first 2D sketch, then retrieval and finally 3D placement. This iterative 2D-3D-2D process is not compatible with the traditional design workflow (i.e., 2D concept design followed by 3D modeling), which is largely sequential and often demands different professionals specialized for different tasks (e.g., concept artists, 3D modelers) [Chopine 2011]. In addition, their performance is highly sensitive to the quality of individual sketches. User intervention is thus often needed for every step in the process.  ", 
        "id": 1782, 
        "title": "Sketch2Scene: sketch-based co-retrieval and co-placement of 3D models."
    }, 
    {
        "abstract": "", 
        "id": 1783, 
        "title": "Anisotropic spherical Gaussians."
    }, 
    {
        "abstract": "", 
        "id": 1784, 
        "title": "A sparse control model for image and video editing."
    }, 
    {
        "abstract": "", 
        "id": 1785, 
        "title": "Urban pattern: layout design by hierarchical domain splitting."
    }, 
    {
        "abstract": "", 
        "id": 1786, 
        "title": "Gap processing for adaptive maximal poisson-disk sampling."
    }, 
    {
        "abstract": "", 
        "id": 1787, 
        "title": "Synthesis of tiled patterns using factor graphs."
    }, 
    {
        "abstract": "", 
        "id": 1788, 
        "title": "Wave-ray coupling for interactive sound propagation in large complex scenes."
    }, 
    {
        "abstract": "", 
        "id": 1789, 
        "title": "Saddle vertex graph (SVG): a novel solution to the discrete geodesic problem."
    }, 
    {
        "abstract": "", 
        "id": 1790, 
        "title": "Reconstructing surfaces of particle-based fluids using anisotropic kernels."
    }, 
    {
        "abstract": "We present an algorithm for hierarchical and layered analysis of irregular facades, seeking a high-level understanding of facade structures. By introducing layering into the analysis, we no longer view a facade as a flat structure, but allow it to be structurally separated into depth layers, enabling more compact and natural interpretations of building facades. Computationally, we perform a symmetry-driven search for an optimal hierarchical decomposition defined by split and layering operations applied to an input facade. The objective is symmetry maximization, i.e., to maximize the sum of symmetry of the substructures resulting from recursive decomposition. To this end, we propose a novel integral symmetry measure, which behaves well at both ends of the symmetry spectrum by accounting for all partial symmetries in a discrete structure. Our analysis results in a structural representation, which can be utilized for structural editing and exploration of building facades. ", 
        "id": 1791, 
        "title": "Layered analysis of irregular facades via symmetry maximization."
    }, 
    {
        "abstract": "", 
        "id": 1792, 
        "title": "Spatio-temporal extrapolation for fluid animation."
    }, 
    {
        "abstract": "Physically based simulation can produce quality motion of plants, but requires an authoring stage to convert plant \"polygon soup\" triangle meshes to a format suitable for physically based simulation. We give a system that can author complex simulation-ready plants in a manner of minutes. Our system decomposes the plant geometry, establishes a hierarchy, builds and connects simulation meshes, and detects instances. It scales to anatomically realistic geometry of adult plants, is robust to non-manifold input geometry, gaps between branches or leaves, free-flying leaves not connected to any branch, spurious geometry, and plant self-collisions in the input configuration. We demonstrate the results using a FEM model reduction simulator that can compute large-deformation dynamics of complex plants at interactive rates, subject to user forces, gravity or randomized wind. We also provide plant fracture (with prespecified patterns), inverse kinematics to easily pose plants, as well as interactive design of plant material properties. We authored and simulated over 100 plants from diverse climates and geographic regions, including broadleaf (deciduous) trees and conifers, bushes and flowers. Our largest simulations involve anatomically realistic adult trees with hundreds of branches and over 100,000 leaves. ", 
        "id": 1793, 
        "title": "Interactive authoring of simulation-ready plants."
    }, 
    {
        "abstract": "The highest fidelity images to date of complex materials like cloth use extremely high-resolution volumetric models. However, rendering such complex volumetric media is expensive, with bruteforce path tracing often the only viable solution. Fortunately, common volumetric materials (fabrics, finished wood, synthesized solid textures) are structured, with repeated patterns approximated by tiling a small number of exemplar blocks. In this paper, we introduce a precomputation-based rendering approach for such volumetric media with repeated structures based on a modular transfer formulation. We model each exemplar block as a voxel grid and precompute voxel-to-voxel, patch-to-patch, and patch-to-voxel flux transfer matrices. At render time, when blocks are tiled to produce a high-resolution volume, we accurately compute low-order scattering, with modular flux transfer used to approximate higher-order scattering. We achieve speedups of up to 12 over path tracing on extremely complex volumes, with minimal loss of quality. In addition, we demonstrate that our approach outperforms photon mapping on these materials. ", 
        "id": 1794, 
        "title": "Modular flux transfer: efficient rendering of high-resolution volumes with repeated structures."
    }, 
    {
        "abstract": "", 
        "id": 1795, 
        "title": "Robust realtime physics-based motion control for human grasping."
    }, 
    {
        "abstract": " This paper introduces a particle-based approach for anisotropic surface meshing. Given an input polygonal mesh endowed with a Riemannian metric and a specified number of vertices, the method generates a metric-adapted mesh. The main idea consists of mapping the anisotropic space into a higher dimensional isotropic one, called \"embedding space\". The vertices of the mesh are generated by uniformly sampling the surface in this higher dimensional embedding space, and the sampling is further regularized by optimizing an energy function with a quasi-Newton algorithm. All the computations can be re-expressed in terms of the dot product in the embedding space, and the Jacobian matrices of the mappings that connect different spaces. This transform makes it unnecessary to explicitly represent the coordinates in the embedding space, and also provides all necessary expressions of energy and forces for efficient computations. Through energy optimization, it naturally leads to the desired anisotropic particle distributions in the original space. The triangles are then generated by computing the Restricted Anisotropic Voronoi Diagram and its dual Delaunay triangulation. We compare our results qualitatively and quantitatively with the state-of-the-art in anisotropic surface meshing on several examples, using the standard measurement criteria.  {zichunzhong,xguo}@utdallas.edu, bruno.levy@inria.fr, weihua.mao@utsouthwestern.edu  {wenping,fsun}@cs.hku.hk, thomasyoung.liu@gmail.com,  ACM Reference Format Zhong, Z., Guo, X., Wang, W., Lvy, B., Sun, F., Liu, Y., Mao, W. 2013. Particle-Based Anisotropic Surface Meshing. ACM Trans. Graph. 32, 4, Article 99 (July 2013), 14 pages. DOI = 10.1145/2461912.2461946 http://doi.acm.org/10.1145/2461912.2461946. Copyright Notice Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Copyright  ACM 0730-0301/13/07-ART99 $15.00. DOI: http://doi.acm.org/10.1145/2461912.2461946  ", 
        "id": 1796, 
        "title": "Particle-based anisotropic surface meshing."
    }, 
    {
        "abstract": "We present an approach to detailed reconstruction of complex realworld scenes with a handheld commodity range sensor. The user moves the sensor freely through the environment and images the scene. An offline registration and integration pipeline produces a detailed scene model. To deal with the complex sensor trajectories required to produce detailed reconstructions with a consumer-grade sensor, our pipeline detects points of interest in the scene and preserves detailed geometry around them while a global optimization distributes residual registration errors through the environment. Our results demonstrate that detailed reconstructions of complex scenes can be obtained with a consumer-grade camera. ", 
        "id": 1797, 
        "title": "Dense scene reconstruction with points of interest."
    }, 
    {
        "abstract": "Direct digital manufacturing is a set of rapidly evolving technologies that provide easy ways to manufacture highly customized and unique products. The development pipeline for such products is radically different from the conventional manufacturing pipeline: 3D geometric models are designed by users often with little or no manufacturing experience, and sent directly to the printer. Structural analysis on the user side with conventional tools is often unfeasible as it requires specialized training and software. Trial-anderror, the most common approach, is time-consuming and expensive. We present a method that would identify structural problems in objects designed for 3D printing based on geometry and material properties only, without specific assumptions on loads and manual load setup. We solve a constrained optimization problem to determine the \"worst\" load distribution for a shape that will cause high local stress or large deformations. While in its general form this optimization has a prohibitively high computational cost, we demonstrate that an approximate method makes it possible to solve the problem rapidly for a broad range of printed models. We validate our method both computationally and experimentally and demonstrate that it has good predictive power for a number of diverse 3D printed shapes. ", 
        "id": 1798, 
        "title": "Worst-case structural analysis."
    }, 
    {
        "abstract": "", 
        "id": 1799, 
        "title": "A general and efficient method for finding cycles in 3D curve networks."
    }, 
    {
        "abstract": "We present an efficient grid structure that extends a uniform grid to create a significantly larger far-field grid by dynamically extending the cells surrounding a fine uniform grid while still maintaining fine resolution about the regions of interest. The far-field grid preserves almost every computational advantage of uniform grids including cache coherency, regular subdivisions for parallelization, simple data layout, the existence of efficient numerical discretizations and algorithms for solving partial differential equations, etc. This allows fluid simulations to cover large domains that are often infeasible to enclose with sufficient resolution using a uniform grid, while still effectively capturing fine scale details in regions of interest using dynamic adaptivity. ", 
        "id": 1800, 
        "title": "A new grid structure for domain extension."
    }, 
    {
        "abstract": "In this paper, we propose a general purpose approach to handwriting beautification using online input from a stylus. Given a sample of writings, drawings, or sketches from the same user, our method improves a user's strokes in real-time as they are drawn. Our approach relies on one main insight. The appearance of the average of multiple instances of the same written word or shape is better than most of the individual instances. We utilize this observation using a two-stage approach. First, we propose an efficient real-time method for finding matching sets of stroke samples called tokens in a potentially large database of writings from a user. Second, we refine the user's most recently written strokes by averaging them with the matching tokens. Our approach works without handwriting recognition, and does not require a database of predefined letters, words, or shapes. Our results show improved results for a wide range of writing styles and drawings. ", 
        "id": 1801, 
        "title": "Handwriting beautification using token means."
    }, 
    {
        "abstract": "We introduce focal points for characterizing, comparing, and organizing collections of complex and heterogeneous data and apply the concepts and algorithms developed to collections of 3D indoor scenes. We represent each scene by a graph of its constituent objects and define focal points as representative substructures in a scene collection. To organize a heterogeneous scene collection, we cluster the scenes based on a set of extracted focal points: scenes in a cluster are closely connected when viewed from the perspective of the representative focal points of that cluster. The key concept of representativity requires that the focal points occur frequently in the cluster and that they result in a compact cluster. Hence, the problem of focal point extraction is intermixed with the problem of clustering groups of scenes based on their representative focal points. We present a co-analysis algorithm which interleaves frequent pattern mining and subspace clustering to extract a set of contextual focal points which guide the clustering of the scene collection. We demonstrate advantages of focal-centric scene comparison and organization over existing approaches, particularly in dealing with hybrid scenes, scenes consisting of elements which suggest membership in different semantic categories. ", 
        "id": 1802, 
        "title": "Organizing heterogeneous scene collections through contextual focal points."
    }, 
    {
        "abstract": "This paper introduces an algorithm for computing low-distortion, bijective mappings between surface meshes. The algorithm recieves as input a coarse set of corresponding pairs of points on the two surfaces, and follows three steps: (i) cutting the two meshes to disks in a consistent manner; (ii) jointly flattening the two disks via a novel formulation for minimizing isometric distortion while guaranteeing local injectivity (the flattenings can overlap, however); and (iii) computing a unique continuous bijection that is consistent with the flattenings. The construction of the algorithm stems from two novel observations: first, bijections between disk-type surfaces can be uniquely and efficiently represented via consistent locally injective flattenings that are allowed to be globally overlapping. This observation reduces the problem of computing bijective surface mappings to the task of computing locally injective flattenings, which is shown to be easier. Second, locally injective flattenings that minimize isometric distortion can be efficiently characterized and optimized in a convex framework. Experiments that map a wide baseline of pairs of surface meshes using the algorithm are provided. They demonstrate the ability of the algorithm to produce high-quality continuous bijective mappings between pairs of surfaces of varying isometric distortion levels. ", 
        "id": 1803, 
        "title": "Lifted bijections for low distortion surface mappings."
    }, 
    {
        "abstract": "We introduce an algorithm for generating novel 3D models via topology-varying shape blending. Given a source and a target shape, our method blends them topologically and geometrically, producing continuous series of in-betweens as new shape creations. The blending operations are defined on a spatio-structural graph composed of medial curves and sheets. Such a shape abstraction is structure-oriented, part-aware, and facilitates topology manipulations. Fundamental topological operations including split and merge are realized by allowing one-to-many correspondences between the source and the target. Multiple blending paths are sampled and presented in an interactive, exploratory tool for creative 3D modeling. We show a variety of topology-varying 3D shapes generated via continuous structural blending between man-made shapes exhibiting complex topological differences, in real time. ", 
        "id": 1804, 
        "title": "Topology-varying 3D shape creation via structural blending."
    }, 
    {
        "abstract": "", 
        "id": 1805, 
        "title": "Refractive radiative transfer equation."
    }, 
    {
        "abstract": "We present an approach that takes multiple videos captured by social cameras--cameras that are carried or worn by members of the group involved in an activity--and produces a coherent \"cut\" video of the activity. Footage from social cameras contains an intimate, personalized view that reflects the part of an event that was of importance to the camera operator (or wearer). We leverage the insight that social cameras share the focus of attention of the people carrying them. We use this insight to determine where the important \"content\" in a scene is taking place, and use it in conjunction with cinematographic guidelines to select which cameras to cut to and to determine the timing of those cuts. A trellis graph representation is used to optimize an objective function that maximizes coverage of the important content in the scene, while respecting cinematographic guidelines such as the 180-degree rule and avoiding jump cuts. We demonstrate cuts of the videos in various styles and lengths for a number of scenarios, including sports games, street performances, family activities, and social get-togethers. We evaluate our results through an in-depth analysis of the cuts in the resulting videos and through comparison with videos produced by a professional editor and existing commercial solutions. ", 
        "id": 1806, 
        "title": "Automatic editing of footage from multiple social cameras."
    }, 
    {
        "abstract": "", 
        "id": 1807, 
        "title": "Fast Local Laplacian Filters: Theory and Applications."
    }, 
    {
        "abstract": "", 
        "id": 1808, 
        "title": "Painting-to-3D model alignment via discriminative visual elements."
    }, 
    {
        "abstract": "", 
        "id": 1809, 
        "title": "Temporally coherent local tone mapping of HDR video."
    }, 
    {
        "abstract": "We introduce the Polar-Annular Mesh representation (PAM). A PAM is a mesh-skeleton co-representation designed for the modeling of 3D organic, articulated shapes. A PAM represents a manifold mesh as a partition of polar (triangle fans) and annular (rings of quads) regions. The skeletal topology of a shape is uniquely embedded in the mesh connectivity of a PAM, enabling both surface and skeletal modeling operations, interchangeably and directly on the mesh itself. We develop an algorithm to convert arbitrary triangle meshes into PAMs as well as techniques to simplify PAMs and a method to convert a PAM to a quad-only mesh. We further present a PAM-based multi-touch sculpting application in order to demonstrate its utility as a shape representation for the interactive modeling of organic, articulated figures as well as for editing and posing of pre-existing models.", 
        "id": 1810, 
        "title": "Interactive shape modeling using a skeleton-mesh co-representation."
    }, 
    {
        "abstract": "Radiative transfer equations (RTEs) with different scattering parameters can lead to identical solution radiance fields. Similarity theory studies this effect by introducing a hierarchy of equivalence relations called \"similarity relations\". Unfortunately, given a set of scattering parameters, it remains unclear how to find altered ones satisfying these relations, significantly limiting the theory's practical value. This paper presents a complete exposition of similarity theory, which provides fundamental insights into the structure of the RTE's parameter space. To utilize the theory in its general high-order form, we introduce a new approach to solve for the altered parameters including the absorption and scattering coefficients as well as a fully tabulated phase function. We demonstrate the practical utility of our work using two applications: forward and inverse rendering of translucent media. Forward rendering is our main application, and we develop an algorithm exploiting similarity relations to offer \"free\" speedups for Monte Carlo rendering of optically dense and forward-scattering materials. For inverse rendering, we propose a proof-of-concept approach which warps the parameter space and greatly improves the efficiency of gradient descent algorithms. We believe similarity theory is important for simulating and acquiring volume-based appearance, and our approach has the potential to benefit a wide range of future applications in this area. ACM Reference Format Zhao, S., Ramamoorthi, R., Bala, K. 2014. High-Order Similarity Relations in Radiative Transfer. ACM Trans. Graph. 33, 4, Article 104 (July 2014), 12 pages. DOI = 10.1145/2601097.2601104 http://doi.acm.org/10.1145/2601097.2601104. Copyright Notice Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Copyright  ACM 0730-0301/14/07-ART104 $15.00. DOI: http://doi.acm.org/10.1145/2601097.2601104  ", 
        "id": 1811, 
        "title": "High-order similarity relations in radiative transfer."
    }, 
    {
        "abstract": "", 
        "id": 1812, 
        "title": "Automatic shader simplification using surface signal approximation."
    }, 
    {
        "abstract": "Intrinsic image decomposition separates an image into a reflectance layer and a shading layer. Automatic intrinsic image decomposition remains a significant challenge, particularly for real-world scenes. Advances on this longstanding problem have been spurred by public datasets of ground truth data, such as the MIT Intrinsic Images dataset. However, the difficulty of acquiring ground truth data has meant that such datasets cover a small range of materials and objects. In contrast, real-world scenes contain a rich range of shapes and materials, lit by complex illumination. In this paper we introduce Intrinsic Images in the Wild, a large-scale, public dataset for evaluating intrinsic image decompositions of indoor scenes. We create this benchmark through millions of crowdsourced annotations of relative comparisons of material properties at pairs of points in each scene. Crowdsourcing enables a scalable approach to acquiring a large database, and uses the ability of humans to judge material comparisons, despite variations in illumination. Given our database, we develop a dense CRF-based intrinsic image algorithm for images in the wild that outperforms a range of state-of-the-art intrinsic image algorithms. Intrinsic image decomposition remains a challenging problem; we release our code and database publicly to support future research on this problem, available online at http://intrinsic.cs.cornell.edu/.", 
        "id": 1813, 
        "title": "Intrinsic images in the wild."
    }, 
    {
        "abstract": "", 
        "id": 1814, 
        "title": "Animation of Deformable Bodies with Quadratic B\u00e9zier Finite Elements."
    }, 
    {
        "abstract": "Structured decorative patterns are common ornamentations in a variety of media like books, web pages, greeting cards and interior design. Creating such art from scratch using conventional software is time consuming for experts and daunting for novices. We introduce DecoBrush, a data-driven drawing system that generalizes the conventional digital \"painting\" concept beyond the scope of natural media to allow synthesis of structured decorative patterns following user-sketched paths. The user simply selects an example library and draws the overall shape of a pattern. DecoBrush then synthesizes a shape in the style of the exemplars but roughly matching the overall shape. If the designer wishes to alter the result, DecoBrush also supports user-guided refinement via simple drawing and erasing tools. For a variety of example styles, we demonstrate highquality user-constrained synthesized patterns that visually resemble the exemplars while exhibiting plausible structural variations. ", 
        "id": 1815, 
        "title": "DecoBrush: drawing structured decorative patterns by example."
    }, 
    {
        "abstract": "Headshot portraits are a popular subject in photography but to achieve a compelling visual style requires advanced skills that a casual photographer will not have. Further, algorithms that automate or assist the stylization of generic photographs do not perform well on headshots due to the feature-specific, local retouching that a professional photographer typically applies to generate such portraits. We introduce a technique to transfer the style of an example headshot photo onto a new one. This can allow one to easily reproduce the look of renowned artists. At the core of our approach is a new multiscale technique to robustly transfer the local statistics of an example portrait onto a new one. This technique matches properties such as the local contrast and the overall lighting direction while being tolerant to the unavoidable differences between the faces of two different people. Additionally, because artists sometimes produce entire headshot collections in a common style, we show how to automatically find a good example to use as a reference for a given portrait, enabling style transfer without the user having to search for a suitable example for each input. We demonstrate our approach on data taken in a controlled environment as well as on a large set of photos downloaded from the Internet. We show that we can successfully handle styles by a variety of different artists. ACM Reference Format Shih, Y., Paris, S., Barnes, C., Freeman, W., Durand, F. 2014. Style Transfer for Headshot Portraits. ACM Trans. Graph. 33, 4, Article 148 (July 2014), 14 pages. DOI = 10.1145/2601097.2601137 http://doi.acm.org/10.1145/2601097.2601137. Copyright Notice Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Copyright  ACM 0730-0301/14/07-ART148 $15.00. DOI: http://doi.acm.org/10.1145/2601097.2601137  ", 
        "id": 1816, 
        "title": "Style transfer for headshot portraits."
    }, 
    {
        "abstract": "While each new generation of processors gets larger caches and more compute power, external memory bandwidth capabilities increase at a much lower pace. Additionally, processors are equipped with wide vector units that require low instruction level divergence to be efficiently utilized. In order to exploit these trends for ray tracing, we present an alternative to traditional depth-first ray traversal that takes advantage of the available cache hierarchy, and provides high SIMD efficiency, while keeping memory bus traffic low. Our main contribution is an efficient algorithm for traversing large packets of rays against a bounding volume hierarchy in a way that groups coherent rays during traversal. In contrast to previous large packet traversal methods, our algorithm allows for individual traversal order for each ray, which is essential for efficient ray tracing. Ray tracing algorithms is a mature research field in computer graphics, and despite this, our new technique increases traversal performance by 36-53%, and is applicable to most ray tracers.", 
        "id": 1817, 
        "title": "Dynamic ray stream traversal."
    }, 
    {
        "abstract": "Facial scanning has become the industry-standard approach for creating digital doubles in movies and video games. This involves capturing an actor while they perform different expressions that span their range of facial motion. Unfortunately, the scans typically contain a superposition of the desired expression on top of un-wanted rigid head movement. In order to extract true expression deformations, it is essential to factor out the rigid head movement for each expression, a process referred to as rigid stabilization. In order to achieve production-quality in industry, face stabilization is usually performed through a tedious and error-prone manual process. In this paper we present the first automatic face stabilization method that achieves professional-quality results on large sets of facial expressions. Since human faces can undergo a wide range of deformation, there is not a single point on the skin surface that moves rigidly with the underlying skull. Consequently, computing the rigid transformation from direct observation, a common approach in previous methods, is error prone and leads to inaccurate results. Instead, we propose to indirectly stabilize the expressions by explicitly aligning them to an estimate of the underlying skull using anatomically-motivated constraints. We show that the proposed method not only outperforms existing techniques but is also on par with manual stabilization, yet requires less than a second of computation time.", 
        "id": 1818, 
        "title": "Rigid stabilization of facial expressions."
    }, 
    {
        "abstract": "", 
        "id": 1819, 
        "title": "A Local Frequency Analysis of Light Scattering and Absorption."
    }, 
    {
        "abstract": "", 
        "id": 1820, 
        "title": "Computing smooth surface contours with accurate topology."
    }, 
    {
        "abstract": "", 
        "id": 1821, 
        "title": "High-quality capture of eyes."
    }, 
    {
        "abstract": "", 
        "id": 1822, 
        "title": "Facial performance enhancement using dynamic shape space analysis."
    }, 
    {
        "abstract": "We present a new method for implicit time integration of physical systems. Our approach builds a bridge between nodal Finite Element methods and Position Based Dynamics, leading to a simple, efficient, robust, yet accurate solver that supports many different types of constraints. We propose specially designed energy potentials that can be solved efficiently using an alternating optimization approach. Inspired by continuum mechanics, we derive a set of continuum-based potentials that can be efficiently incorporated within our solver. We demonstrate the generality and robustness of our approach in many different applications ranging from the simulation of solids, cloths, and shells, to example-based simulation. Comparisons to Newton-based and Position Based Dynamics solvers highlight the benefits of our formulation.", 
        "id": 1823, 
        "title": "Projective dynamics: fusing constraint projections for fast simulation."
    }, 
    {
        "abstract": " Links: DL PDF  True2Form is a sketch-based modeling system that reconstructs 3D curves from typical design sketches. Our approach to infer 3D form from 2D drawings is a novel mathematical framework of insights derived from perception and design literature. We note that designers favor viewpoints that maximally reveal 3D shape information, and strategically sketch descriptive curves that convey intrinsic shape properties, such as curvature, symmetry, or parallelism. Studies indicate that viewers apply these properties selectively to envision a globally consistent 3D shape. We mimic this selective regularization algorithmically, by progressively detecting and enforcing applicable properties, accounting for their global impact on an evolving 3D curve network. Balancing regularity enforcement against sketch fidelity at each step allows us to correct for inaccuracy inherent in free-hand sketching. We perceptually validate our approach by showing agreement between our algorithm and viewers in selecting applicable regularities. We further evaluate our solution by: reconstructing a range of 3D models from diversely sourced sketches; comparisons to prior art; and visual comparison to both ground-truth and 3D reconstructions by designers. ", 
        "id": 1824, 
        "title": "True2Form: 3D curve networks from 2D sketches via selective regularization."
    }, 
    {
        "abstract": "We present a thorough study to evaluate different light field editing interfaces, tools and workflows from a user perspective. This is of special relevance given the multidimensional nature of light fields, which may make common image editing tasks become complex in light field space. We additionally investigate the potential benefits of using depth information when editing, and the limitations imposed by imperfect depth reconstruction using current techniques. We perform two different experiments, collecting both objective and subjective data from a varied number of editing tasks of increasing complexity based on local point-and-click tools. In the first experiment, we rely on perfect depth from synthetic light fields, and focus on simple edits. This allows us to gain basic insight on light field editing, and to design a more advanced editing interface. This is then used in the second experiment, employing real light fields with imperfect reconstructed depth, and covering more advanced editing tasks. Our study shows that users can edit light fields with our tested interface and tools, even in the presence of imperfect depth. They follow different workflows depending on the task at hand, mostly relying on a combination of different depth cues. Last, we confirm our findings by asking a set of artists to freely edit both real and synthetic light fields.  Links: DL PDF WEB VIDEO DATA CODE ", 
        "id": 1825, 
        "title": "How do people edit light fields?"
    }, 
    {
        "abstract": "We introduce a complete morphological analysis framework for 3D point clouds. Starting from an unorganized point set sampling a surface, we propose morphological operators in the form of projections, allowing to sample erosions, dilations, closings and openings of an object without any explicit mesh structure. Our framework supports structuring elements with arbitrary shape, accounts robustly for geometric and morphological sharp features, remains efficient at large scales and comes together with a specific adaptive sampler. Based on this meshless framework, we propose applications which benefit from the non-linear nature of morphological analysis and can be expressed as simple sequences of our operators, including medial axis sampling, hysteresis shape filtering and geometry-preserving topological simplification. ", 
        "id": 1826, 
        "title": "Point morphology."
    }, 
    {
        "abstract": "Font Manifold in 2D Fonts are continuously generated at any location on the manifold The manifold is probabilistic: the heatmap providing a smooth transition between existing fonts and novel shows the regions that produce good novel fonts synthesized typefaces Figure 1: The manifold offonts. On the left, we show a 2D manifold learnt from 46 fonts. Every point in the manifold corresponds to a complete font; as you move across the manifold the corresponding font smoothly changes by interpolating and extrapolating the the original training fonts. We demonstrate this effect with the text on the right; each character is createdfrom a different 2D location in the manifold that is obtained by moving along the straight line shown on the left. The colored dots match up with the colored words. The heatmap of the manifold is indicative of the likelihood of a location containing a good font. In addition to the results presented in this paper, we provide a standalone Javascript based viewer that allows users to explore both the joint manifold offonts and manifolds for individual characters. Abstract The design and manipulation of typefaces and fonts is an area requiring substantial expertise; it can take many years of study to become a proficient typographer. At the same time, the use of typefaces is ubiquitous; there are many users who, while not experts, would like to be more involved in tweaking or changing existing fonts without suffering the learning curve of professional typography packages. Given the wealth of fonts that are available today, we would like to exploit the expertise used to produce these fonts, and to enable everyday users to create, explore, and edit fonts. To this end, we build a generative manifold of standard fonts. Every location on the manifold corresponds to a unique and novel typeface, and is obtained by learning a non-linear mapping that intelligently interpolates and extrapolates existing fonts. Using the manifold, we can smoothly interpolate and move between existing fonts. We can also use the manifold as a constraint that makes a variety of new applications possible. For instance, when editing a single character, we can update all the other glyphs in a font simultaneously to keep them compatible with our changes.", 
        "id": 1827, 
        "title": "Learning a manifold of fonts."
    }, 
    {
        "abstract": "", 
        "id": 1828, 
        "title": "Dual strip weaving: interactive design of quad layouts using elastica strips."
    }, 
    {
        "abstract": "We present a fully automatic approach to real-time facial tracking and animation with a single video camera. Our approach does not need any calibration for each individual user. It learns a generic regressor from public image datasets, which can be applied to any user and arbitrary video cameras to infer accurate 2D facial landmarks as well as the 3D facial shape from 2D video frames. The inferred 2D landmarks are then used to adapt the camera matrix and the user identity to better match the facial expressions of the current user. The regression and adaptation are performed in an alternating manner. With more and more facial expressions observed in the video, the whole process converges quickly with accurate facial tracking and animation. In experiments, our approach demonstrates a level of robustness and accuracy on par with state-of-theart techniques that require a time-consuming calibration step for each individual user, while running at 28 fps on average. We consider our approach to be an attractive solution for wide deployment in consumer-level applications. ", 
        "id": 1829, 
        "title": "Displaced dynamic expression regression for real-time facial tracking and animation."
    }, 
    {
        "abstract": "Picture subjects and text balloons are basic elements in comics, working together to propel the story forward. Japanese comics artists often leverage a carefully designed composition of subjects and balloons (generally referred to as panel elements) to provide a continuous and fluid reading experience. However, such a composition is hard to produce for people without the required experience and knowledge. In this paper, we propose an approach for novices to synthesize a composition of panel elements that can effectively guide the readers attention to convey the story. Our primary contribution is a probabilistic graphical model that describes the relationships among the artists guiding path, the panel elements, and the viewer attention, which can be effectively learned from a small set of existing manga pages. We show that the proposed approach can measurably improve the readability, visual appeal, and communication of the story of the resulting pages, as compared to an existing method. We also demonstrate that the proposed approach enables novice users to create higher-quality compositions with less time, compared with commercially available programs.", 
        "id": 1830, 
        "title": "Look over here: attention-directing composition of manga elements."
    }, 
    {
        "abstract": "", 
        "id": 1831, 
        "title": "Coupled structure-from-motion and 3D symmetry detection for urban facades."
    }, 
    {
        "abstract": "(a) (b) (c) (d) (e) Figure 1: A reduced skinning model of 150K hairs for interactive simulation: (a) We visualize the guide hairs and their weights on other hairs using a colormap. With 150K hair strands, our reduced simulation runs at 40ms per frame. Two of the simulated frames are shown in and (d). As a comparison of the simulation quality, we show the same frames generated by a full simulation (30-60 seconds perframe) in and (e). Our reduced model exhibits comparable hair motions and details as captured by the full simulation. Abstract Realistic hair animation is a crucial component in depicting virtual characters in interactive applications. While much progress has been made in high-quality hair simulation, the overwhelming computation cost hinders similar fidelity in realtime simulations. To bridge this gap, we propose a data-driven solution. Building upon precom-puted simulation data, our approach constructs a reduced model to optimally represent hair motion characteristics with a small number of guide hairs and the corresponding interpolation relationships. At runtime, utilizing such a reduced model, we only simulate guide hairs that capture the general hair motion and interpolate all rest strands. We further propose a hair correction method that corrects the resulting hair motion with a position-based model to resolve hair collisions and thus captures motion details. Our hair simulation method enables a simulation of a full head of hairs with over 150K strands in realtime. We demonstrate the efficacy and robustness of our method with various hairstyles and driven motions (e.g., head movement and wind force), and compared against full simulation results that does not appear in the training data.", 
        "id": 1832, 
        "title": "A reduced model for interactive hairs."
    }, 
    {
        "abstract": "We present a generalized linear light source solution to estimate both the local shading frame and anisotropic surface reflectance of a planar spatially varying material sample. We generalize linear light source reflectometry by modulating the intensity along the linear light source, and show that a constant and two sinusoidal lighting patterns are sufficient for estimating the local shading frame and anisotropic surface reflectance. We propose a novel reconstruction algorithm based on the key observation that after factoring out the tangent rotation, the anisotropic surface reflectance lies in a low rank subspace. We exploit the differences in tangent rotation between surface points to infer the low rank subspace and fit each surface points reflectance function in the projected low rank subspace to the observations. We propose two prototype acquisition devices for capturing surface reflectance that differ on whether the camera is fixed with respect to the linear light source or fixed with respect to the material sample. We demonstrate convincing results obtained from reflectance scans of surfaces with different reflectance and shading frame variations.", 
        "id": 1833, 
        "title": "Reflectance scanning: estimating shading frame and BRDF with generalized linear light sources."
    }, 
    {
        "abstract": "", 
        "id": 1834, 
        "title": "Automatic semantic modeling of indoor scenes from low-quality RGB-D data using contextual information."
    }, 
    {
        "abstract": "Physically based animation of detailed fracture effects is not only computationally expensive, but also difficult to implement due to numerical instability. In this paper, we propose a physics-inspired approach to enrich low-resolution fracture animation by realistic fracture details. Given a custom-designed material strength field, we adaptively refine a coarse fracture surface into a detailed one, based on a discrete gradient descent flow. Using the new fracture surface, we then generate a high-resolution fracture animation with details on both the fracture surface and the exterior surface. Our experiment shows that this approach is simple, fast, and friendly to user design and control. It can generate realistic fracture animations within a few seconds. ", 
        "id": 1835, 
        "title": "Physics-inspired adaptive fracture refinement."
    }, 
    {
        "abstract": " Inverse shape design for elastic objects greatly eases the design ef-  forts by letting users focus on desired target shapes without thinking  about elastic deformations. Solving this problem using classic it-  erative methods (e.g., Newton-Raphson methods), however, often  suffers from slow convergence toward a desired solution. In this  paper, we propose an asymptotic numerical method that exploits  the underlying mathematical structure of specific nonlinear material  (a)  (b)  (c)  models, and thus runs orders of magnitude faster than traditional  Newton-type methods. We apply this method to compute rest shapes  for elastic fabrication, where the rest shape of an elastic object is  computed such that after physical fabrication the real object deforms  into a desired shape. We illustrate the performance and robustness  of our method through a series of elastic fabrication experiments.  ", 
        "id": 1836, 
        "title": "An asymptotic numerical method for inverse elastic shape design."
    }, 
    {
        "abstract": "This paper presents a novel structure-preserving image decomposition operator called bilateral texture filter. As a simple modification of the original bilateral filter [Tomasi and Manduchi 1998], it performs local patch-based analysis of texture features and incorporates its results into the range filter kernel. The central idea to ensure proper texture/structure separation is based on patch shift that captures the texture information from the most representative texture patch clear of prominent structure edges. Our method outperforms the original bilateral filter in removing texture while preserving main image structures, at the cost of some added computation. It inherits well-known advantages of the bilateral filter, such as simplicity, local nature, ease of implementation, scalability, and adaptability to other application scenarios.", 
        "id": 1837, 
        "title": "Bilateral texture filtering."
    }, 
    {
        "abstract": "", 
        "id": 1838, 
        "title": "Field-aligned mesh joinery."
    }, 
    {
        "abstract": "", 
        "id": 1839, 
        "title": "Yarn-level simulation of woven cloth."
    }, 
    {
        "abstract": "", 
        "id": 1840, 
        "title": "Deep shading buffers on commodity GPUs."
    }, 
    {
        "abstract": "We propose a powerful hardware architecture for pixel shading, which enables flexible control of shading rates and automatic shading reuse between triangles in tessellated primitives. The main goal is efficient pixel shading for moderately to finely tessellated geometry, which is not handled well by current GPUs. Our method effectively decouples the cost of pixel shading from the geometric complexity. It thereby enables a wider use of tessellation and fine geometry, even at very limited power budgets. The core idea is to shade over small local grids in parametric patch space, and reuse shading for nearby samples. We also support the decomposition of shaders into multiple parts, which are shaded at different frequencies. Shading rates can be locally and adaptively controlled, in order to direct the computations to visually important areas and to provide performance scaling with a graceful degradation of quality. Another important benefit of shading in patch space is that it allows efficient rendering of distribution effects, which further closes the gap between real-time and offline rendering.", 
        "id": 1841, 
        "title": "AMFS: adaptive multi-frequency shading for future graphics processors."
    }, 
    {
        "abstract": "", 
        "id": 1842, 
        "title": "Progressive Light Transport Simulation on the GPU: Survey and Improvements."
    }, 
    {
        "abstract": "", 
        "id": 1843, 
        "title": "Boosting monte carlo rendering by ray histogram fusion."
    }, 
    {
        "abstract": "We introduce an example-based rigging approach to automatically generate linear blend skinning models with skeletal structure. Based on a set of example poses, our approach can output its skeleton, joint positions, linear blend skinning weights, and corresponding bone transformations. The output can be directly used to set up skeleton-based animation in various 3D modeling and animation software as well as game engines. Specifically, we formulate the solving of a linear blend skinning model with a skeleton as an optimization with joint constraints and weight smoothness regularization, and solve it using an iterative rigging algorithm that (i) alternatively updates skinning weights, joint locations, and bone transformations, and (ii) automatically prunes redundant bones that can be generated by an over-estimated bone initialization. Due to the automatic redundant bone pruning, our approach is more robust than existing example-based rigging approaches. Furthermore, in terms of rigging accuracy, even with a single set of parameters, our approach can soundly outperform state of the art methods on various types of experimental datasets including humans, quadrupled animals, and highly deformable models. ", 
        "id": 1844, 
        "title": "Robust and accurate skeletal rigging from mesh sequences."
    }, 
    {
        "abstract": "", 
        "id": 1845, 
        "title": "Appearance-from-motion: recovering spatially varying surface reflectance under unknown lighting."
    }, 
    {
        "abstract": "Fused Filament Fabrication (FFF) is the process of 3D printing objects from melted plastic filament. The hot plastic exits a nozzle and fuses with the part just below, adding a layer of material to the object being formed. However, filament can only be deposited on top of an existing surface. Therefore, overhangs require a disposable support structure to be printed, temporarily supporting the threads of plastic that would otherwise hang in empty space. Existing techniques for support generation fall into two categories: The first allow for very reliable prints by enclosing the bottom of the object in a dense structure, at the expense of increased material usage and build times. The second generate thin hierarchical structures connecting to the surface in a sparse number of points. This uses less material, at the expense of reliability: the part might become unstable, the structure itself may become difficult to print, the bottom surface quality degrades. The user therefore has to correct the structure and its parameters for each new object. We propose to exploit the ability of FFF printers to print bridges across gaps. Since bridges are always supported by pillars at their extremities, they are both stronger and more stable than hierarchical tree structures. Our technique first selects the points to support based on overhang and part stability during the entire print process. It then optimizes for a printable scaffolding composed of bridges and vertical pillars, supporting all points. The result is an automated support generation technique using little material while ensuring fine surface quality and stability during the printing process. ", 
        "id": 1846, 
        "title": "Bridging the gap: automated steady scaffoldings for 3D printing."
    }, 
    {
        "abstract": "", 
        "id": 1847, 
        "title": "k-d Darts: Sampling by k-dimensional flat searches."
    }, 
    {
        "abstract": "", 
        "id": 1848, 
        "title": "Level-of-detail quad meshing."
    }, 
    {
        "abstract": "Recently, we have seen a growing trend in the design and fabrication of personalized figurines, created by scanning real people and then physically reproducing miniature statues with 3D printers. This is currently a hot topic both in academia and industry, and the printed figurines are gaining more and more realism, especially with state-of-the-art facial scanning technology improving. However, current systems all contain the same limitation no previous method is able to suitably capture personalized hair-styles for physical reproduction. Typically, the subjects hair is approximated very coarsely or replaced completely with a template model. In this paper we present the first method for stylized hair capture, a technique to reconstruct an individuals actual hair-style in a manner suitable for physical reproduction. Inspired by centuries-old artistic sculptures, our method generates hair as a closed-manifold surface, yet contains the structural and color elements stylized in a way that captures the defining characteristics of the hair-style. The key to our approach is a novel multi-view stylization algorithm, which extends feature-preserving color filtering from 2D images to irregular manifolds in 3D, and introduces abstract geometric details that are coherent with the color stylization. The proposed technique fits naturally in traditional pipelines for figurine reproduction, and we demonstrate the robustness and versatility of our approach by capturing several subjects with widely varying hair-styles.", 
        "id": 1849, 
        "title": "Capturing and stylizing hair for 3D fabrication."
    }, 
    {
        "abstract": "We present a new adaptive fluid simulation method that captures a high resolution surface with precise dynamics, without an inefficient fine discretization of the entire fluid volume. Prior adaptive methods using octrees or unstructured meshes carry large overheads and implementation complexity. We instead stick with coarse regular Cartesian grids, using detailed cut cells at boundaries, and discretize the dynamics with a p-adaptive Discontinuous Galerkin (DG) method. This retains much of the data structure simplicity of regular grids, more efficiently captures smooth parts of the flow, and offers the flexibility to easily increase resolving power where needed without geometric refinement. ", 
        "id": 1850, 
        "title": "Detailed water with coarse grids: combining surface meshes and adaptive discontinuous Galerkin."
    }, 
    {
        "abstract": "", 
        "id": 1851, 
        "title": "Mirror mirror: crowdsourcing better portraits."
    }, 
    {
        "abstract": "We introduce a new framework for simulating the dynamics of mus-culoskeletal systems, with volumetric muscles in close contact and a novel data-driven muscle activation model. Muscles are simulated using an Eulerian-on-Lagrangian discretization that handles volume preservation, large deformation, and close contact between adjacent tissues. Volume preservation is crucial for accurately capturing the dynamics of muscles and other biological tissues. We show how to couple the dynamics of soft tissues with Lagrangian multi-body dynamics simulators, which are widely available. Our physiologically based muscle activation model utilizes knowledge of the active shapes of muscles, which can be easily obtained from medical imaging data or designed to meet artistic needs. We demonstrate results with models derived from MRI data and models designed for artistic effect.", 
        "id": 1852, 
        "title": "Active volumetric musculoskeletal systems."
    }, 
    {
        "abstract": "", 
        "id": 1853, 
        "title": "ConstructAide: analyzing and visualizing construction sites through photographs and building models."
    }, 
    {
        "abstract": "When sound hits an object, it causes small vibrations of the ob-jects surface. We show how, using only high-speed video of the object, we can extract those minute vibrations and partially recover the sound that produced them, allowing us to turn everyday objectsa glass of water, a potted plant, a box of tissues, or a bag of chipsinto visual microphones. We recover sounds from highspeed footage of a variety of objects with different properties, and use both real and simulated data to examine some of the factors that affect our ability to visually recover sound. We evaluate the quality of recovered sounds using intelligibility and SNR metrics and provide input and recovered audio samples for direct comparison. We also explore how to leverage the rolling shutter in regular consumer cameras to recover audio from standard frame-rate videos, and use the spatial resolution of our method to visualize how sound-related vibrations vary over an objects surface, which we can use to recover the vibration modes of an object.", 
        "id": 1854, 
        "title": "The visual microphone: passive recovery of sound from video."
    }, 
    {
        "abstract": "Any sampled point acquired from a real-world geometric object or scene represents a finite surface area and not just a single surface point. Samples therefore have an inherent scale, very valuable information that has been crucial for high quality reconstructions. We introduce a new method for surface reconstruction from oriented, scale-enabled sample points which operates on large, redundant and potentially noisy point sets. The approach draws upon a simple yet efficient mathematical formulation to construct an implicit function as the sum of compactly supported basis functions. The implicit function has spatially continuous \"floating\" scale and can be readily evaluated without any preprocessing. The final surface is extracted as the zero-level set of the implicit function. One of the key properties of the approach is that it is virtually parameter-free even for complex, mixed-scale datasets. In addition, our method is easy to implement, scalable and does not require any global operations. We evaluate our method on a wide range of datasets for which it compares favorably to popular classic and current methods. ", 
        "id": 1855, 
        "title": "Floating scale surface reconstruction."
    }, 
    {
        "abstract": "", 
        "id": 1856, 
        "title": "Anisotropic simplicial meshing using local convex functions."
    }, 
    {
        "abstract": "", 
        "id": 1857, 
        "title": "Massively-parallel vector graphics."
    }, 
    {
        "abstract": "This paper presents a method for measuring the similarity in style between two pieces of vector art, independent of content. Similarity is measured by the differences between four types of features: color, shading, texture, and stroke. Feature weightings are learned from crowdsourced experiments. This perceptual similarity enables style-based search. Using our style-based search feature, we demonstrate an application that allows users to create stylisticallycoherent clip art mash-ups. ", 
        "id": 1858, 
        "title": "A similarity measure for illustration style."
    }, 
    {
        "abstract": "", 
        "id": 1859, 
        "title": "Local random-phase noise for procedural texturing."
    }, 
    {
        "abstract": "We present a reflectance display: a dynamic digital display capable of showing images and videos with spatially-varying, userdefined reflectance functions. Our display is passive: it operates by phase-modulation of reflected light. As such, it does not rely on any illumination recording sensors, nor does it require expensive on-the-fly rendering. It reacts to lighting changes instantaneously and consumes only a minimal amount of energy. Our work builds on the wave optics approach to BRDF fabrication of Levin et al. shortciteLevinBRDFFab13. We replace their expensive onetime hardware fabrication with a programable liquid crystal spatial light modulator, retaining high resolution of approximately 160 dpi. Our approach enables the display of a much wider family of angular reflectances, and it allows the display of dynamic content with time varying reflectance properties--\"reflectance videos\". To facilitate these new capabilities we develop novel reflectance design algorithms with improved resolution tradeoffs. We demonstrate the utility of our display with a diverse set of experiments including display of custom reflectance images and videos, interactive reflectance editing, display of 3D content reproducing lighting and depth variation, and simultaneous display of two independent channels on one screen.  Links: DL PDF WEB ", 
        "id": 1860, 
        "title": "A reflectance display."
    }, 
    {
        "abstract": "", 
        "id": 1861, 
        "title": "Weighted Triangulations for Geometry Processing."
    }, 
    {
        "abstract": "We explore the connection between fluid capture, simulation and proximal methods, a class of algorithms commonly used for inverse problems in image processing and computer vision. Our key finding is that the proximal operator constraining fluid velocities to be divergence-free is directly equivalent to the pressure-projection methods commonly used in incompressible flow solvers. This observation lets us treat the inverse problem of fluid tracking as a constrained flow problem all while working in an efficient, modular framework. In addition it lets us tightly couple fluid simulation into flow tracking, providing a global prior that significantly increases tracking accuracy and temporal coherence as compared to previous techniques. We demonstrate how we can use these improved results for a variety of applications, such as re-simulation, detail enhancement, and domain modification. We furthermore give an outlook of the applications beyond fluid tracking that our proximal operator framework could enable by exploring the connection of deblurring and fluid guiding.", 
        "id": 1862, 
        "title": "From capture to simulation: connecting forward and inverse problems in fluids."
    }, 
    {
        "abstract": "We propose an interactive, optimization-in-the-loop tool for designing inflatable structures. Given a target shape, the user draws a network of seams defining desired segment boundaries in 3D. Our method computes optimally-shaped flat panels for the segments, such that the inflated structure is as close as possible to the target while satisfying the desired seam positions. Our approach is underpinned by physics-based pattern optimization, accurate coarse-scale simulation using tension field theory, and a specialized constraint-optimization method. Our system is fast enough to warrant interactive exploration of different seam layouts, including internal connections, and their effects on the inflated shape. We demonstrate the resulting design process on a varied set of simulation examples, some of which we have fabricated, demonstrating excellent agreement with the design intent. ", 
        "id": 1863, 
        "title": "Designing inflatable structures."
    }, 
    {
        "abstract": "We present a design system for linkage-based characters, combining form and function in an aesthetically-pleasing manner. Linkage-based character design exhibits a mix of discrete and continuous problems, making for a highly unintuitive design space that is difficult to navigate without assistance. Our system significantly simplifies this task by allowing users to interactively browse different topology options, thus guiding the discrete set of choices that need to be made. A subsequent continuous optimization step improves motion quality and, crucially, safeguards against singularities. We demonstrate the flexibility of our method on a diverse set of character designs, and then realize our designs by physically fabricating prototypes. ", 
        "id": 1864, 
        "title": "Computational design of linkage-based characters."
    }, 
    {
        "abstract": "We present a computational approach for designing wire meshes, i.e., freeform surfaces composed of woven wires arranged in a regular grid. To facilitate shape exploration, we map material properties of wire meshes to the geometric model of Chebyshev nets. This abstraction is exploited to build an efficient optimization scheme. While the theory of Chebyshev nets suggests a highly constrained design space, we show that allowing controlled deviations from the underlying surface provides a rich shape space for design exploration. Our algorithm balances globally coupled material constraints with aesthetic and geometric design objectives that can be specified by the user in an interactive design session. In addition to sculptural art, wire meshes represent an innovative medium for industrial applications including composite materials and architectural facades. We demonstrate the effectiveness of our approach using a variety of digital and physical prototypes with a level of shape complexity unobtainable using previous methods. ", 
        "id": 1865, 
        "title": "Wire mesh design."
    }, 
    {
        "abstract": "We present a triangle mesh-based technique for tracking the evolution of three-dimensional multimaterial interfaces undergoing complex deformations. It is the first non-manifold triangle mesh tracking method to simultaneously maintain intersection-free meshes and support the proposed broad set of multimaterial remeshing and topological operations. We represent the interface as a non-manifold triangle mesh with material labels assigned to each half-face to distinguish volumetric regions. Starting from proposed application-dependent vertex velocities, we deform the mesh, seeking a non-intersecting, watertight solution. This goal necessitates development of various collision-safe, label-aware non-manifold mesh operations: multimaterial mesh improvement; T1 and T2 processes, topological transitions arising in foam dynamics and multiphase flows; and multimaterial merging, in which a new interface is created between colliding materials. We demonstrate the robustness and effectiveness of our approach on a range of scenarios including geometric flows and multiphase fluid animation.", 
        "id": 1866, 
        "title": "Multimaterial mesh-based surface tracking."
    }, 
    {
        "abstract": "", 
        "id": 1867, 
        "title": "Edit propagation using geometric relationship functions."
    }, 
    {
        "abstract": "Global illumination algorithms using Markov chain Monte Carlo (MCMC) sampling are well-known for their efficiency in scenes with complex light transport. Samples in such algorithms are generated as a history of Markov chain states so that they are distributed according to the contributions to the image. The whole process is done based only on the information of the path contributions and user-defined transition probabilities from one state to the others. In light transport simulation, however, there is more information that can be used to improve the efficiency of path sampling. A notable example is multiple importance sampling (MIS) in bidirectional path tracing, which utilizes the probability densities of constructing a given path with different estimators. While MIS is a powerful ordinary Monte Carlo method, how to incorporate such additional information into MCMC sampling has been an open problem. We introduce a novel MCMC sampling framework, primary space serial tempering, which fuses the ideas of MCMC sampling and MIS for the first time. The key idea is to explore not only the sample space using a Markov chain, but also different estimators to generate samples by utilizing the information already available for MIS. Based on this framework, we also develop a novel rendering algorithm, multiplexed Metropolis light transport, which automatically and adaptively constructs paths with appropriate techniques as predicted by MIS. The final algorithm is very easy to implement, yet in many cases shows comparable (or even better) performance than significantly more complex MCMC rendering algorithms. ", 
        "id": 1868, 
        "title": "Multiplexed metropolis light transport."
    }, 
    {
        "abstract": "We present a new approach to clothing simulation using low-dimensional linear subspaces with temporally adaptive bases. Our method exploits full-space simulation training data in order to construct a pool of low-dimensional bases distributed across pose space. For this purpose, we interpret the simulation data as offsets from a kinematic deformation model that captures the global shape of clothing due to body pose. During subspace simulation, we select low-dimensional sets of basis vectors according to the current pose of the character and the state of its clothing. Thanks to this adaptive basis selection scheme, our method is able to reproduce diverse and detailed folding patterns with only a few basis vectors. Our experiments demonstrate the feasibility of subspace clothing simulation and indicate its potential in terms of quality and computational efficiency.", 
        "id": 1869, 
        "title": "Subspace clothing simulation using adaptive bases."
    }, 
    {
        "abstract": "We present a Model-Predictive Control (MPC) system for online synthesis of interactive and physically valid character motion. Our system enables a complex (36-DOF) 3D human character model to balance in a given pose, dodge projectiles, and improvise a get up strategy if forced to lose balance, all in a dynamic and unpredictable environment. Such contact-rich, predictive and reactive motions have previously only been generated offline or using a handcrafted state machine or a dataset of reference motions, which our system does not require. For each animation frame, our system generates trajectories of character control parameters for the near future -- a few seconds -- using Sequential Monte Carlo sampling. Our main technical contribution is a multimodal, tree-based sampler that simultaneously explores multiple different near-term control strategies represented as parameter splines. The strategies represented by each sample are evaluated in parallel using a causal physics engine. The best strategy, as determined by an objective function measuring goal achievement, fluidity of motion, etc., is used as the control signal for the current frame, but maintaining multiple hypotheses is crucial for adapting to dynamically changing environments. ", 
        "id": 1870, 
        "title": "Online motion synthesis using sequential Monte Carlo."
    }, 
    {
        "abstract": "", 
        "id": 1871, 
        "title": "SceneGrok: inferring action maps in 3D environments."
    }, 
    {
        "abstract": "", 
        "id": 1872, 
        "title": "Context-based coherent surface completion."
    }, 
    {
        "abstract": "Due to complex shaders and high-resolution displays (particularly on mobile graphics platforms), fragment shading often dominates the cost of rendering in games. To improve the efficiency of shading on GPUs, we extend the graphics pipeline to natively support techniques that adaptively sample components of the shading function more sparsely than per-pixel rates. We perform an extensive study of the challenges of integrating adaptive, multi-rate shading into the graphics pipeline, and evaluate two- and three-rate implementations that we believe are practical evolutions of modern GPU designs. We design new shading language abstractions that simplify development of shaders for this system, and design adaptive techniques that use these mechanisms to reduce the number of instructions performed during shading by more than a factor of three while maintaining high image quality.  ", 
        "id": 1873, 
        "title": "Extending the graphics pipeline with adaptive, multi-rate shading."
    }, 
    {
        "abstract": "For about a century, researchers and experimentalists have strived to bring glasses-free 3D experiences to the big screen. Much progress has been made and light field projection systems are now commercially available. Unfortunately, available display systems usually employ dozens of devices making such setups costly, energy inefficient, and bulky. We present a compressive approach to light field synthesis with projection devices. For this purpose, we propose a novel, passive screen design that is inspired by angle-expanding Keplerian telescopes. Combined with high-speed light field projection and nonnegative light field factorization, we demonstrate that compressive light field projection is possible with a single device. We build a prototype light field projector and angle-expanding screen from scratch, evaluate the system in simulation, present a variety of results, and demonstrate that the projector can alternatively achieve super-resolved and high dynamic range 2D image display when used with a conventional screen. ", 
        "id": 1874, 
        "title": "A compressive light field projection system."
    }, 
    {
        "abstract": "Specialized image signal processors (ISPs) exploit the structure of image processing pipelines to minimize memory bandwidth using the architectural pattern of line-buffering, where all intermediate data between each stage is stored in small on-chip buffers. This provides high energy efficiency, allowing long pipelines with tera-op/sec. image processing in battery-powered devices, but traditionally requires painstaking manual design in hardware. Based on this pattern, we present Darkroom, a language and compiler for image processing. The semantics of the Darkroom language allow it to compile programs directly into line-buffered pipelines, with all intermediate values in local line-buffer storage, eliminating unnecessary communication with off-chip DRAM. We formulate the problem of optimally scheduling line-buffered pipelines to minimize buffering as an integer linear program. Finally, given an optimally scheduled pipeline, Darkroom synthesizes hardware descriptions for ASIC or FPGA, or fast CPU code. We evaluate Darkroom implementations of a range of applications, including a camera pipeline, low-level feature detection algorithms, and deblurring. For many applications, we demonstrate gigapixel/sec. performance in under 0.5mm2 of ASIC silicon at 250 mW (simulated on a 45nm foundry process), realtime 1080p/60 video processing using a fraction of the resources of a modern FPGA, and tens of megapixels/sec. of throughput on a quad-core x86 processor.  ", 
        "id": 1875, 
        "title": "Darkroom: compiling high-level image processing code into hardware pipelines."
    }, 
    {
        "abstract": "", 
        "id": 1876, 
        "title": "Data-driven segmentation and labeling of freehand sketches."
    }, 
    {
        "abstract": "", 
        "id": 1877, 
        "title": "Near-Regular Structure Discovery Using Linear Programming."
    }, 
    {
        "abstract": "", 
        "id": 1878, 
        "title": "\u2113"
    }, 
    {
        "abstract": "We propose a method for automatically guiding patch-based image completion using mid-level structural cues. Our method first estimates planar projection parameters, softly segments the known region into planes, and discovers translational regularity within these planes. This information is then converted into soft constraints for the low-level completion algorithm by defining prior probabilities for patch offsets and transformations. Our method handles multiple planes, and in the absence of any detected planes falls back to a baseline fronto-parallel image completion algorithm. We validate our technique through extensive comparisons with state-of-the-art algorithms on a variety of scenes.", 
        "id": 1879, 
        "title": "Image completion using planar structure guidance."
    }, 
    {
        "abstract": "The construction of networks of maps among shapes in a collection enables a variety of applications in data-driven geometry processing. A key task in network construction is to make the maps consistent with each other. This consistency constraint, when properly defined, leads not only to a concise representation of such networks, but more importantly, it serves as a strong regularizer for correcting and improving noisy initial maps computed between pairs of shapes in isolation. Up-to-now, however, the consistency constraint has only been fully formulated for point-based maps or for shape collections that are fully similar. In this paper, we introduce a framework for computing consistent functional maps within heterogeneous shape collections. In such collections not all shapes share the same structure  different types of shared structure may be present within different (but possibly overlapping) sub-collections. Unlike point-based maps, functional maps can encode similarities at multiple levels of detail (points or parts), and thus are particularly suitable for coping with such diversity within a shape collection. We show how to rigorously formulate the consistency constraint in the functional map setting. The formulation leads to a powerful tool for computing consistent functional maps, and also for discovering shared structures, such as meaningful shape parts. We also show how to adapt the procedure for handling very large-scale shape collections. Experimental results on benchmark datasets show that the proposed framework significantly improves upon state-of-the-art data-driven techniques. We demonstrate the usefulness of the framework in shape co-segmentation and various shape exploration tasks.", 
        "id": 1880, 
        "title": "Functional map networks for analyzing and exploring large shape collections."
    }, 
    {
        "abstract": "", 
        "id": 1881, 
        "title": "Approximate pyramidal shape decomposition."
    }, 
    {
        "abstract": " Links: DL PDF  We introduce a data-driven hair capture framework based on example strands generated through hair simulation. Our method can robustly reconstruct faithful 3D hair models from unprocessed input point clouds with large amounts of outliers. Current state-of-the-art techniques use geometrically-inspired heuristics to derive global hair strand structures, which can yield implausible hair strands for hairstyles involving large occlusions, multiple layers, or wisps of varying lengths. We address this problem using a voting-based fitting algorithm to discover structurally plausible configurations among the locally grown hair segments from a database of simulated examples. To generate these examples, we exhaustively sample the simulation configurations within the feasible parameter space constrained by the current input hairstyle. The number of necessary simulations can be further reduced by leveraging symmetry and constrained initial conditions. The final hairstyle can then be structurally represented by a limited number of examples. To handle constrained hairstyles such as a ponytail of which realistic simulations are more difficult, we allow the user to sketch a few strokes to generate strand examples through an intuitive interface. Our approach focuses on robustness and generality. Since our method is structurally plausible by construction, we ensure an improved control during hair digitization and avoid implausible hair synthesis for a wide range of hairstyles. ", 
        "id": 1882, 
        "title": "Robust hair capture using simulated examples."
    }, 
    {
        "abstract": "", 
        "id": 1883, 
        "title": "Capturing braided hairstyles."
    }, 
    {
        "abstract": "This paper presents a novel three dimensional (3D) flower modeling technique that utilizes an X-ray computed tomography (CT) system and real-world flowers. Although a CT system provides volume data that captures the internal structures of flowers, it is difficult to accurately segment them into regions of particular organs and model them as smooth surfaces because a flower consists of thin organs that contact one another. We thus introduce a semiautomatic modeling technique that is based on a new active contour model with energy functionals designed for flower CT. Our key idea is to approximate flower components by two important primitives, a shaft and a sheet. Based on our active contour model, we also provide novel user interfaces and a numerical scheme to fit these primitives so as to reconstruct realistic thin flower organs efficiently. To demonstrate the feasibility of our technique, we provide various flower models reconstructed from CT volumes. ", 
        "id": 1884, 
        "title": "Flower modeling via X-ray computed tomography."
    }, 
    {
        "abstract": "This paper introduces novel interactive techniques for designing original hand-launched free-flight glider airplanes which can actually fly. The aerodynamic properties of a glider aircraft depend on their shape, imposing significant design constraints. We present a compact and efficient representation of glider aerodynamics that can be fit to real-world conditions using a data-driven method. To do so, we acquire a sample set of glider flight trajectories using a video camera and the system learns a nonlinear relationship between forces on the wing and wing shape. Our acquisition system is much simpler to construct than a wind tunnel, but using it we can efficiently discover a wing model for simple gliding aircraft. Our resulting model can handle general free-form wing shapes and yet agrees sufficiently well with the acquired airplane flight trajectories. Based on this compact aerodynamics model, we present a design tool in which the wing configuration created by a user is interactively optimized to maximize flight-ability. To demonstrate the effectiveness of our tool for glider design by novice users, we compare it with a traditional design workflow. ", 
        "id": 1885, 
        "title": "Pteromys: interactive design and optimization of free-formed free-flight model airplanes."
    }, 
    {
        "abstract": "A traditional camera requires the photographer to select the many parameters at capture time. While advances in light field photography have enabled post-capture control of focus and perspective, they suffer from several limitations including lower spatial resolution, need for hardware modifications, and restrictive choice of aperture and focus setting. In this paper, we propose \"compressive epsilon photography,\" a technique for achieving complete postcapture control of focus and aperture in a traditional camera by acquiring a carefully selected set of 8 to 16 images and computationally reconstructing images corresponding to all other focus-aperture settings. We make the following contributions: first, we learn the statistical redundancies in focal-aperture stacks using a Gaussian Mixture Model; second, we derive a greedy sampling strategy for selecting the best focus-aperture settings; and third, we develop an algorithm for reconstructing the entire focal-aperture stack from a few captured images. As a consequence, only a burst of images with carefully selected camera settings are acquired. Post-capture, the user can then select any focal-aperture setting of choice and the corresponding image can be rendered using our algorithm. We show extensive results on several real data sets. ", 
        "id": 1886, 
        "title": "Compressive epsilon photography for post-capture control in digital imaging."
    }, 
    {
        "abstract": "", 
        "id": 1887, 
        "title": "Real-time shading-based refinement for consumer depth cameras."
    }, 
    {
        "abstract": "We present a machine learning technique for estimating absolute, per-pixel depth using any conventional monocular 2D camera, with minor hardware modifications. Our approach targets close-range human capture and interaction where dense 3D estimation of hands and faces is desired. We use hybrid classification-regression forests to learn how to map from near infrared intensity images to absolute, metric depth in real-time. We demonstrate a variety of human-computer interaction and capture scenarios. Experiments show an accuracy that outperforms a conventional light fall-off baseline, and is comparable to high-quality consumer depth cameras, but with a dramatically reduced cost, power consumption, and form-factor.", 
        "id": 1888, 
        "title": "Learning to be a depth camera for close-range human capture and interaction."
    }, 
    {
        "abstract": "We present a combined hardware and software solution for markerless reconstruction of non-rigidly deforming physical objects with arbitrary shape in real-time. Our system uses a single self-contained stereo camera unit built from off-the-shelf components and consumer graphics hardware to generate spatio-temporally coherent 3D models at 30 Hz. A new stereo matching algorithm estimates real-time RGB-D data. We start by scanning a smooth template model of the subject as they move rigidly. This geometric surface prior avoids strong scene assumptions, such as a kinematic human skeleton or a parametric shape model. Next, a novel GPU pipeline performs non-rigid registration of live RGB-D data to the smooth template using an extended non-linear as-rigid-as-possible (ARAP) framework. High-frequency details are fused onto the final mesh using a linear deformation model. The system is an order of magnitude faster than state-of-the-art methods, while matching the quality and robustness of many offline algorithms. We show precise real-time reconstructions of diverse scenes, including: large deformations of users' heads, hands, and upper bodies; fine-scale wrinkles and folds of skin and clothing; and non-rigid interactions performed by users on flexible objects such as toys. We demonstrate how acquired models can be used for many interactive scenarios, including re-texturing, online performance capture and preview, and real-time shape and motion re-targeting. ", 
        "id": 1889, 
        "title": "Real-time non-rigid reconstruction using an RGB-D camera."
    }, 
    {
        "abstract": "", 
        "id": 1890, 
        "title": "Skinning cubic B\u00e9zier splines and Catmull-Clark subdivision surfaces."
    }, 
    {
        "abstract": "Articulation of 3D characters requires control over many degrees of freedom: a difficult task with standard 2D interfaces. We present a tangible input device composed of interchangeable, hot-pluggable parts. Embedded sensors measure the device's pose at rates suitable for real-time editing and animation. Splitter parts allow branching to accommodate any skeletal tree. During assembly, the device recognizes topological changes as individual parts or pre-assembled subtrees are plugged and unplugged. A novel semi-automatic registration approach helps the user quickly map the device's degrees of freedom to a virtual skeleton inside the character. User studies report favorable comparisons to mouse and keyboard interfaces for the tasks of target acquisition and pose replication. Our device provides input for character rigging and automatic weight computation, direct skeletal deformation, interaction with physical simulations, and handle-based variational geometric modeling. ", 
        "id": 1891, 
        "title": "Tangible and modular input device for character articulation."
    }, 
    {
        "abstract": "We present a general and practical method for computing BSDFs of layered materials. Its ingredients are transport-theoretical models of isotropic or anisotropic scattering layers and smooth or rough boundaries of conductors and dielectrics. Following expansion into a directional basis that supports arbitrary composition, we are able to efficiently and accurately synthesize BSDFs for a great variety of layered structures. Reflectance models created by our system correctly account for multiple scattering within and between layers, and in the context of a rendering system they are efficient to evaluate and support texturing and exact importance sampling. Although our approach essentially involves tabulating reflectance functions in a Fourier basis, the generated models are compact to store due to the inherent sparsity of our representation, and are accurate even for narrowly peaked functions. While methods for rendering general layered surfaces have been investigated in the past, ours is the first system that supports arbitrary layer structures while remaining both efficient and accurate. We validate our model by comparing to measurements of real-world examples of layered materials, and we demonstrate an interactive visual design tool that enables easy exploration of the space of layered materials. We provide a fully practical, high-performance implementation in an open-source rendering system. ACM Reference Format Jakob, W., d'Eon, E., Jakob, O., Marschner, S. 2014. A Comprehensive Framework for Rendering Layered Materials. ACM Trans. Graph. 33, 4, Article 118 (July 2014), 14 pages. DOI = 10.1145/2601097.2601139 http://doi.acm.org/10.1145/2601097.2601139. Copyright Notice Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. 2014 Copyright held by the Owner/Author. Publication rights licensed to ACM. 0730-0301/14/07-ART118 $15.00. DOI: http://dx.doi.org/10.1145/2601097.2601139  ", 
        "id": 1892, 
        "title": "A comprehensive framework for rendering layered materials."
    }, 
    {
        "abstract": "This paper investigates rendering glittery surfaces, ones which exhibit shifting random patterns of glints as the surface or viewer moves. It applies both to dramatically glittery surfaces that contain mirror-like flakes and also to rough surfaces that exhibit more subtle small scale glitter, without which most glossy surfaces appear too smooth in close-up. These phenomena can in principle be simulated by high-resolution normal maps, but maps with tiny features create severe aliasing problems under narrow-angle illumination. In this paper we present a stochastic model for the effects of random subpixel structures that generates glitter and spatial noise that behave correctly under different illumination conditions and viewing distances, while also being temporally coherent so that they look right in motion. The model is based on microfacet theory, but it replaces the usual continuous microfacet distribution with a discrete distribution of scattering particles on the surface. A novel stochastic hierarchy allows efficient evaluation in the presence of large numbers of random particles, without ever having to consider the particles individually. This leads to a multiscale procedural BRDF that is readily implemented in standard rendering systems, and which converges back to the smooth case in the limit. ACM Reference Format Jakob, W., Hasan, M., Yan, L., Lawrence, J., Ramamoorthi, R., Marschner, S. 2014. Discrete Stochastic Microfacet Models. ACM Trans. Graph. 33, 4, Article 115 (July 2014), 10 pages. DOI = 10.1145/2601097.2601186 http://doi.acm.org/10.1145/2601097.2601186. Copyright Notice Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. 2014 Copyright held by the Owner/Author. Publication rights licensed to ACM. 0730-0301/14/07-ART115 $15.00. DOI: http://dx.doi.org/10.1145/2601097.2601186  ", 
        "id": 1893, 
        "title": "Discrete stochastic microfacet models."
    }, 
    {
        "abstract": "", 
        "id": 1894, 
        "title": "A framework for transient rendering."
    }, 
    {
        "abstract": "", 
        "id": 1895, 
        "title": "Deformation embedding for point-based elastoplastic simulation."
    }, 
    {
        "abstract": "", 
        "id": 1896, 
        "title": "Dynamic and Robust Local Clearance Triangulations."
    }, 
    {
        "abstract": "The path integral formulation of light transport is the basis for (Markov chain) Monte Carlo global illumination methods. In this paper we present half vector space light transport (HSLT), a novel approach to sampling and integrating light transport paths on surfaces. The key is a partitioning of the path space into subspaces in which a path is represented by its start and end point constraints and a sequence of generalized half vectors. We show that this representation has several benefits. It enables importance sampling of all interactions along paths in between two endpoints. Based on this, we propose a new mutation strategy, to be used with Markov chain Monte Carlo methods such as Metropolis light transport (MLT), which is well-suited for all types of surface transport paths (dif-fuse/glossy/specular interaction). One important characteristic of our approach is that the Fourier-domain properties of the path integral can be easily estimated. These can be used to achieve optimal correlation of the samples due to well-chosen mutation step sizes, leading to more efficient exploration of light transport features. We also propose a novel approach to control stratification in MLT with our mutation strategy.", 
        "id": 1897, 
        "title": "The natural-constraint representation of the path space for efficient light transport simulation."
    }, 
    {
        "abstract": "", 
        "id": 1898, 
        "title": "Automatic Scene Inference for 3D Object Compositing."
    }, 
    {
        "abstract": "", 
        "id": 1899, 
        "title": "Exposing Photo Manipulation from Shading and Shadows."
    }, 
    {
        "abstract": "Photo-editing software restricts the control of objects in a photograph to the 2D image plane. We present a method that enables users to perform the full range of 3D manipulations, including scaling, rotation, translation, and nonrigid deformations, to an object in a photograph. As 3D manipulations often reveal parts of the object that are hidden in the original photograph, our approach uses publicly available 3D models to guide the completion of the geometry and appearance of the revealed areas of the object. The completion process leverages the structure and symmetry in the stock 3D model to factor out the effects of illumination, and to complete the appearance of the object. We demonstrate our system by producing object manipulations that would be impossible in traditional 2D photoediting programs, such as turning a car over, making a paper-crane flap its wings, or manipulating airplanes in a historical photograph to change its story. ", 
        "id": 1900, 
        "title": "3D object manipulation in a single photograph using stock 3D models."
    }, 
    {
        "abstract": "", 
        "id": 1901, 
        "title": "A framework for the experimental comparison of solar and skydome illumination."
    }, 
    {
        "abstract": " As 3D acquisition devices and modeling tools become widely available there is a growing need for automatic algorithms that analyze the semantics and functionality of digitized shapes. Most recent research has focused on analyzing geometric structures of shapes. Our work is motivated by the observation that a majority of manmade shapes are designed to be used by people. Thus, in order to fully understand their semantics, one needs to answer a fundamental question: \"how do people interact with these objects?\" As an initial step towards this goal, we offer a novel algorithm for automatically predicting a static pose that a person would need to adopt in order to use an object. Specifically, given an input 3D shape, the goal of our analysis is to predict a corresponding human pose, including contact points and kinematic parameters. This is especially challenging for man-made objects that commonly exhibit a lot of variance in their geometric structure. We address this challenge by observing that contact points usually share consistent local geometric features related to the anthropometric properties of corresponding parts and that human body is subject to kinematic constraints and priors. Accordingly, our method effectively combines local region classification and global kinematically-constrained search to successfully predict poses for various objects. We also evaluate our algorithm on six diverse collections of 3D polygonal models (chairs, gym equipment, cockpits, carts, bicycles, and bipedal devices) containing a total of 147 models. Finally, we demonstrate that the poses predicted by our algorithm can be used in several shape analysis problems, such as establishing correspondences between objects, detecting salient regions, finding informative viewpoints, and retrieving functionally-similar shapes. ", 
        "id": 1902, 
        "title": "Shape2Pose: human-centric shape analysis."
    }, 
    {
        "abstract": "Editing large-scale crowd animation is a daunting task due to the lack of an efficient manipulation method. This paper presents a novel cage-based editing method for large-scale crowd animation. The cage encloses animated characters and supports convenient space/time manipulation methods that were unachievable with previous approaches. The proposed method is based on a combination of cage-based deformation and as-rigid-as-possible deformation with a set of constraints integrated into the system to produce desired results. Our system allows animators to edit existing crowd animations intuitively with real-time performance while maintaining complex interactions between individual characters. Our examples demonstrate how our cage-based user interfaces mitigate the time and effort for the user to manipulate large crowd animation. ", 
        "id": 1903, 
        "title": "Interactive manipulation of large-scale crowd animation."
    }, 
    {
        "abstract": "Controlling the singular values of n-dimensional matrices is often required in geometric algorithms in graphics and engineering. This paper introduces a convex framework for problems that involve singular values. Specifically, it enables the optimization of functionals and constraints expressed in terms of the extremal singular values of matrices. Towards this end, we introduce a family of convex sets of matrices whose singular values are bounded. These sets are formulated using Linear Matrix Inequalities (LMI), allowing optimization with standard convex Semidefinite Programming (SDP) solvers. We further show that these sets are optimal, in the sense that there exist no larger convex sets that bound singular values. A number of geometry processing problems are naturally described in terms of singular values. We employ the proposed framework to optimize and improve upon standard approaches. We experiment with this new framework in several applications: volumetric mesh deformations, extremal quasi-conformal mappings in three dimensions, non-rigid shape registration and averaging of rotations. We show that in all applications the proposed approach leads to algorithms that compare favorably to state-of-art algorithms. ", 
        "id": 1904, 
        "title": "Controlling singular values with semidefinite programming."
    }, 
    {
        "abstract": "Efficiently computing light transport in participating media in a manner that is robust to variations in media density, scattering albedo, and anisotropy is a difficult and important problem in realistic image synthesis. While many specialized rendering techniques can efficiently resolve subsets of transport in specific media, no single approach can robustly handle all types of effects. To address this problem we unify volumetric density estimation, using point and beam estimators, and Monte Carlo solutions to the path integral formulation of the rendering and radiative transport equations. We extend multiple importance sampling to correctly handle combinations of these fundamentally different classes of estimators. This, in turn, allows us to develop a single rendering algorithm that correctly combines the benefits and mediates the limitations of these powerful volume rendering techniques.", 
        "id": 1905, 
        "title": "Unifying points, beams, and paths in volumetric light transport simulation."
    }, 
    {
        "abstract": "more winter more moist more night Figure 1: Our method enables high-level editing of outdoor photographs. In this example, the user provides an input image (left) and six attribute queries corresponding to the desired changes, such as more autumn. Our method hallucinates six plausible versions of the scene with the desired attributes (right), by learning local color transforms from a large dataset of annotated outdoor webcams. Abstract We live in a dynamic visual world where the appearance of scenes changes dramatically from hour to hour or season to season. In this work we study transient scene attributes  high level properties which affect scene appearance, such as snow, autumn, dusk, fog. We define 40 transient attributes and use crowd-sourcing to annotate thousands of images from 101 webcams. We use this transient attribute database to train regressors that can predict the presence of attributes in novel images. We demonstrate a photo organization method based on predicted attributes. Finally we propose a high-level image editing method which allows a user to adjust the attributes of a scene, e.g. change a scene to be snowy or sunset. To support attribute manipulation we introduce a novel appearance transfer technique which is simple and fast yet competitive with the state-of-the-art. We show that we can convincingly modify many transient attributes in outdoor scenes.", 
        "id": 1906, 
        "title": "Transient attributes for high-level understanding and editing of outdoor scenes."
    }, 
    {
        "abstract": "We propose and evaluate a method for significantly compressing modal sound models, thereby making them far more practical for audiovisual applications. The dense eigenmode matrix, needed to compute the sound model's response to contact forces, can consume tens to thousands of megabytes depending on mesh resolution and mode count. Our eigenmode compression pipeline is based on nonlinear optimization of Moving Least Squares (MLS) approximations. Enhanced compression is achieved by exploiting symmetry both within and between eigenmodes, and by adaptively assigning per-mode error levels based on human perception of the far-field pressure amplitudes. Our method provides smooth eigenmode approximations, and efficient random access. We demonstrate that, in many cases, hundredfold compression ratios can be achieved without audible degradation of the rendered sound. ", 
        "id": 1907, 
        "title": "Eigenmode compression for modal sound models."
    }, 
    {
        "abstract": "In this paper, we introduce Inverse-Foley Animation, a technique for optimizing rigid-body animations so that contact events are synchronized with input sound events. A precomputed database of randomly sampled rigid-body contact events is used to build a contact-event graph, which can be searched to determine a plausible sequence of contact events synchronized with the input sound's events. To more easily find motions with matching contact times, we allow transitions between simulated contact events using a motion blending formulation based on modified contact impulses. We fine tune synchronization by slightly retiming ballistic motions. Given a sound, our system can synthesize synchronized motions using graphs built with hundreds of thousands of precomputed motions, and millions of contact events. Our system is easy to use, and has been used to plan motions for hundreds of sounds, and dozens of rigid-body models. ", 
        "id": 1908, 
        "title": "Inverse-Foley animation: synchronizing rigid-body motions to sound."
    }, 
    {
        "abstract": "", 
        "id": 1909, 
        "title": "Locomotion control for many-muscle humanoids."
    }, 
    {
        "abstract": "Sampling a scene by tracing rays and reconstructing an image from such pointwise samples is fundamental to computer graphics. To improve the efficacy of these computations, we propose an alternative theory of sampling. In contrast to traditional formulations for image synthesis, which appeal to nonconstructive Dirac deltas, our theory employs constructive reproducing kernels for the correspondence between continuous functions and pointwise samples. Conceptually, this allows us to obtain a common mathematical formulation of almost all existing numerical techniques for image synthesis. Practically, it enables novel sampling based numerical techniques designed for light transport that provide considerably improved performance per sample. We exemplify the practical benefits of our formulation with three applications: pointwise transport of color spectra, projection of the light energy density into spherical harmonics, and approximation of the shading equation from a photon map. Experimental results verify the utility of our sampling formulation, with lower numerical error rates and enhanced visual quality compared to existing techniques. ", 
        "id": 1910, 
        "title": "A constructive theory of sampling for image synthesis using reproducing Kernel bases."
    }, 
    {
        "abstract": "", 
        "id": 1911, 
        "title": "Creating works-like prototypes of mechanical objects."
    }, 
    {
        "abstract": "", 
        "id": 1912, 
        "title": "Automating Image Morphing Using Structural Similarity on a Halfway Domain."
    }, 
    {
        "abstract": "We present a novel method for elastic animation editing with spacetime constraints. In a sharp departure from previous approaches, we not only optimize control forces added to a linearized dynamic model, but also optimize material properties to better match user constraints and provide plausible and consistent motion. Our approach achieves efficiency and scalability by performing all computations in a reduced rotation-strain (RS) space constructed with both cubature and geometric reduction, leading to two orders of magnitude improvement over the original RS method. We demonstrate the utility and versatility of our method in various applications, including motion editing, pose interpolation, and estimation of material parameters from existing animation sequences. ", 
        "id": 1913, 
        "title": "Space-time editing of elastic motion through material optimization and reduction."
    }, 
    {
        "abstract": "", 
        "id": 1914, 
        "title": "Spatial-spectral encoded compressive hyperspectral imaging."
    }, 
    {
        "abstract": "", 
        "id": 1915, 
        "title": "Feature Matching with Bounded Distortion."
    }, 
    {
        "abstract": "", 
        "id": 1916, 
        "title": "TrackCam: 3D-aware tracking shots from consumer video."
    }, 
    {
        "abstract": "", 
        "id": 1917, 
        "title": "Fast burst images denoising."
    }, 
    {
        "abstract": " Links: DL PDF  In this paper we introduce several innovative variants on the classic Connect-The-Dots puzzle. We study the underlying geometric principles and investigate methods for the automatic generation of high-quality puzzles from line drawings. Specifically, we introduce three new variants of the classic ConnectThe-Dots puzzle. These new variants use different rules for drawing connections, and have several advantages: no need for printed numbers in the puzzle (which look ugly in the final drawing), and perhaps more challenging \"game play\", making the puzzles suitable for different age groups. We study the rules of all four variants in the family, and design principles describing what makes a good puzzle. We identify general principles that apply across the different variants, as well as specific implementations of those principles in the different variants. We make these mathematically precise in the form of criteria a puzzle should satisfy. Furthermore, we investigate methods for the automatic generation of puzzles from a plane graph that describes the input drawing. We show that the problem of generating a good puzzle one satisfying the mentioned criteria is computationally hard, and present several heuristic algorithms. Using our implementation for generating puzzles, we evaluate the quality of the resulting puzzles with respect to two parameters: one for similarity to the original line drawing, and one for ambiguity; i.e. what is the visual accuracy needed to solve the puzzle. ", 
        "id": 1918, 
        "title": "The Connect-The-Dots family of puzzles: design and automatic generation."
    }, 
    {
        "abstract": "", 
        "id": 1919, 
        "title": "Rendering volumetric haptic shapes in mid-air using ultrasound."
    }, 
    {
        "abstract": "", 
        "id": 1920, 
        "title": "MoSh: motion and shape capture from sparse markers."
    }, 
    {
        "abstract": "We present a novel design for an optical see-through augmented reality display that offers a wide field of view and supports a compact form factor approaching ordinary eyeglasses. Instead of conventional optics, our design uses only two simple hardware components: an LCD panel and an array of point light sources (implemented as an edge-lit, etched acrylic sheet) placed directly in front of the eye, out of focus. We code the point light sources through the LCD to form miniature see-through projectors. A virtual aperture encoded on the LCD allows the projectors to be tiled, creating an arbitrarily wide field of view. Software rearranges the target augmented image into tiled sub-images sent to the display, which appear as the correct image when observed out of the viewer's accommodation range. We evaluate the design space of tiled point light projectors with an emphasis on increasing spatial resolution through the use of eye tracking. We demonstrate feasibility through software simulations and a real-time prototype display that offers a 110 diagonal field of view in the form factor of large glasses and discuss remaining challenges to constructing a practical display. ", 
        "id": 1921, 
        "title": "Pinlight displays: wide field of view augmented reality eyeglasses using defocused point light sources."
    }, 
    {
        "abstract": " Links: DL PDF  The emergence of low-cost 3D printers steers the investigation of new geometric problems that control the quality of the fabricated object. In this paper, we present a method to reduce the material cost and weight of a given object while providing a durable printed model that is resistant to impact and external forces. We introduce a hollowing optimization algorithm based on the concept of honeycomb-cells structure. Honeycombs structures are known to be of minimal material cost while providing strength in tension. We utilize the Voronoi diagram to compute irregular honeycomb-like volume tessellations which define the inner structure. We formulate our problem as a strengthtoweight optimization and cast it as mutually finding an optimal interior tessellation and its maximal hollowing subject to relieve the interior stress. Thus, our system allows to build-to-last 3D printed objects with large control over their strength-to-weight ratio and easily model various interior structures. We demonstrate our method on a collection of 3D objects from different categories. Furthermore, we evaluate our method by printing our hollowed models and measure their stress and weights.  ", 
        "id": 1922, 
        "title": "Build-to-last: strength to weight 3D printed objects."
    }, 
    {
        "abstract": "We present a unified dynamics framework for real-time visual effects. Using particles connected by constraints as our fundamental building block allows us to treat contact and collisions in a unified manner, and we show how this representation is flexible enough to model gases, liquids, deformable solids, rigid bodies and cloth with two-way interactions. We address some common problems with traditional particle-based methods and describe a parallel constraint solver based on position-based dynamics that is efficient enough for real-time applications.", 
        "id": 1923, 
        "title": "Unified particle physics for real-time applications."
    }, 
    {
        "abstract": "We present novel algorithms for modeling interactive diffuse reflections and higher-order diffraction in large-scale virtual environments. Our formulation is based on ray-based sound propagation and is directly applicable to complex geometric datasets. We use an incremental approach that combines radiosity and path tracing techniques to iteratively compute diffuse reflections. We also present algorithms for wavelength-dependent simplification and visibility graph computation to accelerate higher-order diffraction at runtime. The overall system can generate plausible sound effects at interactive rates in large, dynamic scenes that have multiple sound sources. We highlight the performance in complex indoor and outdoor environments and observe an order of magnitude performance improvement over previous methods. ", 
        "id": 1924, 
        "title": "High-order diffraction and diffuse reflections for interactive sound propagation in large environments."
    }, 
    {
        "abstract": "", 
        "id": 1925, 
        "title": "Fast and exact continuous collision detection with Bernstein sign classification."
    }, 
    {
        "abstract": "", 
        "id": 1926, 
        "title": "Improved sampling for gradient-domain metropolis light transport."
    }, 
    {
        "abstract": "We present a method for transforming a 3D object into a cube or a box using a continuous folding sequence. Our method produces a single, connected object that can be physically fabricated and folded from one shape to the other. We segment the object into voxels and search for a voxel-tree that can fold from the input shape to the target shape. This involves three major steps: finding a good voxelization, finding the tree structure that can form the input and target shapes' configurations, and finding a non-intersecting folding sequence. We demonstrate our results on several input 3D objects and also physically fabricate some using a 3D printer. ", 
        "id": 1927, 
        "title": "Boxelization: folding 3D objects into boxes."
    }, 
    {
        "abstract": "Sudden temporal depth changes, such as cuts that are introduced by video edits, can significantly degrade the quality of stereoscopic content. Since usually not encountered in the real world, they are very challenging for the audience. This is because the eye vergence has to constantly adapt to new disparities in spite of conflicting accommodation requirements. Such rapid disparity changes may lead to confusion, reduced understanding of the scene, and overall attractiveness of the content. In most cases the problem cannot be solved by simply matching the depth around the transition, as this would require flattening the scene completely. To better understand this limitation of the human visual system, we conducted a series of eye-tracking experiments. The data obtained allowed us to derive and evaluate a model describing adaptation of vergence to disparity changes on a stereoscopic display. Besides computing user-specific models, we also estimated parameters of an average observer model. This enables a range of strategies for minimizing the adaptation time in the audience.", 
        "id": 1928, 
        "title": "Modeling and optimizing eye vergence response to stereoscopic cuts."
    }, 
    {
        "abstract": "", 
        "id": 1929, 
        "title": "Improving visual quality of view transitions in automultiscopic displays."
    }, 
    {
        "abstract": "Monte Carlo (MC) ray-tracing for photo-realistic rendering often requires hours to render a single image due to the large sampling rates needed for convergence. Previous methods have attempted to filter sparsely sampled MC renders but these methods have high reconstruction overheads. Recent work has shown fast performance for individual effects, like soft shadows and indirect illumination, using axis-aligned filtering. While some components of light transport such as indirect or area illumination are smooth, they are often multiplied by high-frequency components such as texture, which prevents their sparse sampling and reconstruction. We propose an approach to adaptively sample and filter for simultaneously rendering primary (defocus blur) and secondary (soft shadows and indirect illumination) distribution effects, based on a multi-dimensional frequency analysis of the direct and indirect illumination light fields. We describe a novel approach of factoring texture and irradiance in the presence of defocus blur, which allows for pre-filtering noisy irradiance when the texture is not noisy. Our approach naturally allows for different sampling rates for pri- ACM Reference Format Mehta, S., Yao, J., Ramamoorthi, R., Durand, F. 2014. Factored Axis-Aligned Filtering for Rendering Multiple Distribution Effects. ACM Trans. Graph. 33, 4, Article 57 (July 2014), 12 pages. DOI = 10.1145/2601097.2601113 http://doi.acm.org/10.1145/2601097.2601113. Copyright Notice Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. 2014 Copyright held by the Owner/Author. Publication rights licensed to ACM. 0730-0301/14/07-ART57 $15.00. DOI: http://dx.doi.org/10.1145/2601097.2601113  mary and secondary effects, further reducing the overall ray count. While the theory considers only Lambertian surfaces, we obtain promising results for moderately glossy surfaces. We demonstrate 30 sampling rate reduction compared to equal quality noise-free MC. Combined with a GPU implementation and low filtering overhead, we can render scenes with complex geometry and diffuse and glossy BRDFs in a few seconds. ", 
        "id": 1930, 
        "title": "Factored axis-aligned filtering for rendering multiple distribution effects."
    }, 
    {
        "abstract": "", 
        "id": 1931, 
        "title": "Exponential integrators for stiff elastodynamic problems."
    }, 
    {
        "abstract": "Images, while easy to acquire, view, publish, and share, they lack critical depth information. This poses a serious bottleneck for many image manipulation, editing, and retrieval tasks. In this paper we consider the problem of adding depth to an image of an object, effectively `lifting' it back to 3D, by exploiting a collection of aligned 3D models of related objects. Our key insight is that, even when the imaged object is not contained in the shape collection, the network of shapes implicitly characterizes a shape-specific deformation subspace that regularizes the problem and enables robust diffusion of depth information from the shape collection to the input image. We evaluate our fully automatic approach on diverse and challenging input images, validate the results against Kinect depth readings, and demonstrate several imaging applications including depth-enhanced image editing and image relighting. ", 
        "id": 1932, 
        "title": "Estimating image depth using shape collections."
    }, 
    {
        "abstract": "", 
        "id": 1933, 
        "title": "Imagining the unseen: stability-based cuboid arrangements for scene understanding."
    }, 
    {
        "abstract": "", 
        "id": 1934, 
        "title": "Creating consistent scene graphs using a probabilistic grammar."
    }, 
    {
        "abstract": "", 
        "id": 1935, 
        "title": "Adaptive Rendering Based on Weighted Local Regression."
    }, 
    {
        "abstract": "", 
        "id": 1936, 
        "title": "RayCore: A Ray-Tracing Hardware Architecture for Mobile Devices."
    }, 
    {
        "abstract": "", 
        "id": 1937, 
        "title": "Errata for GPU-Efficient Recursive Filtering and Summed-Area Tables."
    }, 
    {
        "abstract": "", 
        "id": 1938, 
        "title": "Residual ratio tracking for estimating attenuation in participating media."
    }, 
    {
        "abstract": "This paper presents interfaces for exploring large collections of fonts for design tasks. Existing interfaces typically list fonts in a long, alphabetically-sorted menu that can be challenging and frustrating to explore. We instead propose three interfaces for font selection. First, we organize fonts using high-level descriptive attributes, such as \"dramatic\" or \"legible.\" Second, we organize fonts in a tree-based hierarchical menu based on perceptual similarity. Third, we display fonts that are most similar to a user's currentlyselected font. These tools are complementary; a user may search for \"graceful\" fonts, select a reasonable one, and then refine the results from a list of fonts similar to the selection. To enable these tools, we use crowdsourcing to gather font attribute data, and then train models to predict attribute values for new fonts. We use attributes to help learn a font similarity metric using crowdsourced comparisons. We evaluate the interfaces against a conventional list interface and find that our interfaces are preferred to the baseline. Our interfaces also produce better results in two real-world tasks: finding the nearest match to a target font, and font selection for graphic designs. ", 
        "id": 1939, 
        "title": "Exploratory font selection using crowdsourced attributes."
    }, 
    {
        "abstract": "We analyze light propagation in an unknown scene using projectors and cameras that operate at transient timescales. In this new photography regime, the projector emits a spatio-temporal 3D signal and the camera receives a transformed version of it, determined by the set of all light transport paths through the scene and the time delays they induce. The underlying 3D-to-3D transformation encodes scene geometry and global transport in great detail, but individual transport components (e.g., direct reflections, inter-reflections, caustics, etc.) are coupled nontrivially in both space and time. To overcome this complexity, we observe that transient light transport is always separable in the temporal frequency domain. This makes it possible to analyze transient transport one temporal frequency at a time by trivially adapting techniques from conventional projector-to-camera transport. We use this idea in a prototype that offers three never-seen-before abilities: (1) acquiring time-of-flight depth images that are robust to general indirect transport, such as interreflections and caustics; (2) distinguishing between direct views of objects and their mirror reflection; and (3) using a photonic mixer device to capture sharp, evolving wavefronts of \"light-in-flight\". ", 
        "id": 1940, 
        "title": "Temporal frequency probing for 5D transient analysis of global light transport."
    }, 
    {
        "abstract": "Basic topological modeling, such as the ability to have several faces share a common edge, has been largely absent from vector graphics. We introduce the vector graphics complex (VGC) as a simple data structure to support fundamental topological modeling operations for vector graphics illustrations. The VGC can represent any arbitrary non-manifold topology as an immersion in the plane, unlike planar maps which can only represent embeddings. This allows for the direct representation of incidence relationships between objects and can therefore more faithfully capture the intended semantics of many illustrations, while at the same time keeping the geometric flexibility of stacking-based systems. We describe and implement a set of topological editing operations for the VGC, including glue, unglue, cut, and uncut. Our system maintains a global stacking order for all faces, edges, and vertices without requiring that components of an object reside together on a single layer. This allows for the coordinated editing of shared vertices and edges even for objects that have components distributed across multiple layers. We introduce VGC-specific methods that are tailored towards quickly achieving desired stacking orders for faces, edges, and vertices. ", 
        "id": 1941, 
        "title": "Vector graphics complexes."
    }, 
    {
        "abstract": "", 
        "id": 1942, 
        "title": "Assembling self-supporting structures."
    }, 
    {
        "abstract": "", 
        "id": 1943, 
        "title": "Appearance-mimicking surfaces."
    }, 
    {
        "abstract": "", 
        "id": 1944, 
        "title": "Exploring quadrangulations."
    }, 
    {
        "abstract": "", 
        "id": 1945, 
        "title": "Computational Light Routing: 3D Printed Optical Fibers for Sensing and Display."
    }, 
    {
        "abstract": "This paper presents a method for adaptive fracture propagation in thin sheets. A high-quality triangle mesh is dynamically restructured to adaptively maintain detail wherever it is required by the simulation. These requirements include refining where cracks are likely to either start or advance. Refinement ensures that the stress distribution around the crack tip is well resolved, which is vital for creating highly detailed, realistic crack paths. The dynamic meshing framework allows subsequent coarsening once areas are no longer likely to produce cracking. This coarsening allows efficient simulation by reducing the total number of active nodes and by preventing the formation of thin slivers around the crack path. A local repro-jection scheme and a substepping fracture process help to ensure stability and prevent a loss of plasticity during remeshing. By including bending and stretching plasticity models, the method is able to simulate a large range of materials with very different fracture behaviors.", 
        "id": 1946, 
        "title": "Adaptive tearing and cracking of thin sheets."
    }, 
    {
        "abstract": "", 
        "id": 1947, 
        "title": "Interactive intrinsic video editing."
    }, 
    {
        "abstract": "", 
        "id": 1948, 
        "title": "Windy trees: computing stress response for developmental tree models."
    }, 
    {
        "abstract": "The problem of planar mapping and deformation is central in computer graphics. This paper presents a framework for adapting general, smooth, function bases for building provably good planar mappings. The term \"good\" in this context means the map has no foldovers (injective), is smooth, and has low isometric or conformal distortion. Existing methods that use mesh-based schemes are able to achieve injectivity and/or control distortion, but fail to create smooth mappings, unless they use a prohibitively large number of elements, which slows them down. Meshless methods are usually smooth by construction, yet they are not able to avoid fold-overs and/or control distortion. Our approach constrains the linear deformation spaces induced by popular smooth basis functions, such as B-Splines, Gaussian and Thin-Plate Splines, at a set of collocation points, using specially tailored convex constraints that prevent fold-overs and high distortion at these points. Our analysis then provides the required density of collocation points and/or constraint type, which guarantees that the map is injective and meets the distortion constraints over the entire domain of interest. We demonstrate that our method is interactive at reasonably complicated settings and compares favorably to other state-of-the-art mesh and meshless planar deformation methods. ", 
        "id": 1949, 
        "title": "Provably good planar mappings."
    }, 
    {
        "abstract": "With better and faster acquisition devices comes a demand for fast robust reconstruction algorithms, but no L1-based technique has been fast enough for online use so far. In this paper, we present a novel continuous formulation of the weighted locally optimal projection (WLOP) operator based on a Gaussian mixture describing the input point density. Our method is up to 7 times faster than an optimized GPU implementation of WLOP, and achieves interactive frame rates for moderately sized point clouds. We give a comprehensive quality analysis showing that our continuous operator achieves a generally higher reconstruction quality than its discrete counterpart. Additionally, we show how to apply our continuous formulation to spherical mixtures of normal directions, to also achieve a fast robust normal reconstruction. ", 
        "id": 1950, 
        "title": "Continuous projection for fast L1 reconstruction."
    }, 
    {
        "abstract": "", 
        "id": 1951, 
        "title": "FlexISP: a flexible camera image processing framework."
    }, 
    {
        "abstract": "We demonstrate that layered spatial light modulators (SLMs), subject to fixed lateral displacements and refreshed at staggered intervals, can synthesize images with greater spatiotemporal resolution than that afforded by any single SLM used in their construction. Dubbed cascaded displays, such architectures enable superresolution flat panel displays (e.g., using thin stacks of liquid crystal displays (LCDs)) and digital projectors (e.g., relaying the image of one SLM onto another). We introduce a comprehensive optimization framework, leveraging non-negative matrix and tensor factorization, that decomposes target images and videos into multi-layered, time-multiplexed attenuation patterns--offering a flexible trade-off between apparent image brightness, spatial resolution, and refresh rate. Through this analysis, we develop a real-time dual-layer factorization method that quadruples spatial resolution and doubles refresh rate. Compared to prior superresolution displays, cascaded displays place fewer restrictions on the hardware, offering thin designs without moving parts or the necessity of temporal multiplexing. Furthermore, cascaded displays are the first use of multi-layer displays to increase apparent temporal resolution. We validate these concepts using two custom-built prototypes: a dual-layer LCD and a dual-modulation liquid crystal on silicon (LCoS) projector, with the former emphasizing head-mounted display (HMD) applications. ", 
        "id": 1952, 
        "title": "Cascaded displays: spatiotemporal superresolution using offset pixel layers."
    }, 
    {
        "abstract": "The acoustic wave field in a complex scene is a chaotic 7D function of time and the positions of source and listener, making it difficult to compress and interpolate. This hampers precomputed approaches which tabulate impulse responses (IRs) to allow immersive, real-time sound propagation in static scenes. We code the field of time-varying IRs in terms of a few perceptual parameters derived from the IR's energy decay. The resulting parameter fields are spatially smooth and compressed using a lossless scheme similar to PNG. We show that this encoding removes two of the seven dimensions, making it possible to handle large scenes such as entire game maps within 100MB of memory. Run-time decoding is fast, taking 100s per source. We introduce an efficient and scalable method for convolutionally rendering acoustic parameters that generates artifact-free audio even for fast motion and sudden changes in reverberance. We demonstrate convincing spatially-varying effects in complex scenes including occlusion/obstruction and reverberation, in our system integrated with Unreal Engine 3TM. ", 
        "id": 1953, 
        "title": "Parametric wave field coding for precomputed sound propagation."
    }, 
    {
        "abstract": "Millions of people worldwide need glasses or contact lenses to see or read properly. We introduce a computational display technology that predistorts the presented content for an observer, so that the target image is perceived without the need for eyewear. By designing optics in concert with prefiltering algorithms, the proposed display architecture achieves significantly higher resolution and contrast than prior approaches to vision-correcting image display. We demonstrate that inexpensive light field displays driven by efficient implementations of 4D prefiltering algorithms can produce the desired vision-corrected imagery, even for higher-order aberrations that are difficult to be corrected with glasses. The proposed computational display architecture is evaluated in simulation and with a low-cost prototype device. ", 
        "id": 1954, 
        "title": "Eyeglasses-free display: towards correcting visual aberrations with computational light field displays."
    }, 
    {
        "abstract": "", 
        "id": 1955, 
        "title": "Toward BxDF display using multilayer diffraction."
    }, 
    {
        "abstract": "We present a method for smoothly blending between existing liquid animations. We introduce a semi-automatic method for matching two existing liquid animations, which we use to create new fluid motion that plausibly interpolates the input. Our contributions include a new space-time non-rigid iterative closest point algorithm that incorporates user guidance, a subsampling technique for efficient registration of meshes with millions of vertices, and a fast surface extraction algorithm that produces 3D triangle meshes from a 4D space-time surface. Our technique can be used to instantly create hundreds of new simulations, or to interactively explore complex parameter spaces. Our method is guaranteed to produce output that does not deviate from the input animations, and it generalizes to multiple dimensions. Because our method runs at interactive rates after the initial precomputation step, it has potential applications in games and training simulations. ", 
        "id": 1956, 
        "title": "Blending liquids."
    }, 
    {
        "abstract": "", 
        "id": 1957, 
        "title": "Robust Polylines Tracing for N-Symmetry Direction Field on Triangulated Surfaces."
    }, 
    {
        "abstract": "We propose a novel graphics system based on the expansion of 3D acoustic-manipulation technology. In conventional research on acoustic levitation, small objects are trapped in the acoustic beams of standing waves. We expand this method by changing the distribution of the acoustic-potential field (APF). Using this technique, we can generate the graphics using levitated small objects. Our approach makes available many expressions, such as the expression by materials and non-digital appearance. These kinds of expressions are used in many applications, and we aim to combine them with digital controllability. In the current system, multiple particles are levitated together at 4.25-mm intervals. The spatial resolution of the position is 0.5 mm. Particles move at up to 72 cm/s. The allowable density of the material can be up to 7 g/cm3. For this study, we use three options of APF: 2D grid, high-speed movement, and combination with motion capture. These are used to realize floating screen or mid-air raster graphics, mid-air vector graphics, and interaction with levitated objects. This paper reports the details of the acoustic-potential field generator on the design, control, performance evaluation, and exploration of the application space. To discuss the various noncontact manipulation technologies in a unified manner, we introduce a concept called \"computational potential field\" (CPF). ", 
        "id": 1958, 
        "title": "Pixie dust: graphics generated by levitated and animated objects in computational acoustic-potential field."
    }, 
    {
        "abstract": "", 
        "id": 1959, 
        "title": "Multiple-Fluid SPH Simulation Using a Mixture Model."
    }, 
    {
        "abstract": "", 
        "id": 1960, 
        "title": "AppIm: linear spaces for image-based appearance editing."
    }, 
    {
        "abstract": "", 
        "id": 1961, 
        "title": "Flow-complex-based shape reconstruction from 3D curves."
    }, 
    {
        "abstract": "", 
        "id": 1962, 
        "title": "Sketch classification and classification-driven analysis using Fisher vectors."
    }, 
    {
        "abstract": "We propose a data-driven method for designing 3D models that can be fabricated. First, our approach converts a collection of expertcreated designs to a dataset of parameterized design templates that includes all information necessary for fabrication. The templates are then used in an interactive design system to create new fabricable models in a design-by-example manner. A simple interface allows novice users to choose template parts from the database, change their parameters, and combine them to create new models. Using the information in the template database, the system can automatically position, align, and connect parts: the system accomplishes this by adjusting parameters, adding appropriate constraints, and assigning connectors. This process ensures that the created models can be fabricated, saves the user from many tedious but necessary tasks, and makes it possible for non-experts to design and create actual physical objects. To demonstrate our data-driven method, we present several examples of complex functional objects that we designed and manufactured using our system. ", 
        "id": 1963, 
        "title": "Design and fabrication by example."
    }, 
    {
        "abstract": "We propose a scheme for animating deformable objects based on spacetime optimization. The main feature is that it robustly and within a few seconds generates interesting motion from a sparse set of spacetime constraints. Providing only partial (as opposed to full) keyframes for positions and velocities is sufficient. The computed motion satisfies the constraints and the remaining degrees of freedom are determined by physical principles using elasticity and the spacetime constraints paradigm. Our modeling of the spacetime optimization problem combines dimensional reduction, modal coordinates, wiggly splines, and rotation strain warping. Our solver is based on a theorem that characterizes the solutions of the optimization problem and allows us to restrict the optimization to low-dimensional search spaces. This treatment of the optimization problem avoids a time discretization and the resulting method can robustly deal with sparse input and wiggly motion.", 
        "id": 1964, 
        "title": "Animating deformable objects using sparse spacetime constraints."
    }, 
    {
        "abstract": "We present a new algorithm for computational caustic design. Our algorithm solves for the shape of a transparent object such that the refracted light paints a desired caustic image on a receiver screen. We introduce an optimal transport formulation to establish a correspondence between the input geometry and the unknown target shape. A subsequent 3D optimization based on an adaptive discretization scheme then finds the target surface from the correspondence map. Our approach supports piecewise smooth surfaces and non-bijective mappings, which eliminates a number of shortcomings of previous methods. This leads to a significantly richer space of caustic images, including smooth transitions, singularities of infinite light density, and completely black areas. We demonstrate the effectiveness of our approach with several simulated and fabricated examples. ", 
        "id": 1965, 
        "title": "High-contrast computational caustic design."
    }, 
    {
        "abstract": "", 
        "id": 1966, 
        "title": "Procedural Design of Exterior Lighting for Buildings with Complex Constraints."
    }, 
    {
        "abstract": "", 
        "id": 1967, 
        "title": "SPGrid: a sparse paged grid structure applied to adaptive smoke simulation."
    }, 
    {
        "abstract": "", 
        "id": 1968, 
        "title": "Automatic acquisition of high-fidelity facial performances using monocular videos."
    }, 
    {
        "abstract": "", 
        "id": 1969, 
        "title": "Continuity Transition with a Single Regular Curved-Knot Spline Surface."
    }, 
    {
        "abstract": "Producing high-quality shadows in large environments is an important and challenging problem for real-time applications such as games. We propose a novel data structure for precomputed shadows, which enables high-quality filtered shadows to be reconstructed for any point in the scene. We convert a high-resolution shadow map to a sparse voxel octree, where each node encodes light visibility for the corresponding voxel, and compress this tree by merging common subtrees. The resulting data structure can be many orders of magnitude smaller than the corresponding shadow map. We also show that it can be efficiently evaluated in real time with large filter kernels. ", 
        "id": 1970, 
        "title": "Compact precomputed voxelized shadows."
    }, 
    {
        "abstract": "We introduce a novel method for computing the earth mover's distance (EMD) between probability distributions on a discrete surface. Rather than using a large linear program with a quadratic number of variables, we apply the theory of optimal transportation and pass to a dual differential formulation with linear scaling. After discretization using finite elements (FEM) and development of an accompanying optimization method, we apply our new EMD to problems in graphics and geometry processing. In particular, we uncover a class of smooth distances on a surface transitioning from a purely spectral distance to the geodesic distance between points; these distances also can be extended to the volume inside and outside the surface. A number of additional applications of our machinery to geometry problems in graphics are presented. ", 
        "id": 1971, 
        "title": "Earth mover's distances on discrete surfaces."
    }, 
    {
        "abstract": "", 
        "id": 1972, 
        "title": "Mesh saliency via spectral processing."
    }, 
    {
        "abstract": "Spinning tops and yo-yos have long fascinated cultures around the world with their unexpected, graceful motions that seemingly elude gravity. We present an algorithm to generate designs for spinning objects by optimizing rotational dynamics properties. As input, the user provides a solid 3D model and a desired axis of rotation. Our approach then modifies the mass distribution such that the principal directions of the moment of inertia align with the target rotation frame. We augment the model by creating voids inside its volume, with interior fill represented by an adaptive multi-resolution voxelization. The discrete voxel fill values are optimized using a continuous, nonlinear formulation. Further, we optimize for rotational stability by maximizing the dominant principal moment. We extend our technique to incorporate deformation and multiple materials for cases where internal voids alone are insufficient. Our method is well-suited for a variety of 3D printed models, ranging from characters to abstract shapes. We demonstrate tops and yo-yos that spin surprisingly stably despite their asymmetric appearance. ", 
        "id": 1973, 
        "title": "Spin-it: optimizing moment of inertia for spinnable objects."
    }, 
    {
        "abstract": "We introduce frame fields, which are a non-orthogonal and nonunit-length generalization of cross fields. Frame fields represent smoothly varying linear transformations on tangent spaces of a surface. We propose an algorithm to create discrete, dense frame fields that satisfy a sparse set of constraints. By computing a surface deformation that warps a frame field into a cross field, we generalize existing quadrangulation algorithms to generate anisotropic and non-uniform quad meshes whose elements shapes match the frame field. With this, our framework enables users to control not only the alignment but also the density and anisotropy of the elements' distribution, resulting in high-quality adaptive quad meshing. ", 
        "id": 1974, 
        "title": "Frame fields: anisotropic and non-orthogonal cross fields."
    }, 
    {
        "abstract": "We introduce a meta-representation that represents the essence of a family of shapes. The meta-representation learns the configurations of shape parts that are common across the family, and encapsulates this knowledge with a system of geometric distributions that encode relative arrangements of parts. Thus, instead of predefined priors, what characterizes a shape family is directly learned from the set of input shapes. The meta-representation is constructed from a set of co-segmented shapes with known correspondence. It can then be used in several applications where we seek to preserve the identity of the shapes as members of the family. We demonstrate applications of the meta-representation in exploration of shape repositories, where interesting shape configurations can be examined in the set; guided editing, where models can be edited while maintaining their familial traits; and coupled editing, where several shapes can be collectively deformed by directly manipulating the distributions in the meta-representation. We evaluate the efficacy of the proposed representation on a variety of shape collections.", 
        "id": 1975, 
        "title": "Meta-representation of shape families."
    }, 
    {
        "abstract": "Data-driven simulation demands good training data drawn from a vast space of possible simulations. While fully sampling these large spaces is infeasible, we observe that in practical applications, such as gameplay, users explore only a vanishingly small subset of the dynamical state space. In this paper we present a sampling approach that takes advantage of this observation by concentrating precomputation around the states that users are most likely to encounter. We demonstrate our technique in a prototype self-refining game whose dynamics improve with play, ultimately providing realistically rendered, rich fluid dynamics in real time on a mobile device. Our results show that our analytics-driven training approach yields lower model error and fewer visual artifacts than a heuristic training strategy. ", 
        "id": 1976, 
        "title": "Self-refining games using player analytics."
    }, 
    {
        "abstract": "", 
        "id": 1977, 
        "title": "Whippletree: task-based scheduling of dynamic workloads on the GPU."
    }, 
    {
        "abstract": "In this paper, we introduce a novel material point method for heat transport, melting and solidifying materials. This brings a wider range of material behaviors into reach of the already versatile material point method. This is in contrast to best-of-breed fluid, solid or rigid body solvers that are difficult to adapt to a wide range of materials. Extending the material point method requires several contributions. We introduce a dilational/deviatoric splitting of the constitutive model and show that an implicit treatment of the Eulerian evolution of the dilational part can be used to simulate arbitrarily incompressible materials. Furthermore, we show that this treatment reduces to a parabolic equation for moderate compressibility and an elliptic, Chorin-style projection at the incompressible limit. Since projections are naturally done on marker and cell (MAC) grids, we devise a staggered grid MPM method. Lastly, to generate varying material parameters, we adapt a heat-equation solver to a material point framework. ", 
        "id": 1978, 
        "title": "Augmented MPM for phase-change and varied materials."
    }, 
    {
        "abstract": "We present a new image-guided drawing interface called EZSketching, which uses a tracing paradigm and automatically corrects sketch lines roughly traced over an image by analyzing and utilizing the image features being traced. While previous edge snapping methods aim at optimizing individual strokes, we show that a co-analysis of multiple roughly placed nearby strokes better captures the user's intent. We formulate automatic sketch improvement as a three-level optimization problem and present an efficient solution to it. EZ-Sketching can tolerate errors from various sources such as indirect control and inherently inaccurate input, and works well for sketching on touch devices with small screens using fingers. Our user study confirms that the drawings our approach helped generate show closer resemblance to the traced images, and are often aesthetically more pleasing. ", 
        "id": 1979, 
        "title": "EZ-sketching: three-level optimization for error-tolerant image tracing."
    }, 
    {
        "abstract": "We propose a new algorithm for random-access evaluation of diffusion curve images (DCIs) using the fast multipole method. Unlike all previous methods, our algorithm achieves real-time performance for rasterization and texture-mapping DCIs of up to millions of curves. After precomputation, computing the color at a single pixel takes nearly constant time. We also incorporate Gaussian radial basis functions into our fast multipole representation using the fast Gauss transform. The fast multipole representation is not only a data structure for fast color evaluation, but also a framework for vector graphics analogues of bitmap editing operations. We exhibit this capability by devising new tools for fast diffusion curve Poisson cloning and composition with masks. ", 
        "id": 1980, 
        "title": "Fast multipole representation of diffusion curves and points."
    }, 
    {
        "abstract": "", 
        "id": 1981, 
        "title": "Ink-and-ray: Bas-relief meshes for adding global illumination effects to hand-drawn characters."
    }, 
    {
        "abstract": "We present a method for converting first-person videos, for example, captured with a helmet camera during activities such as rock climbing or bicycling, into hyper-lapse videos, i.e., timelapse videos with a smoothly moving camera. At high speed-up rates, simple frame sub-sampling coupled with existing video stabilization methods does not work, because the erratic camera shake present in first-person videos is amplified by the speed-up. Our algorithm first reconstructs the 3D input camera path as well as dense, per-frame proxy geometries. We then optimize a novel camera path for the output video that passes near the input cameras while ensuring that the virtual camera looks in directions that can be rendered well from the input. Finally, we generate the novel smoothed, timelapse video by rendering, stitching, and blending appropriately selected source frames for each output frame. We present a number of results for challenging videos that cannot be processed using traditional techniques. ", 
        "id": 1982, 
        "title": "First-person hyper-lapse videos."
    }, 
    {
        "abstract": "", 
        "id": 1983, 
        "title": "Diffusion pruning for rapidly and robustly selecting global correspondences using local isometry."
    }, 
    {
        "abstract": " We develop an algorithm for the efficient and stable simulation of large-scale elastic rod assemblies. We observe that the timeintegration step is severely restricted by a strong nonlinearity in the response of stretching modes to transversal impact, the degree of this nonlinearity varying greatly with the shape of the rod. Building on these observations, we propose a collision response algorithm that adapts its degree of nonlinearity. We illustrate the advantages of the resulting algorithm by analyzing simulations involving elastic rod assemblies of varying density and scale, with up to 1.7 million individual contacts per time step.  ", 
        "id": 1984, 
        "title": "Adaptive nonlinearity for collisions in complex rod assemblies."
    }, 
    {
        "abstract": "", 
        "id": 1985, 
        "title": "Interactive generalized penetration depth computation for rigid and articulated models using object norm."
    }, 
    {
        "abstract": "We present a general approach for simulating and controlling a human character that is riding a bicycle. The two main components of our system are offline learning and online simulation. We simulate the bicycle and the rider as an articulated rigid body system. The rider is controlled by a policy that is optimized through offline learning. We apply policy search to learn the optimal policies, which are parameterized with splines or neural networks for different bicycle maneuvers. We use Neuroevolution of Augmenting Topology (NEAT) to optimize both the parametrization and the parameters of our policies. The learned controllers are robust enough to withstand large perturbations and allow interactive user control. The rider not only learns to steer and to balance in normal riding situations, but also learns to perform a wide variety of stunts, including wheelie, endo, bunny hop, front wheel pivot and back hop. ", 
        "id": 1986, 
        "title": "Learning bicycle stunts."
    }, 
    {
        "abstract": "We solve the form-finding problem for polyhedral meshes in a way which combines form, function and fabrication; taking care of userspecified constraints like boundary interpolation, planarity of faces, statics, panel size and shape, enclosed volume, and last, but not least, cost. Our main application is the interactive modeling of meshes for architectural and industrial design. Our approach can be described as guided exploration of the constraint space whose algebraic structure is simplified by introducing auxiliary variables and ensuring that constraints are at most quadratic. Computationally, we perform a projection onto the constraint space which is biased towards low values of an energy which expresses desirable \"soft\" properties like fairness. We have created a tool which elegantly handles difficult tasks, such as taking boundary-alignment of polyhedral meshes into account, planarization, fairing under planarity side conditions, handling hybrid meshes, and extending the treatment of static equilibrium to shapes which possess overhanging parts. ", 
        "id": 1987, 
        "title": "Form-finding with polyhedral meshes made simple."
    }, 
    {
        "abstract": "We present an efficient new subspace method for simulating the self-contact of articulated deformable bodies, such as characters. Self-contact is highly structured in this setting, as the limited space of possible articulations produces a predictable set of coherent collisions. Subspace methods can leverage this coherence, and have been used in the past to accelerate the collision detection stage of contact simulation. We show that these methods can be used to accelerate the entire contact computation, and allow self-contact to be resolved without looking at all of the contact points. Our analysis of the problem yields a broader insight into the types of non-linearities that subspace methods can efficiently approximate, and leads us to design a pose-space cubature scheme. Our algorithm accelerates self-contact by up to an order of magnitude over other subspace simulations, and accelerates the overall simulation by two orders of magnitude over full-rank simulations. We demonstrate the simulation of high resolution (100K  400K elements) meshes in self-contact at interactive rates (5.8  50 FPS).", 
        "id": 1988, 
        "title": "Simulating articulated subspace self-contact."
    }, 
    {
        "abstract": "In this paper we address the problem of finding correspondences between related shapes of widely varying geometry. We propose a new method based on the observation that symmetry and regularity in shapes is often associated with their function. Hence, they provide cues for matching related geometry even under strong shape variations. Correspondingly, we decomposes shapes into overlapping regions determined by their regularity properties. Afterwards, we form a graph that connects these pieces via pairwise relations that capture geometric relations between rotation axes and reflection planes as well as topological or proximity relations. Finally, we perform graph matching to establish correspondences. The method yields certain more abstract but semantically meaningful correspondences between man-made shapes that are too difficult to recognize by traditional geometric methods. ", 
        "id": 1989, 
        "title": "Relating shapes via geometric symmetries and regularities."
    }, 
    {
        "abstract": "", 
        "id": 1990, 
        "title": "Real-Time Continuous Pose Recovery of Human Hands Using Convolutional Networks."
    }, 
    {
        "abstract": "Modeling how the human body deforms during breathing is important for the realistic animation of lifelike 3D avatars. We learn a model of body shape deformations due to breathing for different breathing types and provide simple animation controls to render lifelike breathing regardless of body shape. We capture and align high-resolution 3D scans of 58 human subjects. We compute deviations from each subject's mean shape during breathing, and study the statistics of such shape changes for different genders, body shapes, and breathing types. We use the volume of the registered scans as a proxy for lung volume and learn a novel non-linear model relating volume and breathing type to 3D shape deformations and pose changes. We then augment a SCAPE body model so that body shape is determined by identity, pose, and the parameters of the breathing model. These parameters provide an intuitive interface with which animators can synthesize 3D human avatars with realistic breathing motions. We also develop a novel interface for animating breathing using a spirometer, which measures the changes in breathing volume of a \"breath actor.\" ", 
        "id": 1991, 
        "title": "Breathing life into shape: capturing, modeling and animating 3D human breathing."
    }, 
    {
        "abstract": "", 
        "id": 1992, 
        "title": "Robust iso-surface tracking for interactive character skinning."
    }, 
    {
        "abstract": "Monte Carlo techniques for light transport simulation rely on importance sampling when constructing light transport paths. Previous work has shown that suitable sampling distributions can be recovered from particles distributed in the scene prior to rendering. We propose to represent the distributions by a parametric mixture model trained in an on-line (i.e. progressive) manner from a potentially infinite stream of particles. This enables recovering good sampling distributions in scenes with complex lighting, where the necessary number of particles may exceed available memory. Using these distributions for sampling scattering directions and light emission significantly improves the performance of state-of-the-art light transport simulation algorithms when dealing with complex lighting.", 
        "id": 1993, 
        "title": "On-line learning of parametric mixture models for light transport simulation."
    }, 
    {
        "abstract": "We introduce a fast tile-based method for adaptive two-dimensional sampling with user-specified spectral properties. At the core of our approach is a deterministic, hierarchical construction of self-similar, equi-area, tri-hex tiles whose centroids have a spatial distribution free of spurious spectral peaks. A lookup table of sample points, computed offline using any existing point set optimizer to shape the samples' Fourier spectrum, is then used to populate the tiles. The result is a linear-time, adaptive, and high-quality sampling of arbitrary density functions that conforms to the desired spectral distribution, achieving a speed improvement of several orders of magnitude over current spectrum-controlled sampling methods. ", 
        "id": 1994, 
        "title": "Fast tile-based adaptive sampling with user-specified Fourier spectra."
    }, 
    {
        "abstract": "We describe Embree, an open source ray tracing framework for x86 CPUs. Embree is explicitly designed to achieve high performance in professional rendering environments in which complex geometry and incoherent ray distributions are common. Embree consists of a set of low-level kernels that maximize utilization of modern CPU architectures, and an API which enables these kernels to be used in existing renderers with minimal programmer effort. In this paper, we describe the design goals and software architecture of Embree, and show that for secondary rays in particular, the performance of Embree is competitive with (and often higher than) existing stateof-the-art methods on CPUs and GPUs. ", 
        "id": 1995, 
        "title": "Embree: a kernel framework for efficient CPU ray tracing."
    }, 
    {
        "abstract": "We present a technique for analyzing a set of animal gaits to predict the gait of a new animal from its shape alone. This method works on a wide range of bipeds and quadrupeds, and adapts the motion style to the size and shape of the animal. We achieve this by combining inverse optimization with sparse data interpolation. Starting with a set of reference walking gaits extracted from sagittal plane video footage, we first use inverse optimization to learn physically motivated parameters describing the style of each of these gaits. Given a new animal, we estimate the parameters describing its gait with sparse data interpolation, then solve a forward optimization problem to synthesize the final gait. To improve the realism of the results, we introduce a novel algorithm called joint inverse optimization which learns coherent patterns in motion style from a database of example animal-gait pairs. We quantify the predictive performance of our model by comparing its synthesized gaits to ground truth walking motions for a range of different animals. We also apply our method to the prediction of gaits for dinosaurs and other extinct creatures. ", 
        "id": 1996, 
        "title": "Generalizing locomotion style to new animals with inverse optimal regression."
    }, 
    {
        "abstract": "The same physical scene seen in bright sunlight and in dusky conditions does not appear identical to the human eye. Similarly, images shown on an 8000 cd/m2 high-dynamic-range (HDR) display and in a 50 cd/m2 peak luminance cinema screen also differ significantly in their appearance. We propose a luminance retargeting method that alters the perceived contrast and colors of an image to match the appearance under different luminance levels. The method relies on psychophysical models of matching contrast, models of rod-contribution to vision, and our own measurements. The retargeting involves finding an optimal tone-curve, spatial contrast processing, and modeling of hue and saturation shifts. This lets us reliably simulate night vision in bright conditions, or compensate for a bright image shown on a darker display so that it reveals details and colors that would otherwise be invisible.", 
        "id": 1997, 
        "title": "Simulating and compensating changes in appearance between day and night vision."
    }, 
    {
        "abstract": " Numerical errors and rounding errors in continuous collision detection (CCD) can easily cause collision detection failures if they are not handled properly. A simple and effective approach is to use error tolerances, as shown in many existing CCD systems. Unfortunately, finding the optimal tolerance values is a difficult problem for users. Larger tolerance values will introduce false positive artifacts, while smaller tolerance values may cause collisions to be undetected. The biggest issue here is that we do not know whether or when CCD will fail, even though failures are extremely rare. In this paper, we demonstrate a set of simple modifications to make a basic CCD implementation failure-proof. Using error analysis, we prove the safety of this method and we formulate suggested tolerance values to reduce false positives. The resulting algorithms are safe, automatic, efficient, and easy to implement. ", 
        "id": 1998, 
        "title": "Defending continuous collision detection against errors."
    }, 
    {
        "abstract": "", 
        "id": 1999, 
        "title": "BiggerPicture: data-driven image extrapolation using graph matching."
    }, 
    {
        "abstract": "Aligning video is a fundamental task in computer graphics and vision, required for a wide range of applications. We present an interactive method for computing optimal nonlinear temporal video alignments of an arbitrary number of videos. We first derive a robust approximation of alignment quality between pairs of clips, computed as a weighted histogram of feature matches. We then find optimal temporal mappings (constituting frame correspondences) using a graph-based approach that allows for very efficient evaluation with artist constraints. This enables an enhancement to the \"snapping\" interface in video editing tools, where videos in a timeline are now able snap to one another when dragged by an artist based on their content, rather than simply start-and-end times. The pairwise snapping is then generalized to multiple clips, achieving a globally optimal temporal synchronization that automatically arranges a series of clips filmed at different times into a single consistent time frame. When followed by a simple spatial registration, we achieve high quality spatiotemporal video alignments at a fraction of the computational complexity compared to previous methods. Assisted temporal alignment is a degree of freedom that has been largely unexplored, but is an important task in video editing. Our approach is simple to implement, highly efficient, and very robust to differences in video content, allowing for interactive exploration of the temporal alignment space for multiple real world HD videos. ", 
        "id": 2000, 
        "title": "VideoSnapping: interactive synchronization of multiple videos."
    }, 
    {
        "abstract": "", 
        "id": 2001, 
        "title": "Decoupling noise and features via weighted \u2113"
    }, 
    {
        "abstract": "We present a framework for learning new analytic BRDF models through Genetic Programming that we call genBRDF. This approach to reflectance modeling can be seen as an extension of traditional methods that rely either on a phenomenological or empirical process. Our technique augments the human effort involved in deriving mathematical expressions that accurately characterize complex high-dimensional reflectance functions through a large-scale optimization. We present a number of analysis tools and data visualization techniques that are crucial to sifting through the large result sets produced by genBRDF in order to identify fruitful expressions. Additionally, we highlight several new models found by genBRDF that have not previously appeared in the BRDF literature. These new BRDF models are compact and more accurate than current state-of-the-art alternatives. ", 
        "id": 2002, 
        "title": "genBRDF: discovering new analytic BRDFs with genetic programming."
    }, 
    {
        "abstract": " We give an algorithm which extracts vortex filaments (\"smoke rings\") from a given 3D velocity field. Given a filament strength h > 0, an optimal number of vortex filaments, together with their extent and placement, is given by the zero set of a complex valued function over the domain. This function is the global minimizer of a quadratic energy based on a Schrdinger operator. Computationally this amounts to finding the eigenvector belonging to the smallest eigenvalue of a Laplacian type sparse matrix. Turning traditional vector field representations of flows, for example, on a regular grid, into a corresponding set of vortex filaments is useful for visualization, analysis of measured flows, hybrid simulation methods, and sparse representations. To demonstrate our method we give examples from each of these.  ", 
        "id": 2003, 
        "title": "Smoke rings from smoke."
    }, 
    {
        "abstract": "(a) Where should new faces be inserted? (b) How should adjacent faces be updated, keeping them planar? (c) How should edge collapses be handled? (d) Example showing all features Figure 1: There are multiple challenges when a PushPull operation is performed on a face or edge. Case (a): New faces can either be inserted for all edges (left) or not at all by adjusting adjacent faces (middle). In addition, our solution can adaptively add new faces where needed (right). New faces are blue and modified adjacent faces are green. In (b-d), the left figure is the input, the middle is the degenerate result by previous approaches, and the right is our result. Non-planar or self-intersecting faces are red and edge collapses are blue dots. Abstract PushPull tools are implemented in most commercial 3D modeling suites. Their purpose is to intuitively transform a face, edge, or vertex, and then to adapt the polygonal mesh locally. However, previous approaches have limitations: Some allow adjustments only when adjacent faces are orthogonal; others support slanted surfaces but never create new details. Moreover, self-intersections and edge-collapses during editing are either ignored or work only partially for solid geometry. To overcome these limitations, we introduce the PushPull++ tool for rapid polygonal modeling. In our solution, we contribute novel methods for adaptive face insertion, adjacent face updates, edge collapse handling, and an intuitive user interface that automatically proposes useful drag directions. We show that PushPull++ reduces the complexity of common modeling tasks by up to an order of magnitude when compared with existing tools.", 
        "id": 2004, 
        "title": "PushPull++."
    }, 
    {
        "abstract": "", 
        "id": 2005, 
        "title": "Structure completion for facade layouts."
    }, 
    {
        "abstract": "", 
        "id": 2006, 
        "title": "Generating and ranking diverse multi-character interactions."
    }, 
    {
        "abstract": "", 
        "id": 2007, 
        "title": "Quality-driven poisson-guided autoscanning."
    }, 
    {
        "abstract": "", 
        "id": 2008, 
        "title": "Hierarchical diffusion curves for accurate automatic image vectorization."
    }, 
    {
        "abstract": "", 
        "id": 2009, 
        "title": "Autocomplete painting repetitions."
    }, 
    {
        "abstract": "", 
        "id": 2010, 
        "title": "Robust surface reconstruction via dictionary learning."
    }, 
    {
        "abstract": "Recent technological advances in facial capture have made it possible to acquire high-fidelity 3D facial performance data with stunningly high spatial-temporal resolution. Current methods for facial expression transfer, however, are often limited to large-scale facial deformation. This paper introduces a novel facial expression transfer and editing technique for high-fidelity facial performance data. The key idea of our approach is to decompose high-fidelity facial performances into high-level facial feature lines, large-scale facial deformation and fine-scale motion details and transfer them appropriately to reconstruct the retargeted facial animation in an efficient optimization framework. The system also allows the user to quickly modify and control the retargeted facial sequences in the spatial-temporal domain. We demonstrate the power of our approach by transferring and editing high-fidelity facial animation data from high-resolution source models to a wide range of target models, including both human faces and non-human faces such as \"monster\" and \"dog\". ", 
        "id": 2011, 
        "title": "Controllable high-fidelity facial performance transfer."
    }, 
    {
        "abstract": "", 
        "id": 2012, 
        "title": "A practical algorithm for rendering interreflections with all-frequency BRDFs."
    }, 
    {
        "abstract": "We present a real-time solution for generating detailed clothing deformations from pre-computed clothing shape examples. Given an input pose, it synthesizes a clothing deformation by blending skinned clothing deformations of nearby examples controlled by the body skeleton. Observing that cloth deformation can be well modeled with sensitivity analysis driven by the underlying skeleton, we introduce a sensitivity based method to construct a pose-dependent rigging solution from sparse examples. We also develop a sensitivity based blending scheme to find nearby examples for the input pose and evaluate their contributions to the result. Finally, we propose a stochastic optimization based greedy scheme for sampling the pose space and generating example clothing shapes. Our solution is fast, compact and can generate realistic clothing animation results for various kinds of clothes in real time.", 
        "id": 2013, 
        "title": "Sensitivity-optimized rigging for example-based real-time clothing synthesis."
    }, 
    {
        "abstract": "", 
        "id": 2014, 
        "title": "Dynamic hair capture using spacetime optimization."
    }, 
    {
        "abstract": "In this paper, we tackle the problem of tiling a domain with a set of deformable templates. A valid solution to this problem completely covers the domain with templates such that the templates do not overlap. We generalize existing specialized solutions and formulate a general layout problem by modeling important constraints and admissible template deformations. Our main idea is to break the layout algorithm into two steps: a discrete step to lay out the approximate template positions and a continuous step to refine the template shapes. Our approach is suitable for a large class of applications, including floorplans, urban layouts, and arts and design. ", 
        "id": 2015, 
        "title": "Computing layouts with deformable templates."
    }, 
    {
        "abstract": "Complex specular surfaces under sharp point lighting show a fascinating glinty appearance, but rendering it is an unsolved problem. Using Monte Carlo pixel sampling for this purpose is impractical: the energy is concentrated in tiny highlights that take up a minuscule fraction of the pixel. We instead compute an accurate solution using a completely different deterministic approach. Our method considers the true distribution of normals on a surface patch seen through a single pixel, which can be highly complex. We show how to evaluate this distribution efficiently, assuming a Gaussian pixel footprint and Gaussian intrinsic roughness. We also take advantage of hierarchical pruning of position-normal space to rapidly find tex-els that might contribute to a given normal distribution evaluation. Our results show complex, temporally varying glints from materials such as bumpy plastics, brushed and scratched metals, metallic paint and ocean waves.", 
        "id": 2016, 
        "title": "Rendering glints on high-resolution normal-mapped specular surfaces."
    }, 
    {
        "abstract": "The evolution of 3D scanning technologies have revolutionized the way real-world object are digitally acquired. Nowadays, high-definition and high-speed scanners can capture even large scale scenes with very high accuracy. Nevertheless, the acquisition of complete 3D objects remains a bottleneck, requiring to carefully sample the whole objects surface, similar to a coverage process. Holes and undersampled regions are common in 3D scans of complex-shaped objects with self occlusions and hidden interiors. In this paper we introduce the novel paradigm of proactive scanning, in which the user actively modifies the scene while scanning it, in order to reveal and access occluded regions. We take a holistic approach and integrate the user interaction into the continuous scanning process. Our algorithm allows for dynamic modifications of the scene as part of a global 3D scanning process. We utilize a scan registration algorithm to compute motion trajectories and separate between user modifications and other motions such as (hand-held) camera movements and small deformations. Thus, we reconstruct together the static parts into a complete unified 3D model. We evaluate our technique by scanning and reconstructing 3D objects and scenes consisting of inaccessible regions such as interiors, entangled plants and clutter.", 
        "id": 2017, 
        "title": "Proactive 3D scanning of inaccessible parts."
    }, 
    {
        "abstract": "In this paper, we address the following research problem: How can we generate a meaningful split grammar that explains a given facade layout? To evaluate if a grammar is meaningful, we propose a cost function based on the description length and minimize this cost using an approximate dynamic programming framework. Our evaluation indicates that our framework extracts meaningful split grammars that are competitive with those of expert users, while some users and all competing automatic solutions are less successful.", 
        "id": 2018, 
        "title": "Inverse procedural modeling of facade layouts."
    }, 
    {
        "abstract": "We present a method to decompose a video into its intrinsic components of reflectance and shading, plus a number of related example applications in video editing such as segmentation, stylization, material editing, recolorization and color transfer. Intrinsic decomposition is an ill-posed problem, which becomes even more challenging in the case of video due to the need for temporal coherence and the potentially large memory requirements of a global approach. Additionally, user interaction should be kept to a minimum in order to ensure efficiency. We propose a probabilistic approach, formulating a Bayesian Maximum a Posteriori problem to drive the propagation of clustered reflectance values from the first frame, and defining additional constraints as priors on the reflectance and shading. We explicitly leverage temporal information in the video by building a causal-anticausal, coarse-to-fine iterative scheme, and by relying on optical flow information. We impose no restrictions on the input video, and show examples representing a varied range of difficult cases. Our method is the first one designed explicitly for video; moreover, it naturally ensures temporal consistency, and compares favorably against the state of the art in this regard. ", 
        "id": 2019, 
        "title": "Intrinsic video and applications."
    }, 
    {
        "abstract": "", 
        "id": 2020, 
        "title": "Morfit: interactive surface reconstruction from incomplete point clouds with curve-driven topology and geometry control."
    }, 
    {
        "abstract": "", 
        "id": 2021, 
        "title": "Parallel chen-han (PCH) algorithm for discrete geodesics."
    }, 
    {
        "abstract": "", 
        "id": 2022, 
        "title": "Poisson-Based Continuous Surface Generation for Goal-Based Caustics."
    }, 
    {
        "abstract": "", 
        "id": 2023, 
        "title": "Co-constrained handles for deformation in shape collections."
    }, 
    {
        "abstract": "", 
        "id": 2024, 
        "title": "A PPPM fast summation method for fluids and beyond."
    }, 
    {
        "abstract": "", 
        "id": 2025, 
        "title": "Local barycentric coordinates."
    }, 
    {
        "abstract": "", 
        "id": 2026, 
        "title": "Leveraging depth cameras and wearable pressure sensors for full-body kinematics and dynamics capture."
    }, 
    {
        "abstract": "", 
        "id": 2027, 
        "title": "Indexing 3D Scenes Using the Interaction Bisector Surface."
    }, 
    {
        "abstract": "", 
        "id": 2028, 
        "title": "Slippage-free background replacement for hand-held video."
    }, 
    {
        "abstract": "", 
        "id": 2029, 
        "title": "Topology-constrained synthesis of vector patterns."
    }, 
    {
        "abstract": "We present a global optimization approach for mapping color images onto geometric reconstructions. Range and color videos produced by consumer-grade RGB-D cameras suffer from noise and optical distortions, which impede accurate mapping of the acquired color data to the reconstructed geometry. Our approach addresses these sources of error by optimizing camera poses in tandem with non-rigid correction functions for all images. All parameters are optimized jointly to maximize the photometric consistency of the reconstructed mapping. We show that this optimization can be performed efficiently by an alternating optimization algorithm that interleaves analytical updates of the color map with decoupled parameter updates for all images. Experimental results demonstrate that our approach substantially improves color mapping fidelity.", 
        "id": 2030, 
        "title": "Color map optimization for 3D reconstruction with consumer depth cameras."
    }, 
    {
        "abstract": "This paper proposes an interactive framework that allows a user to rapidly explore and visualize a large image collection using the medium of average images. Average images have been gaining popularity as means of artistic expression and data visualization, but the creation of compelling examples is a surprisingly laborious and manual process. Our interactive, real-time system provides a way to summarize large amounts of visual data by weighted average(s) of an image collection, with the weights reflecting user-indicated importance. The aim is to capture not just the mean of the distribution, but a set of modes discovered via interactive exploration. We pose ACM Reference Format Zhu, J., Lee, Y., Efros, A. 2014. AverageExplorer: Interactive Exploration and Alignment of Visual Data Collections. ACM Trans. Graph. 33, 4, Article 160 (July 2014), 11 pages. DOI = 10.1145/2601097.2601145 http://doi.acm.org/10.1145/2601097.2601145. Copyright Notice Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. 2014 Copyright held by the Owner/Author. Publication rights licensed to ACM. 0730-0301/14/07-ART160 $15.00. DOI: http://dx.doi.org/10.1145/2601097.2601145  this exploration in terms of a user interactively \"editing\" the average image using various types of strokes, brushes and warps, similar to a normal image editor, with each user interaction providing a new constraint to update the average. New weighted averages can be spawned and edited either individually or jointly. Together, these tools allow the user to simultaneously perform two fundamental operations on visual data: user-guided clustering and user-guided alignment, within the same framework. We show that our system is useful for various computer vision and graphics applications. ", 
        "id": 2031, 
        "title": "AverageExplorer: interactive exploration and alignment of visual data collections."
    }, 
    {
        "abstract": "Many visually interesting natural phenomena are characterized by thin liquid sheets, long filaments, and droplets. We present a new Lagrangian-based numerical method to simulate these codimensional surface tension driven phenomena using non-manifold simplicial complexes. Tetrahedra, triangles, segments, and points are used to model the fluid volume, thin films, filaments, and droplets, respectively. We present a new method for enforcing fluid incompressibility on simplicial complexes along with a physically-guided meshing algorithm to provide temporally consistent information for interparticle forces. Our method naturally allows for transitions between codimensions, either from tetrahedra to triangles to segments to points or vice versa, regardless of the simulation resolution. We demonstrate the efficacy of this method by simulating various natural phenomena that are characterized by thin fluid sheets, filaments, and surface tension effects. ", 
        "id": 2032, 
        "title": "Codimensional surface tension flow on simplicial complexes."
    }, 
    {
        "abstract": "We present an algorithm for mapping a triangle mesh, which is homeomorphic to a disk, to a planar domain with arbitrary fixed boundaries. The algorithm is guaranteed to produce a globally bijective map when the boundary is fixed to a shape that does not self-intersect. Obtaining a one-to-one map is of paramount importance for many graphics applications such as texture mapping. However, for other applications, such as quadrangulation, remeshing, and planar deformations, global bijectively may be unnecessarily constraining and requires significant increase on map distortion. For that reason, our algorithm allows the fixed boundary to intersect itself, and is guaranteed to produce a map that is injective locally (if such a map exists). We also extend the basic ideas of the algorithm to support the computation of discrete approximation for extremal quasiconformal maps. The algorithm is conceptually simple and fast. We demonstrate the superior robustness of our algorithm in various settings and configurations in which state-of-the-art algorithms fail to produce injective maps. ", 
        "id": 2033, 
        "title": "Locally injective parametrization with arbitrary fixed boundaries."
    }, 
    {
        "abstract": "We present a robust method for computing locally bijective global parametrizations aligned with a given cross-field. The singularities of the parametrization in general agree with singularities of the field, except in a small number of cases when several additional cones need to be added in a controlled way. Parametric lines can be constrained to follow an arbitrary set of feature lines on the surface. Our method is based on constructing an initial quad patch partition using robust cross-field integral line tracing. This process is followed by an algorithm modifying the quad layout structure to ensure that consistent parametric lengths can be assigned to the edges. For most meshes, the layout modification algorithm does not add new singularities; a small number of singularities may be added to resolve an explicitly described set of layouts. We demonstrate that our algorithm succeeds on a test data set of over a hundred meshes. ", 
        "id": 2034, 
        "title": "Robust field-aligned global parametrization."
    }, 
    {
        "abstract": "", 
        "id": 2035, 
        "title": "Strict minimizers for geometric optimization."
    }, 
    {
        "abstract": "We introduce a method for computing seamless bijective mappings between two surface-meshes that interpolates a given set of correspondences. A common approach for computing a map between surfaces is to cut the surfaces to disks, flatten them to the plane, and extract the mapping from the flattenings by composing one flattening with the inverse of the other. So far, a significant drawback in this class of techniques is that the choice of cuts introduces a bias in the computation of the map that often causes visible artifacts and wrong correspondences. In this paper we develop a surface mapping technique that is indifferent to the particular cut choice. This is achieved by a novel type of surface flattenings that encodes this cut-invariance, and when optimized with a suitable energy functional results in a seamless surface-to-surface map. We show the algorithm enables producing high-quality seamless bijective maps for pairs of surfaces with a wide range of shape variability and from a small number of prescribed correspondences. We also used this framework to produce three-way, consistent and seamless mappings for triplets of surfaces.", 
        "id": 2036, 
        "title": "Seamless surface mappings."
    }, 
    {
        "abstract": "Material appearance acquisition usually makes a trade-off between acquisition effort and richness of reflectance representation. In this paper, we instead aim for both a light-weight acquisition procedure and a rich reflectance representation simultaneously, by restricting ourselves to one, but very important, class of appearance phenomena: texture-like materials. While such materials reflectance is generally spatially varying, they exhibit self-similarity in the sense that for any point on the texture there exist many others with similar reflectance properties. We show that the texturedness assumption allows reflectance capture using only two images of a planar sample, taken with and without a headlight flash. Our reconstruction pipeline starts with redistributing reflectance observations across the image, followed by a regularized texture statistics transfer and a nonlinear optimization to fit a spatially-varying BRDF (SVBRDF) to the resulting data. The final result describes the material as spatially-varying, diffuse and specular, anisotropic reflectance over a detailed normal map. We validate the method by side-by-side and novel-view comparisons to photographs, comparing normal map resolution to sub-micron ground truth scans, as well as simulated results. Our method is robust enough to use handheld, JPEG-compressed photographs taken with a mobile phone camera and built-in flash.", 
        "id": 2037, 
        "title": "Two-shot SVBRDF capture for stationary materials."
    }, 
    {
        "abstract": "We present the first real-time technique to synthesize fullbandwidth sounds for 2D virtual wind instruments. A novel interactive wave solver is proposed that synthesizes audio at 128,000Hz on commodity graphics cards. Simulating the wave equation captures the resonant and radiative properties of the instrument body automatically. We show that a variety of existing non-linear excitation mechanisms such as reed or lips can be successfully coupled to the instrument's 2D wave field. Virtual musical performances can be created by mapping user inputs to control geometric features of the instrument body, such as tone holes, and modifying parameters of the excitation model, such as blowing pressure. Field visualizations are also produced. Our technique promotes experimentation by providing instant audio-visual feedback from interactive virtual designs. To allow artifact-free audio despite dynamic geometric modification, we present a novel time-varying Perfectly Matched Layer formulation that yields smooth, natural-sounding transitions between notes. We find that visco-thermal wall losses are crucial for musical sound in 2D simulations and propose a practical approximation. Weak non-linearity at high amplitudes is incorporated to improve the sound quality of brass instruments. ", 
        "id": 2038, 
        "title": "Aerophones in flatland: interactive wave simulation of wind instruments."
    }, 
    {
        "abstract": "This paper presents a liquid simulation technique that enforces the incompressibility condition using a stream function solve instead of a pressure projection. Previous methods have used stream function techniques for the simulation of detailed single-phase flows, but a formulation for liquid simulation has proved elusive in part due to the free surface boundary conditions. In this paper, we introduce a stream function approach to liquid simulations with novel boundary conditions for free surfaces, solid obstacles, and solid-fluid coupling. Although our approach increases the dimension of the linear system necessary to enforce incompressibility, it provides interesting and surprising benefits. First, the resulting flow is guaranteed to be divergence-free regardless of the accuracy of the solve. Second, our free-surface boundary conditions guarantee divergence-free motion even in the un-simulated air phase, which enables two-phase flow simulation by only computing a single phase. We implemented this method using a variant of FLIP simulation which only samples particles within a narrow band of the liquid surface, and we illustrate the effectiveness of our method for detailed two-phase flow simulations with complex boundaries, detailed bubble interactions, and two-way solid-fluid coupling.", 
        "id": 2039, 
        "title": "A stream function solver for liquid simulations."
    }, 
    {
        "abstract": "", 
        "id": 2040, 
        "title": "RingIt: Ring-Ordering Casual Photos of a Temporal Event."
    }, 
    {
        "abstract": "", 
        "id": 2041, 
        "title": "Discrete Derivatives of Vector Fields on Surfaces - An Operator Approach."
    }, 
    {
        "abstract": "We present a method for interactive editing of planar linkages. Given a working linkage as input, the user can make targeted edits to the shape or motion of selected parts while preserving other, e.g., functionally-important aspects. In order to make this process intuitive and efficient, we provide a number of editing tools at different levels of abstraction. For instance, the user can directly change the structure of a linkage by displacing joints, edit the motion of selected points on the linkage, or impose limits on the size of its enclosure. Our method safeguards against degenerate configurations during these edits, thus ensuring the correct functioning of the mechanism at all times. Linkage editing poses strict requirements on performance that standard approaches fail to provide. In order to enable interactive and robust editing, we build on a symbolic kinematics approach that uses closed-form expressions instead of numerical methods to compute the motion of a linkage and its derivatives. We demonstrate our system on a diverse set of examples, illustrating the potential to adapt and personalize the structure and motion of existing linkages. To validate the feasibility of our edited designs, we fabricated two physical prototypes.  home. While there is interest and value in replication, however, this usage forgoes the true potential of 3D printers: personalization--the opportunity to adapt content to individual needs and preferences. A variety of existing software tools allow for intuitive editing of static digital models. Some of these tools even maintain or establish structural stability by virtue of finite element analysis. To date, however, no equivalent CAD software has been developed for mechanically-functional models. Yet, a vast array of mechanicallyfunctional objects such as kinetic sculptures, fold-away furniture, electro-mechanical toys, and even robots stand to benefit from userfriendly editing tools and the corresponding potential for personalization that they would bring about. We focus on the challenge of editing planar linkages, which are the beating heart of many mechanically-functional models--and notoriously difficult to design and edit: even for simple linkages, the relation between joint displacements and resulting change in motioncurves is complex and very difficult to predict. Within the group of planar linkages, our method can handle a large set of well-known and widely-used mechanisms.  ", 
        "id": 2042, 
        "title": "LinkEdit: interactive linkage editing using symbolic kinematics."
    }, 
    {
        "abstract": "Popular sites like Houzz, Pinterest, and LikeThatDecor, have communities of users helping each other answer questions about products in images. In this paper we learn an embedding for visual search in interior design. Our embedding contains two different domains of product images: products cropped from internet scenes, and products in their iconic form. With such a multi-domain embedding, we demonstrate several applications of visual search including identifying products in scenes and finding stylistically similar products. To obtain the embedding, we train a convolutional neural network on pairs of images. We explore several training architectures including re-purposing object classifiers, using siamese networks, and using multitask learning. We evaluate our search quantitatively and qualitatively and demonstrate high quality results for search across multiple visual domains, enabling new applications in interior design.", 
        "id": 2043, 
        "title": "Learning visual similarity for product design with convolutional neural networks."
    }, 
    {
        "abstract": "This paper presents a data structure that reduces approximate nearest neighbor query times for image patches in large datasets. Previous work in texture synthesis has demonstrated real-time synthesis from small exemplar textures. However, high performance has proved elusive for modern patch-based optimization techniques which frequently use many exemplar images in the tens of megapixels or above. Our new algorithm, PatchTable, offloads as much of the computation as possible to a pre-computation stage that takes modest time, so patch queries can be as efficient as possible. There are three key insights behind our algorithm: (1) a lookup table similar to locality sensitive hashing can be precomputed, and used to seed sufficiently good initial patch correspondences during querying, (2) missing entries in the table can be filled during precomputation with our fast Voronoi transform, and (3) the initially seeded correspondences can be improved with a precomputed knearest neighbors mapping. We show experimentally that this accelerates the patch query operation by up to 9 over k-coherence, up to 12 over TreeCANN, and up to 200 over PatchMatch. Our fast algorithm allows us to explore efficient and practical imaging and computational photography applications. We show results for artistic video stylization, light field super-resolution, and multiimage editing. ", 
        "id": 2044, 
        "title": "PatchTable: efficient patch queries for large datasets and applications."
    }, 
    {
        "abstract": "We describe our successful initiative to accelerate Adobe Illustrator with the graphics hardware pipeline of modern GPUs. Relying on OpenGL 4.4 plus recent OpenGL extensions for advanced blend modes and first-class GPU-accelerated path rendering, we accelerate the Adobe Graphics Model (AGM) layer responsible for rendering sophisticated Illustrator scenes. Illustrator documents render in either an RGB or CMYK color mode. While GPUs are designed and optimized for RGB rendering, we orchestrate OpenGL rendering of vector content in the proper CMYK color space and accommodate the 5+ color components required. We support both non-isolated and isolated transparency groups, knockout, patterns, and arbitrary path clipping. We harness GPU tessellation to shade paths smoothly with gradient meshes. We do all this and render complex Illustrator scenes 2 to 6x faster than CPU rendering at Full HD resolutions; and 5 to 16x faster at Ultra HD resolutions. ", 
        "id": 2045, 
        "title": "Accelerating vector graphics rendering using the graphics hardware pipeline."
    }, 
    {
        "abstract": "In recent years we have seen numerous improvements on 3D scanning and tracking of human faces, greatly advancing the creation of digital doubles for film and video games. However, despite the high-resolution quality of the reconstruction approaches available, current methods are unable to capture one of the most important regions of the face the eye region. In this work we present the first method for detailed spatio-temporal reconstruction of eyelids. Tracking and reconstructing eyelids is extremely challenging, as this region exhibits very complex and unique skin deformation where skin is folded under while opening the eye. Furthermore, eyelids are often only partially visible and obstructed due to self-occlusion and eyelashes. Our approach is to combine a geometric deformation model with image data, leveraging multi-view stereo, optical flow, contour tracking and wrinkle detection from local skin appearance. Our deformation model serves as a prior that enables reconstruction of eyelids even under strong self-occlusions caused by rolling and folding skin as the eye opens and closes. The output is a person-specific, time-varying eyelid reconstruction with anatomically plausible deformations. Our high-resolution detailed eyelids couple naturally with current facial performance capture approaches. As a result, our method can largely increase the fidelity of facial capture and the creation of digital doubles.", 
        "id": 2046, 
        "title": "Detailed spatio-temporal reconstruction of eyelids."
    }, 
    {
        "abstract": " texturing and 3D object compositing in photographs.  Identifying sparse salient structures from dense pixels is a longstanding problem in visual computing. Solutions to this problem can benefit both image manipulation and understanding. In this paper, we introduce an image transform based on the L1 norm for piecewise image flattening. This transform can effectively preserve and sharpen salient edges and contours while eliminating insignificant details, producing a nearly piecewise constant image with sparse structures. A variant of this image transform can perform edge-preserving smoothing more effectively than existing state-ofthe-art algorithms. We further present a new method for complex scene-level intrinsic image decomposition. Our method relies on the above image transform to suppress surface shading variations, and perform probabilistic reflectance clustering on the flattened image instead of the original input image to achieve higher accuracy. Extensive testing on the Intrinsic-Images-in-the-Wild database indicates our method can perform significantly better than existing techniques both visually and numerically. The obtained intrinsic images have been successfully used in two applications, surface re- ACM Reference Format Bi, S., Han, X., Yu, Y. 2015. An L1 Transform for Edge-Preserving Smoothing and Scene-Level Intrinsic Image Decomposition. ACM Trans. Graph. 34, 4, Article 78 (August 2015), 12 pages. DOI = 10.1145/2766946 http://doi.acm.org/10.1145/2766946. Copyright Notice Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGGRAPH `15 Technical Paper, August 09  13, 2015, Los Angeles, CA. Copyright 2015 ACM 978-1-4503-3331-3/15/08 ... $15.00. DOI: http://doi.acm.org/10.1145/2766946  ", 
        "id": 2047, 
        "title": "An L1 image transform for edge-preserving smoothing and scene-level intrinsic decomposition."
    }, 
    {
        "abstract": "", 
        "id": 2048, 
        "title": "Anisotropic Delaunay Meshes of Surfaces."
    }, 
    {
        "abstract": "We present the first real-time high-fidelity facial capture method. The core idea is to enhance a global real-time face tracker, which provides a low-resolution face mesh, with local regressors that add in medium-scale details, such as expression wrinkles. Our main observation is that although wrinkles appear in different scales and at different locations on the face, they are locally very self-similar and their visual appearance is a direct consequence of their local shape. We therefore train local regressors from high-resolution capture data in order to predict the local geometry from local appearance at runtime. We propose an automatic way to detect and align the local patches required to train the regressors and run them efficiently in real-time. Our formulation is particularly designed to enhance the low-resolution global tracker with exactly the missing expression frequencies, avoiding superimposing spatial frequencies in the result. Our system is generic and can be applied to any real-time tracker that uses a global prior, e.g. blend-shapes. Once trained, our online capture approach can be applied to any new user without additional training, resulting in high-fidelity facial performance reconstruction with person-specific wrinkle details from a monocular video camera in real-time.", 
        "id": 2049, 
        "title": "Real-time high-fidelity facial performance capture."
    }, 
    {
        "abstract": "", 
        "id": 2050, 
        "title": "Hyperspectral Modeling of Skin Appearance."
    }, 
    {
        "abstract": "", 
        "id": 2051, 
        "title": "ImageSpirit: Verbal Guided Image Parsing."
    }, 
    {
        "abstract": "We present a novel explicit surface tracking method. Its main advantage over existing approaches is the fact that it is both completely grid-free and fast which makes it ideal for the use in large unbounded domains. A further advantage is that its running time is less sensitive to temporal variations of the input mesh than existing approaches. In terms of performance, the method provides a good trade-off point between speed and quality. The main idea behind our approach to handle topological changes is to delete all overlapping triangles and to fill or join the resulting holes in a robust and efficient way while guaranteeing that the output mesh is both manifold and without boundary. We demonstrate the flexibility, speed and quality of our method in various applications such as Eulerian and Lagrangian liquid simulations and the simulation of solids under large plastic deformations. ", 
        "id": 2052, 
        "title": "Fast grid-free surface tracking."
    }, 
    {
        "abstract": "We present a framework for the computation of harmonic and conformal mappings in the plane with mathematical guarantees that the computed mappings are C, locally injective and satisfy strict bounds on the conformal and isometric distortion. Such mappings are very desirable in many computer graphics and geometry processing applications. We establish the sufficient and necessary conditions for a harmonic planar mapping to have bounded distortion. Our key observation is that these conditions relate solely to the boundary behavior of the mapping. This leads to an efficient and accurate algorithm that supports handle-based interactive shape-and-image deformation and is demonstrated to outperform other state-of-the-art methods. ", 
        "id": 2053, 
        "title": "Bounded distortion harmonic mappings in the plane."
    }, 
    {
        "abstract": "Conformal deformations are infinitesimal scale-rotations, which can be parameterized by quaternions. The condition that such a quaternion field gives rise to a conformal deformation is nonlinear and in any case only admits Mbius transformations as solutions. We propose a particular decoupling of scaling and rotation which allows us to find near to conformal deformations as minimizers of a quadratic, convex Dirichlet energy. Applied to tetrahedral meshes we find deformations with low quasiconformal distortion as the principal eigenvector of a (quaternionic) Laplace matrix. The resulting algorithms can be implemented with highly optimized standard linear algebra libraries and yield deformations comparable in quality to far more expensive approaches. ", 
        "id": 2054, 
        "title": "Close-to-conformal deformations of volumes."
    }, 
    {
        "abstract": "", 
        "id": 2055, 
        "title": "Beating Shapes Relying on Moir\u00e9 Level Lines."
    }, 
    {
        "abstract": "Dressing is one of the most common activities in human society. Perfecting the skill of dressing can take an average child three to four years of daily practice. The challenge is primarily due to the combined difficulty of coordinating different body parts and manipulating soft and deformable objects (clothes). We present a technique to synthesize human dressing by controlling a human character to put on an article of simulated clothing. We identify a set of primitive actions which account for the vast majority of motions observed in human dressing. These primitive actions can be assembled into a variety of motion sequences for dressing different garments with different styles. Exploiting both feed-forward and feedback control mechanisms, we develop a dressing controller to handle each of the primitive actions. The controller plans a path to achieve the action goal while making constant adjustments locally based on the current state of the simulated cloth when necessary. We demonstrate that our framework is versatile and able to animate dressing with different clothing types including a jacket, a pair of shorts, a robe, and a vest. Our controller is also robust to different cloth mesh resolutions which can cause the cloth simulator to generate significantly different cloth motions. In addition, we show that the same controller can be extended to assistive dressing. ", 
        "id": 2056, 
        "title": "Animating human dressing."
    }, 
    {
        "abstract": "We present the first end-to-end solution to create high-quality freeviewpoint video encoded as a compact data stream. Our system records performances using a dense set of RGB and IR video cameras, generates dynamic textured surfaces, and compresses these to a streamable 3D video format. Four technical advances contribute to high fidelity and robustness: multimodal multi-view stereo fusing RGB, IR, and silhouette information; adaptive meshing guided by automatic detection of perceptually salient areas; mesh tracking to create temporally coherent subsequences; and encoding of tracked textured meshes as an MPEG video stream. Quantitative experiments demonstrate geometric accuracy, texture fidelity, and encoding efficiency. We release several datasets with calibrated inputs and processed results to foster future research. ", 
        "id": 2057, 
        "title": "High-quality streamable free-viewpoint video."
    }, 
    {
        "abstract": "", 
        "id": 2058, 
        "title": "Linear Volumetric Focus for Light Field Cameras."
    }, 
    {
        "abstract": "Recent shape retrieval and interactive modeling algorithms enable the re-use of existing models in many applications. However, most of those techniques require a pre-labeled model with some semantic information. We introduce a fully automatic approach to simultaneously segment and detect similarities within an existing 3D architectural model. Our framework approaches the segmentation problem as a weighted minimum set cover over an input triangle soup, and maximizes the repetition of similar segments to find a best set of unique component types and instances. The solution for this set-cover formulation starts with a search space reduction to eliminate unlikely combinations of triangles, and continues with a combinatorial optimization within each disjoint subspace that outputs the components and their types. We show the discovered components of a variety of architectural models obtained from public databases. We demonstrate experiments testing the robustness of our algorithm, in terms of threshold sensitivity, vertex displacement, and triangulation variations of the original model. In addition, we compare our components with those of competing approaches and evaluate our results against user-based segmentations. We have processed a database of 50 buildings, with various structures and over 200K polygons per building, with a segmentation time averaging up to 4 minutes.", 
        "id": 2059, 
        "title": "Coupled segmentation and similarity detection for architectural models."
    }, 
    {
        "abstract": "Recently, generating a high quality all-hex mesh of a given volume has gained much attention. However, little, if any, effort has been put into the optimization of the hex-mesh structure, which is equally important to the local element quality of a hex-mesh that may influence the performance and accuracy of subsequent computations. In this paper, we present a first and complete pipeline to optimize the global structure of a hex-mesh. Specifically, we first extract the base-complex of a hex-mesh and study the misalignments among its singularities by adapting the previously introduced hexahedral sheets to the base-complex. Second, we identify the valid removal base-complex sheets from the base-complex that contain misaligned singularities. We then propose an effective algorithm to remove these valid removal sheets in order. Finally, we present a structure-aware optimization strategy to improve the geometric quality of the resulting hex-mesh after fixing the misalignments. Our experimental results demonstrate that our pipeline can significantly reduce the number of components of a variety of hex-meshes generated by state-of-the-art methods, while maintaining high geometric quality.", 
        "id": 2060, 
        "title": "Hexahedral mesh re-parameterization from aligned base-complex."
    }, 
    {
        "abstract": "Mesh editing software is improving, allowing skilled artists to create detailed meshes efficiently. For a variety of reasons, artists are interested in sharing not just their final mesh but also their whole workflow, though the common media for sharing has limitations. In this paper, we present 3DFlow, an algorithm that computes continuous summarizations of mesh editing workflows. 3DFlow takes as input a sequence of meshes and outputs a visualization of the workflow summarized at any level of detail. The output is enhanced by highlighting edited regions and, if provided, overlaying visual annotations to indicated the artist's work, e.g. summarizing brush strokes in sculpting. We tested 3DFlow with a large set of inputs using a variety of mesh editing techniques, from digital sculpting to low-poly modeling, and found 3DFlow performed well for all. Furthermore, 3DFlow is independent of the modeling software used because it requires only mesh snapshots, and uses the additional information only for optional overlays. We release 3DFlow as open source for artists to showcase their work and release all our datasets so other researchers can improve upon our work. ", 
        "id": 2061, 
        "title": "3DFlow: continuous summarization of mesh editing workflows."
    }, 
    {
        "abstract": "", 
        "id": 2062, 
        "title": "Synthesis of Complex Image Appearance from Limited Exemplars."
    }, 
    {
        "abstract": "We present a novel measurement-based method for editing the albedo of diffuse surfaces with consistent interreflections in a photograph of a scene under natural lighting. Key to our method is a novel technique for decomposing a photograph of a scene in several images that encode how much of the observed radiance has interacted a specified number of times with the target diffuse surface. Altering the albedo of the target area is then simply a weighted sum of the decomposed components. We estimate the interaction components by recursively applying the light transport operator and formulate the resulting radiance in each recursion as a linear expression in terms of the relevant interaction components. Our method only requires a camera-projector pair, and the number of required measurements per scene is linearly proportional to the decomposition degree for a single target area. Our method does not impose restrictions on the lighting or on the material properties in the unaltered part of the scene. Furthermore, we extend our method to accommodate editing of the albedo in multiple target areas with consistent interreflections and we introduce a prediction model for reducing the acquisition cost. We demonstrate our method on a variety of scenes and validate the accuracy on both synthetic and real examples. ", 
        "id": 2063, 
        "title": "Measurement-based editing of diffuse albedo with consistent interreflections."
    }, 
    {
        "abstract": "Several techniques exist to automatically synthesize a 2D image resembling an input exemplar texture. Most of the approaches optimize a new image so that the color neighborhoods in the output closely match those in the input, across all scales. In this paper we revisit by-example texture synthesis in the context of additive manufacturing. Our goal is to generate not only colors, but also structure along output surfaces: given an exemplar indicating 'solid' and 'empty' pixels, we generate a similar pattern along the output surface. The core challenge is to guarantee that the pattern is not only fully connected, but also structurally sound. To achieve this goal we propose a novel formulation for on-surface by-example texture synthesis that directly works in a voxel shell around the surface. It enables efficient local updates to the pattern, letting our structural optimizer perform changes that improve the overall rigidity of the pattern. We use this technique in an iterative scheme that jointly optimizes for appearance and structural soundness. We consider fabricability constraints and a user-provided description of a force profile that the object has to resist. Our results fully exploit the capabilities of additive manufacturing by letting users design intricate structures along surfaces. The structures are complex, yet they resemble input exemplars, resulting in a modeling tool accessible to casual users.  ", 
        "id": 2064, 
        "title": "By-example synthesis of structurally sound patterns."
    }, 
    {
        "abstract": " Zoomorphic shapes are man-made shapes that possess the form or appearance of an animal. They have desirable aesthetic properties, but are difficult to create using conventional modeling tools. We present a method for creating zoomorphic shapes by merging a man-made shape and an animal shape. To identify a pair of shapes that are suitable for merging, we use an efficient graph kernel based technique. We formulate the merging process as a continuous optimization problem where the two shapes are deformed jointly to minimize an energy function combining several design factors. The modeler can adjust the weighting between these factors to attain high-level control over the final shape produced. A novel technique ensures that the zoomorphic shape does not violate the design restrictions of the man-made shape. We demonstrate the versatility and effectiveness of our approach by generating a wide variety of zoomorphic shapes. ", 
        "id": 2065, 
        "title": "Zoomorphic design."
    }, 
    {
        "abstract": "We present a novel approach for the interactive synthesis and editing of virtual worlds. Our method is inspired by painting operations and uses methods for statistical example-based synthesis to automate content synthesis and deformation. Our real-time approach takes a form of local inverse procedural modeling based on intermediate statistical models: selected regions of procedurally and manually constructed example scenes are analyzed, and their parameters are stored as distributions in a palette, similar to colors on a painters palette. These distributions can then be interactively applied with brushes and combined in various ways, like in painting systems. Selected regions can also be moved or stretched while maintaining the consistency of their content. Our method captures both distributions of elements and structured objects, and models their interactions. Results range from the interactive editing of 2D artwork maps to the design of 3D virtual worlds, where constraints set by the terrains slope are also taken into account. ", 
        "id": 2066, 
        "title": "WorldBrush: interactive example-based synthesis of procedural virtual worlds."
    }, 
    {
        "abstract": "", 
        "id": 2067, 
        "title": "Smoothed Quadratic Energies on Meshes."
    }, 
    {
        "abstract": "", 
        "id": 2068, 
        "title": "Dehazing Using Color-Lines."
    }, 
    {
        "abstract": "Image editing applications offer a wide array of tools for color manipulation. Some of these tools are easy to understand but offer a limited range of expressiveness. Other more powerful tools are time consuming for experts and inscrutable to novices. Researchers have described a variety of more sophisticated methods but these are typically not interactive, which is crucial for creative exploration. This paper introduces a simple, intuitive and interactive tool that allows non-experts to recolor an image by editing a color palette. This system is comprised of several components: a GUI that is easy to learn and understand, an efficient algorithm for creating a color palette from an image, and a novel color transfer algorithm that recolors the image based on a user-modified palette. We evaluate our approach via a user study, showing that it is faster and easier to use than two alternatives, and allows untrained users to achieve results comparable to those of experts using professional software. ", 
        "id": 2069, 
        "title": "Palette-based photo recoloring."
    }, 
    {
        "abstract": "We present a unified computational approach for taking photos through reflecting or occluding elements such as windows and fences. Rather than capturing a single image, we instruct the user to take a short image sequence while slightly moving the camera. Differences that often exist in the relative position of the background and the obstructing elements from the camera allow us to separate them based on their motions, and to recover the desired background scene as if the visual obstructions were not there. We show results on controlled experiments and many real and practical scenarios, including shooting through reflections, fences, and raindrop-covered windows.", 
        "id": 2070, 
        "title": "A computational approach for obstruction-free photography."
    }, 
    {
        "abstract": "", 
        "id": 2071, 
        "title": "Directional Dipole Model for Subsurface Scattering."
    }, 
    {
        "abstract": "Figure 1: 2D mesh deformation: comparison with the state-of-the-art methods. The input mesh T is triangulated from a 2D regular quadrilateral mesh, and an interior handle is movedfrom the right side to the left side while fixing all the boundary vertices. Left to right: deformation results from our AMIPS method, bounded distortion mapping [Lipman 2012], locally injective mapping [Schuller et al. 2013] and the strict minimizer [Levi and Zorin 2014]. Our method achieves the lowest maximal isometric distortion 8isomaX = maxtT max{0-1 1,t, 02,t } among all the methods with the least computation time, where 01,t and 02,t (01,t  02,t) are singular values of the Jacobian of the mapping associated with triangle t. Our method also achieves more evenly and smoothly distributed distortion (see the standard deviation of the isometric distortion 8iso dev). The color on triangles encodes the isometric distortion, with white being optimal. Abstract Computing locally injective mappings with low distortion in an efficient way is a fundamental task in computer graphics. By revisiting the well-known MIPS (Most-Isometric ParameterizationS) method, we introduce an advanced MIPS method that inherits the local injectivity of MIPS, achieves as low as possible distortions compared to the state-of-the-art locally injective mapping techniques, and performs one to two orders of magnitude faster in computing a mesh-based mapping. The success of our method relies on two key components. The first one is an enhanced MIPS energy function that penalizes the maximal distortion significantly and distributes the distortion evenly over the domain for both mesh-based and mesh-less mappings. The second is a use of the inexact block coordinate descent method in mesh-based mapping in a way that efficiently minimizes the distortion with the capability not to be trapped early by the local minimum. We demonstrate the capability and superiority of our method in various applications including mesh parameterization, mesh-based and meshless deformation, and mesh improvement.", 
        "id": 2072, 
        "title": "Computing locally injective mappings by advanced MIPS."
    }, 
    {
        "abstract": "Furniture typically consists of assemblies of elongated and planar parts that are connected together by glue, nails, hinges, screws, or other means that do not encourage disassembly and re-assembly. An alternative approach is to use an interlocking mechanism, where the component parts tightly interlock with one another. The challenge in designing such a network of interlocking joints is that local analysis is insufficient to guarantee global interlocking, and there is a huge number of joint combinations that require an enormous exploration effort to ensure global interlocking. In this paper, we present a computational solution to support the design of a network of interlocking joints that form a globally-interlocking furniture assembly. The key idea is to break the furniture complex into an overlapping set of small groups, where the parts in each group are immobilized by a local key, and adjacent groups are further locked with dependencies. The dependency among the groups saves the effort of exploring the immobilization of every subset of parts in the assembly, thus allowing the intensive interlocking computation to be localized within each small group. We demonstrate the effectiveness of our technique on many globally-interlocking furniture assemblies of various shapes and complexity. ", 
        "id": 2073, 
        "title": "Computational interlocking furniture assembly."
    }, 
    {
        "abstract": "", 
        "id": 2074, 
        "title": "Driving High-Resolution Facial Scans with Video Performance Capture."
    }, 
    {
        "abstract": " We present a computational imaging system, inspired by the optical coherence tomography (OCT) framework, that uses interferometry to produce decompositions of light transport in small scenes or volumes. The system decomposes transport according to various attributes of the paths that photons travel through the scene, including where on the source the paths originate, their pathlengths from source to camera through the scene, their wavelength, and their polarization. Since it uses interference, the system can achieve high pathlength resolutions, with the ability to distinguish paths whose lengths differ by as little as ten microns. We describe how to construct and optimize an optical assembly for this technique, and we build a prototype to measure and visualize three-dimensional shape, direct and indirect reflection components, and properties of scattering, refractive/dispersive, and birefringent materials.  ", 
        "id": 2075, 
        "title": "Micron-scale light transport decomposition using interferometry."
    }, 
    {
        "abstract": "This paper introduces a new particle-based approach to incompressible fluid simulation. We depart from previous Lagrangian methods by considering fluid particles no longer purely as material points, but also as volumetric parcels that partition the fluid domain. The fluid motion is described as a time series of well-shaped power diagrams (hence the name power particles), offering evenly spaced particles and accurate pressure computations. As a result, we circumvent the typical excess damping arising from kernel-based evaluations of internal forces or density without having recourse to auxiliary Eulerian grids. The versatility of our solver is demonstrated by the simulation of multiphase flows and free surfaces. ", 
        "id": 2076, 
        "title": "Power particles: an incompressible fluid solver based on power diagrams."
    }, 
    {
        "abstract": " ", 
        "id": 2077, 
        "title": "Double bubbles sans toil and trouble: discrete circulation-preserving vortex sheets for soap films and foams."
    }, 
    {
        "abstract": " We present a space-time abstraction for the sketch-based design of character animation. It allows animators to draft a full coordinated motion using a single stroke called the space-time curve (STC). From the STC we compute a dynamic line of action (DLOA) that drives the motion of a 3D character through projective constraints. Our dynamic models for the line's motion are entirely geometric, require no pre-existing data, and allow full artistic control. The resulting DLOA can be refined by over-sketching strokes along the space-time curve, or by composing another DLOA on top leading to control over complex motions with few strokes. Additionally, the resulting dynamic line of action can be applied to arbitrary body parts or characters. To match a 3D character to the 2D line over time, we introduce a robust matching algorithm based on closed-form solutions, yielding a tight match while allowing squash and stretch of the character's skeleton. Our experiments show that space-time sketching has the potential of bringing animation design within the reach of beginners while saving time for skilled artists.  ", 
        "id": 2078, 
        "title": "Space-time sketching of character animation."
    }, 
    {
        "abstract": " ", 
        "id": 2079, 
        "title": "High-resolution brittle fracture simulation with boundary elements."
    }, 
    {
        "abstract": "", 
        "id": 2080, 
        "title": "Iterative Training of Dynamic Skills Inspired by Human Coaching Techniques."
    }, 
    {
        "abstract": "We present a novel, general-purpose Model-Predictive Control (MPC) algorithm that we call Control Particle Belief Propagation (C-PBP). C-PBP combines multimodal, gradient-free sampling and a Markov Random Field factorization to effectively perform simultaneous path finding and smoothing in high-dimensional spaces. We demonstrate the method in online synthesis of interactive and physically valid humanoid movements, including balancing, recovery from both small and extreme disturbances, reaching, balancing on a ball, juggling a ball, and fully steerable locomotion in an environment with obstacles. Such a large repertoire of movements has not been demonstrated before at interactive frame rates, especially considering that all our movement emerges from simple cost functions. Furthermore, we abstain from using any precomputation to train a control policy offline, reference data such as motion capture clips, or state machines that break the movements down into more manageable subtasks. Operating under these conditions enables rapid and convenient iteration when designing the cost functions.", 
        "id": 2081, 
        "title": "Online control of simulated humanoids using particle belief propagation."
    }, 
    {
        "abstract": "We present a method for controlling the output of procedural modeling programs using Sequential Monte Carlo (SMC). Previous probabilistic methods for controlling procedural models use Markov Chain Monte Carlo (MCMC), which receives control feedback only for completely-generated models. In contrast, SMC receives feedback incrementally on incomplete models, allowing it to reallocate computational resources and converge quickly. To handle the many possible sequentializations of a structured, recursive procedural modeling program, we develop and prove the correctness of a new SMC variant, Stochastically-Ordered Sequential Monte Carlo (SOSMC). We implement SOSMC for general-purpose programs using a new programming primitive: the stochastic future. Finally, we show that SOSMC reliably generates high-quality outputs for a variety of programs and control scoring functions. For small computational budgets, SOSMCs outputs often score nearly twice as high as those of MCMC or normal SMC.", 
        "id": 2082, 
        "title": "Controlling procedural modeling programs with stochastically-ordered sequential Monte Carlo."
    }, 
    {
        "abstract": "Over the last few years, depth cameras have become increasingly popular for a range of applications, including human-computer interaction and gaming, augmented reality, machine vision, and medical imaging. Many of the commercially-available devices use the time-of-flight principle, where active illumination is temporally coded and analyzed in the camera to estimate a per-pixel depth map of the scene. In this paper, we propose a fundamentally new imaging modality for all time-of-flight (ToF) cameras: per-pixel radial velocity measurement. The proposed technique exploits the Doppler effect of objects in motion, which shifts the temporal illumination frequency before it reaches the camera. Using carefully coded illumination and modulation frequencies of the ToF camera, object velocities directly map to measured pixel intensities. We show that a slight modification of our imaging system allows for color, depth, and velocity information to be captured simultaneously. Combining the optical flow computed on the RGB frames with the measured metric radial velocity allows us to further estimate the full 3D metric velocity field of the scene. The proposed technique has applications in many computer graphics and vision problems, for example motion tracking, segmentation, recognition, and motion deblurring.", 
        "id": 2083, 
        "title": "Doppler time-of-flight imaging."
    }, 
    {
        "abstract": "Figure 1: Top-left: rendering a voxelized forest at decreasing levels of detail (left to right). Bottom-right: visualization of the voxel structure at the matching resolutions. We use the SGGX microflake distribution to represent volumetric anisotropic materials. Our representation supports downscaling and interpolation, resulting in smooth and antialiased renderings at multiple scales. Abstract We introduce the Symmetric GGX (SGGX) distribution to represent spatially-varying properties of anisotropic microflake participating media. Our key theoretical insight is to represent a microflake distribution by the projected area of the microflakes. We use the projected area to parameterize the shape of an ellipsoid, from which we recover a distribution of normals. The representation based on the projected area allows for robust linear interpolation and prefiltering, and thanks to its geometric interpretation, we derive closed form expressions for all operations used in the microflake framework. We also incorporate microflakes with diffuse reflectance in our theoretical framework. This allows us to model the appearance of rough diffuse materials in addition to rough specular materials. Finally, we use the idea of sampling the distribution of visible normals to design a perfect importance sampling technique for our SGGX microflake phase functions. It is analytic, deterministic, simple to implement, and one order of magnitude faster than previous work.", 
        "id": 2084, 
        "title": "The SGGX microflake distribution."
    }, 
    {
        "abstract": "", 
        "id": 2085, 
        "title": "Robust Simulation of Sparsely Sampled Thin Features in SPH-Based Free Surface Flows."
    }, 
    {
        "abstract": "Over the last few years, virtual reality (VR) has re-emerged as a technology that is now feasible at low cost via inexpensive cellphone components. In particular, advances of high-resolution micro displays, low-latency orientation trackers, and modern GPUs facilitate immersive experiences at low cost. One of the remaining challenges to further improve visual comfort in VR experiences is the vergence-accommodation conflict inherent to all stereoscopic displays. Accurate reproduction of all depth cues is crucial for visual comfort. By combining well-known stereoscopic display principles with emerging factored light field technology, we present the first wearable VR display supporting high image resolution as well as focus cues. A light field is presented to each eye, which provides more natural viewing experiences than conventional near-eye displays. Since the eye box is just slightly larger than the pupil size, rank-1 light field factorizations are sufficient to produce correct or nearly-correct focus cues; no time-multiplexed image display or gaze tracking is required. We analyze lens distortions in 4D light field space and correct them using the afforded high-dimensional image formation. We also demonstrate significant improvements in resolution and retinal blur quality over related near-eye displays. Finally, we analyze diffraction limits of these types of displays. ACM Reference Format Huang, F., Chen, K., Wetzstein, G. 2015. The Light Field Stereoscope: Immersive Computer Graphics via Factored Near-Eye Light Field Display with Focus Cues. ACM Trans. Graph. 34, 4, Article 60 (August 2015), 12 pages. DOI = 10.1145/2766922 http://doi.acm.org/10.1145/2766922. Copyright Notice Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGGRAPH `15 Technical Paper, August 09  13, 2015, Los Angeles, CA. Copyright is held by the owner/author(s). Publication rights licensed to ACM. ACM 978-1-4503-3331-3/15/08 ... $15.00. DOI: http://dx.doi.org/10.1145/2766922  ", 
        "id": 2086, 
        "title": "The light field stereoscope: immersive computer graphics via factored near-eye light field displays with focus cues."
    }, 
    {
        "abstract": "", 
        "id": 2087, 
        "title": "Hybrid Skeletal-Surface Motion Graphs for Character Animation from 4D Performance Capture."
    }, 
    {
        "abstract": "We present an approach to automatic 3D reconstruction of objects depicted in Web images. The approach reconstructs objects from single views. The key idea is to jointly analyze a collection of images of different objects along with a smaller collection of existing 3D models. The images are analyzed and reconstructed together. Joint analysis regularizes the formulated optimization problems, stabilizes correspondence estimation, and leads to reasonable reproduction of object appearance without traditional multi-view cues. ", 
        "id": 2088, 
        "title": "Single-view reconstruction via joint analysis of image and shape collections."
    }, 
    {
        "abstract": "Human hair presents highly convoluted structures and spans an extraordinarily wide range of hairstyles, which is essential for the digitization of compelling virtual avatars but also one of the most challenging to create. Cutting-edge hair modeling techniques typically rely on expensive capture devices and significant manual labor. We introduce a novel data-driven framework that can digitize complete and highly complex 3D hairstyles from a single-view photograph. We first construct a large database of manually crafted hair models from several online repositories. Given a reference photo of the target hairstyle and a few user strokes as guidance, we automatically search for multiple best matching examples from the database and combine them consistently into a single hairstyle to form the large-scale structure of the hair model. We then synthesize the final hair strands by jointly optimizing for the projected 2D similarity to the reference photo, the physical plausibility of each strand, as well as the local orientation coherency between neighboring strands. We demonstrate the effectiveness and robustness of our method on a variety of hairstyles and challenging images, and compare our system with state-of-the-art hair modeling algorithms. ", 
        "id": 2089, 
        "title": "Single-view hair modeling using a hairstyle database."
    }, 
    {
        "abstract": "We introduce a contextual descriptor which aims to provide a geometric description of the functionality of a 3D object in the context of a given scene. Differently from previous works, we do not regard functionality as an abstract label or represent it implicitly through an agent. Our descriptor, called interaction context or ICON for short, explicitly represents the geometry of object-to-object interactions. Our approach to object functionality analysis is based on the key premise that functionality should mainly be derived from interactions between objects and not objects in isolation. Specifically, ICON collects geometric and structural features to encode interactions between a central object in a 3D scene and its surrounding objects. These interactions are then grouped based on feature similarity, leading to a hierarchical structure. By focusing on interactions and their organization, ICON is insensitive to the numbers of objects that appear in a scene, the specific disposition of objects around the central object, or the objects' fine-grained geometry. With a series of experiments, we demonstrate the potential of ICON in functionality-oriented shape processing, including shape retrieval (either directly or by complementing existing shape descriptors), segmentation, and synthesis. ", 
        "id": 2090, 
        "title": "Interaction context (ICON): towards a geometric functionality descriptor."
    }, 
    {
        "abstract": "", 
        "id": 2091, 
        "title": "BendFields: Regularized Curvature Fields from Rough Concept Sketches."
    }, 
    {
        "abstract": "We present a complete pipeline for creating fully rigged, personalized 3D facial avatars from hand-held video. Our system faithfully recovers facial expression dynamics of the user by adapting a blend-shape template to an image sequence of recorded expressions using an optimization that integrates feature tracking, optical flow, and shape from shading. Fine-scale details such as wrinkles are captured separately in normal maps and ambient occlusion maps. From this userand expression-specific data, we learn a regressor for on-the-fly detail synthesis during animation to enhance the perceptual realism of the avatars. Our system demonstrates that the use of appropriate reconstruction priors yields compelling face rigs even with a minimalistic acquisition system and limited user assistance. This facilitates a range of new applications in computer animation and consumer-level online communication based on personalized avatars. We present realtime application demos to validate our method.", 
        "id": 2092, 
        "title": "Dynamic 3D avatar creation from hand-held video input."
    }, 
    {
        "abstract": "Recent digital fabrication tools have opened up accessibility to personalized rapid prototyping; however, such tools are limited to product-scale objects. The materials currently available for use in 3D printing are too fine for large-scale objects, and CNC gantry sizes limit the scope of printable objects. In this paper, we propose a new method for printing architecture-scale objects. Our proposal includes three developments: (i) a construction material consisting of chopsticks and glue, (ii) a handheld chopstick dispenser, and (iii) a printing guidance system that uses projection mapping. The proposed chopstickglue material is cost effective, environmentally sustainable, and can be printed more quickly than conventional materials. The developed handheld dispenser enables consistent feeding of the chopstickglue material composite. The printing guidance system  consisting of a depth camera and a projector  evaluates a given shape in real time and indicates where humans should deposit chopsticks by projecting a simple color code onto the form under construction. Given the mechanical specifications of the stickglue composite, an experimental pavilion was designed as a case study of the proposed method and built without scaffoldings and formworks. The case study also revealed several fundamental limitations, such as the projector does not work in daylight, which requires future investigations. ", 
        "id": 2093, 
        "title": "Architecture-scale human-assisted additive manufacturing."
    }, 
    {
        "abstract": "(a) Input geomertry (b) Airy stress function (c) Self-supporting surface Figure 1: An Airy stress function is directly computed by the proposed computational approach to self-supporting surfaces. Abstract This paper presents a method that employs parametric surfaces as surface geometry representations at any stage of a computational process to compute self-supporting surfaces. This approach can be differentiated from existing relevant methods because such methods represent surfaces by a triangulated mesh surface or a network consisting of lines. The proposed method is based on the theory of Airy stress functions. Although some existing methods are also based on this theory, they apply its discrete version to discrete geometries. The proposed method simultaneously applies the theory to parametric surfaces directly and the discrete theory to the edges of parametric patches. The discontinuous boundary between continuous patches naturally corresponds to ribs seen in traditional vault masonry buildings. We use nonuniform rational B-spline surfaces in this study; however, the basic idea can be applied to other parametric surfaces. A variety of self-supporting surfaces obtained by the proposed computational scheme is presented.", 
        "id": 2094, 
        "title": "Parametric self-supporting surfaces via direct computation of airy stress functions."
    }, 
    {
        "abstract": "", 
        "id": 2095, 
        "title": "Simulating the Visual Experience of Very Bright and Very Dark Scenes."
    }, 
    {
        "abstract": "Figure 1: Our linear subspaces are very fast to compute. This enables the users to add (or remove) control handles very quickly, allowing them to realize their creative intent in a single interactive session. Abstract We propose a method to design linear deformation subspaces, unifying linear blend skinning and generalized barycentric coordinates. Deformation subspaces cut down the time complexity of variational shape deformation methods and physics-based animation (reduced-order physics). Our subspaces feature many desirable properties: interpolation, smoothness, shape-awareness, locality, and both constant and linear precision. We achieve these by minimizing a quadratic deformation energy, built via a discrete Laplacian inducing linear precision on the domain boundary. Our main advantage is speed: subspace bases are solutions to a sparse linear system, computed interactively even for generously tessellated domains. Users may seamlessly switch between applying transformations at handles and editing the subspace by adding, removing or relocating control handles. The combination of fast computation and good properties means that designing the right subspace is now just as creative as manipulating handles. This paradigm shift in handle-based deformation opens new opportunities to explore the space of shape deformations.", 
        "id": 2096, 
        "title": "Linear subspace design for real-time shape deformation."
    }, 
    {
        "abstract": "", 
        "id": 2097, 
        "title": "Gaze-Driven Video Re-Editing."
    }, 
    {
        "abstract": "", 
        "id": 2098, 
        "title": "Water Wave Animation via Wavefront Parameter Interpolation."
    }, 
    {
        "abstract": "This paper presents a new technique for frame field generation. As generic frame fields (with arbitrary anisotropy, orientation, and sizing) can be regarded as cross fields in a specific Riemannian metric, we tackle frame field design by first computing a discrete metric on the input surface that is compatible with a sparse or dense set of input constraints. The final frame field is then found by computing an optimal cross field in this customized metric. We propose frame field design constraints on alignment, size, and skewness at arbitrary locations on the mesh as well as along feature curves, offering much improved flexibility over previous approaches. We demonstrate the advantages of our frame field generation through the automatic quadrangulation of man-made and organic shapes with controllable anisotropy, robust handling of narrow surface strips, and precise feature alignment. We also extend our technique to the design of n-vector fields.", 
        "id": 2099, 
        "title": "Frame field generation through metric customization."
    }, 
    {
        "abstract": "Hybrid Lagrangian/Eulerian simulation is commonplace in computer graphics for fluids and other materials undergoing large deformation. In these methods, particles are used to resolve transport and topological change, while a background Eulerian grid is used for computing mechanical forces and collision responses. Particle-in-Cell (PIC) techniques, particularly the Fluid Implicit Particle (FLIP) variants have become the norm in computer graphics calculations. While these approaches have proven very powerful, they do suffer from some well known limitations. The original PIC is stable, but highly dissipative, while FLIP, designed to remove this dissipation, is more noisy and at times, unstable. We present a novel technique designed to retain the stability of the original PIC, without suffering from the noise and instability of FLIP. Our primary observation is that the dissipation in the original PIC results from a loss of information when transferring between grid and particle representations. We prevent this loss of information by augmenting each particle with a locally affine, rather than locally constant, description of the velocity. We show that this not only stably removes the dissipation of PIC, but that it also allows for exact conservation of angular momentum across the transfers between particles and grid.", 
        "id": 2100, 
        "title": "The affine particle-in-cell method."
    }, 
    {
        "abstract": "Figure 1: Hand-held videos often exhibit significant semi-regular high-frequency camera motion due to, for example, running (dotted blue line). This example shows how a naive 8x hyperlapse (i.e., keeping 1 out every 8 frames) results in frames with little overlap that are hard to align (black lines). By allowing small violations of the target skip rate we create hyperlapse videos that are smooth even when there is significant camera motion (pink lines). Optimizing an energy function (color-coded in Middle image) that balances matching the target rate while minimizing frame-to-frame motion results in a set offrames that are then stabilized. (Right) To illustrate the alignment we show the mean and standard deviation of three successive frames (in red box on the Left plot) after stabilization for the naive hyperlapse (Top Right) and our result (Bottom Right)  these show that our selected frames align much better than those from naive selection. Abstract Long videos can be played much faster than real-time by recording only one frame per second or by dropping all but one frame each second, i.e., by creating a timelapse. Unstable hand-held moving videos can be stabilized with a number of recently described methods. Unfortunately, creating a stabilized timelapse, or hyperlapse, cannot be achieved through a simple combination of these two methods. Two hyperlapse methods have been previously demonstrated: one with high computational complexity and one requiring special sensors. We present an algorithm for creating hyperlapse videos that can handle significant high-frequency camera motion and runs in real-time on HD video. Our approach does not require sensor data, thus can be run on videos captured on any camera. We optimally select frames from the input video that best match a desired target speed-up while also resulting in the smoothest possible camera motion. We evaluate our approach using several input videos from a range of cameras and compare these results to existing methods.", 
        "id": 2101, 
        "title": "Real-time hyperlapse creation via optimal frame selection."
    }, 
    {
        "abstract": "", 
        "id": 2102, 
        "title": "Shape Segmentation by Approximate Convexity Analysis."
    }, 
    {
        "abstract": "The most successful approaches for filtering Monte Carlo noise use feature-based filters (e.g., cross-bilateral and cross non-local means filters) that exploit additional scene features such as world positions and shading normals. However, their main challenge is finding the optimal weights for each feature in the filter to reduce noise but preserve scene detail. In this paper, we observe there is a complex relationship between the noisy scene data and the ideal filter parameters, and propose to learn this relationship using a nonlinear regression model. To do this, we use a multilayer perceptron neural network and combine it with a matching filter during both training and testing. To use our framework, we first train it in an offline process on a set of noisy images of scenes with a variety of distributed effects. Then at run-time, the trained network can be used to drive the filter parameters for new scenes to produce filtered images that approximate the ground truth. We demonstrate that our trained network can generate filtered images in only a few seconds that are superior to previous approaches on a wide range of distributed effects such as depth of field, motion blur, area lighting, glossy reflections, and global illumination. ", 
        "id": 2103, 
        "title": "A machine learning approach for filtering Monte Carlo noise."
    }, 
    {
        "abstract": "We introduce gradient-domain rendering for Monte Carlo image synthesis. While previous gradient-domain Metropolis Light Transport sought to distribute more samples in areas of high gradients, we show, in contrast, that estimating image gradients is also possible using standard (non-Metropolis) Monte Carlo algorithms, and furthermore, that even without changing the sample distribution, this often leads to significant error reduction. This broadens the applicability of gradient rendering considerably. To gain insight into the conditions under which gradient-domain sampling is beneficial, we present a frequency analysis that compares Monte Carlo sampling of gradients followed by Poisson reconstruction to traditional Monte Carlo sampling. Finally, we describe Gradient-Domain Path Tracing (G-PT), a relatively simple modification of the standard path tracing algorithm that can yield far superior results. ", 
        "id": 2104, 
        "title": "Gradient-domain path tracing."
    }, 
    {
        "abstract": "Many compelling video processing effects can be achieved if perpixel depth information and 3D camera calibrations are known. However, the success of such methods is highly dependent on the accuracy of this \"scene-space\" information. We present a novel, sampling-based framework for processing video that enables highquality scene-space video effects in the presence of inevitable errors in depth and camera pose estimation. Instead of trying to improve the explicit 3D scene representation, the key idea of our method is to exploit the high redundancy of approximate scene information that arises due to most scene points being visible multiple times across many frames of video. Based on this observation, we propose a novel pixel gathering and filtering approach. The gathering step is general and collects pixel samples in scene-space, while the filtering step is application-specific and computes a desired output video from the gathered sample sets. Our approach is easily parallelizable and has been implemented on GPU, allowing us to take full advantage of large volumes of video data and facilitating practical runtimes on HD video using a standard desktop computer. Our generic scene-space formulation is able to comprehensively describe a multitude of video processing applications such as denoising, deblurring, super resolution, object removal, computational shutter functions, and other scene-space camera effects. We present results for various casually captured, hand-held, moving, compressed, monocular videos depicting challenging scenes recorded in uncontrolled environments. ACM Reference Format Klose, F., Wang, O., Bazin, J., Magnor, M., Sorkine-Hornung, A. 2015. Sampling Based Scene-space Video Processing. ACM Trans. Graph. 34, 4, Article 67 (August 2015), 11 pages. DOI = 10.1145/2766920 http://doi.acm.org/10.1145/2766920. Copyright Notice Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGGRAPH `15 Technical Paper, August 09  13, 2015, Los Angeles, CA. Copyright is held by the owner/author(s). Publication rights licensed to ACM. ACM 978-1-4503-3331-3/15/08 ... $15.00. DOI: http://dx.doi.org/10.1145/2766920  ", 
        "id": 2105, 
        "title": "Sampling based scene-space video processing."
    }, 
    {
        "abstract": "Stripe patterns are ubiquitous in nature, describing macroscopic phenomena such as stripes on plants and animals, down to material impurities on the atomic scale. We propose a method for synthesizing stripe patterns on triangulated surfaces, where singularities are automatically inserted in order to achieve userspecified orientation and line spacing. Patterns are characterized as global minimizers of a convex-quadratic energy which is welldefined in the smooth setting. Computation amounts to finding the principal eigenvector of a symmetric positive-definite matrix with the same sparsity as the standard graph Laplacian. The resulting patterns are globally continuous, and can be applied to a variety of tasks in design and texture synthesis. ", 
        "id": 2106, 
        "title": "Stripe patterns on surfaces."
    }, 
    {
        "abstract": "1Princeton University 2Adobe Research (a) Ignoring style compatibility (b) Optimizing style compatibility Figure 1: This paper proposes a method to learn a metric for stylistic compatibility between furniture in a scene. (a) The image on the left shows a plausible furniture arrangement, but with a randomly chosen mix of clashing furniture styles. The scene on the right has the same arrangement but with furniture pieces chosen to optimize stylistic compatibility according to our metric. Abstract This paper presents a method for learning to predict the stylistic compatibility between 3D furniture models from different object classes: e.g., how well does this chair go with that table? To do this, we collect relative assessments of style compatibility using crowdsourcing. We then compute geometric features for each 3D model and learn a mapping of them into a space where Euclidean distances represent style incompatibility. Motivated by the geometric subtleties of style, we introduce part-aware geometric feature vectors that characterize the shapes of different parts of an object separately. Motivated by the need to compute style compatibility between different object classes, we introduce a method to learn object class-specific mappings from geometric features to a shared feature space. During experiments with these methods, we find that they are effective at predicting style compatibility agreed upon by people. We find in user studies that the learned compatibility metric is useful for novel interactive tools that: 1) retrieve stylistically compatible models for a query, 2) suggest a piece of furniture for an existing scene, and 3) help guide an interactive 3D modeler towards scenes with compatible furniture.", 
        "id": 2107, 
        "title": "Style compatibility for 3D furniture models."
    }, 
    {
        "abstract": "Good icons are legible, and legible icons are scale-dependent. Experienced icon designers use a set of common strategies to create legible scale variations of icons, but executing those strategies with current tools can be challenging. In part, this is because many apparent objects, like hairlines formed by negative space, are not explicitly represented as objects in vector drawings. We present transient widgets as a mechanism for selecting and manipulating apparent objects that is independent of the underlying drawing representation. We implement transient widgets using a constraintbased editing framework; demonstrate their utility for performing the kinds of edits most common when producing scale variations of icons; and report qualitative feedback on the system from professional icon designers. ", 
        "id": 2108, 
        "title": "Lillicon: using transient widgets to create scale variations of icons."
    }, 
    {
        "abstract": "", 
        "id": 2109, 
        "title": "A Light Transport Framework for Lenslet Light Field Cameras."
    }, 
    {
        "abstract": " We introduce music-driven video montage, a media format that offers a pleasant way to browse or summarize video clips collected from various occasions, including gatherings and adventures. In music-driven video montage, the music drives the composition of the video content. According to musical movement and beats, video clips are organized to form a montage that visually reflects the experiential properties of the music. Nonetheless, it takes enormous manual work and artistic expertise to create it. In this paper, we develop a framework for automatically generating music-driven video montages. The input is a set of video clips and a piece of background music. By analyzing the music and video content, our system extracts carefully designed temporal features from the input, and casts the synthesis problem as an optimization and solves the parameters through Markov Chain Monte Carlo sampling. The output is a video montage whose visual activities are cut and synchronized with the rhythm of the music, rendering a symphony of audio-visual resonance.  Figure 1: Given a set of video clips and a piece of music, our system analyzes the video and music content, and produces a video montage that \"dances\" to the beat of the music.  ", 
        "id": 2110, 
        "title": "audeosynth: music-driven video montage."
    }, 
    {
        "abstract": " We introduce the foldabilization problem for space-saving furniture design. Namely, given a 3D object representing a piece of furniture, our goal is to apply a minimum amount of modification to the object so that it can be folded to save space -- the object is thus foldabilized. We focus on one instance of the problem where folding is with respect to a prescribed folding direction and allowed object modifications include hinge insertion and part shrinking. We develop an automatic algorithm for foldabilization by formulating and solving a nested optimization problem operating at two granularity levels of the input shape. Specifically, the input shape is first partitioned into a set of integral folding units. For each unit, we construct a graph which encodes conflict relations, e.g., collisions, between foldings implied by various patch foldabilizations within the unit. Finding a minimum-cost foldabilization with a conflictfree folding is an instance of the maximum-weight independent set problem. In the outer loop of the optimization, we process the folding units in an optimized ordering where the units are sorted based on estimated foldabilization costs. We show numerous foldabilization results computed at interactive speed and 3D-print physical prototypes of these results to demonstrate manufacturability.  Figure 1: Two automatic foldabilizations of a chair with respect to two folding directions. Shown on the right are fabrication results produced by a MakerBot Replicator II 3D printer. Folding is possible by adding hinges, shrinking parts (chair back in the top row), or allowing slanting or shearing, leading to less hinges and better structural soundness (bottom right). The foldable chair in the top row resembles the Stitch Chair by the designer Adam Goodrum.  ", 
        "id": 2111, 
        "title": "Foldabilizing furniture."
    }, 
    {
        "abstract": "", 
        "id": 2112, 
        "title": "Spectral Quadrangulation with Feature Curve Alignment and Element Size Control."
    }, 
    {
        "abstract": " Control, Virtual Camera Interpolation  A large range of computer graphics applications such as data visualization or virtual movie production require users to position and move viewpoints in 3D scenes to effectively convey visual information or tell stories. The desired viewpoints and camera paths are required to satisfy a number of visual properties (e.g. size, vantage angle, visibility, and on-screen position of targets). Yet, existing camera manipulation tools only provide limited interaction methods and automated techniques remain computationally expensive. In this work, we introduce the Toric space, a novel and compact representation for intuitive and efficient virtual camera control. We first show how visual properties are expressed in this Toric space and propose an efficient interval-based search technique for automated viewpoint computation. We then derive a novel screen-space manipulation technique that provides intuitive and real-time control of visual properties. Finally, we propose an effective viewpoint interpolation technique which ensures the continuity of visual properties along the generated paths. The proposed approach (i) performs better than existing automated viewpoint computation techniques in terms of speed and precision, (ii) provides a screen-space manipulation tool that is more efficient than classical manipulators and easier to use for beginners, and (iii) enables the creation of complex camera motions such as long takes in a very short time and in a controllable way. As a result, the approach should quickly find its place in a number of applications that require interactive or automated camera control such as 3D modelers, navigation tools or 3D games. ", 
        "id": 2113, 
        "title": "Intuitive and efficient camera control with the toric space."
    }, 
    {
        "abstract": "strain sensors foam liner Figure 1: To enable immersive face-to-face communication in virtual worlds, the facial expressions of a user have to be captured while wearing a virtual reality head-mounted display. Because the face is largely occluded by typical wearable displays, we have designed an HMD that combines ultra-thin strain sensors with a head-mounted RGB-D camera for real-time facial performance capture and animation. Abstract There are currently no solutions for enabling direct face-to-face interaction between virtual reality (VR) users wearing head-mounted displays (HMDs). The main challenge is that the headset obstructs a significant portion of a users face, preventing effective facial capture with traditional techniques. To advance virtual reality as a next-generation communication platform, we develop a novel HMD that enables 3D facial performance-driven animation in real-time. Our wearable system uses ultra-thin flexible electronic materials that are mounted on the foam liner of the headset to measure surface strain signals corresponding to upper face expressions. These strain signals are combined with a head-mounted RGB-D camera to enhance the tracking in the mouth region and to account for inaccurate HMD placement. To map the input signals to a 3D face model, we perform a single-instance offline training session for each person. For reusable and accurate online operation, we propose a short calibration step to readjust the Gaussian mixture distribution of the mapping before each use. The resulting animations are visually on par with cutting-edge depth sensor-driven facial performance capture systems and hence, are suitable for social interactions in virtual worlds.", 
        "id": 2114, 
        "title": "Facial performance sensing head-mounted display."
    }, 
    {
        "abstract": "The usability of hexahedral meshes depends on the degree to which the shape of their elements deviates from a perfect cube; a single concave, or inverted element makes a mesh unusable. While a range of methods exist for discretizing 3D objects with an initial topologically suitable hex mesh, their output meshes frequently contain poorly shaped and even inverted elements, requiring a further quality optimization step. We introduce a novel framework for optimizing hex-mesh quality capable of generating inversion-free high-quality meshes from such poor initial inputs. We recast hex quality improvement as an optimization of the shape of overlapping cones, or unions, of tetrahedra surrounding every directed edge in the hex mesh, and show the two to be equivalent. We then formulate cone shape optimization as a sequence of convex quadratic optimization problems, where hex convexity is encoded via simple linear inequality constraints. As this solution space may be empty, we therefore present an alternate formulation which allows the solver to proceed even when constraints cannot be satisfied exactly. We iteratively improve mesh element quality by solving at each step a set of local, per-cone, convex constrained optimization problems, followed by a global energy minimization step which reconciles these local solutions. This latter method provides no theoretical guarantees on the solution but produces inversion-free, high quality meshes in practice. We demonstrate the robustness of our framework by optimizing numerous poor quality input meshes generated using a variety of initial meshing methods and producing high-quality inversion-free meshes in each case. We further validate our algorithm by comparing it against previous work, and demonstrate a significant improvement in both worst and average element quality.", 
        "id": 2115, 
        "title": "Practical hex-mesh optimization via edge-cone rectification."
    }, 
    {
        "abstract": "The human perception of stylistic similarity transcends structure and function: for instance, a bed and a dresser may share a common style. An algorithmically computed style similarity measure that mimics human perception can benefit a range of computer graphics applications. Previous work in style analysis focused on shapes within the same class, and leveraged structural similarity between these shapes to facilitate analysis. In contrast, we introduce the first structure-transcending style similarity measure and validate it to be well aligned with human perception of stylistic similarity. Our measure is inspired by observations about style similarity in art history literature, which point to the presence of similarly shaped, salient, geometric elements as one of the key indicators of stylistic similarity. We translate these observations into an algorithmic measure by first quantifying the geometric properties that make humans perceive geometric elements as similarly shaped and salient in the context of style, then employing this quantification to detect pairs of matching style related elements on the analyzed models, and finally collating the element-level geometric similarity measurements into an object-level style measure consistent with human perception. To achieve this consistency we employ crowdsourcing to quantify the different components of our measure; we learn the relative perceptual importance of a range of elementary shape distances and other parameters used in our measurement from 50K responses to cross-structure style similarity queries provided by over 2500 participants.We train and validate our method on this dataset, showing it to successfully predict relative style similarity with near 90% accuracy based on 10-fold cross-validation.", 
        "id": 2116, 
        "title": "Elements of style: learning perceptual shape style similarity."
    }, 
    {
        "abstract": "We introduce in this paper an algorithm that generates from an input tolerance volume a surface triangle mesh guaranteed to be within the tolerance, intersection free and topologically correct. A pliant meshing algorithm is used to capture the topology and discover the anisotropy in the input tolerance volume in order to generate a concise output. We first refine a 3D Delaunay triangulation over the tolerance volume while maintaining a piecewise-linear function on this triangulation, until an isosurface of this function matches the topology sought after. We then embed the isosurface into the 3D triangulation via mutual tessellation, and simplify it while preserving the topology. Our approach extends to surfaces with boundaries and to non-manifold surfaces. We demonstrate the versatility and efficacy of our approach on a variety of data sets and tolerance volumes. ", 
        "id": 2117, 
        "title": "Isotopic approximation within a tolerance volume."
    }, 
    {
        "abstract": "We address the problem of modeling and rendering granular materials--such as large structures made of sand, snow, or sugar-- where an aggregate object is composed of many randomly oriented, but discernible grains. These materials pose a particular challenge as the complex scattering properties of individual grains, and their packing arrangement, can have a dramatic effect on the large-scale appearance of the aggregate object. We propose a multi-scale modeling and rendering framework that adapts to the structure of scattered light at different scales. We rely on path tracing the individual grains only at the finest scale, and--by decoupling individual grains from their arrangement--we develop a modular approach for simulating longer-scale light transport. We model light interactions within and across grains as separate processes and leverage this decomposition to derive parameters for classical radiative transport, including standard volumetric path tracing and a diffusion method that can quickly summarize the large scale transport due to many grain interactions. We require only a one-time precomputation per exemplar grain, which we can then reuse for arbitrary aggregate shapes and a continuum of different packing rates and scales of grains. We demonstrate The work was done while the author was employed at Disney Research. ACM Reference Format Meng, J., Papas, M., Habel, R., Dachsbacher, C., Marschner, S., Gross, M., Jarosz, W. 2015. Multi-Scale Modeling and Rendering of Granular Materials. ACM Trans. Graph. 34, 4, Article 49 (August 2015), 13 pages. DOI = 10.1145/2766949 http://doi.acm.org/10.1145/2766949. Copyright Notice Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGGRAPH `15 Technical Paper, August 09  13, 2015, Los Angeles, CA. Copyright is held by the owner/author(s). Publication rights licensed to ACM. ACM 978-1-4503-3331-3/15/08 ... $15.00. DOI: http://dx.doi.org/10.1145/2766949  our method on scenes containing mixtures of tens of millions of individual, complex, specular grains that would be otherwise infeasible to render with standard techniques. ", 
        "id": 2118, 
        "title": "Multi-scale modeling and rendering of granular materials."
    }, 
    {
        "abstract": "We propose a method for fabricating deformable objects with spatially varying elasticity using 3D printing. Using a single, relatively stiff printer material, our method designs an assembly of smallscale microstructures that have the effect of a softer material at the object scale, with properties depending on the microstructure used in each part of the object. We build on work in the area of metamaterials, using numerical optimization to design tiled microstructures with desired properties, but with the key difference that our method designs families of related structures that can be interpolated to smoothly vary the material properties over a wide range. To create an object with spatially varying elastic properties, we tile the object's interior with microstructures drawn from these families, generating a different microstructure for each cell using an efficient algorithm to select compatible structures for neighboring cells. We show results computed for both 2D and 3D objects, validating several 2D and 3D printed structures using standard material tests as well as demonstrating various example applications. ", 
        "id": 2119, 
        "title": "Microstructures to control elasticity in 3D printing."
    }, 
    {
        "abstract": "This paper introduces OmniAD, a novel data-driven pipeline to model and acquire the aerodynamics of three-dimensional rigid objects. Traditionally, aerodynamics are examined through elaborate wind tunnel experiments or expensive fluid dynamics computations, and are only measured for a small number of discrete wind directions. OmniAD allows the evaluation of aerodynamic forces, such as drag and lift, for any incoming wind direction using a novel representation based on spherical harmonics. Our data-driven technique acquires the aerodynamic properties of an object simply by capturing its falling motion using a single camera. Once model parameters are estimated, OmniAD enables realistic real-time simulation of rigid bodies, such as the tumbling and gliding of leaves, without simulating the surrounding air. In addition, we propose an intuitive user interface based on OmniAD to interactively design three-dimensional kites that actually fly. Various nontraditional kites were designed to demonstrate the physical validity of our model.", 
        "id": 2120, 
        "title": "OmniAD: data-driven omni-directional aerodynamics."
    }, 
    {
        "abstract": "Crafting the behavior of a deformable object is difficultwhether it is a biomechanically accurate character model or a new multimate-rial 3D printable design. Getting it right requires constant iteration, performed either manually or driven by an automated system. Unfortunately, Previous algorithms for accelerating three-dimensional finite element analysis of elastic objects suffer from expensive pre-computation stages that rely on a priori knowledge of the objects geometry and material composition. In this paper we introduce Data-Driven Finite Elements as a solution to this problem. Given a material palette, our method constructs a metamaterial library which is reusable for subsequent simulations, regardless of object geometry and/or material composition. At runtime, we perform fast coarsening of a simulation mesh using a simple table lookup to select the appropriate metamaterial model for the coarsened elements. When the objects material distribution or geometry changes, we do not need to update the metamaterial librarywe simply need to update the metamaterial assignments to the coarsened elements. An important advantage of our approach is that it is applicable to non-linear material models. This is important for designing objects that undergo finite deformation (such as those produced by multimaterial 3D printing). Our method yields speed gains of up to two orders of magnitude while maintaining good accuracy. We demonstrate the effectiveness of the method on both virtual and 3D printed examples in order to show its utility as a tool for deformable object design.", 
        "id": 2121, 
        "title": "Data-driven finite elements for geometry and material design."
    }, 
    {
        "abstract": "We address the problem of allowing casual users to customize parametric models while maintaining their valid state as 3D-printable functional objects. We define Fab Form as any design representation that lends itself to interactive customization by a novice user, while remaining valid and manufacturable. We propose a method to achieve these Fab Form requirements for general parametric designs tagged with a general set of automated validity tests and a small number of parameters exposed to the casual user. Our solution separates Fab Form evaluation into a precomputation stage and a runtime stage. Parts of the geometry and design validity (such as manufacturability) are evaluated and stored in the precomputa-tion stage by adaptively sampling the design space. At runtime the remainder of the evaluation is performed. This allows interactive navigation in the valid regions of the design space using an automatically generated Web user interface (UI). We evaluate our approach by converting several parametric models into corresponding Fab Forms.", 
        "id": 2122, 
        "title": "Fab forms: customizable objects for fabrication with validity and geometry caching."
    }, 
    {
        "abstract": " ", 
        "id": 2123, 
        "title": "MultiFab: a machine vision assisted platform for multi-material 3D printing."
    }, 
    {
        "abstract": "", 
        "id": 2124, 
        "title": "Using Nesterov's Method to Accelerate Multibody Dynamics with Friction and Contact."
    }, 
    {
        "abstract": "We present an interactive simulation framework for authoring surgical procedures of soft tissue manipulation using physics-based simulation to animate the flesh. This interactive authoring tool can be used by clinical educators to craft three-dimensional illustrations of the intricate maneuvers involved in craniofacial repairs, in contrast to two-dimensional sketches and still photographs which are the medium used to describe these procedures in the traditional surgical curriculum. Our virtual environment also allows surgeons-in-training to develop cognitive skills for craniofacial surgery by experimenting with different approaches to reconstructive challenges, adapting stock techniques to flesh regions with nonstandard shape, and reach preliminary predictions about the feasibility of a given repair plan. We use a Cartesian grid-based embedded discretization of nonlinear elasticity to maximize regularity, and expose opportunities for aggressive multithreading and SIMD accelerations. Using a grid-based approach facilitates performance and scalability, but constrains our ability to capture the topology of thin surgical incisions. We circumvent this restriction by hybridizing the grid-based discretization with an explicit hexahedral mesh representation in regions where the embedding mesh necessitates overlap or nonmanifold connectivity. Finally, we detail how the front-end of our system can run on lightweight clients, while the core simulation capability can be hosted on a dedicated server and delivered as a network service.", 
        "id": 2125, 
        "title": "GRIDiron: an interactive authoring and cognitive training foundation for reconstructive plastic surgery procedures."
    }, 
    {
        "abstract": "With the proliferation of acquisition devices, gathering massive volumes of 3D data is now easy. Processing such large masses of pointclouds, however, remains a challenge. This is particularly a problem for raw scans with missing data, noise, and varying sampling density. In this work, we present a simple, scalable, yet powerful data reconstruction algorithm. We focus on reconstruction of man-made scenes as regular arrangements of planes (RAP), thereby selecting both local plane-based approximations along with their global inter-plane relations. We propose a novel selection formulation to directly balance between data fitting and the simplicity of the resulting arrangement of extracted planes. The main technical contribution is a formulation that allows less-dominant orientations to still retain their internal regularity, and not become overwhelmed and regularized by the dominant scene orientations. We evaluate our approach on a variety of complex 2D and 3D pointclouds, and demonstrate the advantages over existing alternative methods.", 
        "id": 2126, 
        "title": "RAPter: rebuilding man-made scenes with regular arrangements of planes."
    }, 
    {
        "abstract": "", 
        "id": 2127, 
        "title": "A Total Variation Approach for Customizing Imagery to Improve Visual Acuity."
    }, 
    {
        "abstract": " ", 
        "id": 2128, 
        "title": "Adaptive rendering with linear predictions."
    }, 
    {
        "abstract": "We propose a new method for both collision detection and collision response geared towards handling complex deformable objects in close contact. Our method does not miss collision events between time steps and solves the challenging problem of untangling automatically and robustly. It is conceptually simple and straight forward to parallelize due to the regularity of the algorithm. The main idea is to tessellate the air between objects once before the simulation and by considering one unilateral constraint per element that prevents its inversion during the simulation. If large relative rotations and translations are present in the simulation, an additional dynamic mesh optimization step is needed to prevent mesh locking. This step is fast in 2D and allows the simulation of arbitrary scenes. Because mesh optimization is expensive in 3D, however, the method is best suited for the subclass of 3D scenarios in which relative motions are limited. This subclass contains two important problems, namely the simulation of multi-layered clothing and tissue on animated characters.", 
        "id": 2129, 
        "title": "Air meshes for robust collision handling."
    }, 
    {
        "abstract": "Given the 2-manifold surface of a 3d object, we propose a novel method for the computation of an offset surface with varying thickness such that the solid volume between the surface and its offset satisfies a set of prescribed constraints and at the same time minimizes a given objective functional. Since the constraints as well as the objective functional can easily be adjusted to specific application requirements, our method provides a flexible and powerful tool for shape optimization. We use manifold harmonics to derive a reduced-order formulation of the optimization problem, which guarantees a smooth offset surface and speeds up the computation independently from the input mesh resolution without affecting the quality of the result. The constrained optimization problem can be solved in a numerically robust manner with commodity solvers. Furthermore, the method allows simultaneously optimizing an inner and an outer offset in order to increase the degrees of freedom. We demonstrate our method in a number of examples where we control the physical mass properties of rigid objects for the purpose of 3d printing.", 
        "id": 2130, 
        "title": "Reduced-order shape optimization using offset surfaces."
    }, 
    {
        "abstract": "We present a technique for synthesizing the effects of skin microstructure deformation by anisotropically convolving a highresolution displacement map to match normal distribution changes in measured skin samples. We use a 10-micron resolution scanning technique to measure several in vivo skin samples as they are stretched and compressed in different directions, quantifying how stretching smooths the skin and compression makes it rougher. We tabulate the resulting surface normal distributions, and show that convolving a neutral skin microstructure displacement map with blurring and sharpening filters can mimic normal distribution changes and microstructure deformations. We implement the spatially-varying displacement map filtering on the GPU to interactively render the effects of dynamic microgeometry on animated faces obtained from high-resolution facial scans. ", 
        "id": 2131, 
        "title": "Skin microstructure deformation with displacement map convolution."
    }, 
    {
        "abstract": "Figure 1: Reproducing a real-world scene on a multi-plane display. Given a focus stack consisting of images of a scene focused at different distances, we use optimization to determine images to show on the presentation planes of the multi-plane display so that the image seen through the display when focusing at different distances matches the corresponding image of the input scene. The presentation planes combine additively in the viewers eye to produce an image with realistic focus cues. Abstract We present a technique for displaying three-dimensional imagery of general scenes with nearly correct focus cues on multi-plane displays. These displays present an additive combination of images at a discrete set of optical distances, allowing the viewer to focus at different distances in the simulated scene. Our proposed technique extends the capabilities of multi-plane displays to general scenes with occlusions and non-Lambertian effects by using a model of defocus in the eye of the viewer. Requiring no explicit knowledge of the scene geometry, our technique uses an optimization algorithm to compute the images to be displayed on the presentation planes so that the retinal images when accommodating to different distances match the corresponding retinal images of the input scene as closely as possible. We demonstrate the utility of the technique using imagery acquired from both synthetic and real-world scenes, and analyze the systems characteristics including bounds on achievable resolution.", 
        "id": 2132, 
        "title": "Optimal presentation of imagery with focus cues on multi-plane displays."
    }, 
    {
        "abstract": "", 
        "id": 2133, 
        "title": "Data-Driven Color Manifolds."
    }, 
    {
        "abstract": " We propose a method of three-dimensional (3D) modeling of volumetric fluid phenomena from sparse multi-view images (e.g., only a single-view input or a pair of front- and side-view inputs). The volume determined from such sparse inputs using previous methods appears blurry and unnatural with novel views; however, our method preserves the appearance of novel viewing angles by transferring the appearance information from input images to novel viewing angles. For appearance information, we use histograms of image intensities and steerable coefficients. We formulate the volume modeling as an energy minimization problem with statistical hard constraints, which is solved using an expectation maximization (EM)-like iterative algorithm. Our algorithm begins with a rough estimate of the initial volume modeled from the input images, followed by an iterative process whereby we first render the images of the current volume with novel viewing angles. Then, we modify the rendered images by transferring the appearance information from the input images, and we thereafter model the improved volume based on the modified images. We iterate these operations until the volume converges. We demonstrate our method successfully provides natural-looking volume sequences of fluids (i.e., fire, smoke, explosions, and a water splash) from sparse multiview videos. To create production-ready fluid animations, we further propose a method of rendering and editing fluids using a commercially available fluid simulator. ", 
        "id": 2134, 
        "title": "Fluid volume modeling from sparse multi-view images by appearance transfer."
    }, 
    {
        "abstract": "Programmable coding of light between a source and a sensor has led to several important results in computational illumination, imaging and display. Little is known, however, about how to utilize energy most effectively, especially for applications in live imaging. In this paper, we derive a novel framework to maximize energy efficiency by homogeneous matrix factorization that respects the physical constraints of many coding mechanisms (DMDs/LCDs, lasers, etc.). We demonstrate energy-efficient imaging using two prototypes based on DMD and laser illumination. For our DMD-based prototype, we use fast local optimization to derive codes that yield brighter images with fewer artifacts in many transport probing tasks. Our second prototype uses a novel combination of a low-power laser projector and a rolling shutter camera. We use this prototype to demonstrate never-seen-before capabilities such as (1) capturing live structured-light video of very bright sceneseven a light bulb that has been turned on; (2) capturing epipolar-only and indirect-only live video with optimal energy efficiency; (3) using a low-power projector to reconstruct 3D objects in challenging conditions such as strong indirect light, strong ambient light, and smoke; and (4) recording live video from a projectorsrather than the cameraspoint of view.", 
        "id": 2135, 
        "title": "Homogeneous codes for energy-efficient illumination and imaging."
    }, 
    {
        "abstract": "We propose a perceptually based method for downscaling images that provides a better apparent depiction of the input image. We formulate image downscaling as an optimization problem where the difference between the input and output images is measured using a widely adopted perceptual image quality metric. The downscaled images retain perceptually important features and details, resulting in an accurate and spatio-temporally consistent representation of the high resolution input. We derive the solution of the optimization problem in closed-form, which leads to a simple, efficient and parallelizable implementation with sums and convolutions. The algorithm has running times similar to linear filtering and is orders of magnitude faster than the state-of-the-art for image downscaling. We validate the effectiveness of the technique with extensive tests on many images, video, and by performing a user study, which indicates a clear preference for the results of the new algorithm. ", 
        "id": 2136, 
        "title": "Perceptually based downscaling of images."
    }, 
    {
        "abstract": "We present a geometric representation of a tetrahedral mesh that is solely based on dihedral angles. We first show that the shape of a tetrahedral mesh is completely defined by its dihedral angles. This proof leads to a set of angular constraints that must be satisfied for an immersion to exist in R3. This formulation lets us easily specify conditions to avoid inverted tetrahedra and multiply-covered vertices, thus leading to locally injective maps. We then present a constrained optimization method that modifies input angles when they do not satisfy constraints. Additionally, we develop a fast spectral reconstruction method to robustly recover positions from dihedral angles. We demonstrate the applicability of our representation with examples of volume parameterization, shape interpolation, mesh optimization, connectivity shapes, and mesh compression. ", 
        "id": 2137, 
        "title": "Dihedral angle-based maps of tetrahedral meshes."
    }, 
    {
        "abstract": "We propose a new approach for automatic surfacing of 3D curve networks, a long standing computer graphics problem which has garnered new attention with the emergence of sketch based modeling systems capable of producing such networks. Our approach is motivated by recent studies suggesting that artist-designed curve networks consist of descriptive curves that convey intrinsic shape properties, and are dominated by representative flow lines designed to convey the principal curvature lines on the surface. Studies indicate that viewers complete the intended surface shape by envisioning a surface whose curvature lines smoothly blend these flow-line curves. Following these observations we design a surfacing framework that automatically aligns the curvature lines of the constructed surface with the representative flow lines and smoothly interpolates these representative flow, or curvature directions while minimizing undesired curvature variation. Starting with an initial triangle mesh of the network, we dynamically adapt the mesh to maximize the agreement between the principal curvature direction field on the surface and a smooth flow field suggested by the representative flow-line curves. Our main technical contribution is a framework for curvature-based surface modeling, that facilitates the creation of surfaces with prescribed curvature characteristics. We validate our method via visual inspection, via comparison to artist created and ground truth surfaces, as well as comparison to prior art, and confirm that our results are well aligned with the computed flow fields and with viewer perception of the input networks.", 
        "id": 2138, 
        "title": "Flow aligned surfacing of curve networks."
    }, 
    {
        "abstract": " The locomotion skills developed for physics-based characters most often target flat terrain. However, much of their potential lies with the creation of dynamic, momentum-based motions across more complex terrains. In this paper, we learn controllers that allow simulated characters to traverse terrains with gaps, steps, and walls using highly dynamic gaits. This is achieved using reinforcement learning, with careful attention given to the action representation, non-parametric approximation of both the value function and the policy; epsilon-greedy exploration; and the learning of a good state distance metric. The methods enable a 21-link planar dog and a 7-link planar biped to navigate challenging sequences of terrain using bounding and running gaits. We evaluate the impact of the key features of our skill learning pipeline on the resulting performance. ", 
        "id": 2139, 
        "title": "Dynamic terrain traversal skills using reinforcement learning."
    }, 
    {
        "abstract": "time number space-time visualization time-slices visualization key vertex 11 key closed edge 3 key open edge 10 key face 2 Legend inbetween vertex 10 inbetween closed edge 3 inbetween open edge 9 inbetween face 1", 
        "id": 2140, 
        "title": "Vector graphics animation with time-varying topology."
    }, 
    {
        "abstract": " We present a framework for designing curl-free tangent vector fields on discrete surfaces. Such vector fields are gradients of locallydefined scalar functions, and this property is beneficial for creating surface parameterizations, since the gradients of the parameterization coordinate functions are then exactly aligned with the designed fields. We introduce a novel definition for discrete curl between unordered sets of vectors (PolyVectors), and devise a curl-eliminating continuous optimization that is independent of the matchings between them. Our algorithm naturally places the singularities required to satisfy the user-provided alignment constraints, and our fields are the gradients of an inversion-free parameterization by design.  ", 
        "id": 2141, 
        "title": "Integrable PolyVector fields."
    }, 
    {
        "abstract": "We propose an interactive quadrangulation method based on a large collection of patterns that are learned from models manually designed by artists. The patterns are distilled into compact quadrangulation rules and stored in a database. At run-time, the user draws strokes to define patches and desired edge flows, and the system queries the database to extract fitting patterns to tessellate the sketches' interiors. The quadrangulation patterns are general and can be applied to tessellate large regions while controlling the positions of the singularities and the edge flow. We demonstrate the effectiveness of our algorithm through a series of live retopology sessions and an informal user study with three professional artists. ", 
        "id": 2142, 
        "title": "Data-driven interactive quadrangulation."
    }, 
    {
        "abstract": "SecondSkin is a sketch-based modeling system focused on the creation of structures comprised of layered, shape interdependent 3D volumes. Our approach is built on three novel insights gleaned from an analysis of representative artist sketches. First, we observe that a closed loop of strokes typically define surface patches that bound volumes in conjunction with underlying surfaces. Second, a significant majority of these strokes map to a small set of curvetypes, that describe the 3D geometric relationship between the stroke and underlying layer geometry. Third, we find that a few simple geometric features allow us to consistently classify 2D strokes to our proposed set of 3D curve-types. Our algorithm thus processes strokes as they are drawn, identifies their curve-type, and interprets them as 3D curves on and around underlying 3D geometry, using other connected 3D curves for context. Curve loops are automatically surfaced and turned into volumes bound to the underlying layer, creating additional curves and surfaces as necessary. Stroke classification by 15 viewers on a suite of ground truth sketches validates our curve-types and classification algorithm. We evaluate SecondSkin via a compelling gallery of layered 3D models that would be tedious to produce using current sketch modelers. ACM Reference Format De Paoli, C., Singh, K. 2015. SecondSkin: Sketch-Based Construction of Layered 3D Models. ACM Trans. Graph. 34, 4, Article 126 (August 2015), 10 pages. DOI = 10.1145/2766948 http://doi.acm.org/10.1145/2766948. Copyright Notice Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGGRAPH `15 Technical Paper, August 09  13, 2015, Los Angeles, CA. Copyright 2015 ACM 978-1-4503-3331-3/15/08 ... $15.00. DOI: http://doi.acm.org/10.1145/2766948  ", 
        "id": 2143, 
        "title": "SecondSkin: sketch-based construction of layered 3D models."
    }, 
    {
        "abstract": "We present Piko, a framework for designing, optimizing, and retargeting implementations of graphics pipelines on multiple architectures. Piko programmers express a graphics pipeline by organizing the computation within each stage into spatial bins and specifying a scheduling preference for these bins. Our compiler, Pikoc, compiles this input into an optimized implementation targeted to a massively-parallel GPU or a multicore CPU. Piko manages work granularity in a programmable and flexible manner, allowing programmers to build load-balanced parallel pipeline implementations, to exploit spatial and producer-consumer locality in a pipeline implementation, and to explore tradeoffs between these considerations. We demonstrate that Piko can implement a wide range of pipelines, including rasterization, Reyes, ray tracing, rasterization/ray tracing hybrid, and deferred rendering. Piko allows us to implement efficient graphics pipelines with relative ease and to quickly explore design alternatives by modifying the spatial binning configurations and scheduling preferences for individual stages, all while delivering real-time performance that is within a factor six of state-of-the-art rendering systems. ", 
        "id": 2144, 
        "title": "Piko: a framework for authoring programmable graphics pipelines."
    }, 
    {
        "abstract": "We present a novel implicit formulation for highly viscous fluids simulated with Smoothed Particle Hydrodynamics SPH. Compared to explicit methods, our formulation is significantly more efficient and handles a larger range of viscosities. Differing from existing implicit formulations, our approach reconstructs the velocity field from a target velocity gradient. This gradient encodes a desired shear-rate damping and preserves the velocity divergence that is introduced by the SPH pressure solver to counteract density deviations. The target gradient ensures that pressure and viscosity computation do not interfere. Therefore, only one pressure projection step is required, which is in contrast to state-of-the-art implicit Eulerian formulations. While our model differs from true viscosity in that vorticity diffusion is not encoded in the target gradient, it nevertheless captures many of the qualitative behaviors of viscous liquids. Our formulation can easily be incorporated into complex scenarios with one- and two-way coupled solids and multiple fluid phases with different densities and viscosities. ", 
        "id": 2145, 
        "title": "An implicit viscosity formulation for SPH fluids."
    }, 
    {
        "abstract": "We present a computational tool for fabrication-oriented design of flexible rod meshes. Given a deformable surface and a set of deformed poses as input, our method automatically computes a printable rod mesh that, once manufactured, closely matches the input poses under the same boundary conditions. The core of our method is formed by an optimization scheme that adjusts the cross-sectional profiles of the rods and their rest centerline in order to best approximate the target deformations. This approach allows us to locally control the bending and stretching resistance of the surface with a single material, yielding high design flexibility and low fabrication cost. ", 
        "id": 2146, 
        "title": "Design and fabrication of flexible rod meshes."
    }, 
    {
        "abstract": "We propose a new spectral analysis of the variance in Monte Carlo integration, expressed in terms of the power spectra of the sampling pattern and the integrand involved. We build our framework in the Euclidean space using Fourier tools and on the sphere using spherical harmonics. We further provide a theoretical background that explains how our spherical framework can be extended to the hemispherical domain. We use our framework to estimate the variance convergence rate of different state-of-the-art sampling patterns in both the Euclidean and spherical domains, as the number of samples increases. Furthermore, we formulate design principles for constructing sampling methods that can be tailored according to available resources. We validate our theoretical framework by performing numerical integration over several integrands sampled using different sampling patterns. ", 
        "id": 2147, 
        "title": "Variance analysis for Monte Carlo integration."
    }, 
    {
        "abstract": "We present a new approach for the reproduction of color images on a metallic substrate that look bright and colorful under specular reflection observation conditions and also look good under nonspecular reflection observation conditions. We fit amounts of both the white ink and the classical cyan, magenta and yellow inks according to a formula optimizing the reproduction of colors simultaneously under specular and non-specular observation conditions. In addition, we can hide patterns such as text or graphical symbols in one viewing mode, specular or non-specular, and reveal them in the other viewing mode. We rely on the tradeoff between amounts of white diffuse ink and amounts of cyan, magenta and yellow inks to control lightness in specular and in non-specular observation conditions. Further effects are grayscale images that alternate from a first image to a second independent image when tilting the print from specular to non-specular reflection observation conditions. Applications comprise art and entertainment, publicity, posters, as well as document security. ", 
        "id": 2148, 
        "title": "Color imaging and pattern hiding on a metallic substrate."
    }, 
    {
        "abstract": "To look human, digital full-body avatars need to have soft-tissue deformations like those of real people. We learn a model of soft-tissue deformations from examples using a high-resolution 4D capture system and a method that accurately registers a template mesh to sequences of 3D scans. Using over 40,000 scans of ten subjects, we learn how softtissue motion causes mesh triangles to deform relative to a base 3D body model. Our Dyna model uses a low-dimensional linear subspace to approximate soft-tissue deformation and relates the subspace coefficients to the changing pose of the body. Dyna uses a second-order auto-regressive model that predicts soft-tissue deformations based on previous deformations, the velocity and acceleration of the body, and the angular velocities and accelerations of the limbs. Dyna also models how deformations vary with a persons body mass index (BMI), producing different deformations for people with different shapes. Dyna realistically represents the dynamics of soft tissue for previously unseen subjects and motions. We provide tools for animators to modify the deformations and apply them to new stylized characters.", 
        "id": 2149, 
        "title": "Dyna: a model of dynamic human shape in motion."
    }, 
    {
        "abstract": " Eye alignment to the optical system is very critical in many modern devices, such as for biometrics, gaze tracking, head mounted displays, and health. We show alignment in the context of the most difficult challenge: retinal imaging. Alignment in retinal imaging, even conducted by a physician, is very challenging due to precise alignment requirements and lack of direct user eye gaze control. Self-imaging of the retina is nearly impossible. We frame this problem as a user-interface (UI) challenge. We can create a better UI by controlling the eye box of a projected cue. Our key concept is to exploit the reciprocity, \"If you see me, I see you\", to develop near eye alignment displays. Two technical aspects are critical: a) tightness of the eye box and (b) the eye box discovery comfort. We demonstrate that previous pupil forming display architectures are not adequate to address alignment in depth. We then analyze two ray-based designs to determine efficacious fixation patterns. These ray based displays and a sequence of user steps allow lateral (x, y) and depth (z) wise alignment to deal with image centering and focus. We show a highly portable prototype and demonstrate the effectiveness through a user study. ", 
        "id": 2150, 
        "title": "eyeSelfie: self directed eye alignment using reciprocal eye box imaging."
    }, 
    {
        "abstract": "Figure 1: Relighting of various scenes using light transport captured by our method from a small number of images. Abstract We present a neural network regression method for relighting real-world scenes from a small number of images. The relighting in this work is formulated as the product of the scenes light transport matrix and new lighting vectors, with the light transport matrix reconstructed from the input images. Based on the observation that there should exist non-linear local coherence in the light transport matrix, our method approximates matrix segments using neural networks that model light transport as a non-linear function of light source position and pixel coordinates. Central to this approach is a proposed neural network design which incorporates various elements that facilitate modeling of light transport from a small image set. In contrast to most image based relighting techniques, this regression-based approach allows input images to be captured under arbitrary illumination conditions, including light sources moved freely by hand. We validate our method with light transport data of real scenes containing complex lighting effects, and demonstrate that fewer input images are required in comparison to related techniques.", 
        "id": 2151, 
        "title": "Image based relighting using neural networks."
    }, 
    {
        "abstract": "", 
        "id": 2152, 
        "title": "Garment Replacement in Monocular Video Sequences."
    }, 
    {
        "abstract": "The tendons of the hand and other biomechanical systems form a complex network of sheaths, pulleys, and branches. By modeling these anatomical structures, we obtain realistic simulations of coordination and dynamics that were previously not possible. First, we introduce Eulerian-on-Lagrangian discretization of tendon strands, with a new selective quasistatic formulation that eliminates unnecessary degrees of freedom in the longitudinal direction, while maintaining the dynamic behavior in transverse directions. This formulation also allows us to take larger time steps. Second, we introduce two control methods for biomechanical systems: first, a general-purpose learning-based approach requiring no previous system knowledge, and a second approach using data extracted from the simulator. We use various examples to compare the performance of these controllers. ", 
        "id": 2153, 
        "title": "Biomechanical simulation and control of hands and tendinous systems."
    }, 
    {
        "abstract": "We propose a method to create a wide range of human body shapes from a single input 3D anatomy template. Our approach is inspired by biological processes responsible for human body growth. In particular, we simulate growth of skeletal muscles and subcutaneous fat using physics-based models which combine growth and elasticity. Together with a tool to edit proportions of the bones, our method allows us to achieve a desired shape of the human body by directly controlling hypertrophy (or atrophy) of every muscle and enlargement of fat tissues. We achieve near-interactive run times by utilizing a special quasi-statics solver (Projective Dynamics) and by crafting a volumetric discretization which results in accurate deformations without an excessive number of degrees of freedom. Our system is intuitive to use and the resulting human body models are ready for simulation using existing physics-based animation methods, because we deform not only the surface, but also the entire volumetric model.", 
        "id": 2154, 
        "title": "Computational bodybuilding: anatomically-based modeling of human bodies."
    }, 
    {
        "abstract": "(a) Multi-shape coordination (b) Boolean operations (c) Advanced context sensitivity (d) Best of several alternatives Figure 1: Our novel grammar language CGA++ enables many advanced procedural modeling scenarios not possible with previous solutions (top; bottom: ours), as exemplified with a grammar for residential suburban buildings comprising a main house, a wing, and a garage, and allowing different configurations of these. (a) With CGA++, modeling decisions can be coordinated across multiple shapes, e.g., to guarantee that overall exactly one door is created. (b) CGA++ enables operations involving multiple shapes, such as Boolean operations. Hence, masses can be merged to avoid overlapping geometries, allowing, e.g., one roof covering the whole building. (c) Generic contextual information can be obtained and acted on in CGA++, whereas previous solutions at best support a narrow set of context sensitivity. While they only allow canceling windows partially occluded, CGA++ additionally enables consistently adjusting all top floor windows. (d) Traditionally, only one alternative can be pursued during one specific derivation. CGA++, however, makes it possible to investigate multiple ones and choose the best of them. On a corner lot, the building grammar may fail if it executes only one option stochastically, and the selected one causes the garage to end up on an irregular footprint. CGA++ allows all options to be explored, robustly evading such failure cases. Abstract We present the novel grammar language CGA++ for the procedural modeling of architecture. While existing grammar-based approaches can produce stunning results, they are limited in what modeling scenarios can be realized. In particular, many context-sensitive tasks are precluded, not least because within the rules specifying how one shape is refined, the necessary knowledge about other shapes is not available. Transcending such limitations, CGA++ significantly raises the expressiveness and offers a generic and integrated solution for many advanced procedural modeling problems. Pivotally, CGA++ grants first-class citizenship to shapes, enabling, within a grammar, directly accessing shapes and shape trees, operations on multiple shapes, rewriting shape (sub)trees, and spawning new trees (e.g., to explore multiple alternatives). The new linguistic device of events allows coordination across multiple shapes, featuring powerful dynamic grouping and synchronization. Various examples illustrate CGA++, demonstrating solutions to previously infeasible modeling challenges.", 
        "id": 2155, 
        "title": "Advanced procedural modeling of architecture."
    }, 
    {
        "abstract": "We introduce an approach for synthesizing time-lapse videos of popular landmarks from large community photo collections. The approach is completely automated and leverages the vast quantity of photos available online. First, we cluster 86 million photos into landmarks and popular viewpoints. Then, we sort the photos by date and warp each photo onto a common viewpoint. Finally, we stabilize the appearance of the sequence to compensate for lighting effects and minimize flicker. Our resulting time-lapses show diverse changes in the worlds most popular sites, like glaciers shrinking, skyscrapers being constructed, and waterfalls changing course.", 
        "id": 2156, 
        "title": "Time-lapse mining from internet photos."
    }, 
    {
        "abstract": "In this paper we present a novel approach to appearance transfer for fluid animations based on flow-guided texture synthesis. In contrast to common practice where pre-captured sets of fluid elements are combined in order to achieve desired motion and look, we bring the possibility of fine-tuning motion properties in advance using CG techniques, and then transferring the desired look from a selected appearance exemplar. We demonstrate that such a practical workflow cannot be simply implemented using current state-of-the-art techniques, analyze what the main obstacles are, and propose a solution to resolve them. In addition, we extend the algorithm to allow for synthesis with rich boundary effects and video exemplars. Finally, we present numerous results that demonstrate the versatility of the proposed approach. ", 
        "id": 2157, 
        "title": "LazyFluids: appearance transfer for fluid animations."
    }, 
    {
        "abstract": "", 
        "id": 2158, 
        "title": "Light Field Reconstruction Using Sparsity in the Continuous Fourier Domain."
    }, 
    {
        "abstract": "", 
        "id": 2159, 
        "title": "Augmented Airbrush for Computer Aided Painting (CAP)."
    }, 
    {
        "abstract": "We present a perceptual control space for simulation of cloth that works with any physical simulator, treating it as a black box. The perceptual control space provides intuitive, art-directable control over the simulation behavior based on a learned mapping from common descriptors for cloth (e.g., flowiness, softness) to the parameters of the simulation. To learn the mapping, we perform a series of perceptual experiments in which the simulation parameters are varied and participants assess the values of the common terms of the cloth on a scale. A multi-dimensional sub-space regression is performed on the results to build a perceptual generative model over the simulator parameters. We evaluate the perceptual control space by demonstrating that the generative model does in fact create simulated clothing that is rated by participants as having the expected properties. We also show that this perceptual control space generalizes to garments and motions not in the original experiments. ", 
        "id": 2160, 
        "title": "A perceptual control space for garment simulation."
    }, 
    {
        "abstract": "", 
        "id": 2161, 
        "title": "Realistic Biomechanical Simulation and Control of Human Swimming."
    }, 
    {
        "abstract": "We present a fully automatic method for generating guaranteed bijective surface parameterizations from triangulated 3D surfaces partitioned into charts. We do so by using a distortion metric that prevents local folds of triangles in the parameterization and a barrier function that prevents intersection of the chart boundaries. In addition, we show how to modify the line search of an interior point method to directly compute the singularities of the distortion metric and barrier functions to maintain a bijective map. By using an isometric metric that is efficient to compute and a spatial hash to accelerate the evaluation and gradient of the barrier function for the boundary, we achieve fast optimization times. Unlike previous methods, we do not require the boundary be constrained by the user to a non-intersecting shape to guarantee a bijection, and the boundary of the parameterization is free to change shape during the optimization to minimize distortion. ", 
        "id": 2162, 
        "title": "Bijective parameterization with free boundaries."
    }, 
    {
        "abstract": "This paper introduces a new class of algorithms for optimization problems involving optimal transportation over geometric domains. Our main contribution is to show that optimal transportation can be made tractable over large domains used in graphics, such as images and triangle meshes, improving performance by orders of magnitude compared to previous work. To this end, we approximate optimal transportation distances using entropic regularization. The resulting objective contains a geodesic distance-based kernel that can be approximated with the heat kernel. This approach leads to simple iterative numerical schemes with linear convergence, in which each iteration only requires Gaussian convolution or the solution of a sparse, pre-factored linear system. We demonstrate the versatility and efficiency of our method on tasks including reflectance interpolation, color transfer, and geometry processing. ", 
        "id": 2163, 
        "title": "Convolutional wasserstein distances: efficient optimal transportation on geometric domains."
    }, 
    {
        "abstract": "We present the first computational method that allows ordinary users to create complex twisty joints and puzzles inspired by the Rubik's Cube mechanism. Given a user-supplied 3D model and a small subset of rotation axes, our method automatically adjusts those rotation axes and adds others to construct a \"nonblocking\" twisty joint in the shape of the 3D model. Our method outputs the shapes of pieces which can be directly 3D printed and assembled into an interlocking puzzle. We develop a grouptheoretic approach to representing a wide class of twisty puzzles by establishing a connection between non-blocking twisty joints and the finite subgroups of the rotation group SO(3). The theoretical foundation enables us to build an efficient system for automatically completing the set of rotation axes and fast collision detection between pieces. We also generalize the Rubik's Cube mechanism to a large family of twisty puzzles. ", 
        "id": 2164, 
        "title": "Computational design of twisty joints and puzzles."
    }, 
    {
        "abstract": "The creation of a painting, in the physical world or digitally, is a process that occurs over time. Later strokes cover earlier strokes, and strokes painted at a similar time are likely to be part of the same object. In the final painting, this temporal history is lost, and a static arrangement of color is all that remains. The rich literature for interacting with image editing history cannot be used. To enable these interactions, we present a set of techniques to decompose a time lapse video of a painting (defined generally to include pencils, markers, etc.) into a sequence of translucent \"stroke\" images. We present translucency-maximizing solutions for recovering physical (Kubelka and Munk layering) or digital (Porter and Duff \"over\" blending operation) paint parameters from before/after image pairs. We also present a pipeline for processing real-world videos of paintings capable of handling long-term occlusions, such as the painter's hand and its shadow, color shifts, and noise. ", 
        "id": 2165, 
        "title": "Decomposing time-lapse paintings into layers."
    }, 
    {
        "abstract": "1University of California, Santa Barbara 2Pixar Animation Studios (a) (b) (c) (d) Figure 1: (a) The simulation runs at 16 FPS, entirely within the subspace, 67 faster than a full space simulation over the entire mesh. (b) Novel wall collisions begin, activating full space tets, shown in red in the inset. The simulation still runs at 2.1 FPS, a 7.7 speedup. (c) Collisions produce a deformation far outside the basis, and 49% of the tets are simulated in full space. The step runs at 0.5 FPS; still a 1.9 speedup. (d) The collisions are removed, and the 67 speedup returns. Abstract Subspace deformable body simulations can be very fast, but can behave unrealistically when behaviors outside the prescribed subspace, such as novel external collisions, are encountered. We address this limitation by presenting a fast, flexible new method that allows full space computation to be activated in the neighborhood of novel events while the rest of the body still computes in a subspace. We achieve this using a method we call subspace condensation, a variant on the classic static condensation precomputation. However, instead of a precomputation, we use the speed of subspace methods to perform the condensation at every frame. This approach allows the full space regions to be specified arbitrarily at runtime, and forms a natural two-way coupling with the subspace regions. While condensation is usually only applicable to linear materials, the speed of our technique enables its application to nonlinear materials as well. We show the effectiveness of our approach by applying it to a variety of articulated character scenarios.", 
        "id": 2166, 
        "title": "Subspace condensation: full space adaptivity for subspace deformations."
    }, 
    {
        "abstract": "We present a unification of the two main approaches to simulate deformable solids, namely elasticity and constraints. Elasticity accurately handles soft to moderately stiff objects, but becomes numerically hard as stiffness increases. Constraints efficiently handle high stiffness, but when integrated in time they can suffer from instabilities in the nullspace directions, generating spurious transverse vibrations when pulling hard on thin inextensible objects or articulated rigid bodies. We show that geometric stiffness, the tensor encoding the change of force directions (as opposed to intensities) in response to a change of positions, is the missing piece between the two approaches. This previously neglected stiffness term is easy to implement and dramatically improves the stability of inextensible objects and articulated chains, without adding artificial bending forces. This allows time step increases up to several orders of magnitude using standard linear solvers. ", 
        "id": 2167, 
        "title": "Stable constrained dynamics."
    }, 
    {
        "abstract": "", 
        "id": 2168, 
        "title": "Real-Time Nonlinear Shape Interpolation."
    }, 
    {
        "abstract": "", 
        "id": 2169, 
        "title": "Layered Light Field Reconstruction for Defocus Blur."
    }, 
    {
        "abstract": "We establish a framework to design triangular and circular polygonal meshes by using face-based compatible Mobius transformations. Embracing the viewpoint of surfaces from circles, we characterize discrete conformality for such meshes, in which the invariants are circles, cross-ratios, and mutual intersection angles. Such transformations are important in practice for editing meshes without distortions or loss of details. In addition, they are of substantial theoretical interest in discrete differential geometry. Our framework allows for handle-based deformations, and interpolation between given meshes with controlled conformal error. ", 
        "id": 2170, 
        "title": "Conformal mesh deformations with M\u00f6bius transformations."
    }, 
    {
        "abstract": "", 
        "id": 2171, 
        "title": "Complex Luminaires: Illumination and Appearance Rendering."
    }, 
    {
        "abstract": "", 
        "id": 2172, 
        "title": "LOD Generation for Urban Scenes."
    }, 
    {
        "abstract": "We present a data-driven method for deformation capture and modeling of general soft objects. We adopt an iterative framework that consists of one component for physics-based deformation tracking and another for spacetime optimization of deformation parameters. Low cost depth sensors are used for the deformation capture, and we do not require any force-displacement measurements, thus making the data capture a cheap and convenient process. We augment a state-of-the-art probabilistic tracking method to robustly handle noise, occlusions, fast movements and large deformations. The spacetime optimization aims to match the simulated trajectories with the tracked ones. The optimized deformation model is then used to boost the accuracy of the tracking results, which can in turn improve the deformation parameter estimation itself in later iterations. Numerical experiments demonstrate that the tracking and parameter optimization components complement each other nicely. Our spacetime optimization of the deformation model includes not only the material elasticity parameters and dynamic damping coefficients, but also the reference shape which can differ significantly from the static shape for soft objects. The resulting optimization problem is highly nonlinear in high dimensions, and challenging to solve with previous methods. We propose a novel splitting algorithm that alternates between reference shape optimization and deformation parameter estimation, and thus enables tailoring the optimization of each subproblem more efficiently and robustly. email: {wangbin, wulh}@siat.ac.cn email: kkyin@comp.nus.edu.sg email: {ascher, libinliu}@cs.ubc.ca Corresponding author: Hui Huang (hhzhiyan@gmail.com) ACM Reference Format Wang, B., Wu, L., Yin, K., Ascher, U., Liu, L., Huang, H. 2015. Deformation Capture and Modeling of Soft Objects. ACM Trans. Graph. 34, 4, Article 94 (August 2015), 12 pages. DOI = 10.1145/2766911 http://doi.acm.org/10.1145/2766911. Copyright Notice Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGGRAPH `15 Technical Paper, August 09  13, 2015, Los Angeles, CA. Copyright 2015 ACM 978-1-4503-3331-3/15/08 ... $15.00. DOI: http://doi.acm.org/10.1145/2766911  Our system enables realistic motion reconstruction as well as synthesis of virtual soft objects in response to user stimulation. Validation experiments show that our method not only is accurate, but also compares favorably to existing techniques. We also showcase the ability of our system with high quality animations generated from optimized deformation parameters for a variety of soft objects, such as live plants and fabricated models. ", 
        "id": 2173, 
        "title": "Deformation capture and modeling of soft objects."
    }, 
    {
        "abstract": " Li-Yi Wei    Chia-Kai Liang  Lytro Inc.  Graham Myhre Dragoniac  Colvin Pitts  Kurt Akeley  Univ. Hong Kong  regular  noise  Conventional camera designs usually shun sample irregularities and lens aberrations. We demonstrate that such irregularities and aberrations, when properly applied, can improve the quality and usability of light field cameras. Examples include spherical aberrations for the mainlens, and misaligned sampling patterns for the microlens and photosensor elements. These observations are a natural consequence of a key difference between conventional and light field cameras: optimizing for a single captured 2D image versus a range of reprojected 2D images from a captured 4D light field. We propose designs in mainlens aberrations and microlens/photosensor sample patterns, and evaluate them through simulated measurements and captured results with our hardware prototype.  aberration misalign  ", 
        "id": 2174, 
        "title": "Improving light field camera sample design with irregularity and aberration."
    }, 
    {
        "abstract": "We present a method to learn and propagate shape placements in 2D polygonal scenes from a few examples provided by a user. The placement of a shape is modeled as an oriented bounding box. Simple geometric relationships between this bounding box and nearby scene polygons define a feature set for the placement. The feature sets of all example placements are then used to learn a probabilistic model over all possible placements and scenes. With this model, we can generate a new set of placements with similar geometric relationships in any given scene. We introduce extensions that enable propagation and generation of shapes in 3D scenes, as well as the application of a learned modeling session to large scenes without additional user interaction. These concepts allow us to generate complex scenes with thousands of objects with relatively little user interaction. *paul@cg.tuwien.ac.at sjeschke@ist.ac.at wimmer@cg.tuwien.ac.at", 
        "id": 2175, 
        "title": "Learning shape placements by example."
    }, 
    {
        "abstract": "This paper presents a novel solution for realtime generation of stylistic human motion that automatically transforms unlabeled, heterogeneous motion data into new styles. The key idea of our approach is an online learning algorithm that automatically constructs a series of local mixtures of autoregressive models (MAR) to capture the complex relationships between styles of motion. We construct local MAR models on the fly by searching for the closest examples of each input pose in the database. Once the model parameters are estimated from the training data, the model adapts the current pose with simple linear transformations. In addition, we introduce an efficient local regression model to predict the timings of synthesized poses in the output style. We demonstrate the power of our approach by transferring stylistic human motion for a wide variety of actions, including walking, running, punching, kicking, jumping and transitions between those behaviors. Our method achieves superior performance in a comparison against alternative methods. We have also performed experiments to evaluate the generalization ability of our data-driven model as well as the key components of our system. I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realismanimation;", 
        "id": 2176, 
        "title": "Realtime style transfer for unlabeled heterogeneous human motion."
    }, 
    {
        "abstract": "", 
        "id": 2177, 
        "title": "Interactive Material Design Using Model Reduction."
    }, 
    {
        "abstract": "The Finite Element Method is widely used for solid deformable object simulation in film, computer games, virtual reality and medicine. Previous applications of nonlinear solid elasticity employed materials from a few standard families such as linear corotational, nonlinear St.Venant-Kirchhoff, Neo-Hookean, Ogden or Mooney-Rivlin materials. However, the spaces of all nonlinear isotropic and anisotropic materials are infinite-dimensional and much broader than these standard materials. In this paper, we demonstrate how to intuitively explore the space of isotropic and anisotropic nonlinear materials, for design of animations in computer graphics and related fields. In order to do so, we first formulate the internal elastic forces and tangent stiffness matrices in the space of the principal stretches of the material. We then demonstrate how to design new isotropic materials by editing a single stress-strain curve, using a spline interface. Similarly, anisotropic (orthotropic) materials can be designed by editing three curves, one ACM Reference Format Xu, H., Sin, F., Zhu, Y., Barbic, J. 2015. Nonlinear Material Design Using Principal Stretches. ACM Trans. Graph. 34, 4, Article 75 (August 2015), 11 pages. DOI = 10.1145/2766917 http://doi.acm.org/10.1145/2766917. Copyright Notice Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGGRAPH `15 Technical Paper, August 09  13, 2015, Los Angeles, CA. Copyright 2015 ACM 978-1-4503-3331-3/15/08 ... $15.00. DOI: http://doi.acm.org/10.1145/2766917  for each material direction. We demonstrate that modifying these curves using our proposed interface has an intuitive, visual, effect on the simulation. Our materials accelerate simulation design and enable visual effects that are difficult or impossible to achieve with standard nonlinear materials. ", 
        "id": 2178, 
        "title": "Nonlinear material design using principal stretches."
    }, 
    {
        "abstract": " ", 
        "id": 2179, 
        "title": "Semantic shape editing using deformation handles."
    }, 
    {
        "abstract": " Table 1: Algorithm abbreviations used through out this paper.  Most visual effects fluid solvers use a time-splitting approach where velocity is first advected in the flow, then projected to be incompressible with pressure. Even if a highly accurate advection scheme is used, the self-advection step typically transfers some kinetic energy from divergence-free modes into divergent modes, which are then projected out by pressure, losing energy noticeably for large time steps. Instead of taking smaller time steps or using significantly more complex time integration, we propose a new scheme called IVOCK (Integrated Vorticity of Convective Kinematics) which cheaply captures much of what is lost in self-advection by identifying it as a violation of the vorticity equation. We measure vorticity on the grid before and after advection, taking into account vortex stretching, and use a cheap multigrid V-cycle approximation to a vector potential whose curl will correct the vorticity error. IVOCK works independently of the advection scheme (we present examples with various semi-Lagrangian methods and FLIP), works independently of how boundary conditions are applied (it just corrects error in advection, leaving pressure etc. to take care of boundaries and other forces), and other solver parameters (we provide smoke, fire, and water examples). For 10  25% extra computation time per step much larger steps can be used, while producing detailed vorticial structures and convincing turbulence that are lost without correction. ", 
        "id": 2180, 
        "title": "Restoring the missing vorticity in advection-projection fluid solvers."
    }, 
    {
        "abstract": " Hydrographic printing is a well-known technique in industry for transferring color inks on a thin film to the surface of a manufactured 3D object. It enables high-quality coloring of object surfaces and works with a wide range of materials, but suffers from the inability to accurately register color texture to complex surface geometries. Thus, it is hardly usable by ordinary users with customized shapes and textures. We present computational hydrographic printing, a new method that inherits the versatility of traditional hydrographic printing, while also enabling precise alignment of surface textures to possibly complex 3D surfaces. In particular, we propose the first computational model for simulating hydrographic printing process. This simulation enables us to compute a color image to feed into our hydrographic system for precise texture registration. We then build a physical hydrographic system upon off-the-shelf hardware, integrating virtual simulation, object calibration and controlled immersion. To overcome the difficulty of handling complex surfaces, we further extend our method to enable multiple immersions, each with a different object orientation, so the combined colors of individual immersions form a desired texture on the object surface. We validate the accuracy of our computational model through physical experiments, and demonstrate the efficacy and robustness of our system using a variety of objects with complex surface textures. ", 
        "id": 2181, 
        "title": "Computational hydrographic printing."
    }, 
    {
        "abstract": " We present a new brittle fracture simulation method based on a boundary integral formulation of elasticity and recent explicit surface mesh evolution algorithms. Unlike prior physically-based simulations in graphics, this avoids the need for volumetric sampling and calculations, which aren't reflected in the rendered output. We represent each quasi-rigid body by a closed triangle mesh of its boundary, on which we solve quasi-static linear elasticity via boundary integrals in response to boundary conditions and loads such as impact forces and gravity. A fracture condition based on maximum tensile stress is subsequently evaluated at mesh vertices, while crack initiation and propagation are formulated as an interface tracking procedure in material space. Existing explicit mesh tracking methods are modified to support evolving cracks directly in the triangle mesh representation, giving highly detailed fractures with sharp features, independent of any volumetric sampling (unlike tetrahedral mesh or level set approaches); the triangle mesh representation also allows simple integration into rigid body engines. We also give details on our well-conditioned integral equation treatment solved with a kernel-independent Fast Multipole Method for linear time summation. Various brittle fracture scenarios demonstrate the efficacy and robustness of our new method.  ", 
        "id": 2182, 
        "title": "Simulating rigid body fracture with surface meshes."
    }, 
    {
        "abstract": "We present a novel method to simulate codimensional nonNewtonian fluids on simplicial complexes. Our method extends previous work for codimensional incompressible flow to various types of non-Newtonian fluids including both shear thinning and thickening, Bingham plastics, and elastoplastics. We propose a novel time integration scheme for semi-implicitly treating elasticity, which when combined with a semi-implicit method for variable viscosity alleviates the need for small time steps. Furthermore, we propose an improved treatment of viscosity on the rims of thin fluid sheets that allows us to capture their elusive, visually appealing twisting motion. In order to simulate complex phenomena such as the mixing of colored paint, we adopt a multiple level set framework and propose a discretization on simplicial complexes that facilitates the tracking of material interfaces across codimensions. We demonstrate the efficacy of our approach by simulating a wide variety of non-Newtonian fluid phenomena exhibiting various codimensional features. ", 
        "id": 2183, 
        "title": "Codimensional non-Newtonian fluids."
    }, 
    {
        "abstract": "We present a novel method to obtain fine-scale detail in 3D reconstructions generated with low-budget RGB-D cameras or other commodity scanning devices. As the depth data of these sensors is noisy, truncated signed distance fields are typically used to regularize out the noise, which unfortunately leads to over-smoothed results. In our approach, we leverage RGB data to refine these reconstructions through shading cues, as color input is typically of much higher resolution than the depth data. As a result, we obtain reconstructions with high geometric detail, far beyond the depth resolution of the camera itself. Our core contribution is shading-based refinement directly on the implicit surface representation, which is generated from globally-aligned RGB-D images. We formulate the inverse shading problem on the volumetric distance field, and present a novel objective function which jointly optimizes for fine-scale surface geometry and spatially-varying surface reflectance. In order to enable the efficient reconstruction of sub-millimeter detail, we store and process our surface using a sparse voxel hashing scheme which we augment by introducing a grid hierarchy. A tailored GPU-based Gauss-Newton solver enables us to refine large shape models to previously unseen resolution within only a few seconds.", 
        "id": 2184, 
        "title": "Shading-based refinement on volumetric signed distance functions."
    }, 
    {
        "abstract": "We introduce elastic textures: a set of parametric, tileable, printable, cubic patterns achieving a broad range of isotropic elastic material properties: the softest pattern is over a thousand times softer than the stiffest, and the Poissons ratios range from below zero to nearly 0.5. Using a combinatorial search over topologies followed by shape optimization, we explore a wide space of truss-like, symmetric 3D patterns to obtain a small family. This pattern family can be printed without internal support structure on a single-material 3D printer and can be used to fabricate objects with prescribed mechanical behavior. The family can be extended easily to create anisotropic patterns with target orthotropic properties. We demonstrate that our elastic textures are able to achieve a user-supplied varying material property distribution. We also present a material optimization algorithm to choose material properties at each point within an object to best fit a target deformation under a prescribed scenario. We show that, by fabricating these spatially varying materials with elastic textures, the desired behavior is achieved.", 
        "id": 2185, 
        "title": "Elastic textures for additive fabrication."
    }, 
    {
        "abstract": " Meshes with T-joints (T-meshes) and related high-order surfaces have many advantages in situations where flexible local refinement is needed. At the same time, designing subdivision rules and bases for T-meshes is much more difficult, and fewer options are available. For common geometric modeling tasks it is desirable to retain the simplicity and flexibility of commonly used subdivision surfaces, and extend them to handle T-meshes. We propose a subdivision scheme extending Catmull-Clark and NURSS to a special class of quad T-meshes, dyadic T-meshes, which have no more than one T-joint per edge. Our scheme is based on a factorization with the same structure as Catmull-Clark subdivision. On regular T-meshes it is a refinement scheme for a subset of standard T-splines. While we use more variations of subdivision masks compared to Catmull-Clark and NURSS, the minimal size of the stencil is maintained, and all variations in formulas are due to simple changes in coefficients.  ", 
        "id": 2186, 
        "title": "Dyadic T-mesh subdivision."
    }, 
    {
        "abstract": "In this work we detail the first algorithm that provides topological control during surface reconstruction from an input set of planar cross-sections. Our work has broad application in a number of fields including surface modeling and biomedical image analysis, where surfaces of known topology must be recovered. Given curves on arbitrarily oriented cross-sections, our method produces a manifold interpolating surface that exactly matches a user-specified genus. The key insight behind our approach is to formulate the topological search as a divide-and-conquer optimization process which scores local sets of topologies and combines them to satisfy the global topology constraint. We further extend our method to allow image data to guide the topological search, achieving even better results than relying on the curves alone. By simultaneously satisfying both geometric and topological constraints, we are able to produce accurate reconstructions with fewer input cross-sections, hence reducing the manual time needed to extract the desired shape.", 
        "id": 2187, 
        "title": "Topology-constrained surface reconstruction from cross-sections."
    }
]